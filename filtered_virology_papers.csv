PMID,Title,Abstract,is_relevant,method_type,method_name
39367648,An initial game-theoretic assessment of enhanced tissue preparation and imaging protocols for improved deep learning inference of spatial transcriptomics from tissue morphology,"The application of deep learning to spatial transcriptomics (ST) can reveal relationships between gene expression and tissue architecture. Prior work has demonstrated that inferring gene expression from tissue histomorphology can discern these spatial molecular markers to enable population scale studies, reducing the fiscal barriers associated with large-scale spatial profiling. However, while most improvements in algorithmic performance have focused on improving model architectures, little is known about how the quality of tissue preparation and imaging can affect deep learning model training for spatial inference from morphology and its potential for widespread clinical adoption. Prior studies for ST inference from histology typically utilize manually stained frozen sections with imaging on non-clinical grade scanners. Training such models on ST cohorts is also costly. We hypothesize that adopting tissue processing and imaging practices that mirror standards for clinical implementation (permanent sections, automated tissue staining, and clinical grade scanning) can significantly improve model performance. An enhanced specimen processing and imaging protocol was developed for deep learning-based ST inference from morphology. This protocol featured the Visium CytAssist assay to permit automated hematoxylin and eosin staining (e.g. Leica Bond), 40×-resolution imaging, and joining of multiple patients' tissue sections per capture area prior to ST profiling. Using a cohort of 13 pathologic T Stage-III stage colorectal cancer patients, we compared the performance of models trained on slide prepared using enhanced versus traditional (i.e. manual staining and low-resolution imaging) protocols. Leveraging Inceptionv3 neural networks, we predicted gene expression across serial, histologically-matched tissue sections using whole slide images (WSI) from both protocols. The data Shapley was used to quantify and compare marginal performance gains on a patient-by-patient basis attributed to using the enhanced protocol versus the actual costs of spatial profiling. Findings indicate that training and validating on WSI acquired through the enhanced protocol as opposed to the traditional method resulted in improved performance at lower fiscal cost. In the realm of ST, the enhancement of deep learning architectures frequently captures the spotlight; however, the significance of specimen processing and imaging is often understated. This research, informed through a game-theoretic lens, underscores the substantial impact that specimen preparation/imaging can have on spatial transcriptomic inference from morphology. It is essential to integrate such optimized processing protocols to facilitate the identification of prognostic markers at a larger scale.",True,other,convolutional neural network
39181806,Cross-modal Transfer Learning Based on an Improved CycleGAN Model for Accurate Kidney Segmentation in Ultrasound Images,"OBJECTIVE: Deep-learning algorithms have been widely applied in the field of automatic kidney ultrasound (US) image segmentation. However, obtaining a large number of accurate kidney labels clinically is very difficult and time-consuming. To solve this problem, we have proposed an efficient cross-modal transfer learning method to improve the performance of the segmentation network on a limited labeled kidney US dataset.
METHODS: We aim to implement an improved image-to-image translation network called Seg-CycleGAN to generate accurate annotated kidney US data from labeled abdomen computed tomography images. The Seg-CycleGAN framework primarily consists of two structures: (i) a standard CycleGAN network to visually simulate kidney US from a publicly available labeled abdomen computed tomography dataset; (ii) and a segmentation network to ensure accurate kidney anatomical structures in US images. Based on the large number of simulated kidney US images and small number of real annotated kidney US images, we then aimed to employ a fine-tuning strategy to obtain better segmentation results.
RESULTS: To validate the effectiveness of the proposed method, we tested this method on both normal and abnormal kidney US images. The experimental results showed that the proposed method achieved a segmentation accuracy of 0.8548 in dice similarity coefficient on all testing datasets and 0.7622 on the abnormal testing dataset.
CONCLUSIONS: Compared with existing data augmentation and transfer learning methods, the proposed method improved the accuracy and generalization of the kidney US image segmentation network on a limited number of training datasets. It therefore has the potential to significantly reduce annotation costs in clinical settings.",True,other,convolutional neural network
39056477,"DeepComBat: A statistically motivated, hyperparameter-robust, deep learning approach to harmonization of neuroimaging data","Neuroimaging data acquired using multiple scanners or protocols are increasingly available. However, such data exhibit technical artifacts across batches which introduce confounding and decrease reproducibility. This is especially true when multi-batch data are analyzed using complex downstream models which are more likely to pick up on and implicitly incorporate batch-related information. Previously proposed image harmonization methods have sought to remove these batch effects; however, batch effects remain detectable in the data after applying these methods. We present DeepComBat, a deep learning harmonization method based on a conditional variational autoencoder and the ComBat method. DeepComBat combines the strengths of statistical and deep learning methods in order to account for the multivariate relationships between features while simultaneously relaxing strong assumptions made by previous deep learning harmonization methods. As a result, DeepComBat can perform multivariate harmonization while preserving data structure and avoiding the introduction of synthetic artifacts. We apply this method to cortical thickness measurements from a cognitive-aging cohort and show DeepComBat qualitatively and quantitatively outperforms existing methods in removing batch effects while preserving biological heterogeneity. Additionally, DeepComBat provides a new perspective for statistically motivated deep learning harmonization methods.",True,other,convolutional neural network
39013794,Deep Learning - Methods to Amplify Epidemiological Data Collection and Analyses,"Deep learning is a subfield of artificial intelligence and machine learning based mostly on neural networks and often combined with attention algorithms that has been used to detect and identify objects in text, audio, images, and video. Serghiou and Rough (Am J Epidemiol. 0000;000(00):0000-0000) present a primer for epidemiologists on deep learning models. These models provide substantial opportunities for epidemiologists to expand and amplify their research in both data collection and analyses by increasing the geographic reach of studies, including more research subjects, and working with large or high dimensional data. The tools for implementing deep learning methods are not quite yet as straightforward or ubiquitous for epidemiologists as traditional regression methods found in standard statistical software, but there are exciting opportunities for interdisciplinary collaboration with deep learning experts, just as epidemiologists have with statisticians, healthcare providers, urban planners, and other professionals. Despite the novelty of these methods, epidemiological principles of assessing bias, study design, interpretation and others still apply when implementing deep learning methods or assessing the findings of studies that have used them.",True,other,convolutional neural network
38959721,Uncertainty-aware multiple-instance learning for reliable classification: Application to optical coherence tomography,"Deep learning classification models for medical image analysis often perform well on data from scanners that were used to acquire the training data. However, when these models are applied to data from different vendors, their performance tends to drop substantially. Artifacts that only occur within scans from specific scanners are major causes of this poor generalizability. We aimed to enhance the reliability of deep learning classification models using a novel method called Uncertainty-Based Instance eXclusion (UBIX). UBIX is an inference-time module that can be employed in multiple-instance learning (MIL) settings. MIL is a paradigm in which instances (generally crops or slices) of a bag (generally an image) contribute towards a bag-level output. Instead of assuming equal contribution of all instances to the bag-level output, UBIX detects instances corrupted due to local artifacts on-the-fly using uncertainty estimation, reducing or fully ignoring their contributions before MIL pooling. In our experiments, instances are 2D slices and bags are volumetric images, but alternative definitions are also possible. Although UBIX is generally applicable to diverse classification tasks, we focused on the staging of age-related macular degeneration in optical coherence tomography. Our models were trained on data from a single scanner and tested on external datasets from different vendors, which included vendor-specific artifacts. UBIX showed reliable behavior, with a slight decrease in performance (a decrease of the quadratic weighted kappa (κ<sub>w</sub>) from 0.861 to 0.708), when applied to images from different vendors containing artifacts; while a state-of-the-art 3D neural network without UBIX suffered from a significant detriment of performance (κ<sub>w</sub> from 0.852 to 0.084) on the same test set. We showed that instances with unseen artifacts can be identified with OOD detection. UBIX can reduce their contribution to the bag-level predictions, improving reliability without retraining on new data. This potentially increases the applicability of artificial intelligence models to data from other scanners than the ones for which they were developed. The source code for UBIX, including trained model weights, is publicly available through https://github.com/qurAI-amsterdam/ubix-for-reliable-classification.",True,other,LSTM
38922025,Automated Nuclear Morphometry: A Deep Learning Approach for Prognostication in Canine Pulmonary Carcinoma to Enhance Reproducibility,"The integration of deep learning-based tools into diagnostic workflows is increasingly prevalent due to their efficiency and reproducibility in various settings. We investigated the utility of automated nuclear morphometry for assessing nuclear pleomorphism (NP), a criterion of malignancy in the current grading system in canine pulmonary carcinoma (cPC), and its prognostic implications. We developed a deep learning-based algorithm for evaluating NP (variation in size, i.e., anisokaryosis and/or shape) using a segmentation model. Its performance was evaluated on 46 cPC cases with comprehensive follow-up data regarding its accuracy in nuclear segmentation and its prognostic ability. Its assessment of NP was compared to manual morphometry and established prognostic tests (pathologists' NP estimates (n = 11), mitotic count, histological grading, and TNM-stage). The standard deviation (SD) of the nuclear area, indicative of anisokaryosis, exhibited good discriminatory ability for tumor-specific survival, with an area under the curve (AUC) of 0.80 and a hazard ratio (HR) of 3.38. The algorithm achieved values comparable to manual morphometry. In contrast, the pathologists' estimates of anisokaryosis resulted in HR values ranging from 0.86 to 34.8, with slight inter-observer reproducibility (k = 0.204). Other conventional tests had no significant prognostic value in our study cohort. Fully automated morphometry promises a time-efficient and reproducible assessment of NP with a high prognostic value. Further refinement of the algorithm, particularly to address undersegmentation, and application to a larger study population are required.",True,other,Not specified
38885231,Classification of white blood cells (leucocytes) from blood smear imagery using machine and deep learning models: A global scoping review,"Machine learning (ML) and deep learning (DL) models are being increasingly employed for medical imagery analyses, with both approaches used to enhance the accuracy of classification/prediction in the diagnoses of various cancers, tumors and bloodborne diseases. To date however, no review of these techniques and their application(s) within the domain of white blood cell (WBC) classification in blood smear images has been undertaken, representing a notable knowledge gap with respect to model selection and comparison. Accordingly, the current study sought to comprehensively identify, explore and contrast ML and DL methods for classifying WBCs. Following development and implementation of a formalized review protocol, a cohort of 136 primary studies published between January 2006 and May 2023 were identified from the global literature, with the most widely used techniques and best-performing WBC classification methods subsequently ascertained. Studies derived from 26 countries, with highest numbers from high-income countries including the United States (n = 32) and The Netherlands (n = 26). While WBC classification was originally rooted in conventional ML, there has been a notable shift toward the use of DL, and particularly convolutional neural networks (CNN), with 54.4% of identified studies (n = 74) including the use of CNNs, and particularly in concurrence with larger datasets and bespoke features e.g., parallel data pre-processing, feature selection, and extraction. While some conventional ML models achieved up to 99% accuracy, accuracy was shown to decrease in concurrence with decreasing dataset size. Deep learning models exhibited improved performance for more extensive datasets and exhibited higher levels of accuracy in concurrence with increasingly large datasets. Availability of appropriate datasets remains a primary challenge, potentially resolvable using data augmentation techniques. Moreover, medical training of computer science researchers is recommended to improve current understanding of leucocyte structure and subsequent selection of appropriate classification models. Likewise, it is critical that future health professionals be made aware of the power, efficacy, precision and applicability of computer science, soft computing and artificial intelligence contributions to medicine, and particularly in areas like medical imaging.",True,other,Not specified
38720370,Deep learning imaging phenotype can classify metabolic syndrome and is predictive of cardiometabolic disorders,"BACKGROUND: Cardiometabolic disorders pose significant health risks globally. Metabolic syndrome, characterized by a cluster of potentially reversible metabolic abnormalities, is a known risk factor for these disorders. Early detection and intervention for individuals with metabolic abnormalities can help mitigate the risk of developing more serious cardiometabolic conditions. This study aimed to develop an image-derived phenotype (IDP) for metabolic abnormality from unenhanced abdominal computed tomography (CT) scans using deep learning. We used this IDP to classify individuals with metabolic syndrome and predict future occurrence of cardiometabolic disorders.
METHODS: A multi-stage deep learning approach was used to extract the IDP from the liver region of unenhanced abdominal CT scans. In a cohort of over 2,000 individuals the IDP was used to classify individuals with metabolic syndrome. In a subset of over 1,300 individuals, the IDP was used to predict future occurrence of hypertension, type II diabetes, and fatty liver disease.
RESULTS: For metabolic syndrome (MetS) classification, we compared the performance of the proposed IDP to liver attenuation and visceral adipose tissue area (VAT). The proposed IDP showed the strongest performance (AUC 0.82) compared to attenuation (AUC 0.70) and VAT (AUC 0.80). For disease prediction, we compared the performance of the IDP to baseline MetS diagnosis. The models including the IDP outperformed MetS for type II diabetes (AUCs 0.91 and 0.90) and fatty liver disease (AUCs 0.67 and 0.62) prediction and performed comparably for hypertension prediction (AUCs of 0.77).
CONCLUSIONS: This study demonstrated the superior performance of a deep learning IDP compared to traditional radiomic features to classify individuals with metabolic syndrome. Additionally, the IDP outperformed the clinical definition of metabolic syndrome in predicting future morbidities. Our findings underscore the utility of data-driven imaging phenotypes as valuable tools in the assessment and management of metabolic syndrome and cardiometabolic disorders.",True,both,Not specified
38454859,The scope of artificial intelligence in retinopathy of prematurity (ROP) management,"Artificial Intelligence (AI) is a revolutionary technology that has the potential to develop into a widely implemented system that could reduce the dependence on qualified professionals/experts for screening the large at-risk population, especially in the Indian scenario. Deep learning involves learning without being explicitly told what to focus on and utilizes several layers of artificial neural networks (ANNs) to create a robust algorithm that is capable of high-complexity tasks. Convolutional neural networks (CNNs) are a subset of ANNs that are particularly useful for image processing as well as cognitive tasks. Training of these algorithms involves inputting raw human-labeled data, which are then processed through the algorithm's multiple layers and allow CNN to develop their own learning of image features. AI systems must be validated using different population datasets since the performance of the AI system would vary according to the population. Indian datasets have been used in AI-based risk model that could predict whether an infant would develop treatment-requiring retinopathy of prematurity (ROP). AI also served as an epidemiological tool by objectively showing that a higher ROP severity was in Neonatal intensive care units (NICUs) that did not have the resources to monitor and titrate oxygen. There are rising concerns about the medicolegal aspect of AI implementation as well as discussion on the possibilities of catastrophic life-threatening diseases like retinoblastoma and lipemia retinalis being missed by AI. Computer-based systems have the advantage over humans in not being susceptible to biases or fatigue. This is especially relevant in a country like India with an increased rate of ROP and a preexisting strained doctor-to-preterm child ratio. Many AI algorithms can perform in a way comparable to or exceeding human experts, and this opens possibilities for future large-scale prospective studies.",True,other,convolutional neural network
38409878,Automated curation of large-scale cancer histopathology image datasets using deep learning,"BACKGROUND: Artificial intelligence (AI) has numerous applications in pathology, supporting diagnosis and prognostication in cancer. However, most AI models are trained on highly selected data, typically one tissue slide per patient. In reality, especially for large surgical resection specimens, dozens of slides can be available for each patient. Manually sorting and labelling whole-slide images (WSIs) is a very time-consuming process, hindering the direct application of AI on the collected tissue samples from large cohorts. In this study we addressed this issue by developing a deep-learning (DL)-based method for automatic curation of large pathology datasets with several slides per patient.
METHODS: We collected multiple large multicentric datasets of colorectal cancer histopathological slides from the United Kingdom (FOXTROT, N = 21,384 slides; CR07, N = 7985 slides) and Germany (DACHS, N = 3606 slides). These datasets contained multiple types of tissue slides, including bowel resection specimens, endoscopic biopsies, lymph node resections, immunohistochemistry-stained slides, and tissue microarrays. We developed, trained, and tested a deep convolutional neural network model to predict the type of slide from the slide overview (thumbnail) image. The primary statistical endpoint was the macro-averaged area under the receiver operating curve (AUROCs) for detection of the type of slide.
RESULTS: In the primary dataset (FOXTROT), with an AUROC of 0.995 [95% confidence interval [CI]: 0.994-0.996] the algorithm achieved a high classification performance and was able to accurately predict the type of slide from the thumbnail image alone. In the two external test cohorts (CR07, DACHS) AUROCs of 0.982 [95% CI: 0.979-0.985] and 0.875 [95% CI: 0.864-0.887] were observed, which indicates the generalizability of the trained model on unseen datasets. With a confidence threshold of 0.95, the model reached an accuracy of 94.6% (7331 classified cases) in CR07 and 85.1% (2752 classified cases) for the DACHS cohort.
CONCLUSION: Our findings show that using the low-resolution thumbnail image is sufficient to accurately classify the type of slide in digital pathology. This can support researchers to make the vast resource of existing pathology archives accessible to modern AI models with only minimal manual annotations.",True,other,recurrent neural network
37774924,"Development of an automated estimation of foot process width using deep learning in kidney biopsies from patients with Fabry, minimal change, and diabetic kidney diseases","Podocyte injury plays a key role in pathogenesis of many kidney diseases with increased podocyte foot process width (FPW), an important measure of podocyte injury. Unfortunately, there is no consensus on the best way to estimate FPW and unbiased stereology, the current gold standard, is time consuming and not widely available. To address this, we developed an automated FPW estimation technique using deep learning. A U-Net architecture variant model was trained to semantically segment the podocyte-glomerular basement membrane interface and filtration slits. Additionally, we employed a post-processing computer vision approach to accurately estimate FPW. A custom segmentation utility was also created to manually classify these structures on digital electron microscopy (EM) images and to prepare a training dataset. The model was applied to EM images of kidney biopsies from 56 patients with Fabry disease, 15 with type 2 diabetes, 10 with minimal change disease, and 17 normal individuals. The results were compared with unbiased stereology measurements performed by expert technicians unaware of the clinical information. FPW measured by deep learning and by the expert technicians were highly correlated and not statistically different in any of the studied groups. A Bland-Altman plot confirmed interchangeability of the methods. FPW measurement time per biopsy was substantially reduced by deep learning. Thus, we have developed a novel validated deep learning model for FPW measurement on EM images. The model is accessible through a cloud-based application making calculation of this important biomarker more widely accessible for research and clinical applications.",True,other,recurrent neural network
37774049,Oral Cancer Prediction Using a Probability Neural Network (PNN),"OBJECTIVE: In India, usually, oral cancer is mostly identified at a progressive stage of malignancy. Hence, we are motivated to identify oral cancer in its early stages, which helps to increase the lifetime of the patient, but this early detection is also more challenging.
METHODS: The proposed research work uses a probabilistic neural network (PNN) for the prediction of oral malignancy. The recommended work uses PNN along with the discrete wavelet transform to predict the cancer cells accurately. The classification accuracy of the PNN model is 80%, and hence this technique is best for the prediction of oral cancer.
RESULT: Due to heterogeneity in the appearance of oral lesions, it is difficult to identify the cancer region. This research work explores the different computer vision techniques that help in the prediction of oral cancer.
CONCLUSION: Oral screening is important in making a decision about oral lesions and also in avoiding delayed referrals, which reduces mortality rates.",True,other,Not specified
37555144,A training program for researchers in population neuroimaging: Early experiences,"Recent advances in neuroimaging create groundbreaking opportunities to better understand human neurological and psychiatric diseases, but also bring new challenges. With the advent of more and more sophisticated and efficient multimodal image processing software, we can now study much larger populations and integrate information from multiple modalities. In consequence, investigators that use neuroimaging techniques must also understand and apply principles of population sampling and contemporary data analytic techniques. The next generation of neuroimaging researchers must be skilled in numerous previously distinct disciplines and so a new integrated model of training is needed. This tutorial presents the rationale for such a new training model and presents the results from the first years of the training program focused on population neuroimaging of Alzheimer's Disease. This approach is applicable to other areas of population neuroimaging.",True,other,convolutional neural network
37450598,Dynamics-informed deconvolutional neural networks for super-resolution identification of regime changes in epidemiological time series,"The ability to infer the timing and amplitude of perturbations in epidemiological systems from their stochastically spread low-resolution outcomes is crucial for multiple applications. However, the general problem of connecting epidemiological curves with the underlying incidence lacks the highly effective methodology present in other inverse problems, such as super-resolution and dehazing from computer vision. Here, we develop an unsupervised physics-informed convolutional neural network approach in reverse to connect death records with incidence that allows the identification of regime changes at single-day resolution. Applied to COVID-19 data with proper regularization and model-selection criteria, the approach can identify the implementation and removal of lockdowns and other nonpharmaceutical interventions (NPIs) with 0.93-day accuracy over the time span of a year.",True,both,convolutional neural network
37173166,The use of mobile thermal imaging and machine learning technology for the detection of early surgical site infections,"BACKGROUND: Surgical Site Infections (SSI) yield subtle, early signs that are not readily identifiable. This study sought to develop a machine learning algorithm that could identify early SSIs based on thermal images.
METHODS: Images were taken of surgical incisions on 193 patients who underwent a variety of surgical procedures. Two neural network models were generated to detect SSIs, one using RGB images, and one incorporating thermal images. Accuracy and Jaccard Index were the primary metrics by which models were evaluated.
RESULTS: Only 5 patients in our cohort developed SSIs (2.8%). Models were instead generated to demarcate the wound site. The models had 89-92% accuracy in predicting pixel class. The Jaccard indices for the RGB and RGB ​+ ​Thermal models were 66% and 64%, respectively.
CONCLUSIONS: Although the low infection rate precluded the ability of our models to identify surgical site infections, we were able to generate two models to successfully segment wounds. This proof-of-concept study demonstrates that computer vision has the potential to support future surgical applications.",True,other,recurrent neural network
38939607,Can Artificial Intelligence Enhance Syncope Management?: A JACC: Advances Multidisciplinary Collaborative Statement,"Syncope, a form of transient loss of consciousness, remains a complex medical condition for which adverse cardiovascular outcomes, including death, are of major concern but rarely occur. Current risk stratification algorithms have not completely delineated which patients benefit from hospitalization and specific interventions. Patients are often admitted unnecessarily and at high cost. Artificial intelligence (AI) and machine learning may help define the transient loss of consciousness event, diagnose the cause, assess short- and long-term risks, predict recurrence, and determine need for hospitalization and therapeutic intervention; however, several challenges remain, including medicolegal and ethical concerns. This collaborative statement, from a multidisciplinary group of clinicians, investigators, and scientists, focuses on the potential role of AI in syncope management with a goal to inspire creation of AI-derived clinical decision support tools that may improve patient outcomes, streamline diagnostics, and reduce health-care costs.",True,other,Not specified
36799341,"Implementable Deep Learning for Multi-sequence Proton MRI Lung Segmentation: A Multi-center, Multi-vendor, and Multi-disease Study","BACKGROUND: Recently, deep learning via convolutional neural networks (CNNs) has largely superseded conventional methods for proton (1 H)-MRI lung segmentation. However, previous deep learning studies have utilized single-center data and limited acquisition parameters.
PURPOSE: Develop a generalizable CNN for lung segmentation in 1 H-MRI, robust to pathology, acquisition protocol, vendor, and center.
STUDY TYPE: Retrospective.
POPULATION: A total of 809 1 H-MRI scans from 258 participants with various pulmonary pathologies (median age (range): 57 (6-85); 42% females) and 31 healthy participants (median age (range): 34 (23-76); 34% females) that were split into training (593 scans (74%); 157 participants (55%)), testing (50 scans (6%); 50 participants (17%)) and external validation (164 scans (20%); 82 participants (28%)) sets.
FIELD STRENGTH/SEQUENCE: 1.5-T and 3-T/3D spoiled-gradient recalled and ultrashort echo-time 1 H-MRI.
ASSESSMENT: 2D and 3D CNNs, trained on single-center, multi-sequence data, and the conventional spatial fuzzy c-means (SFCM) method were compared to manually delineated expert segmentations. Each method was validated on external data originating from several centers. Dice similarity coefficient (DSC), average boundary Hausdorff distance (Average HD), and relative error (XOR) metrics to assess segmentation performance.
STATISTICAL TESTS: Kruskal-Wallis tests assessed significances of differences between acquisitions in the testing set. Friedman tests with post hoc multiple comparisons assessed differences between the 2D CNN, 3D CNN, and SFCM. Bland-Altman analyses assessed agreement with manually derived lung volumes. A P value of <0.05 was considered statistically significant.
RESULTS: The 3D CNN significantly outperformed its 2D analog and SFCM, yielding a median (range) DSC of 0.961 (0.880-0.987), Average HD of 1.63 mm (0.65-5.45) and XOR of 0.079 (0.025-0.240) on the testing set and a DSC of 0.973 (0.866-0.987), Average HD of 1.11 mm (0.47-8.13) and XOR of 0.054 (0.026-0.255) on external validation data.
DATA CONCLUSION: The 3D CNN generated accurate 1 H-MRI lung segmentations on a heterogenous dataset, demonstrating robustness to disease pathology, sequence, vendor, and center.
EVIDENCE LEVEL: 4.
TECHNICAL EFFICACY: Stage 1.",True,other,convolutional neural network
36702828,Author Correction: Federated learning enables big data for rare cancer boundary detection,,True,other,GAN
36470898,Federated learning enables big data for rare cancer boundary detection,"Although machine learning (ML) has shown promise across disciplines, out-of-sample generalizability is concerning. This is currently addressed by sharing multi-site data, but such centralization is challenging/infeasible to scale due to various limitations. Federated ML (FL) provides an alternative paradigm for accurate and generalizable ML, by only sharing numerical model updates. Here we present the largest FL study to-date, involving data from 71 sites across 6 continents, to generate an automatic tumor boundary detector for the rare disease of glioblastoma, reporting the largest such dataset in the literature (n = 6, 314). We demonstrate a 33% delineation improvement for the surgically targetable tumor, and 23% for the complete tumor extent, over a publicly trained model. We anticipate our study to: 1) enable more healthcare studies informed by large diverse data, ensuring meaningful results for rare diseases and underrepresented populations, 2) facilitate further analyses for glioblastoma by releasing our consensus model, and 3) demonstrate the FL effectiveness at such scale and task-complexity as a paradigm shift for multi-site collaborations, alleviating the need for data-sharing.",True,other,Not specified
36143468,Artificial Intelligence in Biological Sciences,"Artificial intelligence (AI), currently a cutting-edge concept, has the potential to improve the quality of life of human beings. The fields of AI and biological research are becoming more intertwined, and methods for extracting and applying the information stored in live organisms are constantly being refined. As the field of AI matures with more trained algorithms, the potential of its application in epidemiology, the study of host-pathogen interactions and drug designing widens. AI is now being applied in several fields of drug discovery, customized medicine, gene editing, radiography, image processing and medication management. More precise diagnosis and cost-effective treatment will be possible in the near future due to the application of AI-based technologies. In the field of agriculture, farmers have reduced waste, increased output and decreased the amount of time it takes to bring their goods to market due to the application of advanced AI-based approaches. Moreover, with the use of AI through machine learning (ML) and deep-learning-based smart programs, one can modify the metabolic pathways of living systems to obtain the best possible outputs with the minimal inputs. Such efforts can improve the industrial strains of microbial species to maximize the yield in the bio-based industrial setup. This article summarizes the potentials of AI and their application to several fields of biology, such as medicine, agriculture, and bio-based industry.",True,other,Not specified
35936377,Analysis and Recognition of Clinical Features of Diabetes Based on Convolutional Neural Network,"Diabetes mellitus is a common chronic noncommunicable disease, the main manifestation of which is the long-term high blood sugar level in patients due to metabolic disorders. However, due to excessive reliance on the clinical experience of ophthalmologists, our diagnosis takes a long time, and it is prone to missed diagnosis and misdiagnosis. In recent years, with the development of deep learning, its application in the auxiliary diagnosis of diabetic retinopathy has become possible. How to use the powerful feature extraction ability of deep learning algorithm to realize the mining of massive medical data is of great significance. Therefore, under the action of computer-aided technology, this paper processes and analyzes the retinal images of the fundus through traditional image processing and convolutional neural network-related methods, so as to achieve the role of assisting clinical treatment. Based on the admission records of diabetic patients after data analysis and feature processing, this paper uses an improved convolutional neural network algorithm to establish a model for predicting changes in diabetic conditions. The model can assist doctors to judge the patient's treatment effect by using it based on the case records of inpatient diagnosis and treatment and to predict the risk of readmission of inpatients after discharge. It also can help to judge the effectiveness of the treatment plan. The results of the study show that the model proposed in this paper has a lower probability of misjudging patients with poor recovery as good recovery, and the prediction is more accurate.",True,other,Not specified
35833287,Combining natural and artificial intelligence for robust automatic anatomy segmentation: Application in neck and thorax auto-contouring,"BACKGROUND: Automatic segmentation of 3D objects in computed tomography (CT) is challenging. Current methods, based mainly on artificial intelligence (AI) and end-to-end deep learning (DL) networks, are weak in garnering high-level anatomic information, which leads to compromised efficiency and robustness. This can be overcome by incorporating natural intelligence (NI) into AI methods via computational models of human anatomic knowledge.
PURPOSE: We formulate a hybrid intelligence (HI) approach that integrates the complementary strengths of NI and AI for organ segmentation in CT images and illustrate performance in the application of radiation therapy (RT) planning via multisite clinical evaluation.
METHODS: The system employs five modules: (i) body region recognition, which automatically trims a given image to a precisely defined target body region; (ii) NI-based automatic anatomy recognition object recognition (AAR-R), which performs object recognition in the trimmed image without DL and outputs a localized fuzzy model for each object; (iii) DL-based recognition (DL-R), which refines the coarse recognition results of AAR-R and outputs a stack of 2D bounding boxes (BBs) for each object; (iv) model morphing (MM), which deforms the AAR-R fuzzy model of each object guided by the BBs output by DL-R; and (v) DL-based delineation (DL-D), which employs the object containment information provided by MM to delineate each object. NI from (ii), AI from (i), (iii), and (v), and their combination from (iv) facilitate the HI system.
RESULTS: The HI system was tested on 26 organs in neck and thorax body regions on CT images obtained prospectively from 464 patients in a study involving four RT centers. Data sets from one separate independent institution involving 125 patients were employed in training/model building for each of the two body regions, whereas 104 and 110 data sets from the 4 RT centers were utilized for testing on neck and thorax, respectively. In the testing data sets, 83% of the images had limitations such as streak artifacts, poor contrast, shape distortion, pathology, or implants. The contours output by the HI system were compared to contours drawn in clinical practice at the four RT centers by utilizing an independently established ground-truth set of contours as reference. Three sets of measures were employed: accuracy via Dice coefficient (DC) and Hausdorff boundary distance (HD), subjective clinical acceptability via a blinded reader study, and efficiency by measuring human time saved in contouring by the HI system. Overall, the HI system achieved a mean DC of 0.78 and 0.87 and a mean HD of 2.22 and 4.53 mm for neck and thorax, respectively. It significantly outperformed clinical contouring in accuracy and saved overall 70% of human time over clinical contouring time, whereas acceptability scores varied significantly from site to site for both auto-contours and clinically drawn contours.
CONCLUSIONS: The HI system is observed to behave like an expert human in robustness in the contouring task but vastly more efficiently. It seems to use NI help where image information alone will not suffice to decide, first for the correct localization of the object and then for the precise delineation of the boundary.",True,other,Not specified
35751196,Eight pruning deep learning models for low storage and high-speed COVID-19 computed tomography lung segmentation and heatmap-based lesion localization: A multicenter study using COVLIAS 2.0,"BACKGROUND: COVLIAS 1.0: an automated lung segmentation was designed for COVID-19 diagnosis. It has issues related to storage space and speed. This study shows that COVLIAS 2.0 uses pruned AI (PAI) networks for improving both storage and speed, wiliest high performance on lung segmentation and lesion localization.
METHOD: ology: The proposed study uses multicenter ∼9,000 CT slices from two different nations, namely, CroMed from Croatia (80 patients, experimental data), and NovMed from Italy (72 patients, validation data). We hypothesize that by using pruning and evolutionary optimization algorithms, the size of the AI models can be reduced significantly, ensuring optimal performance. Eight different pruning techniques (i) differential evolution (DE), (ii) genetic algorithm (GA), (iii) particle swarm optimization algorithm (PSO), and (iv) whale optimization algorithm (WO) in two deep learning frameworks (i) Fully connected network (FCN) and (ii) SegNet were designed. COVLIAS 2.0 was validated using ""Unseen NovMed"" and benchmarked against MedSeg. Statistical tests for stability and reliability were also conducted.
RESULTS: Pruning algorithms (i) FCN-DE, (ii) FCN-GA, (iii) FCN-PSO, and (iv) FCN-WO showed improvement in storage by 92.4%, 95.3%, 98.7%, and 99.8% respectively when compared against solo FCN, and (v) SegNet-DE, (vi) SegNet-GA, (vii) SegNet-PSO, and (viii) SegNet-WO showed improvement by 97.1%, 97.9%, 98.8%, and 99.2% respectively when compared against solo SegNet. AUC > 0.94 (p < 0.0001) on CroMed and > 0.86 (p < 0.0001) on NovMed data set for all eight EA model. PAI <0.25 s per image. DenseNet-121-based Grad-CAM heatmaps showed validation on glass ground opacity lesions.
CONCLUSIONS: Eight PAI networks that were successfully validated are five times faster, storage efficient, and could be used in clinical settings.",True,computer vision,Not specified
35725739,Multimodal deep learning for Alzheimer's disease dementia assessment,"Worldwide, there are nearly 10 million new cases of dementia annually, of which Alzheimer's disease (AD) is the most common. New measures are needed to improve the diagnosis of individuals with cognitive impairment due to various etiologies. Here, we report a deep learning framework that accomplishes multiple diagnostic steps in successive fashion to identify persons with normal cognition (NC), mild cognitive impairment (MCI), AD, and non-AD dementias (nADD). We demonstrate a range of models capable of accepting flexible combinations of routinely collected clinical information, including demographics, medical history, neuropsychological testing, neuroimaging, and functional assessments. We then show that these frameworks compare favorably with the diagnostic accuracy of practicing neurologists and neuroradiologists. Lastly, we apply interpretability methods in computer vision to show that disease-specific patterns detected by our models track distinct patterns of degenerative changes throughout the brain and correspond closely with the presence of neuropathological lesions on autopsy. Our work demonstrates methodologies for validating computational predictions with established standards of medical diagnosis.",True,other,recurrent neural network
35469069,Swarm learning for decentralized artificial intelligence in cancer histopathology,"Artificial intelligence (AI) can predict the presence of molecular alterations directly from routine histopathology slides. However, training robust AI systems requires large datasets for which data collection faces practical, ethical and legal obstacles. These obstacles could be overcome with swarm learning (SL), in which partners jointly train AI models while avoiding data transfer and monopolistic data governance. Here, we demonstrate the successful use of SL in large, multicentric datasets of gigapixel histopathology images from over 5,000 patients. We show that AI models trained using SL can predict BRAF mutational status and microsatellite instability directly from hematoxylin and eosin (H&E)-stained pathology slides of colorectal cancer. We trained AI models on three patient cohorts from Northern Ireland, Germany and the United States, and validated the prediction performance in two independent datasets from the United Kingdom. Our data show that SL-trained AI models outperform most locally trained models, and perform on par with models that are trained on the merged datasets. In addition, we show that SL-based AI models are data efficient. In the future, SL can be used to train distributed AI models for any histopathology image analysis task, eliminating the need for data transfer.",True,other,recurrent neural network
35176101,Deep learning approach based on superpixel segmentation assisted labeling for automatic pressure ulcer diagnosis,"A pressure ulcer is an injury of the skin and underlying tissues adjacent to a bony eminence. Patients who suffer from this disease may have difficulty accessing medical care. Recently, the COVID-19 pandemic has exacerbated this situation. Automatic diagnosis based on machine learning (ML) brings promising solutions. Traditional ML requires complicated preprocessing steps for feature extraction. Its clinical applications are thus limited to particular datasets. Deep learning (DL), which extracts features from convolution layers, can embrace larger datasets that might be deliberately excluded in traditional algorithms. However, DL requires large sets of domain specific labeled data for training. Labeling various tissues of pressure ulcers is a challenge even for experienced plastic surgeons. We propose a superpixel-assisted, region-based method of labeling images for tissue classification. The boundary-based method is applied to create a dataset for wound and re-epithelialization (re-ep) segmentation. Five popular DL models (U-Net, DeeplabV3, PsPNet, FPN, and Mask R-CNN) with encoder (ResNet-101) were trained on the two datasets. A total of 2836 images of pressure ulcers were labeled for tissue classification, while 2893 images were labeled for wound and re-ep segmentation. All five models had satisfactory results. DeeplabV3 had the best performance on both tasks with a precision of 0.9915, recall of 0.9915 and accuracy of 0.9957 on the tissue classification; and a precision of 0.9888, recall of 0.9887 and accuracy of 0.9925 on the wound and re-ep segmentation task. Combining segmentation results with clinical data, our algorithm can detect the signs of wound healing, monitor the progress of healing, estimate the wound size, and suggest the need for surgical debridement.",True,other,convolutional neural network
35148679,Examination of blood samples using deep learning and mobile microscopy,"BACKGROUND: Microscopic examination of human blood samples is an excellent opportunity to assess general health status and diagnose diseases. Conventional blood tests are performed in medical laboratories by specialized professionals and are time and labor intensive. The development of a point-of-care system based on a mobile microscope and powerful algorithms would be beneficial for providing care directly at the patient's bedside. For this purpose human blood samples were visualized using a low-cost mobile microscope, an ocular camera and a smartphone. Training and optimisation of different deep learning methods for instance segmentation are used to detect and count the different blood cells. The accuracy of the results is assessed using quantitative and qualitative evaluation standards.
RESULTS: Instance segmentation models such as Mask R-CNN, Mask Scoring R-CNN, D2Det and YOLACT were trained and optimised for the detection and classification of all blood cell types. These networks were not designed to detect very small objects in large numbers, so extensive modifications were necessary. Thus, segmentation of all blood cell types and their classification was feasible with great accuracy: qualitatively evaluated, mean average precision of 0.57 and mean average recall of 0.61 are achieved for all blood cell types. Quantitatively, 93% of ground truth blood cells can be detected.
CONCLUSIONS: Mobile blood testing as a point-of-care system can be performed with diagnostic accuracy using deep learning methods. In the future, this application could enable very fast, cheap, location- and knowledge-independent patient care.",True,other,Not specified
35110593,Effective deep learning approaches for predicting COVID-19 outcomes from chest computed tomography volumes,"The rapid evolution of the novel coronavirus disease (COVID-19) pandemic has resulted in an urgent need for effective clinical tools to reduce transmission and manage severe illness. Numerous teams are quickly developing artificial intelligence approaches to these problems, including using deep learning to predict COVID-19 diagnosis and prognosis from chest computed tomography (CT) imaging data. In this work, we assess the value of aggregated chest CT data for COVID-19 prognosis compared to clinical metadata alone. We develop a novel patient-level algorithm to aggregate the chest CT volume into a 2D representation that can be easily integrated with clinical metadata to distinguish COVID-19 pneumonia from chest CT volumes from healthy participants and participants with other viral pneumonia. Furthermore, we present a multitask model for joint segmentation of different classes of pulmonary lesions present in COVID-19 infected lungs that can outperform individual segmentation models for each task. We directly compare this multitask segmentation approach to combining feature-agnostic volumetric CT classification feature maps with clinical metadata for predicting mortality. We show that the combination of features derived from the chest CT volumes improve the AUC performance to 0.80 from the 0.52 obtained by using patients' clinical data alone. These approaches enable the automated extraction of clinically relevant features from chest CT volumes for risk stratification of COVID-19 patients.",True,other,Not specified
34853342,Validation of expert system enhanced deep learning algorithm for automated screening for COVID-Pneumonia on chest X-rays,"SARS-CoV2 pandemic exposed the limitations of artificial intelligence based medical imaging systems. Earlier in the pandemic, the absence of sufficient training data prevented effective deep learning (DL) solutions for the diagnosis of COVID-19 based on X-Ray data. Here, addressing the lacunae in existing literature and algorithms with the paucity of initial training data; we describe CovBaseAI, an explainable tool using an ensemble of three DL models and an expert decision system (EDS) for COVID-Pneumonia diagnosis, trained entirely on pre-COVID-19 datasets. The performance and explainability of CovBaseAI was primarily validated on two independent datasets. Firstly, 1401 randomly selected CxR from an Indian quarantine center to assess effectiveness in excluding radiological COVID-Pneumonia requiring higher care. Second, curated dataset; 434 RT-PCR positive cases and 471 non-COVID/Normal historical scans, to assess performance in advanced medical settings. CovBaseAI had an accuracy of 87% with a negative predictive value of 98% in the quarantine-center data. However, sensitivity was 0.66-0.90 taking RT-PCR/radiologist opinion as ground truth. This work provides new insights on the usage of EDS with DL methods and the ability of algorithms to confidently predict COVID-Pneumonia while reinforcing the established learning; that benchmarking based on RT-PCR may not serve as reliable ground truth in radiological diagnosis. Such tools can pave the path for multi-modal high throughput detection of COVID-Pneumonia in screening and referral.",True,other,CNN
34837083,Deep learning enables genetic analysis of the human thoracic aorta,"Enlargement or aneurysm of the aorta predisposes to dissection, an important cause of sudden death. We trained a deep learning model to evaluate the dimensions of the ascending and descending thoracic aorta in 4.6 million cardiac magnetic resonance images from the UK Biobank. We then conducted genome-wide association studies in 39,688 individuals, identifying 82 loci associated with ascending and 47 with descending thoracic aortic diameter, of which 14 loci overlapped. Transcriptome-wide analyses, rare-variant burden tests and human aortic single nucleus RNA sequencing prioritized genes including SVIL, which was strongly associated with descending aortic diameter. A polygenic score for ascending aortic diameter was associated with thoracic aortic aneurysm in 385,621 UK Biobank participants (hazard ratio = 1.43 per s.d., confidence interval 1.32-1.54, P = 3.3 × 10-20). Our results illustrate the potential for rapidly defining quantitative traits with deep learning, an approach that can be broadly applied to biomedical images.",True,other,Not specified
34735458,Accuracy of deep learning-based computed tomography diagnostic system for COVID-19: A consecutive sampling external validation cohort study,"Ali-M3, an artificial intelligence program, analyzes chest computed tomography (CT) and detects the likelihood of coronavirus disease (COVID-19) based on scores ranging from 0 to 1. However, Ali-M3 has not been externally validated. Our aim was to evaluate the accuracy of Ali-M3 for detecting COVID-19 and discuss its clinical value. We evaluated the external validity of Ali-M3 using sequential Japanese sampling data. In this retrospective cohort study, COVID-19 infection probabilities for 617 symptomatic patients were determined using Ali-M3. In 11 Japanese tertiary care facilities, these patients underwent reverse transcription-polymerase chain reaction (RT-PCR) testing. They also underwent chest CT to confirm a diagnosis of COVID-19. Of the 617 patients, 289 (46.8%) were RT-PCR-positive. The area under the curve (AUC) of Ali-M3 for predicting a COVID-19 diagnosis was 0.797 (95% confidence interval: 0.762‒0.833) and the goodness-of-fit was P = 0.156. With a cut-off probability of a diagnosis of COVID-19 by Ali-M3 set at 0.5, the sensitivity and specificity were 80.6% and 68.3%, respectively. A cut-off of 0.2 yielded a sensitivity and specificity of 89.2% and 43.2%, respectively. Among the 223 patients who required oxygen, the AUC was 0.825. Sensitivity at a cut-off of 0.5% and 0.2% was 88.7% and 97.9%, respectively. Although the sensitivity was lower when the days from symptom onset were fewer, the sensitivity increased for both cut-off values after 5 days. We evaluated Ali-M3 using external validation with symptomatic patient data from Japanese tertiary care facilities. As Ali-M3 showed sufficient sensitivity performance, despite a lower specificity performance, Ali-M3 could be useful in excluding a diagnosis of COVID-19.",True,other,Not specified
34678610,Accurate diagnosis and prognosis prediction of gastric cancer using deep learning on digital pathological images: A retrospective multicentre study,"BACKGROUND: To reduce the high incidence and mortality of gastric cancer (GC), we aimed to develop deep learning-based models to assist in predicting the diagnosis and overall survival (OS) of GC patients using pathological images.
METHODS: 2333 hematoxylin and eosin-stained pathological pictures of 1037 GC patients were collected from two cohorts to develop our algorithms, Renmin Hospital of Wuhan University (RHWU) and the Cancer Genome Atlas (TCGA). Additionally, we gained 175 digital pictures of 91 GC patients from National Human Genetic Resources Sharing Service Platform (NHGRP), served as the independent external validation set. Two models were developed using artificial intelligence (AI), one named GastroMIL for diagnosing GC, and the other named MIL-GC for predicting outcome of GC.
FINDINGS: The discriminatory power of GastroMIL achieved accuracy 0.920 in the external validation set, superior to that of the junior pathologist and comparable to that of expert pathologists. In the prognostic model, C-indices for survival prediction of internal and external validation sets were 0.671 and 0.657, respectively. Moreover, the risk score output by MIL-GC in the external validation set was proved to be a strong predictor of OS both in the univariate (HR = 2.414, P < 0.0001) and multivariable (HR = 1.803, P = 0.043) analyses. The predicting process is available at an online website (https://baigao.github.io/Pathologic-Prognostic-Analysis/).
INTERPRETATION: Our study developed AI models and contributed to predicting precise diagnosis and prognosis of GC patients, which will offer assistance to choose appropriate treatment to improve the survival status of GC patients.
FUNDING: Not applicable.",True,other,Not specified
34608186,Detection and analysis of COVID-19 in medical images using deep learning techniques,"The main purpose of this work is to investigate and compare several deep learning enhanced techniques applied to X-ray and CT-scan medical images for the detection of COVID-19. In this paper, we used four powerful pre-trained CNN models, VGG16, DenseNet121, ResNet50,and ResNet152, for the COVID-19 CT-scan binary classification task. The proposed Fast.AI ResNet framework was designed to find out the best architecture, pre-processing, and training parameters for the models largely automatically. The accuracy and F1-score were both above 96% in the diagnosis of COVID-19 using CT-scan images. In addition, we applied transfer learning techniques to overcome the insufficient data and to improve the training time. The binary and multi-class classification of X-ray images tasks were performed by utilizing enhanced VGG16 deep transfer learning architecture. High accuracy of 99% was achieved by enhanced VGG16 in the detection of X-ray images from COVID-19 and pneumonia. The accuracy and validity of the algorithms were assessed on X-ray and CT-scan well-known public datasets. The proposed methods have better results for COVID-19 diagnosis than other related in literature. In our opinion, our work can help virologists and radiologists to make a better and faster diagnosis in the struggle against the outbreak of COVID-19.",True,other,recurrent neural network
34584193,Deep learning-based virtual cytokeratin staining of gastric carcinomas to measure tumor-stroma ratio,"The tumor-stroma ratio (TSR) determined by pathologists is subject to intra- and inter-observer variability. We aimed to develop a computational quantification method of TSR using deep learning-based virtual cytokeratin staining algorithms. Patients with 373 advanced (stage III [n = 171] and IV [n = 202]) gastric cancers were analyzed for TSR. Moderate agreement was observed, with a kappa value of 0.623, between deep learning metrics (dTSR) and visual measurement by pathologists (vTSR) and the area under the curve of receiver operating characteristic of 0.907. Moreover, dTSR was significantly associated with the overall survival of the patients (P = 0.0024). In conclusion, we developed a virtual cytokeratin staining and deep learning-based TSR measurement, which may aid in the diagnosis of TSR in gastric cancer.",True,other,Not specified
34564904,Deep Generative Medical Image Harmonization for Improving Cross-Site Generalization in Deep Learning Predictors,"BACKGROUND: In the medical imaging domain, deep learning-based methods have yet to see widespread clinical adoption, in part due to limited generalization performance across different imaging devices and acquisition protocols. The deviation between estimated brain age and biological age is an established biomarker of brain health and such models may benefit from increased cross-site generalizability.
PURPOSE: To develop and evaluate a deep learning-based image harmonization method to improve cross-site generalizability of deep learning age prediction.
STUDY TYPE: Retrospective.
POPULATION: Eight thousand eight hundred and seventy-six subjects from six sites. Harmonization models were trained using all subjects. Age prediction models were trained using 2739 subjects from a single site and tested using the remaining 6137 subjects from various other sites.
FIELD STRENGTH/SEQUENCE: Brain imaging with magnetization prepared rapid acquisition with gradient echo or spoiled gradient echo sequences at 1.5 T and 3 T.
ASSESSMENT: StarGAN v2, was used to perform a canonical mapping from diverse datasets to a reference domain to reduce site-based variation while preserving semantic information. Generalization performance of deep learning age prediction was evaluated using harmonized, histogram matched, and unharmonized data.
STATISTICAL TESTS: Mean absolute error (MAE) and Pearson correlation between estimated age and biological age quantified the performance of the age prediction model.
RESULTS: Our results indicated a substantial improvement in age prediction in out-of-sample data, with the overall MAE improving from 15.81 (±0.21) years to 11.86 (±0.11) with histogram matching to 7.21 (±0.22) years with generative adversarial network (GAN)-based harmonization. In the multisite case, across the 5 out-of-sample sites, MAE improved from 9.78 (±6.69) years to 7.74 (±3.03) years with histogram normalization to 5.32 (±4.07) years with GAN-based harmonization.
DATA CONCLUSION: While further research is needed, GAN-based medical image harmonization appears to be a promising tool for improving cross-site deep learning generalization.
LEVEL OF EVIDENCE: 4 TECHNICAL EFFICACY: Stage 1.",True,other,convolutional neural network
34558818,Automated Measurements of Body Composition in Abdominal CT Scans Using Artificial Intelligence Can Predict Mortality in Patients With Cirrhosis,"Body composition measures derived from already available electronic medical records (computed tomography [CT] scans) can have significant value, but automation of measurements is needed for clinical implementation. We sought to use artificial intelligence to develop an automated method to measure body composition and test the algorithm on a clinical cohort to predict mortality. We constructed a deep learning algorithm using Google's DeepLabv3+ on a cohort of de-identified CT scans (n = 12,067). To test for the accuracy and clinical usefulness of the algorithm, we used a unique cohort of prospectively followed patients with cirrhosis (n = 238) who had CT scans performed. To assess model performance, we used the confusion matrix and calculated the mean accuracy of 0.977 ± 0.02 (0.975 ± 0.018 for the training and test sets, respectively). To assess for spatial overlap, we measured the mean intersection over union and mean boundary contour scores and found excellent overlap between the manual and automated methods with mean scores of 0.954 ± 0.030, 0.987 ± 0.009, and 0.948 ± 0.039 (0.983 ± 0.013 for the training and test set, respectively). Using these automated measurements, we found that body composition features were predictive of mortality in patients with cirrhosis. On multivariate analysis, the addition of body composition measures significantly improved prediction of mortality for patients with cirrhosis over Model for End-Stage Liver Disease alone (P < 0.001). Conclusion: The measurement of body composition can be automated using artificial intelligence and add significant value for incidental CTs performed for other clinical indications. This is proof of concept that this methodology could allow for wider implementation into the clinical arena.",True,other,Not specified
34391053,Gastrointestinal cancer classification and prognostication from histology using deep learning: Systematic review,"BACKGROUND: Gastrointestinal cancers account for approximately 20% of all cancer diagnoses and are responsible for 22.5% of cancer deaths worldwide. Artificial intelligence-based diagnostic support systems, in particular convolutional neural network (CNN)-based image analysis tools, have shown great potential in medical computer vision. In this systematic review, we summarise recent studies reporting CNN-based approaches for digital biomarkers for characterization and prognostication of gastrointestinal cancer pathology.
METHODS: Pubmed and Medline were screened for peer-reviewed papers dealing with CNN-based gastrointestinal cancer analyses from histological slides, published between 2015 and 2020.Seven hundred and ninety titles and abstracts were screened, and 58 full-text articles were assessed for eligibility.
RESULTS: Sixteen publications fulfilled our inclusion criteria dealing with tumor or precursor lesion characterization or prognostic and predictive biomarkers: 14 studies on colorectal or rectal cancer, three studies on gastric cancer and none on esophageal cancer. These studies were categorised according to their end-points: polyp characterization, tumor characterization and patient outcome. Regarding the translation into clinical practice, we identified several studies demonstrating generalization of the classifier with external tests and comparisons with pathologists, but none presenting clinical implementation.
CONCLUSIONS: Results of recent studies on CNN-based image analysis in gastrointestinal cancer pathology are promising, but studies were conducted in observational and retrospective settings. Large-scale trials are needed to assess performance and predict clinical usefulness. Furthermore, large-scale trials are required for approval of CNN-based prediction models as medical devices.",True,other,CNN
34285218,The impact of site-specific digital histology signatures on deep learning model accuracy and bias,"The Cancer Genome Atlas (TCGA) is one of the largest biorepositories of digital histology. Deep learning (DL) models have been trained on TCGA to predict numerous features directly from histology, including survival, gene expression patterns, and driver mutations. However, we demonstrate that these features vary substantially across tissue submitting sites in TCGA for over 3,000 patients with six cancer subtypes. Additionally, we show that histologic image differences between submitting sites can easily be identified with DL. Site detection remains possible despite commonly used color normalization and augmentation methods, and we quantify the image characteristics constituting this site-specific digital histology signature. We demonstrate that these site-specific signatures lead to biased accuracy for prediction of features including survival, genomic mutations, and tumor stage. Furthermore, ethnicity can also be inferred from site-specific signatures, which must be accounted for to ensure equitable application of DL. These site-specific signatures can lead to overoptimistic estimates of model performance, and we propose a quadratic programming method that abrogates this bias by ensuring models are not trained and validated on samples from the same site.",True,other,Not specified
34253822,Deep learning for COVID-19 detection based on CT images,"COVID-19 has tremendously impacted patients and medical systems globally. Computed tomography images can effectively complement the reverse transcription-polymerase chain reaction testing. This study adopted a convolutional neural network for COVID-19 testing. We examined the performance of different pre-trained models on CT testing and identified that larger, out-of-field datasets boost the testing power of the models. This suggests that a priori knowledge of the models from out-of-field training is also applicable to CT images. The proposed transfer learning approach proves to be more successful than the current approaches described in literature. We believe that our approach has achieved the state-of-the-art performance in identification thus far. Based on experiments with randomly sampled training datasets, the results reveal a satisfactory performance by our model. We investigated the relevant visual characteristics of the CT images used by the model; these may assist clinical doctors in manual screening.",True,other,convolutional neural network
34188098,Long-term cancer survival prediction using multimodal deep learning,"The age of precision medicine demands powerful computational techniques to handle high-dimensional patient data. We present MultiSurv, a multimodal deep learning method for long-term pan-cancer survival prediction. MultiSurv uses dedicated submodels to establish feature representations of clinical, imaging, and different high-dimensional omics data modalities. A data fusion layer aggregates the multimodal representations, and a prediction submodel generates conditional survival probabilities for follow-up time intervals spanning several decades. MultiSurv is the first non-linear and non-proportional survival prediction method that leverages multimodal data. In addition, MultiSurv can handle missing data, including single values and complete data modalities. MultiSurv was applied to data from 33 different cancer types and yields accurate pan-cancer patient survival curves. A quantitative comparison with previous methods showed that Multisurv achieves the best results according to different time-dependent metrics. We also generated visualizations of the learned multimodal representation of MultiSurv, which revealed insights on cancer characteristics and heterogeneity.",True,other,Not specified
34017001,Deep learning predicts cardiovascular disease risks from lung cancer screening low dose computed tomography,"Cancer patients have a higher risk of cardiovascular disease (CVD) mortality than the general population. Low dose computed tomography (LDCT) for lung cancer screening offers an opportunity for simultaneous CVD risk estimation in at-risk patients. Our deep learning CVD risk prediction model, trained with 30,286 LDCTs from the National Lung Cancer Screening Trial, achieves an area under the curve (AUC) of 0.871 on a separate test set of 2,085 subjects and identifies patients with high CVD mortality risks (AUC of 0.768). We validate our model against ECG-gated cardiac CT based markers, including coronary artery calcification (CAC) score, CAD-RADS score, and MESA 10-year risk score from an independent dataset of 335 subjects. Our work shows that, in high-risk patients, deep learning can convert LDCT for lung cancer screening into a dual-screening quantitative tool for CVD risk estimation.",True,other,Not specified
33946042,"Predicting intraventricular hemorrhage growth with a machine learning-based, radiomics-clinical model","We constructed a radiomics-clinical model to predict intraventricular hemorrhage (IVH) growth after spontaneous intracerebral hematoma. The model was developed using a training cohort (N=626) and validated with an independent testing cohort (N=270). Radiomics features and clinical predictors were selected using the least absolute shrinkage and selection operator (LASSO) method and multivariate analysis. The radiomics score (Rad-score) was calculated through linear combination of selected features multiplied by their respective LASSO coefficients. The support vector machine (SVM) method was used to construct the model. IVH growth was experienced by 13.4% and 13.7% of patients in the training and testing cohorts, respectively. The Rad-score was associated with severe IVH and poor outcome. Independent predictors of IVH growth included hypercholesterolemia (odds ratio [OR], 0.12 [95%CI, 0.02-0.90]; p=0.039), baseline Graeb score (OR, 1.26 [95%CI, 1.16-1.36]; p<0.001), time to initial CT (OR, 0.70 [95%CI, 0.58-0.86]; p<0.001), international normalized ratio (OR, 4.27 [95%CI, 1.40, 13.0]; p=0.011), and Rad-score (OR, 2.3 [95%CI, 1.6-3.3]; p<0.001). In the training cohort, the model achieved an AUC of 0.78, sensitivity of 0.83, and specificity of 0.66. In the testing cohort, AUC, sensitivity, and specificity were 0.71, 0.81, and 0.64, respectively. This radiomics-clinical model thus has the potential to predict IVH growth.",True,other,LSTM
33936188,Detection of COVID-19 from CT Lung Scans Using Transfer Learning,"This paper aims to investigate the use of transfer learning architectures in the detection of COVID-19 from CT lung scans. The study evaluates the performances of various transfer learning architectures, as well as the effects of the standard Histogram Equalization and Contrast Limited Adaptive Histogram Equalization. The findings of this study suggest that transfer learning-based frameworks are an alternative to the contemporary methods used to detect the presence of the virus in patients. The highest performing model, the VGG-19 implemented with the Contrast Limited Adaptive Histogram Equalization, on a SARS-CoV-2 dataset, achieved an accuracy and recall of 95.75% and 97.13%, respectively.",True,other,convolutional neural network
33755710,Phage susceptibility testing and infectious titer determination through wide-field lensless monitoring of phage plaque growth,"The growing number of drug-resistant bacterial infections worldwide is driving renewed interest in phage therapy. Based on the use of a personalized cocktail composed of highly specific bacterial viruses, this therapy relies on a range of tests on agar media to determine the most active phage on a given bacterial target (phage susceptibility testing), or to isolate new lytic phages from an environmental sample (enrichment of phage banks). However, these culture-based techniques are still solely interpreted through direct visual detection of plaques. The main objective of this work is to investigate computer-assisted methods in order to ease and accelerate diagnosis in phage therapy but also to study phage plaque growth kinetics. For this purpose, we designed a custom wide-field lensless imaging device, which allows continuous monitoring over a very large area sensor (3.3 cm2). Here we report bacterial susceptibility to Staphylococcus aureus phage in 3 hr and estimation of infectious titer in 8 hr 20 min. These are much shorter time-to-results than the 12 to 24 hours traditionally needed, since naked eye observation and counting of phage plaques is still the most widely used technique for susceptibility testing prior to phage therapy. Moreover, the continuous monitoring of the samples enables the study of plaque growth kinetics, which enables a deeper understanding of the interaction between phage and bacteria. Finally, thanks to the 4.3 μm resolution, we detect phage-resistant bacterial microcolonies of Klebsiella pneumoniae inside the boundaries of phage plaques and thus show that our prototype is also a suitable device to track phage resistance. Lensless imaging is therefore an all-in-one method that could easily be implemented in cost-effective and compact devices in phage laboratories to help with phage therapy diagnosis.",True,text mining,Not specified
33531581,Automated digital TIL analysis (ADTA) adds prognostic value to standard assessment of depth and ulceration in primary melanoma,"Accurate prognostic biomarkers in early-stage melanoma are urgently needed to stratify patients for clinical trials of adjuvant therapy. We applied a previously developed open source deep learning algorithm to detect tumor-infiltrating lymphocytes (TILs) in hematoxylin and eosin (H&E) images of early-stage melanomas. We tested whether automated digital (TIL) analysis (ADTA) improved accuracy of prediction of disease specific survival (DSS) based on current pathology standards. ADTA was applied to a training cohort (n = 80) and a cutoff value was defined based on a Receiver Operating Curve. ADTA was then applied to a validation cohort (n = 145) and the previously determined cutoff value was used to stratify high and low risk patients, as demonstrated by Kaplan-Meier analysis (p ≤ 0.001). Multivariable Cox proportional hazards analysis was performed using ADTA, depth, and ulceration as co-variables and showed that ADTA contributed to DSS prediction (HR: 4.18, CI 1.51-11.58, p = 0.006). ADTA provides an effective and attainable assessment of TILs and should be further evaluated in larger studies for inclusion in staging algorithms.",True,other,Not specified
33531192,Deep Learning for Imaging and Detection of Microorganisms,"Despite tremendous recent interest, the application of deep learning in microbiology has still not reached its full potential. To tackle the challenges faced by human-operated microscopy, deep-learning-based methods have been proposed for microscopic image analysis of a wide range of microorganisms, including viruses, bacteria, fungi, and parasites. We believe that deep-learning technology-based systems will be on the front line of monitoring and investigation of microorganisms.",True,other,recurrent neural network
33514711,Deep convolutional neural networks to predict cardiovascular risk from computed tomography,"Coronary artery calcium is an accurate predictor of cardiovascular events. While it is visible on all computed tomography (CT) scans of the chest, this information is not routinely quantified as it requires expertise, time, and specialized equipment. Here, we show a robust and time-efficient deep learning system to automatically quantify coronary calcium on routine cardiac-gated and non-gated CT. As we evaluate in 20,084 individuals from distinct asymptomatic (Framingham Heart Study, NLST) and stable and acute chest pain (PROMISE, ROMICAT-II) cohorts, the automated score is a strong predictor of cardiovascular events, independent of risk factors (multivariable-adjusted hazard ratios up to 4.3), shows high correlation with manual quantification, and robust test-retest reliability. Our results demonstrate the clinical value of a deep learning system for the automated prediction of cardiovascular events. Implementation into clinical practice would address the unmet need of automating proven imaging biomarkers to guide management and improve population health.",True,other,Not specified
33457181,Deep Learning applications for COVID-19,"This survey explores how Deep Learning has battled the COVID-19 pandemic and provides directions for future research on COVID-19. We cover Deep Learning applications in Natural Language Processing, Computer Vision, Life Sciences, and Epidemiology. We describe how each of these applications vary with the availability of big data and how learning tasks are constructed. We begin by evaluating the current state of Deep Learning and conclude with key limitations of Deep Learning for COVID-19 applications. These limitations include Interpretability, Generalization Metrics, Learning from Limited Labeled Data, and Data Privacy. Natural Language Processing applications include mining COVID-19 research for Information Retrieval and Question Answering, as well as Misinformation Detection, and Public Sentiment Analysis. Computer Vision applications cover Medical Image Analysis, Ambient Intelligence, and Vision-based Robotics. Within Life Sciences, our survey looks at how Deep Learning can be applied to Precision Diagnostics, Protein Structure Prediction, and Drug Repurposing. Deep Learning has additionally been utilized in Spread Forecasting for Epidemiology. Our literature review has found many examples of Deep Learning systems to fight COVID-19. We hope that this survey will help accelerate the use of Deep Learning for COVID-19 research.",True,other,convolutional neural network
33328512,Prediction of disease progression in patients with COVID-19 by artificial intelligence assisted lesion quantification,"To investigate the value of artificial intelligence (AI) assisted quantification on initial chest CT for prediction of disease progression and clinical outcome in patients with coronavirus disease 2019 (COVID-19). Patients with confirmed COVID-19 infection and initially of non-severe type were retrospectively included. The initial CT scan on admission was used for imaging analysis. The presence of ground glass opacity (GGO), consolidation and other findings were visually evaluated. CT severity score was calculated according to the extent of lesion involvement. In addition, AI based quantification of GGO and consolidation volume were also performed. 123 patients (mean age: 64.43 ± 14.02; 62 males) were included. GGO + consolidation was more frequently revealed in progress-to-severe group whereas pure GGO was more likely to be found in non-severe group. Compared to non-severe group, patients in progress-to-severe group had larger GGO volume (167.33 ± 167.88 cm3 versus 101.12 ± 127 cm3, p = 0.013) as well as consolidation volume (40.85 ± 60.4 cm3 versus 6.63 ± 14.91 cm3, p &lt; 0.001). Among imaging parameters, consolidation volume had the largest area under curve (AUC) in discriminating non-severe from progress-to-severe group (AUC = 0.796, p &lt; 0.001) and patients with or without critical events (AUC = 0.754, p &lt; 0.001). According to multivariate regression, consolidation volume and age were two strongest predictors for disease progression (hazard ratio: 1.053 and 1.071, p: 0.006 and 0.008) whereas age and diabetes were predictors for unfavorable outcome. Consolidation volume quantified on initial chest CT was the strongest predictor for disease severity progression and larger consolidation volume was associated with unfavorable clinical outcome.",True,other,Not specified
33328086,Chest x-ray analysis with deep learning-based software as a triage test for pulmonary tuberculosis: a prospective study of diagnostic accuracy for culture-confirmed disease,"BACKGROUND: Deep learning-based radiological image analysis could facilitate use of chest x-rays as triage tests for pulmonary tuberculosis in resource-limited settings. We sought to determine whether commercially available chest x-ray analysis software meet WHO recommendations for minimal sensitivity and specificity as pulmonary tuberculosis triage tests.
METHODS: We recruited symptomatic adults at the Indus Hospital, Karachi, Pakistan. We compared two software, qXR version 2.0 (qXRv2) and CAD4TB version 6.0 (CAD4TBv6), with a reference of mycobacterial culture of two sputa. We assessed qXRv2 using its manufacturer prespecified threshold score for chest x-ray classification as tuberculosis present versus not present. For CAD4TBv6, we used a data-derived threshold, because it does not have a prespecified one. We tested for non-inferiority to preset WHO recommendations (0·90 for sensitivity, 0·70 for specificity) using a non-inferiority limit of 0·05. We identified factors associated with accuracy by stratification and logistic regression.
FINDINGS: We included 2198 (92·7%) of 2370 enrolled participants. 2187 (99·5%) of 2198 were HIV-negative, and 272 (12·4%) had culture-confirmed pulmonary tuberculosis. For both software, accuracy was non-inferior to WHO-recommended minimum values (qXRv2 sensitivity 0·93 [95% CI 0·89-0·95], non-inferiority p=0·0002; CAD4TBv6 sensitivity 0·93 [0·90-0·96], p<0·0001; qXRv2 specificity 0·75 [0·73-0·77], p<0·0001; CAD4TBv6 specificity 0·69 [0·67-0·71], p=0·0003). Sensitivity was lower in smear-negative pulmonary tuberculosis for both software, and in women for CAD4TBv6. Specificity was lower in men and in those with previous tuberculosis, and reduced with increasing age and decreasing body mass index. Smoking and diabetes did not affect accuracy.
INTERPRETATION: In an HIV-negative population, these software met WHO-recommended minimal accuracy for pulmonary tuberculosis triage tests. Sensitivity will be lower when smear-negative pulmonary tuberculosis is more prevalent.
FUNDING: Canadian Institutes of Health Research.",True,other,Not specified
33328047,Prediction of systemic biomarkers from retinal photographs: development and validation of deep-learning algorithms,"BACKGROUND: The application of deep learning to retinal photographs has yielded promising results in predicting age, sex, blood pressure, and haematological parameters. However, the broader applicability of retinal photograph-based deep learning for predicting other systemic biomarkers and the generalisability of this approach to various populations remains unexplored.
METHODS: With use of 236 257 retinal photographs from seven diverse Asian and European cohorts (two health screening centres in South Korea, the Beijing Eye Study, three cohorts in the Singapore Epidemiology of Eye Diseases study, and the UK Biobank), we evaluated the capacities of 47 deep-learning algorithms to predict 47 systemic biomarkers as outcome variables, including demographic factors (age and sex); body composition measurements; blood pressure; haematological parameters; lipid profiles; biochemical measures; biomarkers related to liver function, thyroid function, kidney function, and inflammation; and diabetes. The standard neural network architecture of VGG16 was adopted for model development.
FINDINGS: In addition to previously reported systemic biomarkers, we showed quantification of body composition indices (muscle mass, height, and bodyweight) and creatinine from retinal photographs. Body muscle mass could be predicted with an R2 of 0·52 (95% CI 0·51-0·53) in the internal test set, and of 0·33 (0·30-0·35) in one external test set with muscle mass measurement available. The R2 value for the prediction of height was 0·42 (0·40-0·43), of bodyweight was 0·36 (0·34-0·37), and of creatinine was 0·38 (0·37-0·40) in the internal test set. However, the performances were poorer in external test sets (with the lowest performance in the European cohort), with R2 values ranging between 0·08 and 0·28 for height, 0·04 and 0·19 for bodyweight, and 0·01 and 0·26 for creatinine. Of the 47 systemic biomarkers, 37 could not be predicted well from retinal photographs via deep learning (R2≤0·14 across all external test sets).
INTERPRETATION: Our work provides new insights into the potential use of retinal photographs to predict systemic biomarkers, including body composition indices and serum creatinine, using deep learning in populations with a similar ethnic background. Further evaluations are warranted to validate these findings and evaluate the clinical utility of these algorithms.
FUNDING: Agency for Science, Technology, and Research and National Medical Research Council, Singapore; Korea Institute for Advancement of Technology.",True,other,Not specified
33262137,Deep Learning Predicts HPV Association in Oropharyngeal Squamous Cell Carcinomas and Identifies Patients with a Favorable Prognosis Using Regular H&E Stains,"PURPOSE: Human papillomavirus (HPV) in oropharyngeal squamous cell carcinoma (OPSCC) is tumorigenic and has been associated with a favorable prognosis compared with OPSCC caused by tobacco, alcohol, and other carcinogens. Meanwhile, machine learning has evolved as a powerful tool to predict molecular and cellular alterations of medical images of various sources.
EXPERIMENTAL DESIGN: We generated a deep learning-based HPV prediction score (HPV-ps) on regular hematoxylin and eosin (H&amp;E) stains and assessed its performance to predict HPV association using 273 patients from two different sites (OPSCC; Giessen, n = 163; Cologne, n = 110). Then, the prognostic relevance in a total of 594 patients (Giessen, Cologne, HNSCC TCGA) was evaluated. In addition, we investigated whether four board-certified pathologists could identify HPV association (n = 152) and compared the results to the classifier.
RESULTS: Although pathologists were able to diagnose HPV association from H&amp;E-stained slides (AUC = 0.74, median of four observers), the interrater reliability was minimal (Light Kappa = 0.37; P = 0.129), as compared with AUC = 0.8 using the HPV-ps within two independent cohorts (n = 273). The HPV-ps identified individuals with a favorable prognosis in a total of 594 patients from three cohorts (Giessen, OPSCC, HR = 0.55, P &lt; 0.0001; Cologne, OPSCC, HR = 0.44, P = 0.0027; TCGA, non-OPSCC head and neck, HR = 0.69, P = 0.0073). Interestingly, the HPV-ps further stratified patients when combined with p16 status (Giessen, HR = 0.06, P &lt; 0.0001; Cologne, HR = 0.3, P = 0.046).
CONCLUSIONS: Detection of HPV association in OPSCC using deep learning with help of regular H&E stains may either be used as a single biomarker, or in combination with p16 status, to identify patients with OPSCC with a favorable prognosis, potentially outperforming combined HPV-DNA/p16 status as a biomarker for patient stratification.",True,other,Not specified
33239006,Machine-learning classification of texture features of portable chest X-ray accurately classifies COVID-19 lung infection,"BACKGROUND: The large volume and suboptimal image quality of portable chest X-rays (CXRs) as a result of the COVID-19 pandemic could post significant challenges for radiologists and frontline physicians. Deep-learning artificial intelligent (AI) methods have the potential to help improve diagnostic efficiency and accuracy for reading portable CXRs.
PURPOSE: The study aimed at developing an AI imaging analysis tool to classify COVID-19 lung infection based on portable CXRs.
MATERIALS AND METHODS: Public datasets of COVID-19 (N = 130), bacterial pneumonia (N = 145), non-COVID-19 viral pneumonia (N = 145), and normal (N = 138) CXRs were analyzed. Texture and morphological features were extracted. Five supervised machine-learning AI algorithms were used to classify COVID-19 from other conditions. Two-class and multi-class classification were performed. Statistical analysis was done using unpaired two-tailed t tests with unequal variance between groups. Performance of classification models used the receiver-operating characteristic (ROC) curve analysis.
RESULTS: For the two-class classification, the accuracy, sensitivity and specificity were, respectively, 100%, 100%, and 100% for COVID-19 vs normal; 96.34%, 95.35% and 97.44% for COVID-19 vs bacterial pneumonia; and 97.56%, 97.44% and 97.67% for COVID-19 vs non-COVID-19 viral pneumonia. For the multi-class classification, the combined accuracy and AUC were 79.52% and 0.87, respectively.
CONCLUSION: AI classification of texture and morphological features of portable CXRs accurately distinguishes COVID-19 lung infection in patients in multi-class datasets. Deep-learning methods have the potential to improve diagnostic efficiency and accuracy for portable CXRs.",True,other,Not specified
33231160,Deep Transfer Learning for COVID-19 Prediction: Case Study for Limited Data Problems,"OBJECTIVE: Automatic prediction of COVID-19 using deep convolution neural networks based pre-trained transfer models and Chest X-ray images.
METHODS: This research employs the advantages of computer vision and medical image analysis to develop an automated model that has the clinical potential for early detection of the disease. Using Deep Learning models, the research aims at evaluating the effectiveness and accuracy of different convolutional neural networks models in the automatic diagnosis of COVID-19 from X-ray images as compared to diagnosis performed by experts in the medical community.
RESULTS: Due to the fact that the dataset available for COVID-19 is still limited, the best model to use is the InceptionNetV3. Performance results show that the InceptionNetV3 model yielded the highest accuracy of 98.63% (with data augmentation) and 98.90% (without data augmentation) among the three models designed. However, as the dataset gets bigger, the Inception ResNetV2 and NASNetlarge will do a better job of classification. All the performed networks tend to over-fit when data augmentation is not used, this is due to the small amount of data used for training and validation.
CONCLUSION: A deep transfer learning is proposed to detecting the COVID-19 automatically from chest X-ray by training it with X-ray images gotten from both COVID-19 patients and people with normal chest X-rays. The study is aimed at helping doctors in making decisions in their clinical practice due its high performance and effectiveness, the study also gives an insight to how transfer learning was used to automatically detect the COVID-19.",True,other,convolutional neural network
33215473,Deep learning applications to combat the dissemination of COVID-19 disease: a review,"Recent Coronavirus (COVID-19) is one of the respiratory diseases, and it is known as fast infectious ability. This dissemination can be decelerated by diagnosing and quarantining patients with COVID-19 at early stages, thereby saving numerous lives. Reverse transcription-polymerase chain reaction (RT-PCR) is known as one of the primary diagnostic tools. However, RT-PCR tests are costly and time-consuming; it also requires specific materials, equipment, and instruments. Moreover, most countries are suffering from a lack of testing kits because of limitations on budget and techniques. Thus, this standard method is not suitable to meet the requirements of fast detection and tracking during the COVID-19 pandemic, which motived to employ deep learning (DL)/convolutional neural networks (CNNs) technology with X-ray and CT scans for efficient analysis and diagnostic. This study provides insight about the literature that discussed the deep learning technology and its various techniques that are recently developed to combat the dissemination of COVID-19 disease.",True,other,Not specified
33208341,Using Machine Learning Algorithms to Predict Immunotherapy Response in Patients with Advanced Melanoma,"PURPOSE: Several biomarkers of response to immune checkpoint inhibitors (ICI) show potential but are not yet scalable to the clinic. We developed a pipeline that integrates deep learning on histology specimens with clinical data to predict ICI response in advanced melanoma.
EXPERIMENTAL DESIGN: We used a training cohort from New York University (New York, NY) and a validation cohort from Vanderbilt University (Nashville, TN). We built a multivariable classifier that integrates neural network predictions with clinical data. A ROC curve was generated and the optimal threshold was used to stratify patients as high versus low risk for progression. Kaplan-Meier curves compared progression-free survival (PFS) between the groups. The classifier was validated on two slide scanners (Aperio AT2 and Leica SCN400).
RESULTS: The multivariable classifier predicted response with AUC 0.800 on images from the Aperio AT2 and AUC 0.805 on images from the Leica SCN400. The classifier accurately stratified patients into high versus low risk for disease progression. Vanderbilt patients classified as high risk for progression had significantly worse PFS than those classified as low risk (P = 0.02 for the Aperio AT2; P = 0.03 for the Leica SCN400).
CONCLUSIONS: Histology slides and patients' clinicodemographic characteristics are readily available through standard of care and have the potential to predict ICI treatment outcomes. With prospective validation, we believe our approach has potential for integration into clinical practice.",True,other,Not specified
33184301,"Context aware deep learning for brain tumor segmentation, subtype classification, and survival prediction using radiology images","A brain tumor is an uncontrolled growth of cancerous cells in the brain. Accurate segmentation and classification of tumors are critical for subsequent prognosis and treatment planning. This work proposes context aware deep learning for brain tumor segmentation, subtype classification, and overall survival prediction using structural multimodal magnetic resonance images (mMRI). We first propose a 3D context aware deep learning, that considers uncertainty of tumor location in the radiology mMRI image sub-regions, to obtain tumor segmentation. We then apply a regular 3D convolutional neural network (CNN) on the tumor segments to achieve tumor subtype classification. Finally, we perform survival prediction using a hybrid method of deep learning and machine learning. To evaluate the performance, we apply the proposed methods to the Multimodal Brain Tumor Segmentation Challenge 2019 (BraTS 2019) dataset for tumor segmentation and overall survival prediction, and to the dataset of the Computational Precision Medicine Radiology-Pathology (CPM-RadPath) Challenge on Brain Tumor Classification 2019 for tumor classification. We also perform an extensive performance evaluation based on popular evaluation metrics, such as Dice score coefficient, Hausdorff distance at percentile 95 (HD95), classification accuracy, and mean square error. The results suggest that the proposed method offers robust tumor segmentation and survival prediction, respectively. Furthermore, the tumor classification results in this work is ranked at second place in the testing phase of the 2019 CPM-RadPath global challenge.",True,other,convolutional neural network
33139755,Spatial transcriptomics inferred from pathology whole-slide images links tumor heterogeneity to survival in breast and lung cancer,"Digital analysis of pathology whole-slide images is fast becoming a game changer in cancer diagnosis and treatment. Specifically, deep learning methods have shown great potential to support pathology analysis, with recent studies identifying molecular traits that were not previously recognized in pathology H&E whole-slide images. Simultaneous to these developments, it is becoming increasingly evident that tumor heterogeneity is an important determinant of cancer prognosis and susceptibility to treatment, and should therefore play a role in the evolving practices of matching treatment protocols to patients. State of the art diagnostic procedures, however, do not provide automated methods for characterizing and/or quantifying tumor heterogeneity, certainly not in a spatial context. Further, existing methods for analyzing pathology whole-slide images from bulk measurements require many training samples and complex pipelines. Our work addresses these two challenges. First, we train deep learning models to spatially resolve bulk mRNA and miRNA expression levels on pathology whole-slide images (WSIs). Our models reach up to 0.95 AUC on held-out test sets from two cancer cohorts using a simple training pipeline and a small number of training samples. Using the inferred gene expression levels, we further develop a method to spatially characterize tumor heterogeneity. Specifically, we produce tumor molecular cartographies and heterogeneity maps of WSIs and formulate a heterogeneity index (HTI) that quantifies the level of heterogeneity within these maps. Applying our methods to breast and lung cancer slides, we show a significant statistical link between heterogeneity and survival. Our methods potentially open a new and accessible approach to investigating tumor heterogeneity and other spatial molecular properties and their link to clinical characteristics, including treatment susceptibility and survival.",True,other,Not specified
32973220,2D and 3D convolutional neural networks for outcome modelling of locally advanced head and neck squamous cell carcinoma,"For treatment individualisation of patients with locally advanced head and neck squamous cell carcinoma (HNSCC) treated with primary radiochemotherapy, we explored the capabilities of different deep learning approaches for predicting loco-regional tumour control (LRC) from treatment-planning computed tomography images. Based on multicentre cohorts for exploration (206 patients) and independent validation (85 patients), multiple deep learning strategies including training of 3D- and 2D-convolutional neural networks (CNN) from scratch, transfer learning and extraction of deep autoencoder features were assessed and compared to a clinical model. Analyses were based on Cox proportional hazards regression and model performances were assessed by the concordance index (C-index) and the model's ability to stratify patients based on predicted hazards of LRC. Among all models, an ensemble of 3D-CNNs achieved the best performance (C-index 0.31) with a significant association to LRC on the independent validation cohort. It performed better than the clinical model including the tumour volume (C-index 0.39). Significant differences in LRC were observed between patient groups at low or high risk of tumour recurrence as predicted by the model ([Formula: see text]). This 3D-CNN ensemble will be further evaluated in a currently ongoing prospective validation study once follow-up is complete.",True,other,autoencoder
32929383,Tumor immune profiles noninvasively estimated by FDG PET with deep learning correlate with immunotherapy response in lung adenocarcinoma,"Rationale: The clinical application of biomarkers reflecting tumor immune microenvironment is hurdled by the invasiveness of obtaining tissues despite its importance in immunotherapy. We developed a deep learning-based biomarker which noninvasively estimates a tumor immune profile with fluorodeoxyglucose positron emission tomography (FDG-PET) in lung adenocarcinoma (LUAD). Methods: A deep learning model to predict cytolytic activity score (CytAct) using semi-automatically segmented tumors on FDG-PET trained by a publicly available dataset paired with tissue RNA sequencing (n = 93). This model was validated in two independent cohorts of LUAD: SNUH (n = 43) and The Cancer Genome Atlas (TCGA) cohort (n = 16). The model was applied to the immune checkpoint blockade (ICB) cohort, which consists of patients with metastatic LUAD who underwent ICB treatment (n = 29). Results: The predicted CytAct showed a positive correlation with CytAct of RNA sequencing in validation cohorts (Spearman rho = 0.32, p = 0.04 in SNUH cohort; spearman rho = 0.47, p = 0.07 in TCGA cohort). In ICB cohort, the higher predicted CytAct of individual lesion was associated with more decrement in tumor size after ICB treatment (Spearman rho = -0.54, p &lt; 0.001). Higher minimum predicted CytAct in each patient associated with significantly prolonged progression free survival and overall survival (Hazard ratio 0.25, p = 0.001 and 0.18, p = 0.004, respectively). In patients with multiple lesions, ICB responders had significantly lower variance of predicted CytActs (p = 0.005). Conclusion: The deep learning model that predicts CytAct using FDG-PET of LUAD was validated in independent cohorts. Our approach may be used to noninvasively assess an immune profile and predict outcomes of LUAD patients treated with ICB.",True,other,Not specified
32821348,The role of artificial intelligence in colon polyps detection,"Over the past few decades, artificial intelligence (AI) has evolved dramatically and is believed to have a significant impact on all aspects of technology and daily life. The use of AI in the healthcare system has been rapidly growing, owing to the large amount of data. Various methods of AI including machine learning, deep learning and convolutional neural network (CNN) have been used in diagnostic imaging, which have helped physicians in the accurate diagnosis of diseases and determination of appropriate treatment for them. Using and collecting a huge number of digital images and medical records has led to the creation of big data over a time period. Currently, considerations regarding the diagnosis of various presentations in all endoscopic procedures and imaging findings are solely handled by endoscopists. Moreover, AI has shown to be highly effective in the field of gastroenterology in terms of diagnosis, prognosis, and image processing. Herein, this review aimed to discuss different aspects of AI use for early detection and treatment of gastroenterology diseases.",True,other,CNN
32814641,"Artificial intelligence-assisted cytology for detection of cervical intraepithelial neoplasia or invasive cancer: A multicenter, clinical-based, observational study","OBJECTIVE: Artificial intelligence (AI) could automatedly detect abnormalities in digital cytological images, however, the effect in cervical cancer screening is inconclusive. We aim to evaluate the performance of AI-assisted cytology for the detection of histologically cervical intraepithelial lesions (CIN) or cancer.
METHODS: We trained a supervised deep learning algorithm based on 188,542 digital cytological images. Between Mar 13, 2017, and Oct 20, 2018, 2145 referral women from organized screening were enrolled in a multicenter, clinical-based, observational study. Cervical specimen was sampled to generate two liquid-based slides: one random slide was allocated to AI-assisted reading, and the other to manual reading conducted by skilled cytologists from senior hospital and cytology doctors from primary hospitals. HPV testing and colposcopy-directed biopsy was performed, and histological result was regarded as reference. We calculated the relative sensitivity and relative specificity of AI-assisted reading compared to manual reading for CIN2+. This trial was registered, number ChiCTR2000034131.
RESULTS: In the referral population, AI-assisted reading detected 92.6% of CIN 2 and 96.1% of CIN 3+, significantly higher than or similar to manual reading. AI-assisted reading had equivalent sensitivity (relative sensitivity 1.01, 95%CI, 0.97-1.05) and higher specificity (relative specificity 1.26, 1.20-1.32) compared to skilled cytologists; whereas higher sensitivity (1.12, 1.05-1.20) and specificity (1.36, 1.25-1.48) compared to cytology doctors. In HPV-positive women, AI-assisted reading improved specificity for CIN1 or less at no expense of reduction of sensitivity compared to manual reading.
CONCLUSIONS: AI-assisted cytology may contribute to the primary cytology screening or triage. Further studies are needed in general population.",True,other,recurrent neural network
32796848,Artificial intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets,"Chest CT is emerging as a valuable diagnostic tool for clinical management of COVID-19 associated lung disease. Artificial intelligence (AI) has the potential to aid in rapid evaluation of CT scans for differentiation of COVID-19 findings from other clinical entities. Here we show that a series of deep learning algorithms, trained in a diverse multinational cohort of 1280 patients to localize parietal pleura/lung parenchyma followed by classification of COVID-19 pneumonia, can achieve up to 90.8% accuracy, with 84% sensitivity and 93% specificity, as evaluated in an independent test set (not included in training and validation) of 1337 patients. Normal controls included chest CTs from oncology, emergency, and pneumonia-related indications. The false positive rate in 140 patients with laboratory confirmed other (non COVID-19) pneumonias was 10%. AI-based algorithms can readily identify CT scans with COVID-19 associated pneumonia, as well as distinguish non-COVID related pneumonias with high specificity in diverse patient populations.",True,other,Not specified
32733596,An Intelligent Diagnosis Method of Brain MRI Tumor Segmentation Using Deep Convolutional Neural Network and SVM Algorithm,"Among the currently proposed brain segmentation methods, brain tumor segmentation methods based on traditional image processing and machine learning are not ideal enough. Therefore, deep learning-based brain segmentation methods are widely used. In the brain tumor segmentation method based on deep learning, the convolutional network model has a good brain segmentation effect. The deep convolutional network model has the problems of a large number of parameters and large loss of information in the encoding and decoding process. This paper proposes a deep convolutional neural network fusion support vector machine algorithm (DCNN-F-SVM). The proposed brain tumor segmentation model is mainly divided into three stages. In the first stage, a deep convolutional neural network is trained to learn the mapping from image space to tumor marker space. In the second stage, the predicted labels obtained from the deep convolutional neural network training are input into the integrated support vector machine classifier together with the test images. In the third stage, a deep convolutional neural network and an integrated support vector machine are connected in series to train a deep classifier. Run each model on the BraTS dataset and the self-made dataset to segment brain tumors. The segmentation results show that the performance of the proposed model is significantly better than the deep convolutional neural network and the integrated SVM classifier.",True,other,convolutional neural network
32555646,Deep learning-based survival prediction for multiple cancer types using histopathology images,"Providing prognostic information at the time of cancer diagnosis has important implications for treatment and monitoring. Although cancer staging, histopathological assessment, molecular features, and clinical variables can provide useful prognostic insights, improving risk stratification remains an active research area. We developed a deep learning system (DLS) to predict disease specific survival across 10 cancer types from The Cancer Genome Atlas (TCGA). We used a weakly-supervised approach without pixel-level annotations, and tested three different survival loss functions. The DLS was developed using 9,086 slides from 3,664 cases and evaluated using 3,009 slides from 1,216 cases. In multivariable Cox regression analysis of the combined cohort including all 10 cancers, the DLS was significantly associated with disease specific survival (hazard ratio of 1.58, 95% CI 1.28-1.70, p<0.0001) after adjusting for cancer type, stage, age, and sex. In a per-cancer adjusted subanalysis, the DLS remained a significant predictor of survival in 5 of 10 cancer types. Compared to a baseline model including stage, age, and sex, the c-index of the model demonstrated an absolute 3.7% improvement (95% CI 1.0-6.5) in the combined cohort. Additionally, our models stratified patients within individual cancer stages, particularly stage II (p = 0.025) and stage III (p<0.001). By developing and evaluating prognostic models across multiple cancer types, this work represents one of the most comprehensive studies exploring the direct prediction of clinical outcomes using deep learning and histopathology images. Our analysis demonstrates the potential for this approach to provide significant prognostic information in multiple cancer types, and even within specific pathologic stages. However, given the relatively small number of cases and observed clinical events for a deep learning task of this type, we observed wide confidence intervals for model performance, thus highlighting that future work will benefit from larger datasets assembled for the purposes for survival modeling.",True,other,Not specified
32442672,Deep-Hipo: Multi-scale receptive field deep learning for histopathological image analysis,"Digitizing whole-slide imaging in digital pathology has led to the advancement of computer-aided tissue examination using machine learning techniques, especially convolutional neural networks. A number of convolutional neural network-based methodologies have been proposed to accurately analyze histopathological images for cancer detection, risk prediction, and cancer subtype classification. Most existing methods have conducted patch-based examinations, due to the extremely large size of histopathological images. However, patches of a small window often do not contain sufficient information or patterns for the tasks of interest. It corresponds that pathologists also examine tissues at various magnification levels, while checking complex morphological patterns in a microscope. We propose a novel multi-task based deep learning model for HIstoPatholOgy (named Deep-Hipo) that takes multi-scale patches simultaneously for accurate histopathological image analysis. Deep-Hipo extracts two patches of the same size in both high and low magnification levels, and captures complex morphological patterns in both large and small receptive fields of a whole-slide image. Deep-Hipo has outperformed the current state-of-the-art deep learning methods. We assessed the proposed method in various types of whole-slide images of the stomach: well-differentiated, moderately-differentiated, and poorly-differentiated adenocarcinoma; poorly cohesive carcinoma, including signet-ring cell features; and normal gastric mucosa. The optimally trained model was also applied to histopathological images of The Cancer Genome Atlas (TCGA), Stomach Adenocarcinoma (TCGA-STAD) and TCGA Colon Adenocarcinoma (TCGA-COAD), which show similar pathological patterns with gastric carcinoma, and the experimental results were clinically verified by a pathologist. The source code of Deep-Hipo is publicly available athttp://dataxlab.org/deep-hipo.",True,other,convolutional neural network
32277744,Emerging role of deep learning-based artificial intelligence in tumor pathology,"The development of digital pathology and progression of state-of-the-art algorithms for computer vision have led to increasing interest in the use of artificial intelligence (AI), especially deep learning (DL)-based AI, in tumor pathology. The DL-based algorithms have been developed to conduct all kinds of work involved in tumor pathology, including tumor diagnosis, subtyping, grading, staging, and prognostic prediction, as well as the identification of pathological features, biomarkers and genetic changes. The applications of AI in pathology not only contribute to improve diagnostic accuracy and objectivity but also reduce the workload of pathologists and subsequently enable them to spend additional time on high-level decision-making tasks. In addition, AI is useful for pathologists to meet the requirements of precision oncology. However, there are still some challenges relating to the implementation of AI, including the issues of algorithm validation and interpretability, computing systems, the unbelieving attitude of pathologists, clinicians and patients, as well as regulators and reimbursements. Herein, we present an overview on how AI-based approaches could be integrated into the workflow of pathologists and discuss the challenges and perspectives of the implementation of AI in tumor pathology.",True,other,Not specified
32241264,Deep learning-based cancer survival prognosis from RNA-seq data: approaches and evaluations,"BACKGROUND: Recent advances in kernel-based Deep Learning models have introduced a new era in medical research. Originally designed for pattern recognition and image processing, Deep Learning models are now applied to survival prognosis of cancer patients. Specifically, Deep Learning versions of the Cox proportional hazards models are trained with transcriptomic data to predict survival outcomes in cancer patients.
METHODS: In this study, a broad analysis was performed on TCGA cancers using a variety of Deep Learning-based models, including Cox-nnet, DeepSurv, and a method proposed by our group named AECOX (AutoEncoder with Cox regression network). Concordance index and p-value of the log-rank test are used to evaluate the model performances.
RESULTS: All models show competitive results across 12 cancer types. The last hidden layers of the Deep Learning approaches are lower dimensional representations of the input data that can be used for feature reduction and visualization. Furthermore, the prognosis performances reveal a negative correlation between model accuracy, overall survival time statistics, and tumor mutation burden (TMB), suggesting an association among overall survival time, TMB, and prognosis prediction accuracy.
CONCLUSIONS: Deep Learning based algorithms demonstrate superior performances than traditional machine learning based models. The cancer prognosis results measured in concordance index are indistinguishable across models while are highly variable across cancers. These findings shedding some light into the relationships between patient characteristics and survival learnability on a pan-cancer level.",True,other,Not specified
32134976,Exploring the effect of hypertension on retinal microvasculature using deep learning on East Asian population,"Hypertension is the leading risk factor of cardiovascular disease and has profound effects on both the structure and function of the microvasculature. Abnormalities of the retinal vasculature may reflect the degree of microvascular damage due to hypertension, and these changes can be detected with fundus photographs. This study aimed to use deep learning technique that can detect subclinical features appearing below the threshold of a human observer to explore the effect of hypertension on morphological features of retinal microvasculature. We collected 2012 retinal photographs which included 1007 from patients with a diagnosis of hypertension and 1005 from normotensive control. By method of vessel segmentation, we removed interference information other than retinal vasculature and contained only morphological information about blood vessels. Using these segmented images, we trained a small convolutional neural networks (CNN) classification model and used a deep learning technique called Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heat maps for the class ""hypertension"". Our model achieved an accuracy of 60.94%, a specificity of 51.54%, a precision of 59.27%, and a recall of 70.48%. The AUC was 0.6506. In the heat maps for the class ""hypertension"", red patchy areas were mainly distributed on or around arterial/venous bifurcations. This indicated that the model has identified these regions as being the most important for predicting hypertension. Our study suggested that the effect of hypertension on retinal microvascular morphology mainly occurred at branching of vessels. The change of the branching pattern of retinal vessels was probably the most significant in response to elevated blood pressure.",True,other,Not specified
32134949,Deep learning approach to classification of lung cytological images: Two-step training using actual and synthesized images by progressive growing of generative adversarial networks,"Cytology is the first pathological examination performed in the diagnosis of lung cancer. In our previous study, we introduced a deep convolutional neural network (DCNN) to automatically classify cytological images as images with benign or malignant features and achieved an accuracy of 81.0%. To further improve the DCNN's performance, it is necessary to train the network using more images. However, it is difficult to acquire cell images which contain a various cytological features with the use of many manual operations with a microscope. Therefore, in this study, we aim to improve the classification accuracy of a DCNN with the use of actual and synthesized cytological images with a generative adversarial network (GAN). Based on the proposed method, patch images were obtained from a microscopy image. Accordingly, these generated many additional similar images using a GAN. In this study, we introduce progressive growing of GANs (PGGAN), which enables the generation of high-resolution images. The use of these images allowed us to pretrain a DCNN. The DCNN was then fine-tuned using actual patch images. To confirm the effectiveness of the proposed method, we first evaluated the quality of the images which were generated by PGGAN and by a conventional deep convolutional GAN. We then evaluated the classification performance of benign and malignant cells, and confirmed that the generated images had characteristics similar to those of the actual images. Accordingly, we determined that the overall classification accuracy of lung cells was 85.3% which was improved by approximately 4.3% compared to a previously conducted study without pretraining using GAN-generated images. Based on these results, we confirmed that our proposed method will be effective for the classification of cytological images in cases at which only limited data are acquired.",True,other,convolutional neural network
32128929,Artificial intelligence as the next step towards precision pathology,"Pathology is the cornerstone of cancer care. The need for accuracy in histopathologic diagnosis of cancer is increasing as personalized cancer therapy requires accurate biomarker assessment. The appearance of digital image analysis holds promise to improve both the volume and precision of histomorphological evaluation. Recently, machine learning, and particularly deep learning, has enabled rapid advances in computational pathology. The integration of machine learning into routine care will be a milestone for the healthcare sector in the next decade, and histopathology is right at the centre of this revolution. Examples of potential high-value machine learning applications include both model-based assessment of routine diagnostic features in pathology, and the ability to extract and identify novel features that provide insights into a disease. Recent groundbreaking results have demonstrated that applications of machine learning methods in pathology significantly improves metastases detection in lymph nodes, Ki67 scoring in breast cancer, Gleason grading in prostate cancer and tumour-infiltrating lymphocyte (TIL) scoring in melanoma. Furthermore, deep learning models have also been demonstrated to be able to predict status of some molecular markers in lung, prostate, gastric and colorectal cancer based on standard HE slides. Moreover, prognostic (survival outcomes) deep neural network models based on digitized HE slides have been demonstrated in several diseases, including lung cancer, melanoma and glioma. In this review, we aim to present and summarize the latest developments in digital image analysis and in the application of artificial intelligence in diagnostic pathology.",True,other,Not specified
31981309,Deep Learning-Based Single-Cell Optical Image Studies,"Optical imaging technology that has the advantages of high sensitivity and cost-effectiveness greatly promotes the progress of nondestructive single-cell studies. Complex cellular image analysis tasks such as three-dimensional reconstruction call for machine-learning technology in cell optical image research. With the rapid developments of high-throughput imaging flow cytometry, big data cell optical images are always obtained that may require machine learning for data analysis. In recent years, deep learning has been prevalent in the field of machine learning for large-scale image processing and analysis, which brings a new dawn for single-cell optical image studies with an explosive growth of data availability. Popular deep learning techniques offer new ideas for multimodal and multitask single-cell optical image research. This article provides an overview of the basic knowledge of deep learning and its applications in single-cell optical image studies. We explore the feasibility of applying deep learning techniques to single-cell optical image analysis, where popular techniques such as transfer learning, multimodal learning, multitask learning, and end-to-end learning have been reviewed. Image preprocessing and deep learning model training methods are then summarized. Applications based on deep learning techniques in the field of single-cell optical image studies are reviewed, which include image segmentation, super-resolution image reconstruction, cell tracking, cell counting, cross-modal image reconstruction, and design and control of cell imaging systems. In addition, deep learning in popular single-cell optical imaging techniques such as label-free cell optical imaging, high-content screening, and high-throughput optical imaging cytometry are also mentioned. Finally, the perspectives of deep learning technology for single-cell optical image analysis are discussed. © 2020 International Society for Advancement of Cytometry.",True,other,recurrent neural network
31902041,Prevalence and Diagnosis of Neurological Disorders Using Different Deep Learning Techniques: A Meta-Analysis,"This paper dispenses an exhaustive review on deep learning techniques used in the prognosis of eight different neuropsychiatric and neurological disorders such as stroke, alzheimer, parkinson's, epilepsy, autism, migraine, cerebral palsy, and multiple sclerosis. These diseases are critical, life-threatening and in most of the cases may lead to other precarious human disorders. Deep learning techniques are emerging soft computing technique which has been lucratively used to unravel different real-life problems such as pattern recognition (Face, Emotion, and Speech), traffic management, drug discovery, disease diagnosis, and network intrusion detection. This study confers the discipline, frameworks, and methodologies used by different deep learning techniques to diagnose different human neurological disorders. Here, one hundred and thirty-six different articles related to neurological and neuropsychiatric disorders diagnosed using different deep learning techniques are studied. The morbidity and mortality rate of major neuropsychiatric and neurological disorders has also been delineated. The performance and publication trend of different deep learning techniques employed in the investigation of these diseases has been examined and analyzed. Different performance metrics like accuracy, specificity, and sensitivity have also been examined. The research implication, challenges and the future directions related to the study have also been highlighted. Eventually, the research breaches are identified and it is witnessed that there is more scope in the diagnosis of migraine, cerebral palsy and stroke using different deep learning models. Likewise, there is a potential opportunity to use and explore the performance of Restricted Boltzmann Machine, Deep Boltzmann Machine and Deep Belief Network for diagnosis of different human neuropsychiatric and neurological disorders.",True,other,convolutional neural network
31860791,Deep learning pathological microscopic features in endemic nasopharyngeal cancer: Prognostic value and protentional role for individual induction chemotherapy,"BACKGROUND: To explore the prognostic value and the role for treatment decision of pathological microscopic features in patients with nasopharyngeal carcinoma (NPC) using the method of deep learning.
METHODS: The pathological microscopic features were extracted using the software QuPath (version 0.1.3. Queen's University) in the training cohort (Guangzhou training cohort, n = 843). We used the neural network DeepSurv to analyze the pathological microscopic features (DSPMF) and then classified patients into high-risk and low-risk groups through the time-dependent receiver operating characteristic (ROC). The prognosis accuracy of the pathological feature was validated in a validation cohort (n = 212). The primary endpoint was progression-free survival (PFS).
RESULTS: We found 429 pathological microscopic features in the H&E image. Patients with high-risk scores in the training cohort had shorter 5-year PFS (HR 10.03, 6.06-16.61; P < .0001). The DSPMF (C-index: 0.723) had the higher C-index than the EBV DNA (C-index: 0.612) copies and the N stage (C-index: 0.593). Furthermore, induction chemotherapy (ICT) plus concomitant chemoradiotherapy (CCRT) had better 5-year PFS to those received CCRT (P < .0001) in the high-risk group.
CONCLUSION: The DSPMF is a reliable prognostic tool for survival risk in patients with NPC and might be able to guide the treatment decision.",True,other,Not specified
31636101,Deep Learning Based on Standard H&E Images of Primary Melanoma Tumors Identifies Patients at Risk for Visceral Recurrence and Death,"PURPOSE: Biomarkers for disease-specific survival (DSS) in early-stage melanoma are needed to select patients for adjuvant immunotherapy and accelerate clinical trial design. We present a pathology-based computational method using a deep neural network architecture for DSS prediction.
EXPERIMENTAL DESIGN: The model was trained on 108 patients from four institutions and tested on 104 patients from Yale School of Medicine (YSM, New Haven, CT). A receiver operating characteristic (ROC) curve was generated on the basis of vote aggregation of individual image sequences, an optimized cutoff was selected, and the computational model was tested on a third independent population of 51 patients from Geisinger Health Systems (GHS).
RESULTS: Area under the curve (AUC) in the YSM patients was 0.905 (P &lt; 0.0001). AUC in the GHS patients was 0.880 (P &lt; 0.0001). Using the cutoff selected in the YSM cohort, the computational model predicted DSS in the GHS cohort based on Kaplan-Meier (KM) analysis (P &lt; 0.0001).
CONCLUSIONS: The novel method presented is applicable to digital images, obviating the need for sample shipment and manipulation and representing a practical advance over current genetic and IHC-based methods.",True,both,Not specified
31537506,Technical and Clinical Factors Affecting Success Rate of a Deep Learning Method for Pancreas Segmentation on CT,"PURPOSE: Accurate pancreas segmentation has application in surgical planning, assessment of diabetes, and detection and analysis of pancreatic tumors. Factors that affect pancreas segmentation accuracy have not been previously reported. The purpose of this study is to identify technical and clinical factors that adversely affect the accuracy of pancreas segmentation on CT.
METHOD AND MATERIALS: In this IRB and HIPAA compliant study, a deep convolutional neural network was used for pancreas segmentation in a publicly available archive of 82 portal-venous phase abdominal CT scans of 53 men and 29 women. The accuracies of the segmentations were evaluated by the Dice similarity coefficient (DSC). The DSC was then correlated with demographic and clinical data (age, gender, height, weight, body mass index), CT technical factors (image pixel size, slice thickness, presence or absence of oral contrast), and CT imaging findings (volume and attenuation of pancreas, visceral abdominal fat, and CT attenuation of the structures within a 5 mm neighborhood of the pancreas).
RESULTS: The average DSC was 78% ± 8%. Factors that were statistically significantly correlated with DSC included body mass index (r = 0.34, p < 0.01), visceral abdominal fat (r = 0.51, p < 0.0001), volume of the pancreas (r = 0.41, p = 0.001), standard deviation of CT attenuation within the pancreas (r = 0.30, p = 0.01), and median and average CT attenuation in the immediate neighborhood of the pancreas (r = -0.53, p < 0.0001 and r = -0.52, p < 0.0001). There were no significant correlations between the DSC and the height, gender, or mean CT attenuation of the pancreas.
CONCLUSION: Increased visceral abdominal fat and accumulation of fat within or around the pancreas are major factors associated with more accurate segmentation of the pancreas. Potential applications of our findings include assessment of pancreas segmentation difficulty of a particular scan or dataset and identification of methods that work better for more challenging pancreas segmentations.",True,both,Not specified
31324828,Pan-Renal Cell Carcinoma classification and survival prediction from histopathology images using deep learning,"Histopathological images contain morphological markers of disease progression that have diagnostic and predictive values. In this study, we demonstrate how deep learning framework can be used for an automatic classification of Renal Cell Carcinoma (RCC) subtypes, and for identification of features that predict survival outcome from digital histopathological images. Convolutional neural networks (CNN's) trained on whole-slide images distinguish clear cell and chromophobe RCC from normal tissue with a classification accuracy of 93.39% and 87.34%, respectively. Further, a CNN trained to distinguish clear cell, chromophobe and papillary RCC achieves a classification accuracy of 94.07%. Here, we introduced a novel support vector machine-based method that helped to break the multi-class classification task into multiple binary classification tasks which not only improved the performance of the model but also helped to deal with data imbalance. Finally, we extracted the morphological features from high probability tumor regions identified by the CNN to predict patient survival outcome of most common clear cell RCC. The generated risk index based on both tumor shape and nuclei features are significantly associated with patient survival outcome. These results highlight that deep learning can play a role in both cancer diagnosis and prognosis.",True,other,convolutional neural network
31307769,On-field player workload exposure and knee injury risk monitoring via deep learning,"In sports analytics, an understanding of accurate on-field 3D knee joint moments (KJM) could provide an early warning system for athlete workload exposure and knee injury risk. Traditionally, this analysis has relied on captive laboratory force plates and associated downstream biomechanical modeling, and many researchers have approached the problem of portability by extrapolating models built on linear statistics. An alternative approach would be to capitalize on recent advances in deep learning. In this study, using the pre-trained CaffeNet convolutional neural network (CNN) model, multivariate regression of marker-based motion capture to 3D KJM for three sports-related movement types were compared. The strongest overall mean correlation to source modeling of 0.8895 was achieved over the initial 33% of stance phase for sidestepping. The accuracy of these mean predictions of the three critical KJM associated with anterior cruciate ligament (ACL) injury demonstrate the feasibility of on-field knee injury assessment using deep learning in lieu of laboratory embedded force plates. This multidisciplinary research approach significantly advances machine representation of real-world physical models with practical application for both community and professional level athletes.",True,other,convolutional neural network
31243076,mSphere of Influence: the Rise of Artificial Intelligence in Infection Biology,"Artur Yakimovich works in the field of computational virology and applies machine learning algorithms to study host-pathogen interactions. In this mSphere of Influence article, he reflects on two papers ""Holographic Deep Learning for Rapid Optical Screening of Anthrax Spores"" by Jo et al. (Y. Jo, S. Park, J. Jung, J. Yoon, et al., Sci Adv 3:e1700606, 2017, https://doi.org/10.1126/sciadv.1700606) and ""Bacterial Colony Counting with Convolutional Neural Networks in Digital Microbiology Imaging"" by Ferrari and colleagues (A. Ferrari, S. Lombardi, and A. Signoroni, Pattern Recognition 61:629-640, 2017, https://doi.org/10.1016/j.patcog.2016.07.016). Here he discusses how these papers made an impact on him by showcasing that artificial intelligence algorithms can be equally applicable to both classical infection biology techniques and cutting-edge label-free imaging of pathogens.",True,other,convolutional neural network
31177973,Big Data Approaches to Phenotyping Acute Ischemic Stroke Using Automated Lesion Segmentation of Multi-Center Magnetic Resonance Imaging Data,"Background and Purpose- We evaluated deep learning algorithms' segmentation of acute ischemic lesions on heterogeneous multi-center clinical diffusion-weighted magnetic resonance imaging (MRI) data sets and explored the potential role of this tool for phenotyping acute ischemic stroke. Methods- Ischemic stroke data sets from the MRI-GENIE (MRI-Genetics Interface Exploration) repository consisting of 12 international genetic research centers were retrospectively analyzed using an automated deep learning segmentation algorithm consisting of an ensemble of 3-dimensional convolutional neural networks. Three ensembles were trained using data from the following: (1) 267 patients from an independent single-center cohort, (2) 267 patients from MRI-GENIE, and (3) mixture of (1) and (2). The algorithms' performances were compared against manual outlines from a separate 383 patient subset from MRI-GENIE. Univariable and multivariable logistic regression with respect to demographics, stroke subtypes, and vascular risk factors were performed to identify phenotypes associated with large acute diffusion-weighted MRI volumes and greater stroke severity in 2770 MRI-GENIE patients. Stroke topography was investigated. Results- The ensemble consisting of a mixture of MRI-GENIE and single-center convolutional neural networks performed best. Subset analysis comparing automated and manual lesion volumes in 383 patients found excellent correlation (ρ=0.92; P&lt;0.0001). Median (interquartile range) diffusion-weighted MRI lesion volumes from 2770 patients were 3.7 cm3 (0.9-16.6 cm3). Patients with small artery occlusion stroke subtype had smaller lesion volumes ( P&lt;0.0001) and different topography compared with other stroke subtypes. Conclusions- Automated accurate clinical diffusion-weighted MRI lesion segmentation using deep learning algorithms trained with multi-center and diverse data is feasible. Both lesion volume and topography can provide insight into stroke subtypes with sufficient sample size from big heterogeneous multi-center clinical imaging phenotype data sets.",True,other,convolutional neural network
30629194,An Observational Study of Deep Learning and Automated Evaluation of Cervical Images for Cancer Screening,"BACKGROUND: Human papillomavirus vaccination and cervical screening are lacking in most lower resource settings, where approximately 80% of more than 500 000 cancer cases occur annually. Visual inspection of the cervix following acetic acid application is practical but not reproducible or accurate. The objective of this study was to develop a ""deep learning""-based visual evaluation algorithm that automatically recognizes cervical precancer/cancer.
METHODS: A population-based longitudinal cohort of 9406 women ages 18-94 years in Guanacaste, Costa Rica was followed for 7 years (1993-2000), incorporating multiple cervical screening methods and histopathologic confirmation of precancers. Tumor registry linkage identified cancers up to 18 years. Archived, digitized cervical images from screening, taken with a fixed-focus camera (""cervicography""), were used for training/validation of the deep learning-based algorithm. The resultant image prediction score (0-1) could be categorized to balance sensitivity and specificity for detection of precancer/cancer. All statistical tests were two-sided.
RESULTS: Automated visual evaluation of enrollment cervigrams identified cumulative precancer/cancer cases with greater accuracy (area under the curve [AUC] = 0.91, 95% confidence interval [CI] = 0.89 to 0.93) than original cervigram interpretation (AUC = 0.69, 95% CI = 0.63 to 0.74; P < .001) or conventional cytology (AUC = 0.71, 95% CI = 0.65 to 0.77; P < .001). A single visual screening round restricted to women at the prime screening ages of 25-49 years could identify 127 (55.7%) of 228 precancers (cervical intraepithelial neoplasia 2/cervical intraepithelial neoplasia 3/adenocarcinoma in situ [AIS]) diagnosed cumulatively in the entire adult population (ages 18-94 years) while referring 11.0% for management.
CONCLUSIONS: The results support consideration of automated visual evaluation of cervical images from contemporary digital cameras. If achieved, this might permit dissemination of effective point-of-care cervical screening.",True,both,Not specified
30473381,A picture tells a thousand…exposures: Opportunities and challenges of deep learning image analyses in exposure science and environmental epidemiology,"BACKGROUND: Artificial intelligence (AI) is revolutionizing our world, with applications ranging from medicine to engineering.
OBJECTIVES: Here we discuss the promise, challenges, and probable data sources needed to apply AI in the fields of exposure science and environmental health. In particular, we focus on the use of deep convolutional neural networks to estimate environmental exposures using images and other complementary data sources such as cell phone mobility and social media information.
DISCUSSION: Characterizing the health impacts of multiple spatially-correlated exposures remains a challenge in environmental epidemiology. A shift toward integrated measures that simultaneously capture multiple aspects of the urban built environment could improve efficiency and provide important insights into how our collective environments influence population health. The widespread adoption of AI in exposure science is on the frontier. This will likely result in new ways of understanding environmental impacts on health and may allow for analyses to be efficiently scaled for broad coverage. Image-based convolutional neural networks may also offer a cost-effective means of estimating local environmental exposures in low and middle-income countries where monitoring and surveillance infrastructure is limited. However, suitable databases must first be assembled to train and evaluate these models and these novel approaches should be complemented with traditional exposure metrics.
CONCLUSIONS: The promise of deep learning in environmental health is great and will complement existing measurements for data-rich settings and could enhance the resolution and accuracy of estimates in data poor scenarios. Interdisciplinary partnerships will be needed to fully realize this potential.",True,other,convolutional neural network
29679305,"The New Possibilities from ""Big Data"" to Overlooked Associations Between Diabetes, Biochemical Parameters, Glucose Control, and Osteoporosis","PURPOSE OF REVIEW: To review current practices and technologies within the scope of ""Big Data"" that can further our understanding of diabetes mellitus and osteoporosis from large volumes of data. ""Big Data"" techniques involving supervised machine learning, unsupervised machine learning, and deep learning image analysis are presented with examples of current literature.
RECENT FINDINGS: Supervised machine learning can allow us to better predict diabetes-induced osteoporosis and understand relative predictor importance of diabetes-affected bone tissue. Unsupervised machine learning can allow us to understand patterns in data between diabetic pathophysiology and altered bone metabolism. Image analysis using deep learning can allow us to be less dependent on surrogate predictors and use large volumes of images to classify diabetes-induced osteoporosis and predict future outcomes directly from images. ""Big Data"" techniques herald new possibilities to understand diabetes-induced osteoporosis and ascertain our current ability to classify, understand, and predict this condition.",True,other,recurrent neural network
29239117,Deep Omics,"Deep learning has revolutionized research in image processing, speech recognition, natural language processing, game playing, and will soon revolutionize research in proteomics and genomics. Through three examples in genomics, protein structure prediction, and proteomics, we demonstrate that deep learning is changing bioinformatics research, shifting from algorithm-centric to data-centric approaches.",True,other,recurrent neural network
29114182,Application of Deep Learning in Automated Analysis of Molecular Images in Cancer: A Survey,"Molecular imaging enables the visualization and quantitative analysis of the alterations of biological procedures at molecular and/or cellular level, which is of great significance for early detection of cancer. In recent years, deep leaning has been widely used in medical imaging analysis, as it overcomes the limitations of visual assessment and traditional machine learning techniques by extracting hierarchical features with powerful representation capability. Research on cancer molecular images using deep learning techniques is also increasing dynamically. Hence, in this paper, we review the applications of deep learning in molecular imaging in terms of tumor lesion segmentation, tumor classification, and survival prediction. We also outline some future directions in which researchers may develop more powerful deep learning models for better performance in the applications in cancer molecular imaging.",True,other,Not specified
28892454,Disease Staging and Prognosis in Smokers Using Deep Learning in Chest Computed Tomography,"RATIONALE: Deep learning is a powerful tool that may allow for improved outcome prediction.
OBJECTIVES: To determine if deep learning, specifically convolutional neural network (CNN) analysis, could detect and stage chronic obstructive pulmonary disease (COPD) and predict acute respiratory disease (ARD) events and mortality in smokers.
METHODS: A CNN was trained using computed tomography scans from 7,983 COPDGene participants and evaluated using 1,000 nonoverlapping COPDGene participants and 1,672 ECLIPSE participants. Logistic regression (C statistic and the Hosmer-Lemeshow test) was used to assess COPD diagnosis and ARD prediction. Cox regression (C index and the Greenwood-Nam-D'Agnostino test) was used to assess mortality.
MEASUREMENTS AND MAIN RESULTS: In COPDGene, the C statistic for the detection of COPD was 0.856. A total of 51.1% of participants in COPDGene were accurately staged and 74.95% were within one stage. In ECLIPSE, 29.4% were accurately staged and 74.6% were within one stage. In COPDGene and ECLIPSE, the C statistics for ARD events were 0.64 and 0.55, respectively, and the Hosmer-Lemeshow P values were 0.502 and 0.380, respectively, suggesting no evidence of poor calibration. In COPDGene and ECLIPSE, CNN predicted mortality with fair discrimination (C indices, 0.72 and 0.60, respectively), and without evidence of poor calibration (Greenwood-Nam-D'Agnostino P values, 0.307 and 0.331, respectively).
CONCLUSIONS: A deep-learning approach that uses only computed tomography imaging data can identify those smokers who have COPD and predict who are most likely to have ARD events and those with the highest mortality. At a population level CNN analysis may be a powerful tool for risk assessment.",True,other,convolutional neural network
28871110,A Deep Learning-Based Radiomics Model for Prediction of Survival in Glioblastoma Multiforme,"Traditional radiomics models mainly rely on explicitly-designed handcrafted features from medical images. This paper aimed to investigate if deep features extracted via transfer learning can generate radiomics signatures for prediction of overall survival (OS) in patients with Glioblastoma Multiforme (GBM). This study comprised a discovery data set of 75 patients and an independent validation data set of 37 patients. A total of 1403 handcrafted features and 98304 deep features were extracted from preoperative multi-modality MR images. After feature selection, a six-deep-feature signature was constructed by using the least absolute shrinkage and selection operator (LASSO) Cox regression model. A radiomics nomogram was further presented by combining the signature and clinical risk factors such as age and Karnofsky Performance Score. Compared with traditional risk factors, the proposed signature achieved better performance for prediction of OS (C-index = 0.710, 95% CI: 0.588, 0.932) and significant stratification of patients into prognostically distinct groups (P < 0.001, HR = 5.128, 95% CI: 2.029, 12.960). The combined model achieved improved predictive performance (C-index = 0.739). Our study demonstrates that transfer learning-based deep features are able to generate prognostic imaging signature for OS prediction and patient stratification for GBM, indicating the potential of deep imaging feature-based biomarker in preoperative care of GBM patients.",True,other,recurrent neural network
27713752,Using Deep Learning for Image-Based Plant Disease Detection,"Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.",True,other,recurrent neural network
24224174,Statistical fractal models based on GND-PCA and its application on classification of liver diseases,"A new method is proposed to establish the statistical fractal model for liver diseases classification. Firstly, the fractal theory is used to construct the high-order tensor, and then Generalized N-dimensional Principal Component Analysis (GND-PCA) is used to establish the statistical fractal model and select the feature from the region of liver; at the same time different features have different weights, and finally, Support Vector Machine Optimized Ant Colony (ACO-SVM) algorithm is used to establish the classifier for the recognition of liver disease. In order to verify the effectiveness of the proposed method, PCA eigenface method and normal SVM method are chosen as the contrast methods. The experimental results show that the proposed method can reconstruct liver volume better and improve the classification accuracy of liver diseases.",True,text mining,convolutional neural network
20798308,Virology. Looking inside adenovirus,,True,other,GAN
18485736,Multi-disciplinary studies of viruses: the role of structure in shaping the questions and answers,"This contribution to the 50th anniversary issue of the Journal of Structural Biology traces a path in which the author evolved from seeing macromolecular structure as end in it self to a means of organizing and correlating data from many sources. The author looks at where we have been and where we are going in this enterprise and the role that structure plays in defining ever more ambitious biological questions and testing and refining models that incorporate data from many techniques. In this, essentially, personal account, the author reflects on 35 years of structural virology and the stages experienced; from ""stand alone"" crystallography of virus particles to the study of virus assembly and maturation in vitro and eventually into the entire virus infection process from particle cell entry to egress. In the process data from many sources were incorporated into reasonable and testable models based on structures ranging in resolution from near-atomic determined by crystallography, to nanometer, determined by electron cryo-microscopy and image reconstruction, to five nanometer tomographic studies in the cell. The technological development over this period, for structural studies at all resolutions and functional studies that were unimaginable three decades ago, has been astonishing. Here we look at an aspect of this development applied to virology.",True,text mining,Not specified
8115788,Artificial neural networks for cancer research: outcome prediction,"The use of artificial neural networks in biological and medical research has increased tremendously in the last few years. Artificial neural networks are being used in cancer research for image processing, the analysis of laboratory data for breast cancer diagnosis, the discovery of chemotherapeutic agents, and for cancer outcome prediction. A neural network generalizes from the input data to patterns inherent in the data, and its uses these patterns to make predictions or to classify. This paper explains how neural networks work, and it shows that a neural network is more accurate at predicting breast cancer patient outcome than the current staging system.",True,other,recurrent neural network
39446192,Forecasting dominance of SARS-CoV-2 lineages by anomaly detection using deep AutoEncoders,"The COVID-19 pandemic is marked by the successive emergence of new SARS-CoV-2 variants, lineages, and sublineages that outcompete earlier strains, largely due to factors like increased transmissibility and immune escape. We propose DeepAutoCoV, an unsupervised deep learning anomaly detection system, to predict future dominant lineages (FDLs). We define FDLs as viral (sub)lineages that will constitute >10% of all the viral sequences added to the GISAID, a public database supporting viral genetic sequence sharing, in a given week. DeepAutoCoV is trained and validated by assembling global and country-specific data sets from over 16 million Spike protein sequences sampled over a period of ~4 years. DeepAutoCoV successfully flags FDLs at very low frequencies (0.01%-3%), with median lead times of 4-17 weeks, and predicts FDLs between ~5 and ~25 times better than a baseline approach. For example, the B.1.617.2 vaccine reference strain was flagged as FDL when its frequency was only 0.01%, more than a year before it was considered for an updated COVID-19 vaccine. Furthermore, DeepAutoCoV outputs interpretable results by pinpointing specific mutations potentially linked to increased fitness and may provide significant insights for the optimization of public health 'pre-emptive' intervention strategies.",True,other,recurrent neural network
39417227,Explainable artificial intelligence and domain adaptation for predicting HIV infection with graph neural networks,"OBJECTIVE: Investigation of explainable deep learning methods for graph neural networks to predict HIV infections with social network information and performing domain adaptation to evaluate model transferability across different datasets.
METHODS: Network data from two cohorts of younger sexual minority men (SMM) from two U.S. cities (Chicago, IL, and Houston, TX) were collected between 2014 and 2016. Feature importance from graph attention network (GAT) models were determined using GNNExplainer. Domain adaptation was performed to examine model transferability from one city dataset to the other dataset, training with 100% of the source dataset with 30% of the target dataset and prediction on the remaining 70% from the target dataset.
RESULTS: Domain adaptation showed the ability of GAT to improve prediction over training with single city datasets. Feature importance analysis with GAT models in single city training indicated similar features across different cities, reinforcing potential application of GAT models in predicting HIV infections through domain adaptation.
CONCLUSION: GAT models can be used to address the data sparsity issue in HIV study populations. They are powerful tools for predicting individual risk of HIV that can be further explored for better understanding of HIV transmission.",True,other,convolutional neural network
39413796,Novel multi-omics deconfounding variational autoencoders can obtain meaningful disease subtyping,"Unsupervised learning, particularly clustering, plays a pivotal role in disease subtyping and patient stratification, especially with the abundance of large-scale multi-omics data. Deep learning models, such as variational autoencoders (VAEs), can enhance clustering algorithms by leveraging inter-individual heterogeneity. However, the impact of confounders-external factors unrelated to the condition, e.g. batch effect or age-on clustering is often overlooked, introducing bias and spurious biological conclusions. In this work, we introduce four novel VAE-based deconfounding frameworks tailored for clustering multi-omics data. These frameworks effectively mitigate confounding effects while preserving genuine biological patterns. The deconfounding strategies employed include (i) removal of latent features correlated with confounders, (ii) a conditional VAE, (iii) adversarial training, and (iv) adding a regularization term to the loss function. Using real-life multi-omics data from The Cancer Genome Atlas, we simulated various confounding effects (linear, nonlinear, categorical, mixed) and assessed model performance across 50 repetitions based on reconstruction error, clustering stability, and deconfounding efficacy. Our results demonstrate that our novel models, particularly the conditional multi-omics VAE (cXVAE), successfully handle simulated confounding effects and recover biologically driven clustering structures. cXVAE accurately identifies patient labels and unveils meaningful pathological associations among cancer types, validating deconfounded representations. Furthermore, our study suggests that some of the proposed strategies, such as adversarial training, prove insufficient in confounder removal. In summary, our study contributes by proposing innovative frameworks for simultaneous multi-omics data integration, dimensionality reduction, and deconfounding in clustering. Benchmarking on open-access data offers guidance to end-users, facilitating meaningful patient stratification for optimized precision medicine.",True,other,convolutional neural network
39405390,Patient-Specific Myocardial Infarction Risk Thresholds From AI-Enabled Coronary Plaque Analysis,"BACKGROUND: Plaque quantification from coronary computed tomography angiography has emerged as a valuable predictor of cardiovascular risk. Deep learning can provide automated quantification of coronary plaque from computed tomography angiography. We determined per-patient age- and sex-specific distributions of deep learning-based plaque measurements and further evaluated their risk prediction for myocardial infarction in external samples.
METHODS: In this international, multicenter study of 2803 patients, a previously validated deep learning system was used to quantify coronary plaque from computed tomography angiography. Age- and sex-specific distributions of coronary plaque volume were determined from 956 patients undergoing computed tomography angiography for stable coronary artery disease from 5 cohorts. Multicenter external samples were used to evaluate associations between coronary plaque percentiles and myocardial infarction.
RESULTS: Quantitative deep learning plaque volumes increased with age and were higher in male patients. In the combined external sample (n=1847), patients in the ≥75th percentile of total plaque volume (unadjusted hazard ratio, 2.65 [95% CI, 1.47-4.78]; P=0.001) were at increased risk of myocardial infarction compared with patients below the 50th percentile. Similar relationships were seen for most plaque volumes and persisted in multivariable analyses adjusting for clinical characteristics, coronary artery calcium, stenosis, and plaque volume, with adjusted hazard ratios ranging from 2.38 to 2.50 for patients in the ≥75th percentile of total plaque volume.
CONCLUSIONS: Per-patient age- and sex-specific distributions for deep learning-based coronary plaque volumes are strongly predictive of myocardial infarction, with the highest risk seen in patients with coronary plaque volumes in the ≥75th percentile.",True,other,Not specified
39371086,Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling,"Deep learning has enabled breakthroughs in automated diagnosis from medical imaging, with many successful applications in ophthalmology. However, standard medical image classification approaches only assess disease presence at the time of acquisition, neglecting the common clinical setting of longitudinal imaging. For slow, progressive eye diseases like age-related macular degeneration (AMD) and primary open-angle glaucoma (POAG), patients undergo repeated imaging over time to track disease progression and forecasting the future risk of developing a disease is critical to properly plan treatment. Our proposed Longitudinal Transformer for Survival Analysis (LTSA) enables dynamic disease prognosis from longitudinal medical imaging, modeling the time to disease from sequences of fundus photography images captured over long, irregular time periods. Using longitudinal imaging data from the Age-Related Eye Disease Study (AREDS) and Ocular Hypertension Treatment Study (OHTS), LTSA significantly outperformed a single-image baseline in 19/20 head-to-head comparisons on late AMD prognosis and 18/20 comparisons on POAG prognosis. A temporal attention analysis also suggested that, while the most recent image is typically the most influential, prior imaging still provides additional prognostic value.",True,other,recurrent neural network
39369634,Joint self-supervised and supervised contrastive learning for multimodal MRI data: Towards predicting abnormal neurodevelopment,"The integration of different imaging modalities, such as structural, diffusion tensor, and functional magnetic resonance imaging, with deep learning models has yielded promising outcomes in discerning phenotypic characteristics and enhancing disease diagnosis. The development of such a technique hinges on the efficient fusion of heterogeneous multimodal features, which initially reside within distinct representation spaces. Naively fusing the multimodal features does not adequately capture the complementary information and could even produce redundancy. In this work, we present a novel joint self-supervised and supervised contrastive learning method to learn the robust latent feature representation from multimodal MRI data, allowing the projection of heterogeneous features into a shared common space, and thereby amalgamating both complementary and analogous information across various modalities and among similar subjects. We performed a comparative analysis between our proposed method and alternative deep multimodal learning approaches. Through extensive experiments on two independent datasets, the results demonstrated that our method is significantly superior to several other deep multimodal learning methods in predicting abnormal neurodevelopment. Our method has the capability to facilitate computer-aided diagnosis within clinical practice, harnessing the power of multimodal data. The source code of the proposed model is publicly accessible on GitHub: https://github.com/leonzyzy/Contrastive-Network.",True,other,recurrent neural network
39369547,HIV-1 M group subtype classification using deep learning approach,"Traditionally, the classification of HIV-1 M group subtypes has depended on statistical methods constrained by sample sizes. Here HIV-1-M-SPBEnv was proposed as the first deep learning-based method for classifying HIV-1 M group subtypes via env gene sequences. This approach overcomes sample size challenges by utilizing artificial molecular evolution techniques to generate a synthetic dataset suitable for machine learning. Employing a convolutional Autoencoder embedded with two residual blocks and two transpose residual blocks, followed by a full connected neural network block, HIV-1-M-SPBEnv simplifies complex, high-dimensional DNA sequence data into concise, information-rich, low-dimensional representations, achieving exceptional classification accuracy. Through independent data set validation, the precision, accuracy, recall and F1 score of the HIV-1-M-SPBEnv model predictions were all 100 %, confirming its capability to accurately identify all 12 subtypes of the HIV-1 M group. Deployed through a web server, it provides seamless HIV-1 M group subtype prediction capabilities for researchers and clinicians. HIV-1-M-SPBEnv web server is accessible at http://www.hivsubclass.com and all the code is available at https://github.com/pengsihua2023/HIV-1-M-SPBEnv.",True,other,convolutional neural network
39362767,Validation of an Artificial Intelligence-Based Prediction Model Using 5 External PET/CT Datasets of Diffuse Large B-Cell Lymphoma,"The aim of this study was to validate a previously developed deep learning model in 5 independent clinical trials. The predictive performance of this model was compared with the international prognostic index (IPI) and 2 models incorporating radiomic PET/CT features (clinical PET and PET models). Methods: In total, 1,132 diffuse large B-cell lymphoma patients were included: 296 for training and 836 for external validation. The primary outcome was 2-y time to progression. The deep learning model was trained on maximum-intensity projections from PET/CT scans. The clinical PET model included metabolic tumor volume, maximum distance from the bulkiest lesion to another lesion, SUV<sub>peak</sub>, age, and performance status. The PET model included metabolic tumor volume, maximum distance from the bulkiest lesion to another lesion, and SUV<sub>peak</sub> Model performance was assessed using the area under the curve (AUC) and Kaplan-Meier curves. Results: The IPI yielded an AUC of 0.60 on all external data. The deep learning model yielded a significantly higher AUC of 0.66 (P &lt; 0.01). For each individual clinical trial, the model was consistently better than IPI. Radiomic model AUCs remained higher for all clinical trials. The deep learning and clinical PET models showed equivalent performance (AUC, 0.69; P &gt; 0.05). The PET model yielded the highest AUC of all models (AUC, 0.71; P &lt; 0.05). Conclusion: The deep learning model predicted outcome in all trials with a higher performance than IPI and better survival curve separation. This model can predict treatment outcome in diffuse large B-cell lymphoma without tumor delineation but at the cost of a lower prognostic performance than with radiomics.",True,other,Not specified
39362226,Application of a deep-learning marker for morbidity and mortality prediction derived from retinal photographs: a cohort development and validation study,"BACKGROUND: Biological ageing markers are useful to risk stratify morbidity and mortality more precisely than chronological age. In this study, we aimed to develop a novel deep-learning-based biological ageing marker (referred to as RetiPhenoAge hereafter) using retinal images and PhenoAge, a composite biomarker of phenotypic age.
METHODS: We used retinal photographs from the UK Biobank dataset to train a deep-learning algorithm to predict the composite score of PhenoAge. We used a deep convolutional neural network architecture with multiple layers to develop our deep-learning-based biological ageing marker, as RetiPhenoAge, with the aim of identifying patterns and features in the retina associated with variations of blood biomarkers related to renal, immune, liver functions, inflammation, and energy metabolism, and chronological age. We determined the performance of this biological ageing marker for the prediction of morbidity (cardiovascular disease and cancer events) and mortality (all-cause, cardiovascular disease, and cancer) in three independent cohorts (UK Biobank, the Singapore Epidemiology of Eye Diseases [SEED], and the Age-Related Eye Disease Study [AREDS] from the USA). We also compared the performance of RetiPhenoAge with two other known ageing biomarkers (hand grip strength and adjusted leukocyte telomere length) and one lifestyle factor (physical activity) for risk stratification of mortality and morbidity. We explored the underlying biology of RetiPhenoAge by assessing its associations with different systemic characteristics (eg, diabetes or hypertension) and blood metabolite levels. We also did a genome-wide association study to identify genetic variants associated with RetiPhenoAge, followed by expression quantitative trait loci mapping, a gene-based analysis, and a gene-set analysis. Cox proportional hazards models were used to estimate the hazard ratios (HRs) and corresponding 95% CIs for the associations between RetiPhenoAge and the different morbidity and mortality outcomes.
FINDINGS: Retinal photographs for 34 061 UK Biobank participants were used to train the model, and data for 9429 participants from the SEED cohort and for 3986 participants from the AREDS cohort were included in the study. RetiPhenoAge was associated with all-cause mortality (HR 1·92 [95% CI 1·42-2·61]), cardiovascular disease mortality (1·97 [1·02-3·82]), cancer mortality (2·07 [1·29-3·33]), and cardiovascular disease events (1·70 [1·17-2·47]), independent of PhenoAge and other possible confounders. Similar findings were found in the two independent cohorts (HR 1·67 [1·21-2·31] for cardiovascular disease mortality in SEED and 2·07 [1·10-3·92] in AREDS). RetiPhenoAge had stronger associations with mortality and morbidity than did hand grip strength, telomere length, and physical activity. We identified two genetic variants that were significantly associated with RetiPhenoAge (single nucleotide polymorphisms rs3791224 and rs8001273), and were linked to expression quantitative trait locis in various tissues, including the heart, kidneys, and the brain.
INTERPRETATION: Our new deep-learning-derived biological ageing marker is a robust predictor of mortality and morbidity outcomes and could be used as a novel non-invasive method to measure ageing.
FUNDING: Singapore National Medical Research Council and Agency for Science, Technology and Research, Singapore.",True,other,recurrent neural network
39361651,Improved deep learning prediction of antigen-antibody interactions,"Identifying antibodies that neutralize specific antigens is crucial for developing effective immunotherapies, but this task remains challenging for many target antigens. The rise of deep learning-based computational approaches presents a promising avenue to address this challenge. Here, we assess the performance of a deep learning approach through two benchmark tests aimed at predicting antibodies for the receptor-binding domain of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) spike protein. Three different strategies for constructing input sequence alignments are employed for predicting structural models of antigen-antibody complexes. In our initial testing set, which comprises known experimental structures, these strategies collectively yield a significant top-ranked prediction for 61% of cases and a success rate of 47%. Notably, one strategy that utilizes the sequences of known antigen binders outperforms the other two, achieving a precision of 90% in a subsequent test set of ~1,000 antibodies, balanced between true and control antibodies for the antigen, albeit with a lower recall of 25%. Our results underscore the potential of integrating deep learning methods with single B cell sequencing techniques to enhance the prediction accuracy of antigen-antibody interactions.",True,other,Not specified
39358793,Deep learning-based approaches for multi-omics data integration and analysis,"BACKGROUND: The rapid growth of deep learning, as well as the vast and ever-growing amount of available data, have provided ample opportunity for advances in fusion and analysis of complex and heterogeneous data types. Different data modalities provide complementary information that can be leveraged to gain a more complete understanding of each subject. In the biomedical domain, multi-omics data includes molecular (genomics, transcriptomics, proteomics, epigenomics, metabolomics, etc.) and imaging (radiomics, pathomics) modalities which, when combined, have the potential to improve performance on prediction, classification, clustering and other tasks. Deep learning encompasses a wide variety of methods, each of which have certain strengths and weaknesses for multi-omics integration.
METHOD: In this review, we categorize recent deep learning-based approaches by their basic architectures and discuss their unique capabilities in relation to one another. We also discuss some emerging themes advancing the field of multi-omics integration.
RESULTS: Deep learning-based multi-omics integration methods were categorized broadly into non-generative (feedforward neural networks, graph convolutional neural networks, and autoencoders) and generative (variational methods, generative adversarial models, and a generative pretrained model). Generative methods have the advantage of being able to impose constraints on the shared representations to enforce certain properties or incorporate prior knowledge. They can also be used to generate or impute missing modalities. Recent advances achieved by these methods include the ability to handle incomplete data as well as going beyond the traditional molecular omics data types to integrate other modalities such as imaging data.
CONCLUSION: We expect to see further growth in methods that can handle missingness, as this is a common challenge in working with complex and heterogeneous data. Additionally, methods that integrate more data types are expected to improve performance on downstream tasks by capturing a comprehensive view of each sample.",True,other,recurrent neural network
39358428,Deep learning-derived optimal aviation strategies to control pandemics,"The COVID-19 pandemic affected countries across the globe, demanding drastic public health policies to mitigate the spread of infection, which led to economic crises as a collateral damage. In this work, we investigate the impact of human mobility, described via international commercial flights, on COVID-19 infection dynamics on a global scale. We developed a graph neural network (GNN)-based framework called Dynamic Weighted GraphSAGE (DWSAGE), which operates over spatiotemporal graphs and is well-suited for dynamically changing flight information updated daily. This architecture is designed to be structurally sensitive, capable of learning the relationships between edge features and node features. To gain insights into the influence of air traffic on infection spread, we conducted local sensitivity analysis on our model through perturbation experiments. Our analyses identified Western Europe, the Middle East, and North America as leading regions in fueling the pandemic due to the high volume of air traffic originating or transiting through these areas. We used these observations to propose air traffic reduction strategies that can significantly impact controlling the pandemic with minimal disruption to human mobility. Our work provides a robust deep learning-based tool to study global pandemics and is of key relevance to policymakers for making informed decisions regarding air traffic restrictions during future outbreaks.",True,both,CNN
39357994,Performance analysis of a deep-learning algorithm to detect the presence of inflammation in MRI of sacroiliac joints in patients with axial spondyloarthritis,"OBJECTIVES: To assess the ability of a previously trained deep-learning algorithm to identify the presence of inflammation on MRI of sacroiliac joints (SIJ) in a large external validation set of patients with axial spondyloarthritis (axSpA).
METHODS: Baseline SIJ MRI scans were collected from two prospective randomised controlled trials in patients with non-radiographic (nr-) and radiographic (r-) axSpA (RAPID-axSpA: NCT01087762 and C-OPTIMISE: NCT02505542) and were centrally evaluated by two expert readers (and adjudicator in case of disagreement) for the presence of inflammation by the 2009 Assessment of SpondyloArthritis International Society (ASAS) definition. Scans were processed by the deep-learning algorithm, blinded to clinical information and central expert readings.
RESULTS: Pooling the patients from RAPID-axSpA (n=152) and C-OPTIMISE (n=579) yielded a validation set of 731 patients (mean age: 34.2 years, SD: 8.6; 505/731 (69.1%) male), of which 326/731 (44.6%) had nr-axSpA and 436/731 (59.6%) had inflammation on MRI per central readings. Scans were obtained from over 30 scanners from 5 manufacturers across over 100 clinical sites. Comparing the trained algorithm with the human central readings yielded a sensitivity of 70% (95% CI 66% to 73%), specificity of 81% (95% CI 78% to 84%), positive predictive value of 84% (95% CI 82% to 87%), negative predictive value of 64% (95% CI 61% to 68%), Cohen's kappa of 0.49 (95% CI 0.43 to 0.55) and absolute agreement of 74% (95% CI 72% to 77%).
CONCLUSION: The algorithm enabled acceptable detection of inflammation according to the 2009 ASAS MRI definition in a large external validation cohort.",True,other,Not specified
39348420,Managing spatio-temporal heterogeneity of susceptibles by embedding it into an homogeneous model: A mechanistic and deep learning study,"Accurate prediction of epidemics is pivotal for making well-informed decisions for the control of infectious diseases, but addressing heterogeneity in the system poses a challenge. In this study, we propose a novel modelling framework integrating the spatio-temporal heterogeneity of susceptible individuals into homogeneous models, by introducing a continuous recruitment process for the susceptibles. A neural network approximates the recruitment rate to develop a Universal Differential Equations (UDE) model. Simultaneously, we pre-set a specific form for the recruitment rate and develop a mechanistic model. Data from a COVID Omicron variant outbreak in Shanghai are used to train the UDE model using deep learning methods and to calibrate the mechanistic model using MCMC methods. Subsequently, we project the attack rate and peak of new infections for the first Omicron wave in China after the adjustment of the dynamic zero-COVID policy. Our projections indicate an attack rate and a peak of new infections of 80.06% and 3.17% of the population, respectively, compared with the homogeneous model's projections of 99.97% and 32.78%, thus providing an 18.6% improvement in the prediction accuracy based on the actual data. Our simulations demonstrate that heterogeneity in the susceptibles decreases herd immunity for ~37.36% of the population and prolongs the outbreak period from ~30 days to ~70 days, also aligning with the real case. We consider that this study lays the groundwork for the development of a new class of models and new insights for modelling heterogeneity.",True,computer vision,recurrent neural network
39344712,DeepPBI-KG: a deep learning method for the prediction of phage-bacteria interactions based on key genes,"Phages, the natural predators of bacteria, were discovered more than 100 years ago. However, increasing antimicrobial resistance rates have revitalized phage research. Methods that are more time-consuming and efficient than wet-laboratory experiments are needed to help screen phages quickly for therapeutic use. Traditional computational methods usually ignore the fact that phage-bacteria interactions are achieved by key genes and proteins. Methods for intraspecific prediction are rare since almost all existing methods consider only interactions at the species and genus levels. Moreover, most strains in existing databases contain only partial genome information because whole-genome information for species is difficult to obtain. Here, we propose a new approach for interaction prediction by constructing new features from key genes and proteins via the application of K-means sampling to select high-quality negative samples for prediction. Finally, we develop DeepPBI-KG, a corresponding prediction tool based on feature selection and a deep neural network. The results show that the average area under the curve for prediction reached 0.93 for each strain, and the overall AUC and area under the precision-recall curve reached 0.89 and 0.92, respectively, on the independent test set; these values are greater than those of other existing prediction tools. The forward and reverse validation results indicate that key genes and key proteins regulate and influence the interaction, which supports the reliability of the model. In addition, intraspecific prediction experiments based on Klebsiella pneumoniae data demonstrate the potential applicability of DeepPBI-KG for intraspecific prediction. In summary, the feature engineering and interaction prediction approaches proposed in this study can effectively improve the robustness and stability of interaction prediction, can achieve high generalizability, and may provide new directions and insights for rapid phage screening for therapy.",True,text mining,Not specified
39333289,A novel hybrid deep learning IChOA-CNN-LSTM model for modality-enriched and multilingual emotion recognition in social media,"In the rapidly evolving field of artificial intelligence, the importance of multimodal sentiment analysis has never been more evident, especially amid the ongoing COVID-19 pandemic. Our research addresses the critical need to understand public sentiment across various dimensions of this crisis by integrating data from multiple modalities, such as text, images, audio, and videos sourced from platforms like Twitter. Conventional methods, which primarily focus on text analysis, often fall short in capturing the nuanced intricacies of emotional states, necessitating a more comprehensive approach. To tackle this challenge, our proposed framework introduces a novel hybrid model, IChOA-CNN-LSTM, which leverages Convolutional Neural Networks (CNNs) for precise image feature extraction, Long Short-Term Memory (LSTM) networks for sequential data analysis, and an Improved Chimp Optimization Algorithm for effective feature fusion. Remarkably, our model achieves an impressive accuracy rate of 97.8%, outperforming existing approaches in the field. Additionally, by integrating the GeoCoV19 dataset, we facilitate a comprehensive analysis that spans linguistic and geographical boundaries, enriching our understanding of global pandemic discourse and providing critical insights for informed decision-making in public health crises. Through this holistic approach and innovative techniques, our research significantly advances multimodal sentiment analysis, offering a robust framework for deciphering the complex interplay of emotions during unprecedented global challenges like the COVID-19 pandemic.",True,other,Not specified
39323093,AESurv: autoencoder survival analysis for accurate early prediction of coronary heart disease,"Coronary heart disease (CHD) is one of the leading causes of mortality and morbidity in the United States. Accurate time-to-event CHD prediction models with high-dimensional DNA methylation and clinical features may assist with early prediction and intervention strategies. We developed a state-of-the-art deep learning autoencoder survival analysis model (AESurv) to effectively analyze high-dimensional blood DNA methylation features and traditional clinical risk factors by learning low-dimensional representation of participants for time-to-event CHD prediction. We demonstrated the utility of our model in two cohort studies: the Strong Heart Study cohort (SHS), a prospective cohort studying cardiovascular disease and its risk factors among American Indians adults; the Women's Health Initiative (WHI), a prospective cohort study including randomized clinical trials and observational study to improve postmenopausal women's health with one of the main focuses on cardiovascular disease. Our AESurv model effectively learned participant representations in low-dimensional latent space and achieved better model performance (concordance index-C index of 0.864 ± 0.009 and time-to-event mean area under the receiver operating characteristic curve-AUROC of 0.905 ± 0.009) than other survival analysis models (Cox proportional hazard, Cox proportional hazard deep neural network survival analysis, random survival forest, and gradient boosting survival analysis models) in the SHS. We further validated the AESurv model in WHI and also achieved the best model performance. The AESurv model can be used for accurate CHD prediction and assist health care professionals and patients to perform early intervention strategies. We suggest using AESurv model for future time-to-event CHD prediction based on DNA methylation features.",True,other,Not specified
39317638,Neural network-assisted humanisation of COVID-19 hamster transcriptomic data reveals matching severity states in human disease,"BACKGROUND: Translating findings from animal models to human disease is essential for dissecting disease mechanisms, developing and testing precise therapeutic strategies. The coronavirus disease 2019 (COVID-19) pandemic has highlighted this need, particularly for models showing disease severity-dependent immune responses.
METHODS: Single-cell transcriptomics (scRNAseq) is well poised to reveal similarities and differences between species at the molecular and cellular level with unprecedented resolution. However, computational methods enabling detailed matching are still scarce. Here, we provide a structured scRNAseq-based approach that we applied to scRNAseq from blood leukocytes originating from humans and hamsters affected with moderate or severe COVID-19.
FINDINGS: Integration of data from patients with COVID-19 with two hamster models that develop moderate (Syrian hamster, Mesocricetus auratus) or severe (Roborovski hamster, Phodopus roborovskii) disease revealed that most cellular states are shared across species. A neural network-based analysis using variational autoencoders quantified the overall transcriptomic similarity across species and severity levels, showing highest similarity between neutrophils of Roborovski hamsters and patients with severe COVID-19, while Syrian hamsters better matched patients with moderate disease, particularly in classical monocytes. We further used transcriptome-wide differential expression analysis to identify which disease stages and cell types display strongest transcriptional changes.
INTERPRETATION: Consistently, hamsters' response to COVID-19 was most similar to humans in monocytes and neutrophils. Disease-linked pathways found in all species specifically related to interferon response or inhibition of viral replication. Analysis of candidate genes and signatures supported the results. Our structured neural network-supported workflow could be applied to other diseases, allowing better identification of suitable animal models with similar pathomechanisms across species.
FUNDING: This work was supported by German Federal Ministry of Education and Research, (BMBF) grant IDs: 01ZX1304B, 01ZX1604B, 01ZX1906A, 01ZX1906B, 01KI2124, 01IS18026B and German Research Foundation (DFG) grant IDs: 14933180, 431232613.",True,other,Not specified
39314974,Deep Learning Estimation of Small Airways Disease from Inspiratory Chest CT is Associated with FEV(1) Decline in COPD,"RATIONALE: Quantifying functional small airways disease (fSAD) requires additional expiratory computed tomography (CT) scan, limiting clinical applicability. Artificial intelligence (AI) could enable fSAD quantification from chest CT scan at total lung capacity (TLC) alone (fSADTLC).
OBJECTIVES: To evaluate an AI model for estimating fSADTLC and study its clinical associations in chronic obstructive pulmonary disease (COPD).
METHODS: We analyzed 2513 participants from the SubPopulations and InteRmediate Outcome Measures in COPD Study (SPIROMICS). Using a subset (n = 1055), we developed a generative model to produce virtual expiratory CTs for estimating fSADTLC in the remaining 1458 SPIROMICS participants. We compared fSADTLC with dual volume, parametric response mapping fSADPRM. We investigated univariate and multivariable associations of fSADTLC with FEV<sub>1</sub>, FEV<sub>1</sub>/FVC, six-minute walk distance (6MWD), St. George's Respiratory Questionnaire (SGRQ), and FEV<sub>1</sub> decline. The results were validated in a subset (n = 458) from COPDGene study. Multivariable models were adjusted for age, race, sex, BMI, baseline FEV<sub>1</sub>, smoking pack years, smoking status, and percent emphysema.
MEASUREMENTS AND MAIN RESULTS: Inspiratory fSADTLC was highly correlated with fSADPRM in SPIROMICS (Pearson's R = 0.895) and COPDGene (R = 0.897) cohorts. In SPIROMICS, fSADTLC was associated with FEV<sub>1</sub> (L) (adj.β = -0.034, P &lt; 0.001), FEV<sub>1</sub>/FVC (adj.β = -0.008, P &lt; 0.001), SGRQ (adj.β = 0.243, P &lt; 0.001), and FEV<sub>1</sub> decline (mL / year) (adj.β = -1.156, P &lt; 0.001). fSADTLC was also associated with FEV<sub>1</sub> (L) (adj.β = -0.032, P &lt; 0.001), FEV<sub>1</sub>/FVC (adj.β = -0.007, P &lt; 0.001), SGRQ (adj.β = 0.190, P = 0.02), and FEV<sub>1</sub> decline (mL / year) (adj.β = -0.866, P = 0.001) in COPDGene. We found fSADTLC to be more repeatable than fSADPRM with intraclass correlation of 0.99 (95% CI: 0.98, 0.99) vs. 0.83 (95% CI: 0.76, 0.88).
CONCLUSIONS: Inspiratory fSADTLC captures small airways disease as reliably as fSADPRM and is associated with FEV<sub>1</sub> decline.",True,computer vision,Not specified
39314346,G2PDeep-v2: a web-based deep-learning framework for phenotype prediction and biomarker discovery using multi-omics data,"The G2PDeep-v2 server is a web-based platform powered by deep learning, for phenotype prediction and markers discovery from multi-omics data in any organisms including humans, plants, animals, and viruses. The server provides multiple services for researchers to create deep-learning models through an interactive interface and train these models using an automated hyperparameter tuning algorithm on high-performance computing resources. Users can visualize the results of phenotype and markers predictions and perform Gene Set Enrichment Analysis for the significant markers to provide insights into the molecular mechanisms underlying complex diseases and other biological processes. The G2PDeep-v2 server is publicly available at https://g2pdeep.org/.",True,other,recurrent neural network
39309215,A deep learning method that identifies cellular heterogeneity using nanoscale nuclear features,"Cellular phenotypic heterogeneity is an important hallmark of many biological processes and understanding its origins remains a substantial challenge. This heterogeneity often reflects variations in the chromatin structure, influenced by factors such as viral infections and cancer, which dramatically reshape the cellular landscape. To address the challenge of identifying distinct cell states, we developed artificial intelligence of the nucleus (AINU), a deep learning method that can identify specific nuclear signatures at the nanoscale resolution. AINU can distinguish different cell states based on the spatial arrangement of core histone H3, RNA polymerase II or DNA from super-resolution microscopy images. With only a small number of images as the training data, AINU correctly identifies human somatic cells, human-induced pluripotent stem cells, very early stage infected cells transduced with DNA herpes simplex virus type 1 and even cancer cells after appropriate retraining. Finally, using AI interpretability methods, we find that the RNA polymerase II localizations in the nucleoli aid in distinguishing human-induced pluripotent stem cells from their somatic cells. Overall, AINU coupled with super-resolution microscopy of nuclear structures provides a robust tool for the precise detection of cellular heterogeneity, with considerable potential for advancing diagnostics and therapies in regenerative medicine, virology and cancer biology.",True,other,Not specified
39294054,Deep Learning Model for Pathological Grading and Prognostic Assessment of Lung Cancer Using CT Imaging: A Study on NLST and External Validation Cohorts,"RATIONALE AND OBJECTIVES: To develop and validate a deep learning model for automated pathological grading and prognostic assessment of lung cancer using CT imaging, thereby providing surgeons with a non-invasive tool to guide surgical planning.
MATERIAL AND METHODS: This study utilized 572 cases from the National Lung Screening Trial cohort, dividing them randomly into training (461 cases) and internal validation (111 cases) sets in an 8:2 ratio. Additionally, 224 cases from four cohorts obtained from the Cancer Imaging Archive, all diagnosed with non-small cell lung cancer, were included for external validation. The deep learning model, built on the MobileNetV3 architecture, was assessed in both internal and external validation sets using metrics such as accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUC). The model's prognostic value was further analyzed using Cox proportional hazards models.
RESULTS: The model achieved high accuracy, sensitivity, specificity, and AUC in the internal validation set (accuracy: 0.888, macro AUC: 0.968, macro sensitivity: 0.798, macro specificity: 0.956). External validation demonstrated comparable performance (accuracy: 0.807, macro AUC: 0.920, macro sensitivity: 0.799, macro specificity: 0.896). The model's predicted signatures correlated significantly with patient mortality and provided valuable insights for prognostic assessment (adjusted HR 2.016 [95% CI: 1.010, 4.022]).
CONCLUSIONS: This study successfully developed and validated a deep learning model for the preoperative grading of lung cancer pathology. The model's accurate predictions could serve as a useful adjunct in treatment planning for lung cancer patients, enabling more effective and customized interventions to improve patient outcomes.",True,other,Not specified
39293804,Designing interpretable deep learning applications for functional genomics: a quantitative analysis,"Deep learning applications have had a profound impact on many scientific fields, including functional genomics. Deep learning models can learn complex interactions between and within omics data; however, interpreting and explaining these models can be challenging. Interpretability is essential not only to help progress our understanding of the biological mechanisms underlying traits and diseases but also for establishing trust in these model's efficacy for healthcare applications. Recognizing this importance, recent years have seen the development of numerous diverse interpretability strategies, making it increasingly difficult to navigate the field. In this review, we present a quantitative analysis of the challenges arising when designing interpretable deep learning solutions in functional genomics. We explore design choices related to the characteristics of genomics data, the neural network architectures applied, and strategies for interpretation. By quantifying the current state of the field with a predefined set of criteria, we find the most frequent solutions, highlight exceptional examples, and identify unexplored opportunities for developing interpretable deep learning models in genomics.",True,other,convolutional neural network
39262220,Advanced Machine Learning Models for Predicting Post-Thrombolysis Hemorrhagic Transformation in Acute Ischemic Stroke Patients: A Systematic Review and Meta-Analysis,"Background: Thrombolytic therapy is essential for acute ischemic stroke (AIS) management but poses a risk of hemorrhagic transformation (HT), necessitating accurate prediction to optimize patient care. Methods: A comprehensive search was conducted across PubMed, Web of Science, Scopus, Embase, and Google Scholar, covering studies from inception until July 10, 2024. Studies were included if they used machine learning (ML) or deep learning algorithms to predict HT in AIS patients treated with thrombolysis. Exclusion criteria included studies involving endovascular treatments and those not evaluating model effectiveness. Data extraction and quality assessment were performed following PRISMA guidelines and using the Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD) and Prediction Model Risk of Bias Assessment Tool (PROBAST) tools. Results: Out of 1943 identified records, 12 studies were included in the final analysis, encompassing 18 007 AIS patients who received thrombolytic therapy. The ML models demonstrated high predictive performance, with pooled area under the curve (AUC) values ranging from 0.79 to 0.95. Specifically, XGBoost models achieved AUCs of up to 0.953 and Artificial Neural Network (ANN) models reached up to 0.942. Sensitivity and specificity varied significantly, with the highest sensitivity at 0.90 and specificity at 0.99. Significant predictors of HT included age, glucose levels, NIH Stroke Scale (NIHSS) score, systolic and diastolic blood pressure, and radiomic features. Despite these promising results, methodological disparities and limited external validation highlighted the need for standardized reporting and further rigorous testing. Conclusion: ML techniques, especially XGBoost and ANN, show great promise in predicting HT following thrombolysis in AIS patients, enhancing risk stratification and clinical decision-making. Future research should focus on prospective study designs, standardized reporting, and integrating ML assessments into clinical workflows to improve AIS management and patient outcomes.",True,other,Not specified
39256746,A deep learning model for differentiating paediatric intracranial germ cell tumour subtypes and predicting survival with MRI: a multicentre prospective study,"BACKGROUND: The pretherapeutic differentiation of subtypes of primary intracranial germ cell tumours (iGCTs), including germinomas (GEs) and nongerminomatous germ cell tumours (NGGCTs), is essential for clinical practice because of distinct treatment strategies and prognostic profiles of these diseases. This study aimed to develop a deep learning model, iGNet, to assist in the differentiation and prognostication of iGCT subtypes by employing pretherapeutic MR T2-weighted imaging.
METHODS: The iGNet model, which is based on the nnUNet architecture, was developed using a retrospective dataset of 280 pathologically confirmed iGCT patients. The training dataset included 83 GEs and 117 NGGCTs, while the retrospective internal test dataset included 31 GEs and 49 NGGCTs. The model's diagnostic performance was then assessed with the area under the receiver operating characteristic curve (AUC) in a prospective internal dataset (n = 22) and two external datasets (n = 22 and 20). Next, we compared the diagnostic performance of six neuroradiologists with or without the assistance of iGNet. Finally, the predictive ability of the output of iGNet for progression-free and overall survival was assessed and compared to that of the pathological diagnosis.
RESULTS: iGNet achieved high diagnostic performance, with AUCs between 0.869 and 0.950 across the four test datasets. With the assistance of iGNet, the six neuroradiologists' diagnostic AUCs (averages of the four test datasets) increased by 9.22% to 17.90%. There was no significant difference between the output of iGNet and the results of pathological diagnosis in predicting progression-free and overall survival (P = .889).
CONCLUSIONS: By leveraging pretherapeutic MR imaging data, iGNet accurately differentiates iGCT subtypes, facilitating prognostic evaluation and increasing the potential for tailored treatment.",True,other,Not specified
39256497,Comorbidity-based framework for Alzheimer's disease classification using graph neural networks,"Alzheimer's disease (AD), the most prevalent form of dementia, requires early prediction for timely intervention. Current deep learning approaches, particularly those using traditional neural networks, face challenges such as handling high-dimensional data, interpreting complex relationships, and managing data bias. To address these limitations, we propose a framework utilizing graph neural networks (GNNs), which excel in modeling relationships within graph-structured data. Our study employs GNNs on data from the Alzheimer's Disease Neuroimaging Initiative for binary and multi-class classification across the three stages of AD: cognitively normal (CN), mild cognitive impairment (MCI), and Alzheimer's disease (AD). By incorporating comorbidity data derived from electronic health records, we achieved the most effective multi-classification results. Notably, the GNN model (Chebyshev Convolutional Neural Networks) demonstrated superior performance with a 0.98 accuracy in multi-class classification and 0.99, 0.93, and 0.94 in the AD/CN, AD/MCI, and CN/MCI binary tasks, respectively. The model's robustness was further validated using the Australian Imaging, Biomarker & Lifestyle dataset as an external validation set. This work contributes to the field by offering a robust, accurate, and cost-effective method for early AD prediction (CN vs. MCI), addressing key challenges in existing deep learning approaches.",True,other,recurrent neural network
39256475,Long-term trend prediction of pandemic combining the compartmental and deep learning models,"Predicting the spread trends of a pandemic is crucial, but long-term prediction remains challenging due to complex relationships among disease spread stages and preventive policies. To address this issue, we propose a novel approach that utilizes data augmentation techniques, compartmental model features, and disease preventive policies. We also use a breakpoint detection method to divide the disease spread into distinct stages and weight these stages using a self-attention mechanism to account for variations in virus transmission capabilities. Finally, we introduce a long-term spread trend prediction model for infectious diseases based on a bi-directional gated recurrent unit network. To evaluate the effectiveness of our model, we conducted experiments using public datasets, focusing on the prediction of COVID-19 cases in four countries over a period of 210 days. Experiments shown that the Adjust-R2 index of our model exceeds 0.9914, outperforming existing models. Furthermore, our model reduces the mean absolute error by 0.85-4.52% compared to other models. Our combined approach of using both the compartmental and deep learning models provides valuable insights into the dynamics of disease spread.",True,other,Not specified
39252327,Study of obesity research using machine learning methods: A bibliometric and visualization analysis from 2004 to 2023,"BACKGROUND: Obesity, a multifactorial and complex health condition, has emerged as a significant global public health concern. Integrating machine learning techniques into obesity research offers great promise as an interdisciplinary field, particularly in the screening, diagnosis, and analysis of obesity. Nevertheless, the publications on using machine learning methods in obesity research have not been systematically evaluated. Hence, this study aimed to quantitatively examine, visualize, and analyze the publications concerning the use of machine learning methods in obesity research by means of bibliometrics.
METHODS: The Web of Science core collection was the primary database source for this study, which collected publications on obesity research using machine learning methods over the last 20 years from January 1, 2004, to December 31, 2023. Only articles and reviews that fit the criteria were selected for bibliometric analysis, and in terms of language, only English was accepted. VOSviewer, CiteSpace, and Excel were the primary software utilized.
RESULTS: Between 2004 and 2023, the number of publications on obesity research using machine learning methods increased exponentially. Eventually, 3286 publications that met the eligibility criteria were searched. According to the collaborative network analysis, the United States has the greatest volume of publications, indicating a significant influence on this research. coauthor's analysis showed the authoritative one in this field is Leo Breiman. Scientific Reports is the most widely published journal. The most referenced publication is ""R: a language and environment for statistical computing."" An analysis of keywords shows that deep learning, support vector machines, predictive models, gut microbiota, energy expenditure, and genome are hot topics in this field. Future research directions may include the relationship between obesity and its consequences, such as diabetic retinopathy, as well as the interaction between obesity and epidemiology, such as COVID-19.
CONCLUSION: Utilizing bibliometrics as a research tool and methodology, this study, for the first time, reveals the intrinsic relationship and developmental pattern among obesity research using machine learning methods, which provides academic references for clinicians and researchers in understanding the hotspots and cutting-edge issues as well as the developmental trend in this field to detect patients' obesity problems early and develop personalized treatment plans.",True,other,Not specified
39250511,Innovation in public health surveillance for social distancing during the COVID-19 pandemic: A deep learning and object detection based novel approach,"The Corona Virus Disease (COVID-19) has a huge impact on all of humanity, and people's disregard for COVID-19 regulations has sped up the disease's spread. Our study uses a state-of-the-art object detection model like YOLOv4 (You Only Look Once, version 4), a very effective tool, on real-time 25fps, 1920 X 1080 video data streamed live by a camera-mounted Unmanned Aerial Vehicle (UAV) quad-copter to observe proper maintenance of social distance in an area of 35m range in this study. The model has demonstrated remarkable efficacy in identifying and quantifying instances of social distancing, with an accuracy of 82% and little latency. It has been able to work efficiently with real-time streaming at 25-30 ms. Our model is based on CSPDarkNet-53, which was trained on the MS COCO dataset for image classification. It includes additional layers to capture feature maps from different phases. Additionally, the model's neck is made up of PANet, which is used to aggregate the parameters from various CSPDarkNet-53 layers. The CSPDarkNet-53's 53 convolutional layers are followed by 53 more layers in the model head, for a total of 106 completely convolutional layers in the design. This architecture is further integrated with YOLOv3, resulting in the YOLOv4 model, which will be used by our detection model. Furthermore, to differentiate humans The aforementioned method was used to evaluate drone footage and count social distance violations in real time. Our findings show that our model was reliable and successful at detecting social distance violations in real-time with an average accuracy of 82%.",True,computer vision,CNN
39236563,Prediction of mortality events of patients with acute heart failure in intensive care unit based on deep neural network,"BACKGROUND: Acute heart failure (AHF) in the intensive care unit (ICU) is characterized by its criticality, rapid progression, complex and changeable condition, and its pathophysiological process involves the interaction of multiple organs and systems. This makes it difficult to predict in-hospital mortality events comprehensively and accurately. Traditional analysis methods based on statistics and machine learning suffer from insufficient model performance, poor accuracy caused by prior dependence, and difficulty in adequately considering the complex relationships between multiple risk factors. Therefore, the application of deep neural network (DNN) techniques to the specific scenario, predicting mortality events of patients with AHF under intensive care, has become a research frontier.
METHODS: This research utilized the MIMIC-IV critical care database as the primary data source and employed the synthetic minority over-sampling technique (SMOTE) to balance the dataset. Deep neural network models-backpropagation neural network (BPNN) and recurrent neural network (RNN), which are based on electronic medical record data mining, were employed to investigate the in-hospital death event judgment task of patients with AHF under intensive care. Additionally, multiple single machine learning models and ensemble learning models were constructed for comparative experiments. Moreover, we achieved various optimal performance combinations by modifying the classification threshold of deep neural network models to address the diverse real-world requirements in the ICU. Finally, we conducted an interpretable deep model using SHapley Additive exPlanations (SHAP) to uncover the most influential medical record features for each patient from the aspects of global and local interpretation.
RESULTS: In terms of model performance in this scenario, deep neural network models outperform both single machine learning models and ensemble learning models, achieving the highest Accuracy, Precision, Recall, F1 value, and Area under the ROC curve, which can reach 0.949, 0.925, 0.983, 0.953, and 0.987 respectively. SHAP value analysis revealed that the ICU scores (APSIII, OASIS, SOFA) are significantly correlated with the occurrence of in-hospital fatal events.
CONCLUSIONS: Our study underscores that DNN-based mortality event classifier offers a novel intelligent approach for forecasting and assessing the prognosis of AHF patients in the ICU. Additionally, the ICU scores stand out as the most predictive features, which implies that in the decision-making process of the models, ICU scores can provide the most crucial information, making the greatest positive or negative contribution to influence the incidence of in-hospital mortality among patients with acute heart failure.",True,other,RNN
39235402,Generalizable Deep Learning for the Detection of Incomplete and Complete Retinal Pigment Epithelium and Outer Retinal Atrophy: A MACUSTAR Report,"PURPOSE: The purpose of this study was to develop a deep learning algorithm for detecting and quantifying incomplete retinal pigment epithelium and outer retinal atrophy (iRORA) and complete retinal pigment epithelium and outer retinal atrophy (cRORA) in optical coherence tomography (OCT) that generalizes well to data from different devices and to validate in an intermediate age-related macular degeneration (iAMD) cohort.
METHODS: The algorithm comprised a domain adaptation (DA) model, promoting generalization across devices, and a segmentation model for detecting granular biomarkers defining iRORA/cRORA, which are combined into iRORA/cRORA segmentations. Manual annotations of iRORA/cRORA in OCTs from different devices in the MACUSTAR study (168 patients with iAMD) were compared to the algorithm's output. Eye level classification metrics included sensitivity, specificity, and quadratic weighted Cohen's κ score (κw). Segmentation performance was assessed quantitatively using Bland-Altman plots and qualitatively.
RESULTS: For ZEISS OCTs, sensitivity and specificity for iRORA/cRORA classification were 38.5% and 93.1%, respectively, and 60.0% and 96.4% for cRORA. For Spectralis OCTs, these were 84.0% and 93.7% for iRORA/cRORA, and 62.5% and 97.4% for cRORA. The κw scores for 3-way classification (none, iRORA, and cRORA) were 0.37 and 0.73 for ZEISS and Spectralis, respectively. Removing DA reduced κw from 0.73 to 0.63 for Spectralis.
CONCLUSIONS: The DA-enabled iRORA/cRORA segmentation algorithm showed superior consistency compared to human annotations, and good generalization across OCT devices.
TRANSLATIONAL RELEVANCE: The application of this algorithm may help toward precise and automated tracking of iAMD-related lesion changes, which is crucial in clinical settings and multicenter longitudinal studies on iAMD.",True,both,recurrent neural network
39213233,Multimodal ischemic stroke recurrence prediction model based on the capsule neural network and support vector machine,"Ischemic stroke (IS) has a high recurrence rate. Machine learning (ML) models have been developed based on single-modal biochemical tests, and imaging data have been used to predict stroke recurrence. However, the prediction accuracy of these models is not sufficiently high. Therefore, this study aimed to collect biochemical detection and magnetic resonance imaging (MRI) data to establish a dataset and propose a high-performance heterogeneous multimodal IS recurrence prediction model based on deep learning. This is a retrospective cohort study. Data were retrospectively collected from 634 IS patients in Zhuhai, China, a 12-month follow-up was conducted to determine stroke recurrence. We propose the ischemic stroke multi-group learning (ISGL) model, an integrated model for predicting the recurrence risk of multimodal IS in patients, based on a capsule neural network and a linear support vector machine (SVM). Two capsule neural network prediction models based on T1 and T2 signals in the MRI data and a SVM prediction model based on biochemical test data were established. Finally, a vote was conducted on the final judgment of the integrated model. The ISGL model was compared with 6 classical ML and deep learning models: k-nearest neighbors, SVM, logistic regression, random forest, eXtreme Gradient Boosting, and visual geometry group. The results revealed that the accuracy, specificity, sensitivity and the area under the curve of the ISGL model were 95%, 96%, 94%, and 95%, respectively. Among the comparison models, the visual geometry group method exhibited the best performance, but it much lower than those of the ISGL model. Analysis of the importance of biochemical test data revealed that low-density lipoprotein, smoking, and heart disease history were the positively correlated factors, and total cholesterol, high-density lipoprotein, and diabetes were and the negatively correlated factors. This study proposes the ISGL model can be used simultaneously with MRI and biochemical data to predict IS recurrence. This combination resulted in higher rate of performance than that of the other ML models. Additionally, this study found related risk factors affected recurrence, which can be used to intervene in high-risk patients' recurrence as early as possible and promote the development of secondary prevention of stroke.",True,other,recurrent neural network
39176883,Deep Learning-Based Prediction of Daily COVID-19 Cases Using X (Twitter) Data,"Due to the importance of COVID-19 control, innovative methods for predicting cases using social network data are increasingly under attention. This study aims to predict confirmed COVID-19 cases using X (Twitter) social network data (tweets) and deep learning methods. We prepare data extracted from tweets by natural language processing (NLP) and consider the daily G-value (growth rate) as the target variable of COVID-19, collected from the worldometer. We develop and evaluate a time series mixer (TSMixer) predictive model for multivariate time series. The mean squared error (MSE) loss on the test dataset was 0.0063 for 24-month Gvalue prediction when using the MinMax normalization with recursive feature elimination (RFE) and average or min aggregation method. Our findings illuminate the potential of integrating social media data to enhance daily COVID-19 case predictions and are applicable also for epidemiological forecasting purposes.",True,both,recurrent neural network
39173188,High-Throughput and Integrated CRISPR/Cas12a-Based Molecular Diagnosis Using a Deep Learning Enabled Microfluidic System,"CRISPR/Cas-based molecular diagnosis demonstrates potent potential for sensitive and rapid pathogen detection, notably in SARS-CoV-2 diagnosis and mutation tracking. Yet, a major hurdle hindering widespread practical use is its restricted throughput, limited integration, and complex reagent preparation. Here, a system, <u>m</u>icrofluidic multiplate-based <u>u</u>ltrahigh <u>t</u>hroughput <u>a</u>nalysis of <u>S</u>ARS-CoV-2 variants of concern using CRISPR/<u>Ca</u>s12a and <u>n</u>onextraction RT-LAMP (mutaSCAN), is proposed for rapid detection of SARS-CoV-2 and its variants with limited resource requirements. With the aid of the self-developed reagents and deep-learning enabled prototype device, our mutaSCAN system can detect SARS-CoV-2 in mock swab samples below 30 min as low as 250 copies/mL with the throughput up to 96 per round. Clinical specimens were tested with this system, the accuracy for routine and mutation testing (22 wildtype samples, 26 mutational samples) was 98% and 100%, respectively. No false-positive results were found for negative (n = 24) samples.",True,other,Not specified
39166970,Deep Learning Segmentation of Infiltrative and Enhancing Cellular Tumor at Pre- and Posttreatment Multishell Diffusion MRI of Glioblastoma,"Purpose To develop and validate a deep learning (DL) method to detect and segment enhancing and nonenhancing cellular tumor on pre- and posttreatment MRI scans in patients with glioblastoma and to predict overall survival (OS) and progression-free survival (PFS). Materials and Methods This retrospective study included 1397 MRI scans in 1297 patients with glioblastoma, including an internal set of 243 MRI scans (January 2010 to June 2022) for model training and cross-validation and four external test cohorts. Cellular tumor maps were segmented by two radiologists on the basis of imaging, clinical history, and pathologic findings. Multimodal MRI data with perfusion and multishell diffusion imaging were inputted into a nnU-Net DL model to segment cellular tumor. Segmentation performance (Dice score) and performance in distinguishing recurrent tumor from posttreatment changes (area under the receiver operating characteristic curve [AUC]) were quantified. Model performance in predicting OS and PFS was assessed using Cox multivariable analysis. Results A cohort of 178 patients (mean age, 56 years ± 13 [SD]; 116 male, 62 female) with 243 MRI timepoints, as well as four external datasets with 55, 70, 610, and 419 MRI timepoints, respectively, were evaluated. The median Dice score was 0.79 (IQR, 0.53-0.89), and the AUC for detecting residual or recurrent tumor was 0.84 (95% CI: 0.79, 0.89). In the internal test set, estimated cellular tumor volume was significantly associated with OS (hazard ratio [HR] = 1.04 per milliliter; P &lt; .001) and PFS (HR = 1.04 per milliliter; P &lt; .001) after adjustment for age, sex, and gross total resection (GTR) status. In the external test sets, estimated cellular tumor volume was significantly associated with OS (HR = 1.01 per milliliter; P &lt; .001) after adjustment for age, sex, and GTR status. Conclusion A DL model incorporating advanced imaging could accurately segment enhancing and nonenhancing cellular tumor, distinguish recurrent or residual tumor from posttreatment changes, and predict OS and PFS in patients with glioblastoma. Keywords: Segmentation, Glioblastoma, Multishell Diffusion MRI Supplemental material is available for this article. © RSNA, 2024.",True,other,Not specified
39157582,SpanSeq: similarity-based sequence data splitting method for improved development and assessment of deep learning projects,"The use of deep learning models in computational biology has increased massively in recent years, and it is expected to continue with the current advances in the fields such as Natural Language Processing. These models, although able to draw complex relations between input and target, are also inclined to learn noisy deviations from the pool of data used during their development. In order to assess their performance on unseen data (their capacity to generalize), it is common to split the available data randomly into development (train/validation) and test sets. This procedure, although standard, has been shown to produce dubious assessments of generalization due to the existing similarity between samples in the databases used. In this work, we present SpanSeq, a database partition method for machine learning that can scale to most biological sequences (genes, proteins and genomes) in order to avoid data leakage between sets. We also explore the effect of not restraining similarity between sets by reproducing the development of two state-of-the-art models on bioinformatics, not only confirming the consequences of randomly splitting databases on the model assessment, but expanding those repercussions to the model development. SpanSeq is available at https://github.com/genomicepidemiology/SpanSeq.",True,other,recurrent neural network
39154616,Metadata-enhanced contrastive learning from retinal optical coherence tomography images,"Deep learning has potential to automate screening, monitoring and grading of disease in medical images. Pretraining with contrastive learning enables models to extract robust and generalisable features from natural image datasets, facilitating label-efficient downstream image analysis. However, the direct application of conventional contrastive methods to medical datasets introduces two domain-specific issues. Firstly, several image transformations which have been shown to be crucial for effective contrastive learning do not translate from the natural image to the medical image domain. Secondly, the assumption made by conventional methods, that any two images are dissimilar, is systematically misleading in medical datasets depicting the same anatomy and disease. This is exacerbated in longitudinal image datasets that repeatedly image the same patient cohort to monitor their disease progression over time. In this paper we tackle these issues by extending conventional contrastive frameworks with a novel metadata-enhanced strategy. Our approach employs widely available patient metadata to approximate the true set of inter-image contrastive relationships. To this end we employ records for patient identity, eye position (i.e. left or right) and time series information. In experiments using two large longitudinal datasets containing 170,427 retinal optical coherence tomography (OCT) images of 7912 patients with age-related macular degeneration (AMD), we evaluate the utility of using metadata to incorporate the temporal dynamics of disease progression into pretraining. Our metadata-enhanced approach outperforms both standard contrastive methods and a retinal image foundation model in five out of six image-level downstream tasks related to AMD. We find benefits in both a low-data and high-data regime across tasks ranging from AMD stage and type classification to prediction of visual acuity. Due to its modularity, our method can be quickly and cost-effectively tested to establish the potential benefits of including available metadata in contrastive pretraining.",True,other,convolutional neural network
39152209,Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling,"Deep learning has enabled breakthroughs in automated diagnosis from medical imaging, with many successful applications in ophthalmology. However, standard medical image classification approaches only assess disease presence at the time of acquisition, neglecting the common clinical setting of longitudinal imaging. For slow, progressive eye diseases like age-related macular degeneration (AMD) and primary open-angle glaucoma (POAG), patients undergo repeated imaging over time to track disease progression and forecasting the future risk of developing a disease is critical to properly plan treatment. Our proposed Longitudinal Transformer for Survival Analysis (LTSA) enables dynamic disease prognosis from longitudinal medical imaging, modeling the time to disease from sequences of fundus photography images captured over long, irregular time periods. Using longitudinal imaging data from the Age-Related Eye Disease Study (AREDS) and Ocular Hypertension Treatment Study (OHTS), LTSA significantly outperformed a single-image baseline in 19/20 head-to-head comparisons on late AMD prognosis and 18/20 comparisons on POAG prognosis. A temporal attention analysis also suggested that, while the most recent image is typically the most influential, prior imaging still provides additional prognostic value.",True,other,recurrent neural network
39152187,A comparative analysis of classical and machine learning methods for forecasting TB/HIV co-infection,"TB/HIV coinfection poses a complex public health challenge. Accurate forecasting of future trends is essential for efficient resource allocation and intervention strategy development. This study compares classical statistical and machine learning models to predict TB/HIV coinfection cases stratified by gender and the general populations. We analyzed time series data using exponential smoothing and ARIMA to establish the baseline trend and seasonality. Subsequently, machine learning models (SVR, XGBoost, LSTM, CNN, GRU, CNN-GRU, and CNN-LSTM) were employed to capture the complex dynamics and inherent non-linearities of TB/HIV coinfection data. Performance metrics (MSE, MAE, sMAPE) and the Diebold-Mariano test were used to evaluate the model performance. Results revealed that Deep Learning models, particularly Bidirectional LSTM and CNN-LSTM, significantly outperformed classical methods. This demonstrates the effectiveness of Deep Learning for modeling TB/HIV coinfection time series and generating more accurate forecasts.",True,other,convolutional neural network
39151114,Deep-Transfer-Learning-Based Natural Language Processing of Serial Free-Text Computed Tomography Reports for Predicting Survival of Patients With Pancreatic Cancer,"PURPOSE: To explore the predictive potential of serial computed tomography (CT) radiology reports for pancreatic cancer survival using natural language processing (NLP).
METHODS: Deep-transfer-learning-based NLP models were retrospectively trained and tested with serial, free-text CT reports, and survival information of consecutive patients diagnosed with pancreatic cancer in a Korean tertiary hospital was extracted. Randomly selected patients with pancreatic cancer and their serial CT reports from an independent tertiary hospital in the United States were included in the external testing data set. The concordance index (c-index) of predicted survival and actual survival, and area under the receiver operating characteristic curve (AUROC) for predicting 1-year survival were calculated.
RESULTS: Between January 2004 and June 2021, 2,677 patients with 12,255 CT reports and 670 patients with 3,058 CT reports were allocated to training and internal testing data sets, respectively. ClinicalBERT (Bidirectional Encoder Representations from Transformers) model trained on the single, first CT reports showed a c-index of 0.653 and AUROC of 0.722 in predicting the overall survival of patients with pancreatic cancer. ClinicalBERT trained on up to 15 consecutive reports from the initial report showed an improved c-index of 0.811 and AUROC of 0.911. On the external testing set with 273 patients with 1,947 CT reports, the AUROC was 0.888, indicating the generalizability of our model. Further analyses showed our model's contextual interpretation beyond specific phrases.
CONCLUSION: Deep-transfer-learning-based NLP model of serial CT reports can predict the survival of patients with pancreatic cancer. Clinical decisions can be supported by the developed model, with survival information extracted solely from serial radiology reports.",True,other,Not specified
39148927,Adversarial Learning for MRI Reconstruction and Classification of Cognitively Impaired Individuals,"Game theory-inspired deep learning using a generative adversarial network provides an environment to competitively interact and accomplish a goal. In the context of medical imaging, most work has focused on achieving single tasks such as improving image resolution, segmenting images, and correcting motion artifacts. We developed a dual-objective adversarial learning framework that simultaneously 1) reconstructs higher quality brain magnetic resonance images (MRIs) that 2) retain disease-specific imaging features critical for predicting progression from mild cognitive impairment (MCI) to Alzheimer's disease (AD). We obtained 3-Tesla, T1-weighted brain MRIs of participants from the Alzheimer's Disease Neuroimaging Initiative (ADNI, N=342) and the National Alzheimer's Coordinating Center (NACC, N = 190) datasets. We simulated MRIs with missing data by removing 50% of sagittal slices from the original scans (i.e., diced scans). The generator was trained to reconstruct brain MRIs using the diced scans as input. We introduced a classifier into the GAN architecture to discriminate between stable (i.e., sMCI) and progressive MCI (i.e., pMCI) based on the generated images to facilitate encoding of disease-related information during reconstruction. The framework was trained using ADNI data and externally validated on NACC data. In the NACC cohort, generated images had better image quality than the diced scans (Structural similarity (SSIM) index: 0.553 ± 0.116 versus 0.348 ± 0.108). Furthermore, a classifier utilizing the generated images distinguished pMCI from sMCI more accurately than with the diced scans (F1-score: 0.634 ± 0.019 versus 0.573 ± 0.028). Competitive deep learning has potential to facilitate disease-oriented image reconstruction in those at risk of developing Alzheimer's disease.",True,other,recurrent neural network
39118787,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.",True,other,Not specified
39112910,How do deep-learning models generalize across populations? Cross-ethnicity generalization of COPD detection,"OBJECTIVES: To evaluate the performance and potential biases of deep-learning models in detecting chronic obstructive pulmonary disease (COPD) on chest CT scans across different ethnic groups, specifically non-Hispanic White (NHW) and African American (AA) populations.
MATERIALS AND METHODS: Inspiratory chest CT and clinical data from 7549 Genetic epidemiology of COPD individuals (mean age 62 years old, 56-69 interquartile range), including 5240 NHW and 2309 AA individuals, were retrospectively analyzed. Several factors influencing COPD binary classification performance on different ethnic populations were examined: (1) effects of training population: NHW-only, AA-only, balanced set (half NHW, half AA) and the entire set (NHW + AA all); (2) learning strategy: three supervised learning (SL) vs. three self-supervised learning (SSL) methods. Distribution shifts across ethnicity were further assessed for the top-performing methods.
RESULTS: The learning strategy significantly influenced model performance, with SSL methods achieving higher performances compared to SL methods (p < 0.001), across all training configurations. Training on balanced datasets containing NHW and AA individuals resulted in improved model performance compared to population-specific datasets. Distribution shifts were found between ethnicities for the same health status, particularly when models were trained on nearest-neighbor contrastive SSL. Training on a balanced dataset resulted in fewer distribution shifts across ethnicity and health status, highlighting its efficacy in reducing biases.
CONCLUSION: Our findings demonstrate that utilizing SSL methods and training on large and balanced datasets can enhance COPD detection model performance and reduce biases across diverse ethnic populations. These findings emphasize the importance of equitable AI-driven healthcare solutions for COPD diagnosis.
CRITICAL RELEVANCE STATEMENT: Self-supervised learning coupled with balanced datasets significantly improves COPD detection model performance, addressing biases across diverse ethnic populations and emphasizing the crucial role of equitable AI-driven healthcare solutions.
KEY POINTS: Self-supervised learning methods outperform supervised learning methods, showing higher AUC values (p < 0.001). Balanced datasets with non-Hispanic White and African American individuals improve model performance. Training on diverse datasets enhances COPD detection accuracy. Ethnically diverse datasets reduce bias in COPD detection models. SimCLR models mitigate biases in COPD detection across ethnicities.",True,other,Not specified
39107137,Preeclampsia and its prediction: traditional versus contemporary predictive methods,"OBJECTIVE: Preeclampsia (PE) poses a significant threat to maternal and perinatal health, so its early prediction, prevention, and management are of paramount importance to mitigate adverse pregnancy outcomes. This article provides a brief review spanning epidemiology, etiology, pathophysiology, and risk factors associated with PE, mainly discussing the emerging role of Artificial Intelligence (AI) deep learning (DL) technology in predicting PE, to advance the understanding of PE and foster the clinical application of early prediction methods.
METHODS: Our narrative review comprehensively examines the PE epidemiology, etiology, pathophysiology, risk factors and predictive approaches, including traditional models and AI deep learning technology.
RESULTS: Preeclampsia involves a wide range of biological and biochemical risk factors, among which poor uterine artery remodeling, excessive immune response, endothelial dysfunction, and imbalanced angiogenesis play important roles. Traditional PE prediction models exhibit significant limitations in sensitivity and specificity, particularly in predicting late-onset PE, with detection rates ranging from only 30% to 50%. AI models have exhibited a notable level of predictive accuracy and value across various populations and datasets, achieving detection rates of approximately 70%. Particularly, they have shown superior predictive capabilities for late-onset PE, thereby presenting novel opportunities for early screening and management of the condition.
CONCLUSION: AI DL technology holds promise in revolutionizing the prediction and management of PE. AI-based approaches offer a pathway toward more effective risk assessment methods by addressing the shortcomings of traditional prediction models. Ongoing research efforts should focus on expanding databases and validating the performance of AI in diverse populations, leading to the development of more sophisticated prediction models with improved accuracy.",True,other,Not specified
39104853,Genome composition-based deep learning predicts oncogenic potential of HPVs,"Human papillomaviruses (HPVs) account for more than 30% of cancer cases, with definite identification of the oncogenic role of viral E6 and E7 genes. However, the identification of high-risk HPV genotypes has largely relied on lagged biological exploration and clinical observation, with types unclassified and oncogenicity unknown for many HPVs. In the present study, we retrieved and cleaned HPV sequence records with high quality and analyzed their genomic compositional traits of dinucleotide (DNT) and DNT representation (DCR) to overview the distribution difference among various types of HPVs. Then, a deep learning model was built to predict the oncogenic potential of all HPVs based on E6 and E7 genes. Our results showed that the main three groups of Alpha, Beta, and Gamma HPVs were clearly separated between/among types in the DCR trait for either E6 or E7 coding sequence (CDS) and were clustered within the same group. Moreover, the DCR data of either E6 or E7 were learnable with a convolutional neural network (CNN) model. Either CNN classifier predicted accurately the oncogenicity label of high and low oncogenic HPVs. In summary, the compositional traits of HPV oncogenicity-related genes E6 and E7 were much different between the high and low oncogenic HPVs, and the compositional trait of the DCR-based deep learning classifier predicted the oncogenic phenotype accurately of HPVs. The trained predictor in this study will facilitate the identification of HPV oncogenicity, particularly for those HPVs without clear genotype or phenotype.",True,other,Not specified
39103945,Phenotyping COVID-19 respiratory failure in spontaneously breathing patients with AI on lung CT-scan,"BACKGROUND: Automated analysis of lung computed tomography (CT) scans may help characterize subphenotypes of acute respiratory illness. We integrated lung CT features measured via deep learning with clinical and laboratory data in spontaneously breathing subjects to enhance the identification of COVID-19 subphenotypes.
METHODS: This is a multicenter observational cohort study in spontaneously breathing patients with COVID-19 respiratory failure exposed to early lung CT within 7 days of admission. We explored lung CT images using deep learning approaches to quantitative and qualitative analyses; latent class analysis (LCA) by using clinical, laboratory and lung CT variables; regional differences between subphenotypes following 3D spatial trajectories.
RESULTS: Complete datasets were available in 559 patients. LCA identified two subphenotypes (subphenotype 1 and 2). As compared with subphenotype 2 (n = 403), subphenotype 1 patients (n = 156) were older, had higher inflammatory biomarkers, and were more hypoxemic. Lungs in subphenotype 1 had a higher density gravitational gradient with a greater proportion of consolidated lungs as compared with subphenotype 2. In contrast, subphenotype 2 had a higher density submantellar-hilar gradient with a greater proportion of ground glass opacities as compared with subphenotype 1. Subphenotype 1 showed higher prevalence of comorbidities associated with endothelial dysfunction and higher 90-day mortality than subphenotype 2, even after adjustment for clinically meaningful variables.
CONCLUSIONS: Integrating lung-CT data in a LCA allowed us to identify two subphenotypes of COVID-19, with different clinical trajectories. These exploratory findings suggest a role of automated imaging characterization guided by machine learning in subphenotyping patients with respiratory failure.
TRIAL REGISTRATION: ClinicalTrials.gov Identifier: NCT04395482. Registration date: 19/05/2020.",True,other,Not specified
39102883,Machine learning and deep learning tools for the automated capture of cancer surveillance data,"The National Cancer Institute and the Department of Energy strategic partnership applies advanced computing and predictive machine learning and deep learning models to automate the capture of information from unstructured clinical text for inclusion in cancer registries. Applications include extraction of key data elements from pathology reports, determination of whether a pathology or radiology report is related to cancer, extraction of relevant biomarker information, and identification of recurrence. With the growing complexity of cancer diagnosis and treatment, capturing essential information with purely manual methods is increasingly difficult. These new methods for applying advanced computational capabilities to automate data extraction represent an opportunity to close critical information gaps and create a nimble, flexible platform on which new information sources, such as genomics, can be added. This will ultimately provide a deeper understanding of the drivers of cancer and outcomes in the population and increase the timeliness of reporting. These advances will enable better understanding of how real-world patients are treated and the outcomes associated with those treatments in the context of our complex medical and social environment.",True,other,autoencoder
39097091,IRnet: Immunotherapy response prediction using pathway knowledge-informed graph neural network,"INTRODUCTION: Immune checkpoint inhibitors (ICIs) are potent and precise therapies for various cancer types, significantly improving survival rates in patients who respond positively to them. However, only a minority of patients benefit from ICI treatments.
OBJECTIVES: Identifying ICI responders before treatment could greatly conserve medical resources, minimize potential drug side effects, and expedite the search for alternative therapies. Our goal is to introduce a novel deep-learning method to predict ICI treatment responses in cancer patients.
METHODS: The proposed deep-learning framework leverages graph neural network and biological pathway knowledge. We trained and tested our method using ICI-treated patients' data from several clinical trials covering melanoma, gastric cancer, and bladder cancer.
RESULTS: Our results demonstrate that this predictive model outperforms current state-of-the-art methods and tumor microenvironment-based predictors. Additionally, the model quantifies the importance of pathways, pathway interactions, and genes in its predictions. A web server for IRnet has been developed and deployed, providing broad accessibility to users at https://irnet.missouri.edu.
CONCLUSION: IRnet is a competitive tool for predicting patient responses to immunotherapy, specifically ICIs. Its interpretability also offers valuable insights into the mechanisms underlying ICI treatments.",True,other,Not specified
39095474,Deep learning predicts the 1-year prognosis of pancreatic cancer patients using positive peritoneal washing cytology,"Peritoneal washing cytology (CY) in patients with pancreatic cancer is mainly used for staging; however, it may also be used to evaluate the intraperitoneal status to predict a more accurate prognosis. Here, we investigated the potential of deep learning of CY specimen images for predicting the 1-year prognosis of pancreatic cancer in CY-positive patients. CY specimens from 88 patients with prognostic information were retrospectively analyzed. CY specimens scanned by the whole slide imaging device were segmented and subjected to deep learning with a Vision Transformer (ViT) and a Convolutional Neural Network (CNN). The results indicated that ViT and CNN predicted the 1-year prognosis from scanned images with accuracies of 0.8056 and 0.8009 in the area under the curve of the receiver operating characteristic curves, respectively. Patients predicted to survive 1 year or more by ViT showed significantly longer survivals by Kaplan-Meier analyses. The cell nuclei found to have a negative prognostic impact by ViT appeared to be neutrophils. Our results indicate that AI-mediated analysis of CY specimens can successfully predict the 1-year prognosis of patients with pancreatic cancer positive for CY. Intraperitoneal neutrophils may be a novel prognostic marker and therapeutic target for CY-positive patients with pancreatic cancer.",True,other,Not specified
39090688,Current genomic deep learning models display decreased performance in cell type-specific accessible regions,"BACKGROUND: A number of deep learning models have been developed to predict epigenetic features such as chromatin accessibility from DNA sequence. Model evaluations commonly report performance genome-wide; however, cis regulatory elements (CREs), which play critical roles in gene regulation, make up only a small fraction of the genome. Furthermore, cell type-specific CREs contain a large proportion of complex disease heritability.
RESULTS: We evaluate genomic deep learning models in chromatin accessibility regions with varying degrees of cell type specificity. We assess two modeling directions in the field: general purpose models trained across thousands of outputs (cell types and epigenetic marks) and models tailored to specific tissues and tasks. We find that the accuracy of genomic deep learning models, including two state-of-the-art general purpose models-Enformer and Sei-varies across the genome and is reduced in cell type-specific accessible regions. Using accessibility models trained on cell types from specific tissues, we find that increasing model capacity to learn cell type-specific regulatory syntax-through single-task learning or high capacity multi-task models-can improve performance in cell type-specific accessible regions. We also observe that improving reference sequence predictions does not consistently improve variant effect predictions, indicating that novel strategies are needed to improve performance on variants.
CONCLUSIONS: Our results provide a new perspective on the performance of genomic deep learning models, showing that performance varies across the genome and is particularly reduced in cell type-specific accessible regions. We also identify strategies to maximize performance in cell type-specific accessible regions.",True,other,Not specified
39089210,Deep representation learning from electronic medical records identifies distinct symptom based subtypes and progression patterns for COVID-19 prognosis,"OBJECTIVE: Symptoms are significant kind of phenotypes for managing and controlling of the burst of acute infectious diseases, such as COVID-19. Although patterns of symptom clusters and time series have been considered the high potential prediction factors for the prognosis of patients, the elaborated subtypes and their progression patterns based on symptom phenotypes related to the prognosis of COVID-19 patients still need be detected. This study aims to investigate patient subtypes and their progression patterns with distinct features of outcome and prognosis.
METHODS: This study included a total of 14,139 longitudinal electronic medical records (EMRs) obtained from four hospitals in Hubei Province, China, involving 2,683 individuals in the early stage of COVID-19 pandemic. A deep representation learning model was developed to help acquire the symptom profiles of patients. K-means clustering algorithm is used to divide them into distinct subtypes. Subsequently, symptom progression patterns were identified by considering the subtypes associated with patients upon admission and discharge. Furthermore, we used Fisher's test to identify significant clinical entities for each subtype.
RESULTS: Three distinct patient subtypes exhibiting specific symptoms and prognosis have been identified. Particularly, Subtype 0 includes 44.2% of the whole and is characterized by poor appetite, fatigue and sleep disorders; Subtype 1 includes 25.6% cases and is characterized by confusion, cough with bloody sputum, encopresis and urinary incontinence; Subtype 2 includes 30.2% cases and is characterized by dry cough and rhinorrhea. These three subtypes demonstrate significant disparities in prognosis, with the mortality rates of 4.72%, 8.59%, and 0.25% respectively. Furthermore, symptom cluster progression patterns showed that patients with Subtype 0 who manifest dark yellow urine, chest pain, etc. in the admission stage exhibit an elevated risk of transforming into the more severe subtypes with poor outcome, whereas those presenting with nausea and vomiting tend to incline towards entering the milder subtype.
CONCLUSION: This study has proposed a clinical meaningful approach by utilizing the deep representation learning and real-world EMR data containing symptom phenotypes to identify the COVID-19 subtypes and their progression patterns. The results would be potentially useful to help improve the precise stratification and management of acute infectious diseases.",True,computer vision,Not specified
39077983,A SAR and QSAR study on 3CLpro inhibitors of SARS-CoV-2 using machine learning methods,"The 3C-like Proteinase (3CLpro) of novel coronaviruses is intricately linked to viral replication, making it a crucial target for antiviral agents. In this study, we employed two fingerprint descriptors (ECFP_4 and MACCS) to comprehensively characterize 889 compounds in our dataset. We constructed 24 classification models using machine learning algorithms, including Support Vector Machine (SVM), Random Forest (RF), extreme Gradient Boosting (XGBoost), and Deep Neural Networks (DNN). Among these models, the DNN- and ECFP_4-based Model 1D_2 achieved the most promising results, with a remarkable Matthews correlation coefficient (MCC) value of 0.796 in the 5-fold cross-validation and 0.722 on the test set. The application domains of the models were analysed using d<sub>STD-PRO</sub> calculations. The collected 889 compounds were clustered by K-means algorithm, and the relationships between structural fragments and inhibitory activities of the highly active compounds were analysed for the 10 obtained subsets. In addition, based on 464 3CLpro inhibitors, 27 QSAR models were constructed using three machine learning algorithms with a minimum root mean square error (RMSE) of 0.509 on the test set. The applicability domains of the models and the structure-activity relationships responded from the descriptors were also analysed.",True,other,recurrent neural network
39068894,Integrating multi-task and cost-sensitive learning for predicting mortality risk of chronic diseases in the elderly using real-world data,"BACKGROUND AND OBJECTIVE: Real-world data encompass population diversity, enabling insights into chronic disease mortality risk among the elderly. Deep learning excels on large datasets, offering promise for real-world data. However, current models focus on single diseases, neglecting comorbidities prevalent in patients. Moreover, mortality is infrequent compared to illness, causing extreme class imbalance that impedes reliable prediction. We aim to develop a deep learning framework that accurately forecasts mortality risk from real-world data by addressing comorbidities and class imbalance.
METHODS: We integrated multi-task and cost-sensitive learning, developing an enhanced deep neural network architecture that extends multi-task learning to predict mortality risk across multiple chronic diseases. Each patient cohort with a chronic disease was assigned to a separate task, with shared lower-level parameters capturing inter-disease complexities through distinct top-level networks. Cost-sensitive functions were incorporated to ensure learning of positive class characteristics for each task and achieve accurate prediction of the risk of death from multiple chronic diseases.
RESULTS: Our study covers 15 prevalent chronic diseases and is experimented with real-world data from 482,145 patients (including 9,516 deaths) in Shenzhen, China. The proposed model is compared with six models including three machine learning models: logistic regression, XGBoost, and CatBoost, and three state-of-the-art deep learning models: 1D-CNN, TabNet, and Saint. The experimental results show that, compared with the other compared algorithms, MTL-CSDNN has better prediction results on the test set (ACC=0.99, REC=0.99, PRAUC=0.97, MCC=0.98, G-means = 0.98).
CONCLUSIONS: Our method provides valuable insights into leveraging real-world data for precise multi-disease mortality risk prediction, offering potential applications in optimizing chronic disease management, enhancing well-being, and reducing healthcare costs for the elderly population.",True,other,Not specified
39068267,Development of a deep learning model for cancer diagnosis by inspecting cell-free DNA end-motifs,"Accurate discrimination between patients with and without cancer from cfDNA is crucial for early cancer diagnosis. Herein, we develop and validate a deep-learning-based model entitled end-motif inspection via transformer (EMIT) for discriminating individuals with and without cancer by learning feature representations from cfDNA end-motifs. EMIT is a self-supervised learning approach that models rankings of cfDNA end-motifs. We include 4606 samples subjected to different types of cfDNA sequencing to develop EIMIT, and subsequently evaluate classification performance of linear projections of EMIT on six datasets and an additional inhouse testing set encopassing whole-genome, whole-genome bisulfite and 5-hydroxymethylcytosine sequencing. The linear projection of representations from EMIT achieved area under the receiver operating curve (AUROC) values ranged from 0.895 (0.835-0.955) to 0.996 (0.994-0.997) across these six datasets, outperforming its baseline by significant margins. Additionally, we showed that linear projection of EMIT representations can achieve an AUROC of 0.962 (0.914-1.0) in identification of lung cancer on an independent testing set subjected to whole-exome sequencing. The findings of this study indicate that a transformer-based deep learning model can learn cancer-discrimative representations from cfDNA end-motifs. The representations of this deep learning model can be exploited for discriminating patients with and without cancer.",True,other,Not specified
39063538,Towards Improved XAI-Based Epidemiological Research into the Next Potential Pandemic,"By applying AI techniques to a variety of pandemic-relevant data, artificial intelligence (AI) has substantially supported the control of the spread of the SARS-CoV-2 virus. Along with this, epidemiological machine learning studies of SARS-CoV-2 have been frequently published. While these models can be perceived as precise and policy-relevant to guide governments towards optimal containment policies, their black box nature can hamper building trust and relying confidently on the prescriptions proposed. This paper focuses on interpretable AI-based epidemiological models in the context of the recent SARS-CoV-2 pandemic. We systematically review existing studies, which jointly incorporate AI, SARS-CoV-2 epidemiology, and explainable AI approaches (XAI). First, we propose a conceptual framework by synthesizing the main methodological features of the existing AI pipelines of SARS-CoV-2. Upon the proposed conceptual framework and by analyzing the selected epidemiological studies, we reflect on current research gaps in epidemiological AI toolboxes and how to fill these gaps to generate enhanced policy support in the next potential pandemic.",True,other,convolutional neural network
39052168,Artificial intelligence in chronic kidney diseases: methodology and potential applications,"Chronic kidney disease (CKD) represents a significant global health challenge, characterized by kidney damage and decreased function. Its prevalence has steadily increased, necessitating a comprehensive understanding of its epidemiology, risk factors, and management strategies. While traditional prognostic markers such as estimated glomerular filtration rate (eGFR) and albuminuria provide valuable insights, they may not fully capture the complexity of CKD progression and associated cardiovascular (CV) risks.This paper reviews the current state of renal and CV risk prediction in CKD, highlighting the limitations of traditional models and the potential for integrating artificial intelligence (AI) techniques. AI, particularly machine learning (ML) and deep learning (DL), offers a promising avenue for enhancing risk prediction by analyzing vast and diverse patient data, including genetic markers, biomarkers, and imaging. By identifying intricate patterns and relationships within datasets, AI algorithms can generate more comprehensive risk profiles, enabling personalized and nuanced risk assessments.Despite its potential, the integration of AI into clinical practice faces challenges such as the opacity of some algorithms and concerns regarding data quality, privacy, and bias. Efforts towards explainable AI (XAI) and rigorous data governance are essential to ensure transparency, interpretability, and trustworthiness in AI-driven predictions.",True,other,Not specified
39048590,Robust evaluation of deep learning-based representation methods for survival and gene essentiality prediction on bulk RNA-seq data,"Deep learning (DL) has shown potential to provide powerful representations of bulk RNA-seq data in cancer research. However, there is no consensus regarding the impact of design choices of DL approaches on the performance of the learned representation, including the model architecture, the training methodology and the various hyperparameters. To address this problem, we evaluate the performance of various design choices of DL representation learning methods using TCGA and DepMap pan-cancer datasets and assess their predictive power for survival and gene essentiality predictions. We demonstrate that baseline methods achieve comparable or superior performance compared to more complex models on survival predictions tasks. DL representation methods, however, are the most efficient to predict the gene essentiality of cell lines. We show that auto-encoders (AE) are consistently improved by techniques such as masking and multi-head training. Our results suggest that the impact of DL representations and of pretraining are highly task- and architecture-dependent, highlighting the need for adopting rigorous evaluation guidelines. These guidelines for robust evaluation are implemented in a pipeline made available to the research community.",True,other,Not specified
39028429,A Systematic Review of Artificial Intelligence Models for Time-to-Event Outcome Applied in Cardiovascular Disease Risk Prediction,"Artificial intelligence (AI) based predictive models for early detection of cardiovascular disease (CVD) risk are increasingly being utilised. However, AI based risk prediction models that account for right-censored data have been overlooked. This systematic review (PROSPERO protocol CRD42023492655) includes 33 studies that utilised machine learning (ML) and deep learning (DL) models for survival outcome in CVD prediction. We provided details on the employed ML and DL models, eXplainable AI (XAI) techniques, and type of included variables, with a focus on social determinants of health (SDoH) and gender-stratification. Approximately half of the studies were published in 2023 with the majority from the United States. Random Survival Forest (RSF), Survival Gradient Boosting models, and Penalised Cox models were the most frequently employed ML models. DeepSurv was the most frequently employed DL model. DL models were better at predicting CVD outcomes than ML models. Permutation-based feature importance and Shapley values were the most utilised XAI methods for explaining AI models. Moreover, only one in five studies performed gender-stratification analysis and very few incorporate the wide range of SDoH factors in their prediction model. In conclusion, the evidence indicates that RSF and DeepSurv models are currently the optimal models for predicting CVD outcomes. This study also highlights the better predictive ability of DL survival models, compared to ML models. Future research should ensure the appropriate interpretation of AI models, accounting for SDoH, and gender stratification, as gender plays a significant role in CVD occurrence.",True,other,Not specified
39026761,Current genomic deep learning models display decreased performance in cell type specific accessible regions,"BACKGROUND: A number of deep learning models have been developed to predict epigenetic features such as chromatin accessibility from DNA sequence. Model evaluations commonly report performance genome-wide; however, cis regulatory elements (CREs), which play critical roles in gene regulation, make up only a small fraction of the genome. Furthermore, cell type specific CREs contain a large proportion of complex disease heritability.
RESULTS: We evaluate genomic deep learning models in chromatin accessibility regions with varying degrees of cell type specificity. We assess two modeling directions in the field: general purpose models trained across thousands of outputs (cell types and epigenetic marks), and models tailored to specific tissues and tasks. We find that the accuracy of genomic deep learning models, including two state-of-the-art general purpose models - Enformer and Sei - varies across the genome and is reduced in cell type specific accessible regions. Using accessibility models trained on cell types from specific tissues, we find that increasing model capacity to learn cell type specific regulatory syntax - through single-task learning or high capacity multi-task models - can improve performance in cell type specific accessible regions. We also observe that improving reference sequence predictions does not consistently improve variant effect predictions, indicating that novel strategies are needed to improve performance on variants.
CONCLUSIONS: Our results provide a new perspective on the performance of genomic deep learning models, showing that performance varies across the genome and is particularly reduced in cell type specific accessible regions. We also identify strategies to maximize performance in cell type specific accessible regions.",True,other,Not specified
39022088,Ensemble-based deep learning improves detection of invasive breast cancer in routine histopathology images,"Accurate detection of invasive breast cancer (IC) can provide decision support to pathologists as well as improve downstream computational analyses, where detection of IC is a first step. Tissue containing IC is characterized by the presence of specific morphological features, which can be learned by convolutional neural networks (CNN). Here, we compare the use of a single CNN model versus an ensemble of several base models with the same CNN architecture, and we evaluate prediction performance as well as variability across ensemble based model predictions. Two in-house datasets comprising 587 whole slide images (WSI) are used to train an ensemble of ten InceptionV3 models whose consensus is used to determine the presence of IC. A novel visualisation strategy was developed to communicate ensemble agreement spatially. Performance was evaluated in an internal test set with 118 WSIs, and in an additional external dataset (TCGA breast cancer) with 157 WSI. We observed that the ensemble-based strategy outperformed the single CNN-model alternative with respect to accuracy on tile level in 89 % of all WSIs in the test set. The overall accuracy was 0.92 (DICE coefficient, 0.90) for the ensemble model, and 0.85 (DICE coefficient, 0.83) for the single CNN alternative in the internal test set. For TCGA the ensemble outperformed the single CNN in 96.8 % of the WSI, with an accuracy of 0.87 (DICE coefficient 0.89), the single model provides an accuracy of 0.75 (DICE coefficient 0.78). The results suggest that an ensemble-based modeling strategy for breast cancer invasive cancer detection consistently outperforms the conventional single model alternative. Furthermore, visualisation of the ensemble agreement and confusion areas provide direct visual interpretation of the results. High performing cancer detection can provide decision support in the routine pathology setting as well as facilitate downstream computational analyses.",True,both,convolutional neural network
39017032,Deep Learning to Detect Intracranial Hemorrhage in a National Teleradiology Program and the Impact on Interpretation Time,"The diagnostic performance of an artificial intelligence (AI) clinical decision support solution for acute intracranial hemorrhage (ICH) detection was assessed in a large teleradiology practice. The impact on radiologist read times and system efficiency was also quantified. A total of 61 704 consecutive noncontrast head CT examinations were retrospectively evaluated. System performance was calculated along with mean and median read times for CT studies obtained before (baseline, pre-AI period; August 2021 to May 2022) and after (post-AI period; January 2023 to February 2024) AI implementation. The AI solution had a sensitivity of 75.6%, specificity of 92.1%, accuracy of 91.7%, prevalence of 2.70%, and positive predictive value of 21.1%. Of the 56 745 post-AI CT scans with no bleed identified by a radiologist, examinations falsely flagged as suspected ICH by the AI solution (n = 4464) took an average of 9 minutes 40 seconds (median, 8 minutes 7 seconds) to interpret as compared with 8 minutes 25 seconds (median, 6 minutes 48 seconds) for unremarkable CT scans before AI (n = 49 007) (P &lt; .001) and 8 minutes 38 seconds (median, 6 minutes 53 seconds) after AI when ICH was not suspected by the AI solution (n = 52 281) (P &lt; .001). CT scans with no bleed identified by the AI but reported as positive for ICH by the radiologist (n = 384) took an average of 14 minutes 23 seconds (median, 13 minutes 35 seconds) to interpret as compared with 13 minutes 34 seconds (median, 12 minutes 30 seconds) for CT scans correctly reported as a bleed by the AI (n = 1192) (P = .04). With lengthened read times for falsely flagged examinations, system inefficiencies may outweigh the potential benefits of using the tool in a high volume, low prevalence environment. Keywords: Artificial Intelligence, Intracranial Hemorrhage, Read Time, Report Turnaround Time, System Efficiency Supplemental material is available for this article. © RSNA, 2024.",True,both,Not specified
39009381,Association between myosteatosis and impaired glucose metabolism: A deep learning whole-body magnetic resonance imaging population phenotyping approach,"BACKGROUND: There is increasing evidence that myosteatosis, which is currently not assessed in clinical routine, plays an important role in risk estimation in individuals with impaired glucose metabolism, as it is associated with the progression of insulin resistance. With advances in artificial intelligence, automated and accurate algorithms have become feasible to fill this gap.
METHODS: In this retrospective study, we developed and tested a fully automated deep learning model using data from two prospective cohort studies (German National Cohort [NAKO] and Cooperative Health Research in the Region of Augsburg [KORA]) to quantify myosteatosis on whole-body T1-weighted Dixon magnetic resonance imaging as (1) intramuscular adipose tissue (IMAT; the current standard) and (2) quantitative skeletal muscle (SM) fat fraction (SMFF). Subsequently, we investigated the two measures for their discrimination of and association with impaired glucose metabolism beyond baseline demographics (age, sex and body mass index [BMI]) and cardiometabolic risk factors (lipid panel, systolic blood pressure, smoking status and alcohol consumption) in asymptomatic individuals from the KORA study. Impaired glucose metabolism was defined as impaired fasting glucose or impaired glucose tolerance (140-200 mg/dL) or prevalent diabetes mellitus.
RESULTS: Model performance was high, with Dice coefficients of ≥0.81 for IMAT and ≥0.91 for SM in the internal (NAKO) and external (KORA) testing sets. In the target population (380 KORA participants: mean age of 53.6 ± 9.2 years, BMI of 28.2 ± 4.9 kg/m2, 57.4% male), individuals with impaired glucose metabolism (n = 146; 38.4%) were older and more likely men and showed a higher cardiometabolic risk profile, higher IMAT (4.5 ± 2.2% vs. 3.9 ± 1.7%) and higher SMFF (22.0 ± 4.7% vs. 18.9 ± 3.9%) compared to normoglycaemic controls (all P ≤ 0.005). SMFF showed better discrimination for impaired glucose metabolism than IMAT (area under the receiver operating characteristic curve [AUC] 0.693 vs. 0.582, 95% confidence interval [CI] [0.06-0.16]; P &lt; 0.001) but was not significantly different from BMI (AUC 0.733 vs. 0.693, 95% CI [-0.09 to 0.01]; P = 0.15). In univariable logistic regression, IMAT (odds ratio [OR] = 1.18, 95% CI [1.06-1.32]; P = 0.004) and SMFF (OR = 1.19, 95% CI [1.13-1.26]; P &lt; 0.001) were associated with a higher risk of impaired glucose metabolism. This signal remained robust after multivariable adjustment for baseline demographics and cardiometabolic risk factors for SMFF (OR = 1.10, 95% CI [1.01-1.19]; P = 0.028) but not for IMAT (OR = 1.14, 95% CI [0.97-1.33]; P = 0.11).
CONCLUSIONS: Quantitative SMFF, but not IMAT, is an independent predictor of impaired glucose metabolism, and discrimination is not significantly different from BMI, making it a promising alternative for the currently established approach. Automated methods such as the proposed model may provide a feasible option for opportunistic screening of myosteatosis and, thus, a low-cost personalized risk assessment solution.",True,both,Not specified
39008506,An assessment of the value of deep neural networks in genetic risk prediction for surgically relevant outcomes,"INTRODUCTION: Postoperative complications affect up to 15% of surgical patients constituting a major part of the overall disease burden in a modern healthcare system. While several surgical risk calculators have been developed, none have so far been shown to decrease the associated mortality and morbidity. Combining deep neural networks and genomics with the already established clinical predictors may hold promise for improvement.
METHODS: The UK Biobank was utilized to build linear and deep learning models for the prediction of surgery relevant outcomes. An initial GWAS for the relevant outcomes was initially conducted to select the Single Nucleotide Polymorphisms for inclusion in the models. Model performance was assessed with Receiver Operator Characteristics of the Area Under the Curve and optimum precision and recall. Feature importance was assessed with SHapley Additive exPlanations.
RESULTS: Models were generated for atrial fibrillation, venous thromboembolism and pneumonia as genetics only, clinical features only and a combined model. For venous thromboembolism, the ROC-AUCs were 60.1% [59.6%-60.4%], 63.4% [63.2%-63.4%] and 66.6% [66.2%-66.9%] for the linear models and 51.5% [49.4%-53.4%], 63.2% [61.2%-65.0%] and 62.6% [60.7%-64.5%] for the deep learning SNP, clinical and combined models, respectively. For atrial fibrillation, the ROC-AUCs were 60.3% [60.0%-60.4%], 78.7% [78.7%-78.7%] and 80.0% [79.9%-80.0%] for the linear models and 59.4% [58.2%-60.9%], 78.8% [77.8%-79.8%] and 79.8% [78.8%-80.9%] for the deep learning SNP, clinical and combined models, respectively. For pneumonia, the ROC-AUCs were 50.1% [49.6%-50.6%], 69.2% [69.1%-69.2%] and 68.4% [68.0%-68.5%] for the linear models and 51.0% [49.7%-52.4%], 69.7% [.5%-70.8%] and 69.7% [68.6%-70.8%] for the deep learning SNP, clinical and combined models, respectively.
CONCLUSION: In this report we presented linear and deep learning predictive models for surgery relevant outcomes. Overall, predictability was similar between linear and deep learning models and inclusion of genetics seemed to improve accuracy.",True,other,recurrent neural network
38996199,Deep Learning-Based Dynamic Risk Prediction of Venous Thromboembolism for Patients With Ovarian Cancer in Real-World Settings From Electronic Health Records,"PURPOSE: Patients with epithelial ovarian cancer (EOC) have an elevated risk for venous thromboembolism (VTE). To assess the risk of VTE, models were developed by statistical or machine learning algorithms. However, few models have accommodated deep learning (DL) algorithms in realistic clinical settings. We aimed to develop a predictive DL model, exploiting rich information from electronic health records (EHRs), including dynamic clinical features and the presence of competing risks.
METHODS: We extracted EHRs of 1,268 patients diagnosed with EOC from January 2007 through December 2017 at the National Cancer Center, Korea. DL survival networks using fully connected layers, temporal attention, and recurrent neural networks were adopted and compared with multi-perceptron-based classification models. Prediction accuracy was independently validated in the data set of 423 patients newly diagnosed with EOC from January 2018 to December 2019. Personalized risk plots displaying the individual interval risk were developed.
RESULTS: DL-based survival networks achieved a superior area under the receiver operating characteristic curve (AUROC) between 0.95 and 0.98 while the AUROC of classification models was between 0.85 and 0.90. As clinical information benefits the prediction accuracy, the proposed dynamic survival network outperformed other survival networks for the test and validation data set with the highest time-dependent concordance index (0.974, 0.975) and lowest Brier score (0.051, 0.049) at 6 months after a cancer diagnosis. Our visualization showed that the interval risk fluctuating along with the changes in longitudinal clinical features.
CONCLUSION: Adaption of dynamic patient clinical features and accounting for competing risks from EHRs into the DL algorithms demonstrated VTE risk prediction with high accuracy. Our results show that this novel dynamic survival network can provide personalized risk prediction with the potential to assist risk-based clinical intervention to prevent VTE among patients with EOC.",True,other,RNN
38980373,DeepGRNCS: deep learning-based framework for jointly inferring gene regulatory networks across cell subpopulations,"Inferring gene regulatory networks (GRNs) allows us to obtain a deeper understanding of cellular function and disease pathogenesis. Recent advances in single-cell RNA sequencing (scRNA-seq) technology have improved the accuracy of GRN inference. However, many methods for inferring individual GRNs from scRNA-seq data are limited because they overlook intercellular heterogeneity and similarities between different cell subpopulations, which are often present in the data. Here, we propose a deep learning-based framework, DeepGRNCS, for jointly inferring GRNs across cell subpopulations. We follow the commonly accepted hypothesis that the expression of a target gene can be predicted based on the expression of transcription factors (TFs) due to underlying regulatory relationships. We initially processed scRNA-seq data by discretizing data scattering using the equal-width method. Then, we trained deep learning models to predict target gene expression from TFs. By individually removing each TF from the expression matrix, we used pre-trained deep model predictions to infer regulatory relationships between TFs and genes, thereby constructing the GRN. Our method outperforms existing GRN inference methods for various simulated and real scRNA-seq datasets. Finally, we applied DeepGRNCS to non-small cell lung cancer scRNA-seq data to identify key genes in each cell subpopulation and analyzed their biological relevance. In conclusion, DeepGRNCS effectively predicts cell subpopulation-specific GRNs. The source code is available at https://github.com/Nastume777/DeepGRNCS.",True,other,convolutional neural network
38980369,ctGAN: combined transformation of gene expression and survival data with generative adversarial network,"Recent studies have extensively used deep learning algorithms to analyze gene expression to predict disease diagnosis, treatment effectiveness, and survival outcomes. Survival analysis studies on diseases with high mortality rates, such as cancer, are indispensable. However, deep learning models are plagued by overfitting owing to the limited sample size relative to the large number of genes. Consequently, the latest style-transfer deep generative models have been implemented to generate gene expression data. However, these models are limited in their applicability for clinical purposes because they generate only transcriptomic data. Therefore, this study proposes ctGAN, which enables the combined transformation of gene expression and survival data using a generative adversarial network (GAN). ctGAN improves survival analysis by augmenting data through style transformations between breast cancer and 11 other cancer types. We evaluated the concordance index (C-index) enhancements compared with previous models to demonstrate its superiority. Performance improvements were observed in nine of the 11 cancer types. Moreover, ctGAN outperformed previous models in seven out of the 11 cancer types, with colon adenocarcinoma (COAD) exhibiting the most significant improvement (median C-index increase of ~15.70%). Furthermore, integrating the generated COAD enhanced the log-rank p-value (0.041) compared with using only the real COAD (p-value = 0.797). Based on the data distribution, we demonstrated that the model generated highly plausible data. In clustering evaluation, ctGAN exhibited the highest performance in most cases (89.62%). These findings suggest that ctGAN can be meaningfully utilized to predict disease progression and select personalized treatments in the medical field.",True,other,recurrent neural network
38977853,Unsupervised representation learning on high-dimensional clinical data improves genomic discovery and prediction,"Although high-dimensional clinical data (HDCD) are increasingly available in biobank-scale datasets, their use for genetic discovery remains challenging. Here we introduce an unsupervised deep learning model, Representation Learning for Genetic Discovery on Low-Dimensional Embeddings (REGLE), for discovering associations between genetic variants and HDCD. REGLE leverages variational autoencoders to compute nonlinear disentangled embeddings of HDCD, which become the inputs to genome-wide association studies (GWAS). REGLE can uncover features not captured by existing expert-defined features and enables the creation of accurate disease-specific polygenic risk scores (PRSs) in datasets with very few labeled data. We apply REGLE to perform GWAS on respiratory and circulatory HDCD-spirograms measuring lung function and photoplethysmograms measuring blood volume changes. REGLE replicates known loci while identifying others not previously detected. REGLE are predictive of overall survival, and PRSs constructed from REGLE loci improve disease prediction across multiple biobanks. Overall, REGLE contain clinically relevant information beyond that captured by existing expert-defined features, leading to improved genetic discovery and disease prediction.",True,other,recurrent neural network
38971372,Accurate prediction of all-cause mortality in patients with metabolic dysfunction-associated steatotic liver disease using electronic health records,"INTRODUCTION AND OBJECTIVES: Despite the huge clinical burden of MASLD, validated tools for early risk stratification are lacking, and heterogeneous disease expression and a highly variable rate of progression to clinical outcomes result in prognostic uncertainty. We aimed to investigate longitudinal electronic health record-based outcome prediction in MASLD using a state-of-the-art machine learning model.
PATIENTS AND METHODS: n = 940 patients with histologically-defined MASLD were used to develop a deep-learning model for all-cause mortality prediction. Patient timelines, spanning 12 years, were fully-annotated with demographic/clinical characteristics, ICD-9 and -10 codes, blood test results, prescribing data, and secondary care activity. A Transformer neural network (TNN) was trained to output concomitant probabilities of 12-, 24-, and 36-month all-cause mortality. In-sample performance was assessed using 5-fold cross-validation. Out-of-sample performance was assessed in an independent set of n = 528 MASLD patients.
RESULTS: In-sample model performance achieved AUROC curve 0.74-0.90 (95 % CI: 0.72-0.94), sensitivity 64 %-82 %, specificity 75 %-92 % and Positive Predictive Value (PPV) 94 %-98 %. Out-of-sample model validation had AUROC 0.70-0.86 (95 % CI: 0.67-0.90), sensitivity 69 %-70 %, specificity 96 %-97 % and PPV 75 %-77 %. Key predictive factors, identified using coefficients of determination, were age, presence of type 2 diabetes, and history of hospital admissions with length of stay >14 days.
CONCLUSIONS: A TNN, applied to routinely-collected longitudinal electronic health records, achieved good performance in prediction of 12-, 24-, and 36-month all-cause mortality in patients with MASLD. Extrapolation of our technique to population-level data will enable scalable and accurate risk stratification to identify people most likely to benefit from anticipatory health care and personalized interventions.",True,other,Not specified
38971085,Leveraging advances in data-driven deep learning methods for hybrid epidemic modeling,"Mathematical modeling of epidemic dynamics is crucial to understand its underlying mechanisms, quantify important parameters, and make predictions that facilitate more informed decision-making. There are three major types of models: mechanistic models including the SEIR-type paradigm, alternative data-driven (DD) approaches, and hybrid models that combine mechanistic models with DD approaches. In this paper, we summarize our work in the COVID-19 Scenario Modeling Hub (SMH) for more than 12 rounds since early 2021 for informed decision support. We emphasize the importance of deep learning techniques for epidemic modeling via a flexible DD framework that substantially complements the mechanistic paradigm to evaluate various future epidemic scenarios. We start with a traditional curve-fitting approach to model cumulative COVID-19 based on the underlying SEIR-type mechanisms. Hospitalizations and deaths are modeled as binomial processes of cases and hospitalization, respectively. We further formulate two types of deep learning models based on multivariate long short term memory (LSTM) to address the challenges of more traditional DD models. The first LSTM is structurally similar to the curve fitting approach and assumes that hospitalizations and deaths are binomial processes of cases. Instead of using a predefined exponential curve, LSTM relies on the underlying data to identify the most appropriate functions, and is capable of capturing both long-term and short-term epidemic behaviors. We then relax the assumption of dependent inputs among cases, hospitalizations, and death. Another type of LSTM that handles all input time series as parallel signals, the independent multivariate LSTM, is developed. Independent multivariate LSTM can incorporate a wide range of data sources beyond traditional case-based epidemiological surveillance. The DD framework unleashes its potential in big data era with previously neglected heterogeneous surveillance data sources, such as syndromic, environment, genomic, serologic, infoveillance, and mobility data. DD approaches, especially LSTM, complement and integrate with the mechanistic modeling paradigm, provide a feasible alternative approach to model today's complex socio-epidemiological systems, and further leverage our ability to explore different scenarios for more informed decision-making during health emergencies.",True,text mining,Not specified
38969970,Deepvirusclassifier: a deep learning tool for classifying SARS-CoV-2 based on viral subtypes within the coronaviridae family,"PURPOSE: In this study, we present DeepVirusClassifier, a tool capable of accurately classifying Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) viral sequences among other subtypes of the coronaviridae family. This classification is achieved through a deep neural network model that relies on convolutional neural networks (CNNs). Since viruses within the same family share similar genetic and structural characteristics, the classification process becomes more challenging, necessitating more robust models. With the rapid evolution of viral genomes and the increasing need for timely classification, we aimed to provide a robust and efficient tool that could increase the accuracy of viral identification and classification processes. Contribute to advancing research in viral genomics and assist in surveilling emerging viral strains.
METHODS: Based on a one-dimensional deep CNN, the proposed tool is capable of training and testing on the Coronaviridae family, including SARS-CoV-2. Our model's performance was assessed using various metrics, including F1-score and AUROC. Additionally, artificial mutation tests were conducted to evaluate the model's generalization ability across sequence variations. We also used the BLAST algorithm and conducted comprehensive processing time analyses for comparison.
RESULTS: DeepVirusClassifier demonstrated exceptional performance across several evaluation metrics in the training and testing phases. Indicating its robust learning capacity. Notably, during testing on more than 10,000 viral sequences, the model exhibited a more than 99% sensitivity for sequences with fewer than 2000 mutations. The tool achieves superior accuracy and significantly reduced processing times compared to the Basic Local Alignment Search Tool algorithm. Furthermore, the results appear more reliable than the work discussed in the text, indicating that the tool has great potential to revolutionize viral genomic research.
CONCLUSION: DeepVirusClassifier is a powerful tool for accurately classifying viral sequences, specifically focusing on SARS-CoV-2 and other subtypes within the Coronaviridae family. The superiority of our model becomes evident through rigorous evaluation and comparison with existing methods. Introducing artificial mutations into the sequences demonstrates the tool's ability to identify variations and significantly contributes to viral classification and genomic research. As viral surveillance becomes increasingly critical, our model holds promise in aiding rapid and accurate identification of emerging viral strains.",True,other,convolutional neural network
38969836,Deep learning prediction of survival in patients with heart failure using chest radiographs,"Heart failure (HF) is associated with high rates of morbidity and mortality. The value of deep learning survival prediction models using chest radiographs in patients with heart failure is currently unclear. The aim of our study is to develop and validate a deep learning survival prediction model using chest X-ray (DLSPCXR) in patients with HF. The study retrospectively enrolled a cohort of 353 patients with HF who underwent chest X-ray (CXR) at our institution between March 2012 and March 2017. The dataset was randomly divided into training (n = 247) and validation (n = 106) datasets. Univariate and multivariate Cox analysis were conducted on the training dataset to develop clinical and imaging survival prediction models. The DLSPCXR was trained and the selected clinical parameters were incorporated into DLSPCXR to establish a new model called DLSPinteg. Discrimination performance was evaluated using the time-dependent area under the receiver operating characteristic curves (TD AUC) at 1, 3, and 5-years survival. Delong's test was employed for the comparison of differences between two AUCs of different models. The risk-discrimination capability of the optimal model was evaluated by the Kaplan-Meier curve. In multivariable Cox analysis, older age, higher N-terminal pro-B-type natriuretic peptide (NT-ProBNP), systolic pulmonary artery pressure (sPAP) > 50 mmHg, New York Heart Association (NYHA) functional class III-IV and cardiothoracic ratio (CTR) ≥ 0.62 in CXR were independent predictors of poor prognosis in patients with HF. Based on the receiver operating characteristic (ROC) curve analysis, DLSPCXR had better performance at predicting 5-year survival than the imaging Cox model in the validation cohort (AUC: 0.757 vs. 0.561, P = 0.01). DLSPinteg as the optimal model outperforms the clinical Cox model (AUC: 0.826 vs. 0.633, P = 0.03), imaging Cox model (AUC: 0.826 vs. 0.555, P < 0.001), and DLSPCXR (AUC: 0.826 vs. 0.767, P = 0.06). Deep learning models using chest radiographs can predict survival in patients with heart failure with acceptable accuracy.",True,other,Not specified
38968829,A deep learning approach for overall survival prediction in lung cancer with missing values,"BACKGROUND AND OBJECTIVE: In the field of lung cancer research, particularly in the analysis of overall survival (OS), artificial intelligence (AI) serves crucial roles with specific aims. Given the prevalent issue of missing data in the medical domain, our primary objective is to develop an AI model capable of dynamically handling this missing data. Additionally, we aim to leverage all accessible data, effectively analyzing both uncensored patients who have experienced the event of interest and censored patients who have not, by embedding a specialized technique within our AI model, not commonly utilized in other AI tasks. Through the realization of these objectives, our model aims to provide precise OS predictions for non-small cell lung cancer (NSCLC) patients, thus overcoming these significant challenges.
METHODS: We present a novel approach to survival analysis with missing values in the context of NSCLC, which exploits the strengths of the transformer architecture to account only for available features without requiring any imputation strategy. More specifically, this model tailors the transformer architecture to tabular data by adapting its feature embedding and masked self-attention to mask missing data and fully exploit the available ones. By making use of ad-hoc designed losses for OS, it is able to account for both censored and uncensored patients, as well as changes in risks over time.
RESULTS: We compared our method with state-of-the-art models for survival analysis coupled with different imputation strategies. We evaluated the results obtained over a period of 6 years using different time granularities obtaining a Ct-index, a time-dependent variant of the C-index, of 71.97, 77.58 and 80.72 for time units of 1 month, 1 year and 2 years, respectively, outperforming all state-of-the-art methods regardless of the imputation method used.
CONCLUSIONS: The results show that our model not only outperforms the state-of-the-art's performance but also simplifies the analysis in the presence of missing data, by effectively eliminating the need to identify the most appropriate imputation strategy for predicting OS in NSCLC patients.",True,other,Not specified
38965354,Uncovering hidden and complex relations of pandemic dynamics using an AI driven system,"The COVID-19 pandemic continues to challenge healthcare systems globally, necessitating advanced tools for clinical decision support. Amidst the complexity of COVID-19 symptomatology and disease severity prediction, there is a critical need for robust decision support systems to aid healthcare professionals in timely and informed decision-making. In response to this pressing demand, we introduce BayesCovid, a novel decision support system integrating Bayesian network models and deep learning techniques. BayesCovid automates data preprocessing and leverages advanced computational methods to unravel intricate patterns in COVID-19 symptom dynamics. By combining Bayesian networks and Bayesian deep learning models, BayesCovid offers a comprehensive solution for uncovering hidden relationships between symptoms and predicting disease severity. Experimental validation demonstrates BayesCovid 's high prediction accuracy (83.52-98.97%). Our work represents a significant stride in addressing the urgent need for clinical decision support systems tailored to the complexities of managing COVID-19 cases. By providing healthcare professionals with actionable insights derived from sophisticated computational analysis, BayesCovid aims to enhance clinical decision-making, optimise resource allocation, and improve patient outcomes in the ongoing battle against the COVID-19 pandemic.",True,other,recurrent neural network
38965254,On leveraging self-supervised learning for accurate HCV genotyping,"Hepatitis C virus (HCV) is a major global health concern, affecting millions of individuals worldwide. While existing literature predominantly focuses on disease classification using clinical data, there exists a critical research gap concerning HCV genotyping based on genomic sequences. Accurate HCV genotyping is essential for patient management and treatment decisions. While the neural models excel at capturing complex patterns, they still face challenges, such as data scarcity, that exist a lot in computational genomics. To overcome this challenges, this paper introduces an advanced deep learning approach for HCV genotyping based on the graphical representation of nucleotide sequences that outperforms classical approaches. Notably, it is effective for both partial and complete HCV genomes and addresses challenges associated with imbalanced datasets. In this work, ten HCV genotypes: 1a, 1b, 2a, 2b, 2c, 3a, 3b, 4, 5, and 6 were used in the analysis. This study utilizes Chaos Game Representation for 2D mapping of genomic sequences, employing self-supervised learning using convolutional autoencoder for deep feature extraction, resulting in an outstanding performance for HCV genotyping compared to various machine learning and deep learning models. This baseline provides a benchmark against which the performance of the proposed approach and other models can be evaluated. The experimental results showcase a remarkable classification accuracy of over 99%, outperforming traditional deep learning models. This performance demonstrates the capability of the proposed model to accurately identify HCV genotypes in both partial and complete sequences and in dealing with data scarcity for certain genotypes. The results of the proposed model are compared to NCBI genotyping tool.",True,other,Not specified
38963973,Dual-stream multi-dependency graph neural network enables precise cancer survival analysis,"Histopathology image-based survival prediction aims to provide a precise assessment of cancer prognosis and can inform personalized treatment decision-making in order to improve patient outcomes. However, existing methods cannot automatically model the complex correlations between numerous morphologically diverse patches in each whole slide image (WSI), thereby preventing them from achieving a more profound understanding and inference of the patient status. To address this, here we propose a novel deep learning framework, termed dual-stream multi-dependency graph neural network (DM-GNN), to enable precise cancer patient survival analysis. Specifically, DM-GNN is structured with the feature updating and global analysis branches to better model each WSI as two graphs based on morphological affinity and global co-activating dependencies. As these two dependencies depict each WSI from distinct but complementary perspectives, the two designed branches of DM-GNN can jointly achieve the multi-view modeling of complex correlations between the patches. Moreover, DM-GNN is also capable of boosting the utilization of dependency information during graph construction by introducing the affinity-guided attention recalibration module as the readout function. This novel module offers increased robustness against feature perturbation, thereby ensuring more reliable and stable predictions. Extensive benchmarking experiments on five TCGA datasets demonstrate that DM-GNN outperforms other state-of-the-art methods and offers interpretable prediction insights based on the morphological depiction of high-attention patches. Overall, DM-GNN represents a powerful and auxiliary tool for personalized cancer prognosis from histopathology images and has great potential to assist clinicians in making personalized treatment decisions and improving patient outcomes.",True,other,recurrent neural network
38958568,The Impact of Multi-Institution Datasets on the Generalizability of Machine Learning Prediction Models in the ICU,"OBJECTIVES: To evaluate the transferability of deep learning (DL) models for the early detection of adverse events to previously unseen hospitals.
DESIGN: Retrospective observational cohort study utilizing harmonized intensive care data from four public datasets.
SETTING: ICUs across Europe and the United States.
PATIENTS: Adult patients admitted to the ICU for at least 6 hours who had good data quality.
INTERVENTIONS: None.
MEASUREMENTS AND MAIN RESULTS: Using carefully harmonized data from a total of 334,812 ICU stays, we systematically assessed the transferability of DL models for three common adverse events: death, acute kidney injury (AKI), and sepsis. We tested whether using more than one data source and/or algorithmically optimizing for generalizability during training improves model performance at new hospitals. We found that models achieved high area under the receiver operating characteristic (AUROC) for mortality (0.838-0.869), AKI (0.823-0.866), and sepsis (0.749-0.824) at the training hospital. As expected, AUROC dropped when models were applied at other hospitals, sometimes by as much as -0.200. Using more than one dataset for training mitigated the performance drop, with multicenter models performing roughly on par with the best single-center model. Dedicated methods promoting generalizability did not noticeably improve performance in our experiments.
CONCLUSIONS: Our results emphasize the importance of diverse training data for DL-based risk prediction. They suggest that as data from more hospitals become available for training, models may become increasingly generalizable. Even so, good performance at a new hospital still depended on the inclusion of compatible hospitals during training.",True,other,Not specified
38955591,Prospective Deployment of Deep Learning Reconstruction Facilitates Highly Accelerated Upper Abdominal MRI,"RATIONALE AND OBJECTIVES: To compare a conventional T1 volumetric interpolated breath-hold examination (VIBE) with SPectral Attenuated Inversion Recovery (SPAIR) fat saturation and a deep learning (DL)-reconstructed accelerated VIBE sequence with SPAIR fat saturation achieving a 50 % reduction in breath-hold duration (hereafter, VIBE-SPAIR<sub>DL</sub>) in terms of image quality and diagnostic confidence.
MATERIALS AND METHODS: This prospective study enrolled consecutive patients referred for upper abdominal MRI from November 2023 to December 2023 at a single tertiary center. Patients underwent upper abdominal MRI with acquisition of non-contrast and gadobutrol-enhanced conventional VIBE-SPAIR (fourfold acceleration, acquisition time 16 s) and VIBE-SPAIR<sub>DL</sub> (sixfold acceleration, acquisition time 8 s) on a 1.5 T scanner. Image analysis was performed by four readers, evaluating homogeneity of fat suppression, perceived signal-to-noise ratio (SNR), edge sharpness, artifact level, lesion detectability and diagnostic confidence. A statistical power analysis for patient sample size estimation was performed. Image quality parameters were compared by a repeated measures analysis of variance, and interreader agreement was assessed using Fleiss' κ.
RESULTS: Among 450 consecutive patients, 45 patients were evaluated (mean age, 60 years ± 15 [SD]; 27 men, 18 women). VIBE-SPAIR<sub>DL</sub> acquisition demonstrated superior SNR (P &lt; 0.001), edge sharpness (P &lt; 0.001), and reduced artifacts (P &lt; 0.001) with substantial to almost perfect interreader agreement for non-contrast (κ: 0.70-0.91) and gadobutrol-enhanced MRI (κ: 0.68-0.87). No evidence of a difference was found between conventional VIBE-SPAIR and VIBE-SPAIR<sub>DL</sub> regarding homogeneity of fat suppression, lesion detectability, or diagnostic confidence (all P &gt; 0.05).
CONCLUSION: Deep learning reconstruction of VIBE-SPAIR facilitated a reduction of breath-hold duration by half, while reducing artifacts and improving image quality.
SUMMARY: Deep learning reconstruction of prospectively accelerated T1 volumetric interpolated breath-hold examination for upper abdominal MRI enabled a 50 % reduction in breath-hold time with superior image quality.
KEY RESULTS: 1) In a prospective analysis of 45 patients referred for upper abdominal MRI, accelerated deep learning (DL)-reconstructed VIBE images with spectral fat saturation (SPAIR) showed better overall image quality, with better perceived signal-to-noise ratio and less artifacts (all P &lt; 0.001), despite a 50 % reduction in acquisition time compared to conventional VIBE. 2) No evidence of a difference was found between conventional VIBE-SPAIR and accelerated VIBE-SPAIR<sub>DL</sub> regarding lesion detectability or diagnostic confidence.",True,other,Not specified
38946986,Identification of an ANCA-Associated Vasculitis Cohort Using Deep Learning and Electronic Health Records,"BACKGROUND: ANCA-associated vasculitis (AAV) is a rare but serious disease. Traditional case-identification methods using claims data can be time-intensive and may miss important subgroups. We hypothesized that a deep learning model analyzing electronic health records (EHR) can more accurately identify AAV cases.
METHODS: We examined the Mass General Brigham (MGB) repository of clinical documentation from 12/1/1979 to 5/11/2021, using expert-curated keywords and ICD codes to identify a large cohort of potential AAV cases. Three labeled datasets (I, II, III) were created, each containing note sections. We trained and evaluated a range of machine learning and deep learning algorithms for note-level classification, using metrics like positive predictive value (PPV), sensitivity, F-score, area under the receiver operating characteristic curve (AUROC), and area under the precision and recall curve (AUPRC). The deep learning model was further evaluated for its ability to classify AAV cases at the patient-level, compared with rule-based algorithms in 2,000 randomly chosen samples.
RESULTS: Datasets I, II, and III comprised 6,000, 3,008, and 7,500 note sections, respectively. Deep learning achieved the highest AUROC in all three datasets, with scores of 0.983, 0.991, and 0.991. The deep learning approach also had among the highest PPVs across the three datasets (0.941, 0.954, and 0.800, respectively). In a test cohort of 2,000 cases, the deep learning model achieved a PPV of 0.262 and an estimated sensitivity of 0.975. Compared to the best rule-based algorithm, the deep learning model identified six additional AAV cases, representing 13% of the total.
CONCLUSION: The deep learning model effectively classifies clinical note sections for AAV diagnosis. Its application to EHR notes can potentially uncover additional cases missed by traditional rule-based methods.",True,other,Not specified
38944828,Low muscle quality on a procedural computed tomography scan assessed with deep learning as a practical useful predictor of mortality in patients with severe aortic valve stenosis,"BACKGROUND & AIMS: Accurate diagnosis of sarcopenia requires evaluation of muscle quality, which refers to the amount of fat infiltration in muscle tissue. In this study, we aim to investigate whether we can independently predict mortality risk in transcatheter aortic valve implantation (TAVI) patients, using automatic deep learning algorithms to assess muscle quality on procedural computed tomography (CT) scans.
METHODS: This study included 1199 patients with severe aortic stenosis who underwent transcatheter aortic valve implantation (TAVI) between January 2010 and January 2020. A procedural CT scan was performed as part of the preprocedural-TAVI evaluation, and the scans were analyzed using deep-learning-based software to automatically determine skeletal muscle density (SMD) and intermuscular adipose tissue (IMAT). The association of SMD and IMAT with all-cause mortality was analyzed using a Cox regression model, adjusted for other known mortality predictors, including muscle mass.
RESULTS: The mean age of the participants was 80 ± 7 years, 53% were female. The median observation time was 1084 days, and the overall mortality rate was 39%. We found that the lowest tertile of muscle quality, as determined by SMD, was associated with an increased risk of mortality (HR 1.40 [95%CI: 1.15-1.70], p < 0.01). Similarly, low muscle quality as defined by high IMAT in the lowest tertile was also associated with increased mortality risk (HR 1.24 [95%CI: 1.01-1.52], p = 0.04).
CONCLUSIONS: Our findings suggest that deep learning-assessed low muscle quality, as indicated by fat infiltration in muscle tissue, is a practical, useful and independent predictor of mortality after TAVI.",True,other,Not specified
38935034,"Association of retinal image-based, deep learning cardiac BioAge with telomere length and cardiovascular biomarkers","SIGNIFICANCE: Our retinal image-based deep learning (DL) cardiac biological age (BioAge) model could facilitate fast, accurate, noninvasive screening for cardiovascular disease (CVD) in novel community settings and thus improve outcome with those with limited access to health care services.
PURPOSE: This study aimed to determine whether the results issued by our DL cardiac BioAge model are consistent with the known trends of CVD risk and the biomarker leukocyte telomere length (LTL), in a cohort of individuals from the UK Biobank.
METHODS: A cross-sectional cohort study was conducted using those individuals in the UK Biobank who had LTL data. These individuals were divided by sex, ranked by LTL, and then grouped into deciles. The retinal images were then presented to the DL model, and individual's cardiac BioAge was determined. Individuals within each LTL decile were then ranked by cardiac BioAge, and the mean of the CVD risk biomarkers in the top and bottom quartiles was compared. The relationship between an individual's cardiac BioAge, the CVD biomarkers, and LTL was determined using traditional correlation statistics.
RESULTS: The DL cardiac BioAge model was able to accurately stratify individuals by the traditional CVD risk biomarkers, and for both males and females, those issued with a cardiac BioAge in the top quartile of their chronological peer group had a significantly higher mean systolic blood pressure, hemoglobin A 1c , and 10-year Pooled Cohort Equation CVD risk scores compared with those individuals in the bottom quartile (p<0.001). Cardiac BioAge was associated with LTL shortening for both males and females (males: -0.22, r2 = 0.04; females: -0.18, r2 = 0.03).
CONCLUSIONS: In this cross-sectional cohort study, increasing CVD risk whether assessed by traditional biomarkers, CVD risk scoring, or our DL cardiac BioAge, CVD risk model, was inversely related to LTL. At a population level, our data support the growing body of evidence that suggests LTL shortening is a surrogate marker for increasing CVD risk and that this risk can be captured by our novel DL cardiac BioAge model.",True,other,Not specified
38914836,Development and Validation Study of the Prognostic Impact of Deep Learning-Determined Myxoid Stroma After Neoadjuvant Chemotherapy in Patients with Esophageal Squamous Cell Carcinoma,"PURPOSE: This study was designed to investigate the prognostic significance of artificial intelligence (AI)-based quantification of myxoid stroma in patients undergoing esophageal squamous cell carcinoma (ESCC) surgery after neoadjuvant chemotherapy (NAC) and to verify its significance in an independent validation cohort from another hospital.
METHODS: We evaluated two datasets of patients with pathological stage II or III ESCC who underwent surgery after NAC. Cohort 1 consisted of 85 patients who underwent R0 surgery for the primary tumor after NAC. Cohort 2, the validation cohort, consisted of 80 patients who received same treatments in another hospital. AI-based myxoid stroma was evaluated in resected specimens, and its area was categorized by using the receiver operating characteristic curve for overall survival (OS) of cohort 1.
RESULTS: The F1 scores, which are the degree of agreement between the automatically detected myxoid stroma and manual annotations, were 0.83 and 0.79 for cohorts 1 and 2. The myxoid stroma-high group had a significantly poorer prognosis than the myxoid stroma-low group in terms of OS, disease-specific survival (DSS), and recurrence-free survival (RFS) in cohort 1. Comparable results were observed in cohort 2, where OS, DSS, and RFS were significantly affected by myxoid stroma. Multivariate analysis for RFS revealed that AI-determined myxoid stroma-high was one of the independent prognostic factors in cohort 1 (hazard ratio [HR] 1.97, p = 0.037) and cohort 2 (HR 4.45, p < 0.001).
CONCLUSIONS: AI-determined myxoid stroma may be a novel and useful prognostic factor for patients with pathological stage II or III ESCC after NAC.",True,both,Not specified
38914641,"Deep learning models for predicting the survival of patients with medulloblastoma based on a surveillance, epidemiology, and end results analysis","Medulloblastoma is a malignant neuroepithelial tumor of the central nervous system. Accurate prediction of prognosis is essential for therapeutic decisions in medulloblastoma patients. We analyzed data from 2,322 medulloblastoma patients using the SEER database and randomly divided the dataset into training and testing datasets in a 7:3 ratio. We chose three models to build, one based on neural networks (DeepSurv), one based on ensemble learning that Random Survival Forest (RSF), and a typical Cox Proportional-hazards (CoxPH) model. The DeepSurv model outperformed the RSF and classic CoxPH models with C-indexes of 0.751 and 0.763 for the training and test datasets. Additionally, the DeepSurv model showed better accuracy in predicting 1-, 3-, and 5-year survival rates (AUC: 0.767-0.793). Therefore, our prediction model based on deep learning algorithms can more accurately predict the survival rate and survival period of medulloblastoma compared to other models.",True,both,Not specified
38913518,BioFusionNet: Deep Learning-Based Survival Risk Stratification in ER+ Breast Cancer Through Multifeature and Multimodal Data Fusion,"Breast cancer is a significant health concern affecting millions of women worldwide. Accurate survival risk stratification plays a crucial role in guiding personalised treatment decisions and improving patient outcomes. Here we present BioFusionNet, a deep learning framework that fuses image-derived features with genetic and clinical data to obtain a holistic profile and achieve survival risk stratification of ER+ breast cancer patients. We employ multiple self-supervised feature extractors (DINO and MoCoV3) pretrained on histopathological patches to capture detailed image features. These features are then fused by a variational autoencoder and fed to a self-attention network generating patient-level features. A co-dual-cross-attention mechanism combines the histopathological features with genetic data, enabling the model to capture the interplay between them. Additionally, clinical data is incorporated using a feed-forward network, further enhancing predictive performance and achieving comprehensive multimodal feature integration. Furthermore, we introduce a weighted Cox loss function, specifically designed to handle imbalanced survival data, which is a common challenge. Our model achieves a mean concordance index of 0.77 and a time-dependent area under the curve of 0.84, outperforming state-of-the-art methods. It predicts risk (high versus low) with prognostic significance for overall survival in univariate analysis (HR=2.99, 95% CI: 1.88-4.78, p 0.005), and maintains independent significance in multivariate analysis incorporating standard clinicopathological variables (HR=2.91, 95% CI: 1.80-4.68, p 0.005).",True,both,Not specified
38889117,CAManim: Animating end-to-end network activation maps,"Deep neural networks have been widely adopted in numerous domains due to their high performance and accessibility to developers and application-specific end-users. Fundamental to image-based applications is the development of Convolutional Neural Networks (CNNs), which possess the ability to automatically extract features from data. However, comprehending these complex models and their learned representations, which typically comprise millions of parameters and numerous layers, remains a challenge for both developers and end-users. This challenge arises due to the absence of interpretable and transparent tools to make sense of black-box models. There exists a growing body of Explainable Artificial Intelligence (XAI) literature, including a collection of methods denoted Class Activation Maps (CAMs), that seek to demystify what representations the model learns from the data, how it informs a given prediction, and why it, at times, performs poorly in certain tasks. We propose a novel XAI visualization method denoted CAManim that seeks to simultaneously broaden and focus end-user understanding of CNN predictions by animating the CAM-based network activation maps through all layers, effectively depicting from end-to-end how a model progressively arrives at the final layer activation. Herein, we demonstrate that CAManim works with any CAM-based method and various CNN architectures. Beyond qualitative model assessments, we additionally propose a novel quantitative assessment that expands upon the Remove and Debias (ROAD) metric, pairing the qualitative end-to-end network visual explanations assessment with our novel quantitative ""yellow brick ROAD"" assessment (ybROAD). This builds upon prior research to address the increasing demand for interpretable, robust, and transparent model assessment methodology, ultimately improving an end-user's trust in a given model's predictions. Examples and source code can be found at: https://omni-ml.github.io/pytorch-grad-cam-anim/.",True,other,convolutional neural network
38862472,Mapping the landscape of histomorphological cancer phenotypes using self-supervised learning on unannotated pathology slides,"Cancer diagnosis and management depend upon the extraction of complex information from microscopy images by pathologists, which requires time-consuming expert interpretation prone to human bias. Supervised deep learning approaches have proven powerful, but are inherently limited by the cost and quality of annotations used for training. Therefore, we present Histomorphological Phenotype Learning, a self-supervised methodology requiring no labels and operating via the automatic discovery of discriminatory features in image tiles. Tiles are grouped into morphologically similar clusters which constitute an atlas of histomorphological phenotypes (HP-Atlas), revealing trajectories from benign to malignant tissue via inflammatory and reactive phenotypes. These clusters have distinct features which can be identified using orthogonal methods, linking histologic, molecular and clinical phenotypes. Applied to lung cancer, we show that they align closely with patient survival, with histopathologically recognised tumor types and growth patterns, and with transcriptomic measures of immunophenotype. These properties are maintained in a multi-cancer study.",True,other,Not specified
38853169,"Deep learning models for predicting the survival of patients with hepatocellular carcinoma based on a surveillance, epidemiology, and end results (SEER) database analysis","Hepatocellular carcinoma (HCC) is a common malignancy with poor survival and requires long-term follow-up. Hence, we collected information on patients with Primary Hepatocellular Carcinoma in the United States from the Surveillance, Epidemiology, and EndResults (SEER) database. We used this information to establish a deep learning with a multilayer neural network (the NMTLR model) for predicting the survival rate of patients with Primary Hepatocellular Carcinoma. HCC patients pathologically diagnosed between January 2011 and December 2015 in the SEER (Surveillance, Epidemiology, and End Results) database of the National Cancer Institute of the United States were selected as study subjects. We utilized two deep learning-based algorithms (DeepSurv and Neural Multi-Task Logistic Regression [NMTLR]) and a machine learning-based algorithm (Random Survival Forest [RSF]) for model training. A multivariable Cox Proportional Hazards (CoxPH) model was also constructed for comparison. The dataset was randomly divided into a training set and a test set in a 7:3 ratio. The training dataset underwent hyperparameter tuning through 1000 iterations of random search and fivefold cross-validation. Model performance was assessed using the concordance index (C-index), Brier score, and Integrated Brier Score (IBS). The accuracy of predicting 1-year, 3-year, and 5-year survival rates was evaluated using Receiver Operating Characteristic (ROC) curves, calibration plots, and Area Under the Curve (AUC). The primary outcomes were the 1-year, 3-year, and 5-year overall survival rates. Models were developed using DeepSurv, NMTLR, RSF, and Cox Proportional Hazards regression. Model differentiation was evaluated using the C-index, calibration with concordance plots, and risk stratification capability with the log-rank test. The study included 2197 HCC patients, randomly divided into a training cohort (70%, n = 1537) and a testing cohort (30%, n = 660). Clinical characteristics between the two cohorts showed no significant statistical difference (p > 0.05). The deep learning models outperformed both RSF and CoxPH models, with C-indices of 0.735 (NMTLR) and 0.731 (DeepSurv) in the test dataset. The NMTLR model demonstrated enhanced accuracy and well-calibrated survival estimates, achieving an Area Under the Curve (AUC) of 0.824 for 1-year survival predictions, 0.813 for 3-year, and 0.803 for 5-year survival rates. This model's superior calibration and discriminative ability enhance its utility for clinical prognostication in Primary Hepatocellular Carcinoma. We deployed the NMTLR model as a web application for clinical practice. The NMTLR model have potential advantages over traditional linear models in prognostic assessment and treatment recommendations. This novel analytical approach may provide reliable information on individual survival and treatment recommendations for patients with primary liver cancer.",True,other,Not specified
38851456,A new artificial intelligence system for both stomach and small-bowel capsule endoscopy,"BACKGROUND AND AIMS: Despite the benefits of artificial intelligence in small-bowel (SB) capsule endoscopy (CE) image reading, information on its application in the stomach and SB CE is lacking.
METHODS: In this multicenter, retrospective diagnostic study, gastric imaging data were added to the deep learning-based SmartScan (SS), which has been described previously. A total of 1069 magnetically controlled GI CE examinations (comprising 2,672,542 gastric images) were used in the training phase for recognizing gastric pathologies, producing a new artificial intelligence algorithm named SS Plus. A total of 342 fully automated, magnetically controlled CE examinations were included in the validation phase. The performance of both senior and junior endoscopists with both the SS Plus-assisted reading (SSP-AR) and conventional reading (CR) modes was assessed.
RESULTS: SS Plus was designed to recognize 5 types of gastric lesions and 17 types of SB lesions. SS Plus reduced the number of CE images required for review to 873.90 (median, 1000; interquartile range [IQR], 814.50-1000) versus 44,322.73 (median, 42,393; IQR, 31,722.75-54,971.25) for CR. Furthermore, with SSP-AR, endoscopists took 9.54 minutes (median, 8.51; IQR, 6.05-13.13) to complete the CE video reading. In the 342 CE videos, SS Plus identified 411 gastric and 422 SB lesions, whereas 400 gastric and 368 intestinal lesions were detected with CR. Moreover, junior endoscopists remarkably improved their CE image reading ability with SSP-AR.
CONCLUSIONS: Our study shows that the newly upgraded deep learning-based algorithm SS Plus can detect GI lesions and help improve the diagnostic performance of junior endoscopists in interpreting CE videos.",True,other,Not specified
38833495,Predicting cardiovascular disease risk using photoplethysmography and deep learning,"Cardiovascular diseases (CVDs) are responsible for a large proportion of premature deaths in low- and middle-income countries. Early CVD detection and intervention is critical in these populations, yet many existing CVD risk scores require a physical examination or lab measurements, which can be challenging in such health systems due to limited accessibility. We investigated the potential to use photoplethysmography (PPG), a sensing technology available on most smartphones that can potentially enable large-scale screening at low cost, for CVD risk prediction. We developed a deep learning PPG-based CVD risk score (DLS) to predict the probability of having major adverse cardiovascular events (MACE: non-fatal myocardial infarction, stroke, and cardiovascular death) within ten years, given only age, sex, smoking status and PPG as predictors. We compare the DLS with the office-based refit-WHO score, which adopts the shared predictors from WHO and Globorisk scores (age, sex, smoking status, height, weight and systolic blood pressure) but refitted on the UK Biobank (UKB) cohort. All models were trained on a development dataset (141,509 participants) and evaluated on a geographically separate test (54,856 participants) dataset, both from UKB. DLS's C-statistic (71.1%, 95% CI 69.9-72.4) is non-inferior to office-based refit-WHO score (70.9%, 95% CI 69.7-72.2; non-inferiority margin of 2.5%, p<0.01) in the test dataset. The calibration of the DLS is satisfactory, with a 1.8% mean absolute calibration error. Adding DLS features to the office-based score increases the C-statistic by 1.0% (95% CI 0.6-1.4). DLS predicts ten-year MACE risk comparable with the office-based refit-WHO score. Interpretability analyses suggest that the DLS-extracted features are related to PPG waveform morphology and are independent of heart rate. Our study provides a proof-of-concept and suggests the potential of a PPG-based approach strategies for community-based primary prevention in resource-limited regions.",True,other,RNN
38831336,Deep learning-based risk stratification of preoperative breast biopsies using digital whole slide images,"BACKGROUND: Nottingham histological grade (NHG) is a well established prognostic factor in breast cancer histopathology but has a high inter-assessor variability with many tumours being classified as intermediate grade, NHG2. Here, we evaluate if DeepGrade, a previously developed model for risk stratification of resected tumour specimens, could be applied to risk-stratify tumour biopsy specimens.
METHODS: A total of 11,955,755 tiles from 1169 whole slide images of preoperative biopsies from 896 patients diagnosed with breast cancer in Stockholm, Sweden, were included. DeepGrade, a deep convolutional neural network model, was applied for the prediction of low- and high-risk tumours. It was evaluated against clinically assigned grades NHG1 and NHG3 on the biopsy specimen but also against the grades assigned to the corresponding resection specimen using area under the operating curve (AUC). The prognostic value of the DeepGrade model in the biopsy setting was evaluated using time-to-event analysis.
RESULTS: Based on preoperative biopsy images, the DeepGrade model predicted resected tumour cases of clinical grades NHG1 and NHG3 with an AUC of 0.908 (95% CI: 0.88; 0.93). Furthermore, out of the 432 resected clinically-assigned NHG2 tumours, 281 (65%) were classified as DeepGrade-low and 151 (35%) as DeepGrade-high. Using a multivariable Cox proportional hazards model the hazard ratio between DeepGrade low- and high-risk groups was estimated as 2.01 (95% CI: 1.06; 3.79).
CONCLUSIONS: DeepGrade provided prediction of tumour grades NHG1 and NHG3 on the resection specimen using only the biopsy specimen. The results demonstrate that the DeepGrade model can provide decision support to identify high-risk tumours based on preoperative biopsies, thus improving early treatment decisions.",True,both,Not specified
38827104,Comparison of Three Deep Learning Models in Accurate Classification of 770 Dermoscopy Skin Lesion Images,"Accurately determining and classifying different types of skin cancers is critical for early diagnosis. In this work, we propose a novel use of deep learning for classification of benign and malignant skin lesions using dermoscopy images. We obtained 770 de-identified dermoscopy images from the University of Missouri (MU) Healthcare. We created three unique image datasets that contained the original images and images obtained after applying a hair removal algorithm. We trained three popular deep learning models, namely, ResNet50, DenseNet121, and Inception-V3. We evaluated the accuracy and the area under the curve (AUC) receiver operating characteristic (ROC) for each model and dataset. DenseNet121 achieved the best accuracy (80.52%) and AUC ROC score (0.81) on the third dataset. For this dataset, the sensitivity and specificity were 0.80 and 0.81, respectively. We also present the SHAP (SHapley Additive exPlanations) values for the predictions made by different models to understand their interpretability.",True,other,Not specified
38816209,Achieving large-scale clinician adoption of AI-enabled decision support,"Computerised decision support (CDS) tools enabled by artificial intelligence (AI) seek to enhance accuracy and efficiency of clinician decision-making at the point of care. Statistical models developed using machine learning (ML) underpin most current tools. However, despite thousands of models and hundreds of regulator-approved tools internationally, large-scale uptake into routine clinical practice has proved elusive. While underdeveloped system readiness and investment in AI/ML within Australia and perhaps other countries are impediments, clinician ambivalence towards adopting these tools at scale could be a major inhibitor. We propose a set of principles and several strategic enablers for obtaining broad clinician acceptance of AI/ML-enabled CDS tools.",True,other,Not specified
38813529,Deep learning model for individualized trajectory prediction of clinical outcomes in mild cognitive impairment,"OBJECTIVES: Accurately predicting when patients with mild cognitive impairment (MCI) will progress to dementia is a formidable challenge. This work aims to develop a predictive deep learning model to accurately predict future cognitive decline and magnetic resonance imaging (MRI) marker changes over time at the individual level for patients with MCI.
METHODS: We recruited 657 amnestic patients with MCI from the Samsung Medical Center who underwent cognitive tests, brain MRI scans, and amyloid-β (Aβ) positron emission tomography (PET) scans. We devised a novel deep learning architecture by leveraging an attention mechanism in a recurrent neural network. We trained a predictive model by inputting age, gender, education, apolipoprotein E genotype, neuropsychological test scores, and brain MRI and amyloid PET features. Cognitive outcomes and MRI features of an MCI subject were predicted using the proposed network.
RESULTS: The proposed predictive model demonstrated good prediction performance (AUC = 0.814 ± 0.035) in five-fold cross-validation, along with reliable prediction in cognitive decline and MRI markers over time. Faster cognitive decline and brain atrophy in larger regions were forecasted in patients with Aβ (+) than with Aβ (-).
CONCLUSION: The proposed method provides effective and accurate means for predicting the progression of individuals within a specific period. This model could assist clinicians in identifying subjects at a higher risk of rapid cognitive decline by predicting future cognitive decline and MRI marker changes over time for patients with MCI. Future studies should validate and refine the proposed predictive model further to improve clinical decision-making.",True,other,recurrent neural network
38798507,Deconvolution of polygenic risk score in single cells unravels cellular and molecular heterogeneity of complex human diseases,"Polygenic risk scores (PRSs) are commonly used for predicting an individual's genetic risk of complex diseases. Yet, their implication for disease pathogenesis remains largely limited. Here, we introduce scPRS, a geometric deep learning model that constructs single-cell-resolved PRS leveraging reference single-cell chromatin accessibility profiling data to enhance biological discovery as well as disease prediction. Real-world applications across multiple complex diseases, including type 2 diabetes (T2D), hypertrophic cardiomyopathy (HCM), and Alzheimer's disease (AD), showcase the superior prediction power of scPRS compared to traditional PRS methods. Importantly, scPRS not only predicts disease risk but also uncovers disease-relevant cells, such as hormone-high alpha and beta cells for T2D, cardiomyocytes and pericytes for HCM, and astrocytes, microglia and oligodendrocyte progenitor cells for AD. Facilitated by a layered multi-omic analysis, scPRS further identifies cell-type-specific genetic underpinnings, linking disease-associated genetic variants to gene regulation within corresponding cell types. We substantiate the disease relevance of scPRS-prioritized HCM genes and demonstrate that the suppression of these genes in HCM cardiomyocytes is rescued by Mavacamten treatment. Additionally, we establish a novel microglia-specific regulatory relationship between the AD risk variant rs7922621 and its target genes ANXA11 and TSPAN14. We further illustrate the detrimental effects of suppressing these two genes on microglia phagocytosis. Our work provides a multi-tasking, interpretable framework for precise disease prediction and systematic investigation of the genetic, cellular, and molecular basis of complex diseases, laying the methodological foundation for single-cell genetics.",True,other,Not specified
38798082,Disease-driven domain generalization for neuroimaging-based assessment of Alzheimer's disease,"Development of deep learning models to evaluate structural brain changes caused by cognitive impairment in MRI scans holds significant translational value. The efficacy of these models often encounters challenges due to variabilities arising from different data generation protocols, imaging equipment, radiological artifacts, and shifts in demographic distributions. Domain generalization (DG) techniques show promise in addressing these challenges by enabling the model to learn from one or more source domains and apply this knowledge to new, unseen target domains. Here we present a framework that utilizes model interpretability to enhance the generalizability of classification models across various cohorts. We used MRI scans and clinical diagnoses from four independent cohorts: Alzheimer's Disease Neuroimaging Initiative (ADNI, n = 1821), the Framingham Heart Study (FHS, n = 304), the Australian Imaging Biomarkers & Lifestyle Study of Ageing (AIBL, n = 661), and the National Alzheimer's Coordinating Center (NACC, n = 4647). With this data, we trained a deep neural network to focus on areas of the brain identified as relevant to the disease for model training. Our approach involved training a classifier to differentiate between structural neurodegeneration in individuals with normal cognition (NC), mild cognitive impairment (MCI), and dementia due to Alzheimer's disease (AD). This was achieved by aligning class-wise attention with a unified visual saliency prior, which was computed offline for each class using all the training data. Our method not only competes with state-of-the-art approaches but also shows improved correlation with postmortem histology. This alignment with the gold standard evidence is a significant step towards validating the effectiveness of DG frameworks, paving the way for their broader application in the field.",True,other,recurrent neural network
38786735,Prediction of Myocardial Infarction Using a Combined Generative Adversarial Network Model and Feature-Enhanced Loss Function,"Accurate risk prediction for myocardial infarction (MI) is crucial for preventive strategies, given its significant impact on global mortality and morbidity. Here, we propose a novel deep-learning approach to enhance the prediction of incident MI cases by incorporating metabolomics alongside clinical risk factors. We utilized data from the KORA cohort, including the baseline S4 and follow-up F4 studies, consisting of 1454 participants without prior history of MI. The dataset comprised 19 clinical variables and 363 metabolites. Due to the imbalanced nature of the dataset (78 observed MI cases and 1376 non-MI individuals), we employed a generative adversarial network (GAN) model to generate new incident cases, augmenting the dataset and improving feature representation. To predict MI, we further utilized multi-layer perceptron (MLP) models in conjunction with the synthetic minority oversampling technique (SMOTE) and edited nearest neighbor (ENN) methods to address overfitting and underfitting issues, particularly when dealing with imbalanced datasets. To enhance prediction accuracy, we propose a novel GAN for feature-enhanced (GFE) loss function. The GFE loss function resulted in an approximate 2% improvement in prediction accuracy, yielding a final accuracy of 70%. Furthermore, we evaluated the contribution of each clinical variable and metabolite to the predictive model and identified the 10 most significant variables, including glucose tolerance, sex, and physical activity. This is the first study to construct a deep-learning approach for producing 7-year MI predictions using the newly proposed loss function. Our findings demonstrate the promising potential of our technique in identifying novel biomarkers for MI prediction.",True,other,Not specified
38782779,Deep Learning Models for Predicting Malignancy Risk in CT-Detected Pulmonary Nodules: A Systematic Review and Meta-analysis,"BACKGROUND: There has been growing interest in using artificial intelligence/deep learning (DL) to help diagnose prevalent diseases earlier. In this study we sought to survey the landscape of externally validated DL-based computer-aided diagnostic (CADx) models, and assess their diagnostic performance for predicting the risk of malignancy in computed tomography (CT)-detected pulmonary nodules.
METHODS: An electronic search was performed in four databases (from inception to 10 August 2023). Studies were eligible if they were peer-reviewed experimental or observational articles comparing the diagnostic performance of externally validated DL-based CADx models with models widely used in clinical practice to predict the risk of malignancy. A bivariate random-effect approach for the meta-analysis on the included studies was used.
RESULTS: Seventeen studies were included, comprising 8553 participants and 9884 nodules. Pooled analyses showed DL-based CADx models were 11.6% more sensitive than physician judgement alone, and 14.5% more than clinical risk models alone. They had a similar pooled specificity to physician judgement alone [0.77 (95% CI 0.68-0.84) v 0.81 (95% CI 0.71-0.88)], and were 7.4% more specific than clinical risk models alone. They had superior pooled areas under the receiver operating curve (AUC), with relative pooled AUCs of 1.03 (95% CI 1.00-1.07) and 1.10 (95% CI 1.07-1.13) versus physician judgement and clinical risk models alone, respectively.
CONCLUSION: DL-based models are already used in clinical practice in certain settings for nodule management. Our results show their diagnostic performance potentially justifies wider, more routine deployment alongside experienced physician readers to help inform multidisciplinary team decision-making.",True,other,Not specified
38776299,Big data analysis for Covid-19 in hospital information systems,"The COVID-19 pandemic has triggered a global public health crisis, affecting hundreds of countries. With the increasing number of infected cases, developing automated COVID-19 identification tools based on CT images can effectively assist clinical diagnosis and reduce the tedious workload of image interpretation. To expand the dataset for machine learning methods, it is necessary to aggregate cases from different medical systems to learn robust and generalizable models. This paper proposes a novel deep learning joint framework that can effectively handle heterogeneous datasets with distribution discrepancies for accurate COVID-19 identification. We address the cross-site domain shift by redesigning the COVID-Net's network architecture and learning strategy, and independent feature normalization in latent space to improve prediction accuracy and learning efficiency. Additionally, we propose using a contrastive training objective to enhance the domain invariance of semantic embeddings and boost classification performance on each dataset. We develop and evaluate our method with two large-scale public COVID-19 diagnosis datasets containing CT images. Extensive experiments show that our method consistently improves the performance both datasets, outperforming the original COVID-Net trained on each dataset by 13.27% and 15.15% in AUC respectively, also exceeding existing state-of-the-art multi-site learning methods.",True,other,convolutional neural network
38772191,Computed tomography machine learning classifier correlates with mortality in interstitial lung disease,"BACKGROUND: A machine learning classifier system, Fibresolve, was designed and validated as an adjunct to non-invasive diagnosis in idiopathic pulmonary fibrosis (IPF). The system uses a deep learning algorithm to analyze chest computed tomography (CT) imaging. We hypothesized that Fibresolve is a useful predictor of mortality in interstitial lung diseases (ILD).
METHODS: Fibresolve was previously validated in a multi-site >500-patient dataset. In this analysis, we assessed the usefulness of Fibresolve to predict mortality in a subset of 228 patients with IPF and other ILDs in whom follow up data was available. We applied Cox regression analysis adjusting for the Gender, Age, and Physiology (GAP) score and for other known predictors of mortality in IPF. We also analyzed the role of Fibresolve as tertiles adjusting for GAP stages.
RESULTS: During a median follow-up of 2.8 years (range 5 to 3434 days), 89 patients died. After adjusting for GAP score and other mortality risk factors, the Fibresolve score significantly predicted the risk of death (HR: 7.14; 95% CI: 1.31-38.85; p = 0.02) during the follow-up period, as did forced vital capacity and history of lung cancer. After adjusting for GAP stages and other variables, Fibresolve score split into tertiles significantly predicted the risk of death (p = 0.027 for the model; HR 1.37 for 2nd tertile; 95% CI: 0.77-2.42. HR 2.19 for 3rd tertile; 95% CI: 1.22-3.93).
CONCLUSIONS: The machine learning classifier Fibresolve demonstrated to be an independent predictor of mortality in ILDs, with prognostic performance equivalent to GAP based solely on CT images.",True,other,Not specified
38759059,Applications of deep learning models in precision prediction of survival rates for heart failure patients,"BACKGROUND: Heart failure poses a significant challenge in the global health domain, and accurate prediction of mortality is crucial for devising effective treatment plans. In this study, we employed a Seq2Seq model from deep learning, integrating 12 patient features. By finely modeling continuous medical records, we successfully enhanced the accuracy of mortality prediction.
OBJECTIVE: The objective of this research was to leverage the Seq2Seq model in conjunction with patient features for precise mortality prediction in heart failure cases, surpassing the performance of traditional machine learning methods.
METHODS: The study utilized a Seq2Seq model in deep learning, incorporating 12 patient features, to intricately model continuous medical records. The experimental design aimed to compare the performance of Seq2Seq with traditional machine learning methods in predicting mortality rates.
RESULTS: The experimental results demonstrated that the Seq2Seq model outperformed conventional machine learning methods in terms of predictive accuracy. Feature importance analysis provided critical patient risk factors, offering robust support for formulating personalized treatment plans.
CONCLUSIONS: This research sheds light on the significant applications of deep learning, specifically the Seq2Seq model, in enhancing the precision of mortality prediction in heart failure cases. The findings present a valuable direction for the application of deep learning in the medical field and provide crucial insights for future research and clinical practices.",True,other,recurrent neural network
38742520,PRIEST: predicting viral mutations with immune escape capability of SARS-CoV-2 using temporal evolutionary information,"The dynamic evolution of the severe acute respiratory syndrome coronavirus 2 virus is primarily driven by mutations in its genetic sequence, culminating in the emergence of variants with increased capability to evade host immune responses. Accurate prediction of such mutations is fundamental in mitigating pandemic spread and developing effective control measures. This study introduces a robust and interpretable deep-learning approach called PRIEST. This innovative model leverages time-series viral sequences to foresee potential viral mutations. Our comprehensive experimental evaluations underscore PRIEST's proficiency in accurately predicting immune-evading mutations. Our work represents a substantial step in utilizing deep-learning methodologies for anticipatory viral mutation analysis and pandemic response.",True,other,recurrent neural network
38735156,Data mining and machine learning in HIV infection risk research: An overview and recommendations,"In the contemporary era, the applications of data mining and machine learning have permeated extensively into medical research, significantly contributing to areas such as HIV studies. By reviewing 38 articles published in the past 15 years, the study presents a roadmap based on seven different aspects, utilizing various machine learning techniques for both novice researchers and experienced researchers seeking to comprehend the current state of the art in this area. While traditional regression modeling techniques have been commonly used, researchers are increasingly adopting more advanced fully supervised machine learning and deep learning techniques, which often outperform the traditional methods in predictive performance. Additionally, the study identifies nine new open research issues and outlines possible future research plans to enhance the outcomes of HIV infection risk research. This review is expected to be an insightful guide for researchers, illuminating current practices and suggesting advancements in the field.",True,other,recurrent neural network
38728685,Development and Validation of an Explainable Deep Learning Model to Predict In-Hospital Mortality for Patients With Acute Myocardial Infarction: Algorithm Development and Validation Study,"BACKGROUND: Acute myocardial infarction (AMI) is one of the most severe cardiovascular diseases and is associated with a high risk of in-hospital mortality. However, the current deep learning models for in-hospital mortality prediction lack interpretability.
OBJECTIVE: This study aims to establish an explainable deep learning model to provide individualized in-hospital mortality prediction and risk factor assessment for patients with AMI.
METHODS: In this retrospective multicenter study, we used data for consecutive patients hospitalized with AMI from the Chongqing University Central Hospital between July 2016 and December 2022 and the Electronic Intensive Care Unit Collaborative Research Database. These patients were randomly divided into training (7668/10,955, 70%) and internal test (3287/10,955, 30%) data sets. In addition, data of patients with AMI from the Medical Information Mart for Intensive Care database were used for external validation. Deep learning models were used to predict in-hospital mortality in patients with AMI, and they were compared with linear and tree-based models. The Shapley Additive Explanations method was used to explain the model with the highest area under the receiver operating characteristic curve in both the internal test and external validation data sets to quantify and visualize the features that drive predictions.
RESULTS: A total of 10,955 patients with AMI who were admitted to Chongqing University Central Hospital or included in the Electronic Intensive Care Unit Collaborative Research Database were randomly divided into a training data set of 7668 (70%) patients and an internal test data set of 3287 (30%) patients. A total of 9355 patients from the Medical Information Mart for Intensive Care database were included for independent external validation. In-hospital mortality occurred in 8.74% (670/7668), 8.73% (287/3287), and 9.12% (853/9355) of the patients in the training, internal test, and external validation cohorts, respectively. The Self-Attention and Intersample Attention Transformer model performed best in both the internal test data set and the external validation data set among the 9 prediction models, with the highest area under the receiver operating characteristic curve of 0.86 (95% CI 0.84-0.88) and 0.85 (95% CI 0.84-0.87), respectively. Older age, high heart rate, and low body temperature were the 3 most important predictors of increased mortality, according to the explanations of the Self-Attention and Intersample Attention Transformer model.
CONCLUSIONS: The explainable deep learning model that we developed could provide estimates of mortality and visual contribution of the features to the prediction for a patient with AMI. The explanations suggested that older age, unstable vital signs, and metabolic disorders may increase the risk of mortality in patients with AMI.",True,other,Not specified
38725241,Comparison of deep learning models to traditional Cox regression in predicting survival of colon cancer: Based on the SEER database,"BACKGROUND AND AIM: In this study, a deep learning algorithm was used to predict the survival rate of colon cancer (CC) patients, and compared its performance with traditional Cox regression.
METHODS: In this population-based cohort study, we used the characteristics of patients diagnosed with CC between 2010 and 2015 from the Surveillance, Epidemiology and End Results (SEER) database. The population was randomized into a training set (n = 10 596, 70%) and a test set (n = 4536, 30%). Brier scores, area under the (AUC) receiver operating characteristic curve and calibration curves were used to compare the performance of the three most popular deep learning models, namely, artificial neural networks (ANN), deep neural networks (DNN), and long-short term memory (LSTM) neural networks with Cox proportional hazard (CPH) model.
RESULTS: In the independent test set, the Brier values of ANN, DNN, LSTM and CPH were 0.155, 0.149, 0.148, and 0.170, respectively. The AUC values were 0.906 (95% confidence interval [CI] 0.897-0.916), 0.908 (95% CI 0.899-0.918), 0.910 (95% CI 0.901-0.919), and 0.793 (95% CI 0.769-0.816), respectively. Deep learning showed superior promising results than CPH in predicting CC specific survival.
CONCLUSIONS: Deep learning showed potential advantages over traditional CPH models in terms of prognostic assessment and treatment recommendations. LSTM exhibited optimal predictive accuracy and has the ability to provide reliable information on individual survival and treatment recommendations for CC patients.",True,other,Not specified
38718216,Streamlining social media information retrieval for public health research with deep learning,"OBJECTIVE: Social media-based public health research is crucial for epidemic surveillance, but most studies identify relevant corpora with keyword-matching. This study develops a system to streamline the process of curating colloquial medical dictionaries. We demonstrate the pipeline by curating a Unified Medical Language System (UMLS)-colloquial symptom dictionary from COVID-19-related tweets as proof of concept.
METHODS: COVID-19-related tweets from February 1, 2020, to April 30, 2022 were used. The pipeline includes three modules: a named entity recognition module to detect symptoms in tweets; an entity normalization module to aggregate detected entities; and a mapping module that iteratively maps entities to Unified Medical Language System concepts. A random 500 entity samples were drawn from the final dictionary for accuracy validation. Additionally, we conducted a symptom frequency distribution analysis to compare our dictionary to a pre-defined lexicon from previous research.
RESULTS: We identified 498 480 unique symptom entity expressions from the tweets. Pre-processing reduces the number to 18 226. The final dictionary contains 38 175 unique expressions of symptoms that can be mapped to 966 UMLS concepts (accuracy = 95%). Symptom distribution analysis found that our dictionary detects more symptoms and is effective at identifying psychiatric disorders like anxiety and depression, often missed by pre-defined lexicons.
CONCLUSIONS: This study advances public health research by implementing a novel, systematic pipeline for curating symptom lexicons from social media data. The final lexicon's high accuracy, validated by medical professionals, underscores the potential of this methodology to reliably interpret, and categorize vast amounts of unstructured social media data into actionable medical insights across diverse linguistic and regional landscapes.",True,text mining,CNN
38710671,DeepARV: ensemble deep learning to predict drug-drug interaction of clinical relevance with antiretroviral therapy,"Drug-drug interaction (DDI) may result in clinical toxicity or treatment failure of antiretroviral therapy (ARV) or comedications. Despite the high number of possible drug combinations, only a limited number of clinical DDI studies are conducted. Computational prediction of DDIs could provide key evidence for the rational management of complex therapies. Our study aimed to assess the potential of deep learning approaches to predict DDIs of clinical relevance between ARVs and comedications. DDI severity grading between 30,142 drug pairs was extracted from the Liverpool HIV Drug Interaction database. Two feature construction techniques were employed: 1) drug similarity profiles by comparing Morgan fingerprints, and 2) embeddings from SMILES of each drug via ChemBERTa, a transformer-based model. We developed DeepARV-Sim and DeepARV-ChemBERTa to predict four categories of DDI: i) Red: drugs should not be co-administered, ii) Amber: interaction of potential clinical relevance manageable by monitoring/dose adjustment, iii) Yellow: interaction of weak relevance and iv) Green: no expected interaction. The imbalance in the distribution of DDI severity grades was addressed by undersampling and applying ensemble learning. DeepARV-Sim and DeepARV-ChemBERTa predicted clinically relevant DDI between ARVs and comedications with a weighted mean balanced accuracy of 0.729 ± 0.012 and 0.776 ± 0.011, respectively. DeepARV-Sim and DeepARV-ChemBERTa have the potential to leverage molecular structures associated with DDI risks and reduce DDI class imbalance, effectively increasing the predictive ability on clinically relevant DDIs. This approach could be developed for identifying high-risk pairing of drugs, enhancing the screening process, and targeting DDIs to study in clinical drug development.",True,other,Not specified
38709069,Use of Deep Learning to Evaluate Tumor Microenvironmental Features for Prediction of Colon Cancer Recurrence,"UNLABELLED: Deep learning may detect biologically important signals embedded in tumor morphologic features that confer distinct prognoses. Tumor morphologic features were quantified to enhance patient risk stratification within DNA mismatch repair (MMR) groups using deep learning. Using a quantitative segmentation algorithm (QuantCRC) that identifies 15 distinct morphologic features, we analyzed 402 resected stage III colon carcinomas [191 deficient (d)-MMR; 189 proficient (p)-MMR] from participants in a phase III trial of FOLFOX-based adjuvant chemotherapy. Results were validated in an independent cohort (176 d-MMR; 1,094 p-MMR). Association of morphologic features with clinicopathologic variables, MMR, KRAS, BRAFV600E, and time-to-recurrence (TTR) was determined. Multivariable Cox proportional hazards models were developed to predict TTR. Tumor morphologic features differed significantly by MMR status. Cancers with p-MMR had more immature desmoplastic stroma. Tumors with d-MMR had increased inflammatory stroma, epithelial tumor-infiltrating lymphocytes (TIL), high-grade histology, mucin, and signet ring cells. Stromal subtype did not differ by BRAFV600E or KRAS status. In p-MMR tumors, multivariable analysis identified tumor-stroma ratio (TSR) as the strongest feature associated with TTR [HRadj 2.02; 95% confidence interval (CI), 1.14-3.57; P = 0.018; 3-year recurrence: 40.2% vs. 20.4%; Q1 vs. Q2-4]. Among d-MMR tumors, extent of inflammatory stroma (continuous HRadj 0.98; 95% CI, 0.96-0.99; P = 0.028; 3-year recurrence: 13.3% vs. 33.4%, Q4 vs. Q1) and N stage were the most robust prognostically. Association of TSR with TTR was independently validated. In conclusion, QuantCRC can quantify morphologic differences within MMR groups in routine tumor sections to determine their relative contributions to patient prognosis, and may elucidate relevant pathophysiologic mechanisms driving prognosis.
SIGNIFICANCE: A deep learning algorithm can quantify tumor morphologic features that may reflect underlying mechanisms driving prognosis within MMR groups. TSR was the most robust morphologic feature associated with TTR in p-MMR colon cancers. Extent of inflammatory stroma and N stage were the strongest prognostic features in d-MMR tumors. TIL density was not independently prognostic in either MMR group.",True,other,Not specified
38701420,Genotypic-phenotypic landscape computation based on first principle and deep learning,"The relationship between genotype and fitness is fundamental to evolution, but quantitatively mapping genotypes to fitness has remained challenging. We propose the Phenotypic-Embedding theorem (P-E theorem) that bridges genotype-phenotype through an encoder-decoder deep learning framework. Inspired by this, we proposed a more general first principle for correlating genotype-phenotype, and the P-E theorem provides a computable basis for the application of first principle. As an application example of the P-E theorem, we developed the Co-attention based Transformer model to bridge Genotype and Fitness model, a Transformer-based pre-train foundation model with downstream supervised fine-tuning that can accurately simulate the neutral evolution of viruses and predict immune escape mutations. Accordingly, following the calculation path of the P-E theorem, we accurately obtained the basic reproduction number (${R}_0$) of SARS-CoV-2 from first principles, quantitatively linked immune escape to viral fitness and plotted the genotype-fitness landscape. The theoretical system we established provides a general and interpretable method to construct genotype-phenotype landscapes, providing a new paradigm for studying theoretical and computational biology.",True,text mining,recurrent neural network
38698358,Survival estimation of oral cancer using fuzzy deep learning,"BACKGROUND: Oral cancer is a deadly disease and a major cause of morbidity and mortality worldwide. The purpose of this study was to develop a fuzzy deep learning (FDL)-based model to estimate the survival time based on clinicopathologic data of oral cancer.
METHODS: Electronic medical records of 581 oral squamous cell carcinoma (OSCC) patients, treated with surgery with or without radiochemotherapy, were collected retrospectively from the Oral and Maxillofacial Surgery Clinic and the Regional Cancer Center from 2011 to 2019. The deep learning (DL) model was trained to classify survival time classes based on clinicopathologic data. Fuzzy logic was integrated into the DL model and trained to create FDL-based models to estimate the survival time classes.
RESULTS: The performance of the models was evaluated on a test dataset. The performance of the DL and FDL models for estimation of survival time achieved an accuracy of 0.74 and 0.97 and an area under the receiver operating characteristic (AUC) curve of 0.84 to 1.00 and 1.00, respectively.
CONCLUSIONS: The integration of fuzzy logic into DL models could improve the accuracy to estimate survival time based on clinicopathologic data of oral cancer.",True,other,Not specified
38696251,Improving the Prognostic Evaluation Precision of Hospital Outcomes for Heart Failure Using Admission Notes and Clinical Tabular Data: Multimodal Deep Learning Model,"BACKGROUND: Clinical notes contain contextualized information beyond structured data related to patients' past and current health status.
OBJECTIVE: This study aimed to design a multimodal deep learning approach to improve the evaluation precision of hospital outcomes for heart failure (HF) using admission clinical notes and easily collected tabular data.
METHODS: Data for the development and validation of the multimodal model were retrospectively derived from 3 open-access US databases, including the Medical Information Mart for Intensive Care III v1.4 (MIMIC-III) and MIMIC-IV v1.0, collected from a teaching hospital from 2001 to 2019, and the eICU Collaborative Research Database v1.2, collected from 208 hospitals from 2014 to 2015. The study cohorts consisted of all patients with critical HF. The clinical notes, including chief complaint, history of present illness, physical examination, medical history, and admission medication, as well as clinical variables recorded in electronic health records, were analyzed. We developed a deep learning mortality prediction model for in-hospital patients, which underwent complete internal, prospective, and external evaluation. The Integrated Gradients and SHapley Additive exPlanations (SHAP) methods were used to analyze the importance of risk factors.
RESULTS: The study included 9989 (16.4%) patients in the development set, 2497 (14.1%) patients in the internal validation set, 1896 (18.3%) in the prospective validation set, and 7432 (15%) patients in the external validation set. The area under the receiver operating characteristic curve of the models was 0.838 (95% CI 0.827-0.851), 0.849 (95% CI 0.841-0.856), and 0.767 (95% CI 0.762-0.772), for the internal, prospective, and external validation sets, respectively. The area under the receiver operating characteristic curve of the multimodal model outperformed that of the unimodal models in all test sets, and tabular data contributed to higher discrimination. The medical history and physical examination were more useful than other factors in early assessments.
CONCLUSIONS: The multimodal deep learning model for combining admission notes and clinical tabular data showed promising efficacy as a potentially novel method in evaluating the risk of mortality in patients with HF, providing more accurate and timely decision support.",True,other,Not specified
38691436,Cooperating Graph Neural Networks With Deep Reinforcement Learning for Vaccine Prioritization,"This study explores the vaccine prioritization strategy to reduce the overall burden of the pandemic when the supply is limited. Existing vaccine distribution methods focus on macro-level or simplified micro-level assuming homogeneous behavior within populations without considering mobility patterns. Directly applying these models for micro-level vaccine allocation leads to sub-optimal solutions. To address the issue, we first proposed a Trans-vaccine-SEIR model to incorporate mobility heterogeneity in disease propagation. Then we develop a novel deep reinforcement learning to seek the optimal vaccine allocation strategy for the disease evolution system. The graph neural network is used to effectively capture the structural properties of the mobility network and extract disease features. In our evaluation, the proposed framework reduces 7%-10% of infections and deaths compared to the baseline strategies. Extensive evaluation shows that the proposed framework is robust to seek the optimal vaccine allocation with diverse mobility patterns. In particular, we find transit usage restriction is significantly more effective than restricting cross-zone mobility for the top 10% age-based and income-based zones under optimal vaccine allocation strategy. These results provide valuable insights for areas with limited vaccines and low logistic efficacy.",True,other,Not specified
38681756,Improving Equity in Deep Learning Medical Applications with the Gerchberg-Saxton Algorithm,"Deep learning (DL) has gained prominence in healthcare for its ability to facilitate early diagnosis, treatment identification with associated prognosis, and varying patient outcome predictions. However, because of highly variable medical practices and unsystematic data collection approaches, DL can unfortunately exacerbate biases and distort estimates. For example, the presence of sampling bias poses a significant challenge to the efficacy and generalizability of any statistical model. Even with DL approaches, selection bias can lead to inconsistent, suboptimal, or inaccurate model results, especially for underrepresented populations. Therefore, without addressing bias, wider implementation of DL approaches can potentially cause unintended harm. In this paper, we studied a novel method for bias reduction that leverages the frequency domain transformation via the Gerchberg-Saxton and corresponding impact on the outcome from a racio-ethnic bias perspective.",True,other,Not specified
38678522,Determining individual suitability for neoadjuvant systemic therapy in breast cancer patients through deep learning,"BACKGROUND: The survival advantage of neoadjuvant systemic therapy (NST) for breast cancer patients remains controversial, especially when considering the heterogeneous characteristics of individual patients.
OBJECTIVE: To discern the variability in responses to breast cancer treatment at the individual level and propose personalized treatment recommendations utilizing deep learning (DL).
METHODS: Six models were developed to offer individualized treatment suggestions. Outcomes for patients whose actual treatments aligned with model recommendations were compared to those whose did not. The influence of certain baseline features of patients on NST selection was visualized and quantified by multivariate logistic regression and Poisson regression analyses.
RESULTS: Our study included 94,487 female breast cancer patients. The Balanced Individual Treatment Effect for Survival data (BITES) model outperformed other models in performance, showing a statistically significant protective effect with inverse probability treatment weighting (IPTW)-adjusted baseline features [IPTW-adjusted hazard ratio: 0.51, 95% confidence interval (CI), 0.41-0.64; IPTW-adjusted risk difference: 21.46, 95% CI 18.90-24.01; IPTW-adjusted difference in restricted mean survival time: 21.51, 95% CI 19.37-23.80]. Adherence to BITES recommendations is associated with reduced breast cancer mortality and fewer adverse effects. BITES suggests that patients with TNM stage IIB, IIIB, triple-negative subtype, a higher number of positive axillary lymph nodes, and larger tumors are most likely to benefit from NST.
CONCLUSIONS: Our results demonstrated the potential of BITES to aid in clinical treatment decisions and offer quantitative treatment insights. In our further research, these models should be validated in clinical settings and additional patient features as well as outcome measures should be studied in depth.",True,other,Not specified
38678144,Deep learning approach for cardiovascular disease risk stratification and survival analysis on a Canadian cohort,"The quantification of carotid plaque has been routinely used to predict cardiovascular risk in cardiovascular disease (CVD) and coronary artery disease (CAD). To determine how well carotid plaque features predict the likelihood of CAD and cardiovascular (CV) events using deep learning (DL) and compare against the machine learning (ML) paradigm. The participants in this study consisted of 459 individuals who had undergone coronary angiography, contrast-enhanced ultrasonography, and focused carotid B-mode ultrasound. Each patient was tracked for thirty days. The measurements on these patients consisted of maximum plaque height (MPH), total plaque area (TPA), carotid intima-media thickness (cIMT), and intraplaque neovascularization (IPN). CAD risk and CV event stratification were performed by applying eight types of DL-based models. Univariate and multivariate analysis was also conducted to predict the most significant risk predictors. The DL's model effectiveness was evaluated by the area-under-the-curve measurement while the CV event prediction was evaluated using the Cox proportional hazard model (CPHM) and compared against the DL-based concordance index (c-index). IPN showed a substantial ability to predict CV events (p < 0.0001). The best DL system improved by 21% (0.929 vs. 0.762) over the best ML system. DL-based CV event prediction showed a ~ 17% increase in DL-based c-index compared to the CPHM (0.86 vs. 0.73). CAD and CV incidents were linked to IPN and carotid imaging characteristics. For survival analysis and CAD prediction, the DL-based system performs superior to ML-based models.",True,other,Not specified
38676257,COVID-19 Hierarchical Classification Using a Deep Learning Multi-Modal,"Coronavirus disease 2019 (COVID-19), originating in China, has rapidly spread worldwide. Physicians must examine infected patients and make timely decisions to isolate them. However, completing these processes is difficult due to limited time and availability of expert radiologists, as well as limitations of the reverse-transcription polymerase chain reaction (RT-PCR) method. Deep learning, a sophisticated machine learning technique, leverages radiological imaging modalities for disease diagnosis and image classification tasks. Previous research on COVID-19 classification has encountered several limitations, including binary classification methods, single-feature modalities, small public datasets, and reliance on CT diagnostic processes. Additionally, studies have often utilized a flat structure, disregarding the hierarchical structure of pneumonia classification. This study aims to overcome these limitations by identifying pneumonia caused by COVID-19, distinguishing it from other types of pneumonia and healthy lungs using chest X-ray (CXR) images and related tabular medical data, and demonstrate the value of incorporating tabular medical data in achieving more accurate diagnoses. Resnet-based and VGG-based pre-trained convolutional neural network (CNN) models were employed to extract features, which were then combined using early fusion for the classification of eight distinct classes. We leveraged the hierarchal structure of pneumonia classification within our approach to achieve improved classification outcomes. Since an imbalanced dataset is common in this field, a variety of versions of generative adversarial networks (GANs) were used to generate synthetic data. The proposed approach tested in our private datasets of 4523 patients achieved a macro-avg F1-score of 95.9% and an F1-score of 87.5% for COVID-19 identification using a Resnet-based structure. In conclusion, in this study, we were able to create an accurate deep learning multi-modal to diagnose COVID-19 and differentiate it from other kinds of pneumonia and normal lungs, which will enhance the radiological diagnostic process.",True,other,Not specified
38652882,Deep Learning and Multimodal Artificial Intelligence in Orthopaedic Surgery,"This review article focuses on the applications of deep learning with neural networks and multimodal neural networks in the orthopaedic domain. By providing practical examples of how artificial intelligence (AI) is being applied successfully in orthopaedic surgery, particularly in the realm of imaging data sets and the integration of clinical data, this study aims to provide orthopaedic surgeons with the necessary tools to not only evaluate existing literature but also to consider AI's potential in their own clinical or research pursuits. We first review standard deep neural networks which can analyze numerical clinical variables, then describe convolutional neural networks which can analyze image data, and then introduce multimodal AI models which analyze various types of different data. Then, we contrast these deep learning techniques with related but more limited techniques such as radiomics, describe how to interpret deep learning studies, and how to initiate such studies at your institution. Ultimately, by empowering orthopaedic surgeons with the knowledge and know-how of deep learning, this review aspires to facilitate the translation of research into clinical practice, thereby enhancing the efficacy and precision of real-world orthopaedic care for patients.",True,other,convolutional neural network
38649301,Large-scale genomic survey with deep learning-based method reveals strain-level phage specificity determinants,"BACKGROUND: Phage therapy, reemerging as a promising approach to counter antimicrobial-resistant infections, relies on a comprehensive understanding of the specificity of individual phages. Yet the significant diversity within phage populations presents a considerable challenge. Currently, there is a notable lack of tools designed for large-scale characterization of phage receptor-binding proteins, which are crucial in determining the phage host range.
RESULTS: In this study, we present SpikeHunter, a deep learning method based on the ESM-2 protein language model. With SpikeHunter, we identified 231,965 diverse phage-encoded tailspike proteins, a crucial determinant of phage specificity that targets bacterial polysaccharide receptors, across 787,566 bacterial genomes from 5 virulent, antibiotic-resistant pathogens. Notably, 86.60% (143,200) of these proteins exhibited strong associations with specific bacterial polysaccharides. We discovered that phages with identical tailspike proteins can infect different bacterial species with similar polysaccharide receptors, underscoring the pivotal role of tailspike proteins in determining host range. The specificity is mainly attributed to the protein's C-terminal domain, which strictly correlates with host specificity during domain swapping in tailspike proteins. Importantly, our dataset-driven predictions of phage-host specificity closely match the phage-host pairs observed in real-world phage therapy cases we studied.
CONCLUSIONS: Our research provides a rich resource, including both the method and a database derived from a large-scale genomics survey. This substantially enhances understanding of phage specificity determinants at the strain level and offers a valuable framework for guiding phage selection in therapeutic applications.",True,other,Not specified
38649300,IPEV: identification of prokaryotic and eukaryotic virus-derived sequences in virome using deep learning,"BACKGROUND: The virome obtained through virus-like particle enrichment contains a mixture of prokaryotic and eukaryotic virus-derived fragments. Accurate identification and classification of these elements are crucial to understanding their roles and functions in microbial communities. However, the rapid mutation rates of viral genomes pose challenges in developing high-performance tools for classification, potentially limiting downstream analyses.
FINDINGS: We present IPEV, a novel method to distinguish prokaryotic and eukaryotic viruses in viromes, with a 2-dimensional convolutional neural network combining trinucleotide pair relative distance and frequency. Cross-validation assessments of IPEV demonstrate its state-of-the-art precision, significantly improving the F1-score by approximately 22% on an independent test set compared to existing methods when query viruses share less than 30% sequence similarity with known viruses. Furthermore, IPEV outperforms other methods in accuracy on marine and gut virome samples based on annotations by sequence alignments. IPEV reduces runtime by at most 1,225 times compared to existing methods under the same computing configuration. We also utilized IPEV to analyze longitudinal samples and found that the gut virome exhibits a higher degree of temporal stability than previously observed in persistent personal viromes, providing novel insights into the resilience of the gut virome in individuals.
CONCLUSIONS: IPEV is a high-performance, user-friendly tool that assists biologists in identifying and classifying prokaryotic and eukaryotic viruses within viromes. The tool is available at https://github.com/basehc/IPEV.",True,other,Not specified
38647155,IGCNSDA: unraveling disease-associated snoRNAs with an interpretable graph convolutional network,"Accurately delineating the connection between short nucleolar RNA (snoRNA) and disease is crucial for advancing disease detection and treatment. While traditional biological experimental methods are effective, they are labor-intensive, costly and lack scalability. With the ongoing progress in computer technology, an increasing number of deep learning techniques are being employed to predict snoRNA-disease associations. Nevertheless, the majority of these methods are black-box models, lacking interpretability and the capability to elucidate the snoRNA-disease association mechanism. In this study, we introduce IGCNSDA, an innovative and interpretable graph convolutional network (GCN) approach tailored for the efficient inference of snoRNA-disease associations. IGCNSDA leverages the GCN framework to extract node feature representations of snoRNAs and diseases from the bipartite snoRNA-disease graph. SnoRNAs with high similarity are more likely to be linked to analogous diseases, and vice versa. To facilitate this process, we introduce a subgraph generation algorithm that effectively groups similar snoRNAs and their associated diseases into cohesive subgraphs. Subsequently, we aggregate information from neighboring nodes within these subgraphs, iteratively updating the embeddings of snoRNAs and diseases. The experimental results demonstrate that IGCNSDA outperforms the most recent, highly relevant methods. Additionally, our interpretability analysis provides compelling evidence that IGCNSDA adeptly captures the underlying similarity between snoRNAs and diseases, thus affording researchers enhanced insights into the snoRNA-disease association mechanism. Furthermore, we present illustrative case studies that demonstrate the utility of IGCNSDA as a valuable tool for efficiently predicting potential snoRNA-disease associations. The dataset and source code for IGCNSDA are openly accessible at: https://github.com/altriavin/IGCNSDA.",True,other,RNN
38644402,Investigation of the effectiveness of a classification method based on improved DAE feature extraction for hepatitis C prediction,"Hepatitis C, a particularly dangerous form of viral hepatitis caused by hepatitis C virus (HCV) infection, is a major socio-economic and public health problem. Due to the rapid development of deep learning, it has become a common practice to apply deep learning to the healthcare industry to improve the effectiveness and accuracy of disease identification. In order to improve the effectiveness and accuracy of hepatitis C detection, this study proposes an improved denoising autoencoder (IDAE) and applies it to hepatitis C disease detection. Conventional denoising autoencoder introduces random noise at the input layer of the encoder. However, due to the presence of these features, encoders that directly add random noise may mask certain intrinsic properties of the data, making it challenging to learn deeper features. In this study, the problem of data information loss in traditional denoising autoencoding is addressed by incorporating the concept of residual neural networks into an enhanced denoising autoencoder. In our experimental study, we applied this enhanced denoising autoencoder to the open-source Hepatitis C dataset and the results showed significant results in feature extraction. While existing baseline machine learning methods have less than 90% accuracy and integrated algorithms and traditional autoencoders have only 95% correctness, the improved IDAE achieves 99% accuracy in the downstream hepatitis C classification task, which is a 9% improvement over a single algorithm, and a nearly 4% improvement over integrated algorithms and other autoencoders. The above results demonstrate that IDAE can effectively capture key disease features and improve the accuracy of disease prediction in hepatitis C data. This indicates that IDAE has the potential to be widely used in the detection and management of hepatitis C and similar diseases, especially in the development of early warning systems, progression prediction and personalised treatment strategies.",True,other,autoencoder
38641713,Deep learning prediction of renal anomalies for prenatal ultrasound diagnosis,"Deep learning algorithms have demonstrated remarkable potential in clinical diagnostics, particularly in the field of medical imaging. In this study, we investigated the application of deep learning models in early detection of fetal kidney anomalies. To provide an enhanced interpretation of those models' predictions, we proposed an adapted two-class representation and developed a multi-class model interpretation approach for problems with more than two labels and variable hierarchical grouping of labels. Additionally, we employed the explainable AI (XAI) visualization tools Grad-CAM and HiResCAM, to gain insights into model predictions and identify reasons for misclassifications. The study dataset consisted of 969 ultrasound images from unique patients; 646 control images and 323 cases of kidney anomalies, including 259 cases of unilateral urinary tract dilation and 64 cases of unilateral multicystic dysplastic kidney. The best performing model achieved a cross-validated area under the ROC curve of 91.28% ± 0.52%, with an overall accuracy of 84.03% ± 0.76%, sensitivity of 77.39% ± 1.99%, and specificity of 87.35% ± 1.28%. Our findings emphasize the potential of deep learning models in predicting kidney anomalies from limited prenatal ultrasound imagery. The proposed adaptations in model representation and interpretation represent a novel solution to multi-class prediction problems.",True,other,convolutional neural network
38637823,Development and application of a deep learning-based comprehensive early diagnostic model for chronic obstructive pulmonary disease,"BACKGROUND: Chronic obstructive pulmonary disease (COPD) is a frequently diagnosed yet treatable condition, provided it is identified early and managed effectively. This study aims to develop an advanced COPD diagnostic model by integrating deep learning and radiomics features.
METHODS: We utilized a dataset comprising CT images from 2,983 participants, of which 2,317 participants also provided epidemiological data through questionnaires. Deep learning features were extracted using a Variational Autoencoder, and radiomics features were obtained using the PyRadiomics package. Multi-Layer Perceptrons were used to construct models based on deep learning and radiomics features independently, as well as a fusion model integrating both. Subsequently, epidemiological questionnaire data were incorporated to establish a more comprehensive model. The diagnostic performance of standalone models, the fusion model and the comprehensive model was evaluated and compared using metrics including accuracy, precision, recall, F1-score, Brier score, receiver operating characteristic curves, and area under the curve (AUC).
RESULTS: The fusion model exhibited outstanding performance with an AUC of 0.952, surpassing the standalone models based solely on deep learning features (AUC = 0.844) or radiomics features (AUC = 0.944). Notably, the comprehensive model, incorporating deep learning features, radiomics features, and questionnaire variables demonstrated the highest diagnostic performance among all models, yielding an AUC of 0.971.
CONCLUSION: We developed and implemented a data fusion strategy to construct a state-of-the-art COPD diagnostic model integrating deep learning features, radiomics features, and questionnaire variables. Our data fusion strategy proved effective, and the model can be easily deployed in clinical settings.
TRIAL REGISTRATION: Not applicable. This study is NOT a clinical trial, it does not report the results of a health care intervention on human participants.",True,other,Not specified
38630847,"Deep learning assists detection of esophageal cancer and precursor lesions in a prospective, randomized controlled study","Endoscopy is the primary modality for detecting asymptomatic esophageal squamous cell carcinoma (ESCC) and precancerous lesions. Improving detection rate remains challenging. We developed a system based on deep convolutional neural networks (CNNs) for detecting esophageal cancer and precancerous lesions [high-risk esophageal lesions (HrELs)] and validated its efficacy in improving HrEL detection rate in clinical practice (trial registration ChiCTR2100044126 at www.chictr.org.cn). Between April 2021 and March 2022, 3117 patients ≥50 years old were consecutively recruited from Taizhou Hospital, Zhejiang Province, and randomly assigned 1:1 to an experimental group (CNN-assisted endoscopy) or a control group (unassisted endoscopy) based on block randomization. The primary endpoint was the HrEL detection rate. In the intention-to-treat population, the HrEL detection rate [28 of 1556 (1.8%)] was significantly higher in the experimental group than in the control group [14 of 1561 (0.9%), P = 0.029], and the experimental group detection rate was twice that of the control group. Similar findings were observed between the experimental and control groups [28 of 1524 (1.9%) versus 13 of 1534 (0.9%), respectively; P = 0.021]. The system's sensitivity, specificity, and accuracy for detecting HrELs were 89.7, 98.5, and 98.2%, respectively. No adverse events occurred. The proposed system thus improved HrEL detection rate during endoscopy and was safe. Deep learning assistance may enhance early diagnosis and treatment of esophageal cancer and may become a useful tool for esophageal cancer screening.",True,other,Not specified
38628668,Deep learning model for predicting postoperative survival of patients with gastric cancer,"BACKGROUND: Prognostic prediction for surgical treatment of gastric cancer remains valuable in clinical practice. This study aimed to develop survival models for postoperative gastric cancer patients.
METHODS: Eleven thousand seventy-five patients from the Surveillance, Epidemiology, and End Results (SEER) database were included, and 122 patients from the Chinese database were used for external validation. The training cohort was created to create three separate models, including Cox regression, RSF, and DeepSurv, using data from the SEER database split into training and test cohorts with a 7:3 ratio. Test cohort was used to evaluate model performance using c-index, Brier scores, calibration, and the area under the curve (AUC). The new risk stratification based on the best model will be compared with the AJCC stage on the test and Chinese cohorts using decision curve analysis (DCA), the net reclassification index (NRI), and integrated discrimination improvement (IDI).
RESULTS: It was discovered that the DeepSurv model predicted postoperative gastric cancer patients' overall survival (OS) with a c-index of 0.787; the area under the curve reached 0.781, 0.798, 0.868 at 1-, 3- and 5- years, respectively; the Brier score was below 0.25 at different time points; showing an advantage over the Cox and RSF models. The results are also validated in the China cohort. The calibration plots demonstrated good agreement between the DeepSurv model's forecast and actual results. The NRI values (test cohort: 0.399, 0.288, 0.267 for 1-, 3- and 5-year OS prediction; China cohort:0.399, 0.288 for 1- and 3-year OS prediction) and IDI (test cohort: 0.188, 0.169, 0.157 for 1-, 3- and 5-year OS prediction; China cohort: 0.189, 0.169 for 1- and 3-year OS prediction) indicated that the risk score stratification performed significantly better than the AJCC staging alone (P < 0.05). DCA showed that the risk score stratification was clinically useful and had better discriminative ability than the AJCC staging. Finally, an interactive native web-based prediction tool was constructed for the survival prediction of patients with postoperative gastric cancer.
CONCLUSION: In this study, a high-performance prediction model for the postoperative prognosis of gastric cancer was developed using DeepSurv, which offers essential benefits for risk stratification and prognosis prediction for each patient.",True,other,Not specified
38627315,UroAngel: a single-kidney function prediction system based on computed tomography urography using deep learning,"BACKGROUND: Accurate estimation of the glomerular filtration rate (GFR) is clinically crucial for determining the status of obstruction, developing treatment strategies, and predicting prognosis in obstructive nephropathy (ON). We aimed to develop a deep learning-based system, named UroAngel, for non-invasive and convenient prediction of single-kidney function level.
METHODS: We retrospectively collected computed tomography urography (CTU) images and emission computed tomography diagnostic reports of 520 ON patients. A 3D U-Net model was used to segment the renal parenchyma, and a logistic regression multi-classification model was used to predict renal function level. We compared the predictive performance of UroAngel with the Modification of Diet in Renal Disease (MDRD), Chronic Kidney Disease Epidemiology Collaboration (CKD-EPI) equations, and two expert radiologists in an additional 40 ON patients to validate clinical effectiveness.
RESULTS: UroAngel based on 3D U-Net convolutional neural network could segment the renal cortex accurately, with a Dice similarity coefficient of 0.861. Using the segmented renal cortex to predict renal function stage had high performance with an accuracy of 0.918, outperforming MDRD and CKD-EPI and two radiologists.
CONCLUSIONS: We proposed an automated 3D U-Net-based analysis system for direct prediction of single-kidney function stage from CTU images. UroAngel could accurately predict single-kidney function in ON patients, providing a novel, reliable, convenient, and non-invasive method.",True,other,Not specified
38618987,Prediction of cardiovascular risk factors from retinal fundus photographs: Validation of a deep learning algorithm in a prospective non-interventional study in Kenya,"AIM: Hypertension and diabetes mellitus (DM) are major causes of morbidity and mortality, with growing burdens in low-income countries where they are underdiagnosed and undertreated. Advances in machine learning may provide opportunities to enhance diagnostics in settings with limited medical infrastructure.
MATERIALS AND METHODS: A non-interventional study was conducted to develop and validate a machine learning algorithm to estimate cardiovascular clinical and laboratory parameters. At two sites in Kenya, digital retinal fundus photographs were collected alongside blood pressure (BP), laboratory measures and medical history. The performance of machine learning models, originally trained using data from the UK Biobank, were evaluated for their ability to estimate BP, glycated haemoglobin, estimated glomerular filtration rate and diagnoses from fundus images.
RESULTS: In total, 301 participants were enrolled. Compared with the UK Biobank population used for algorithm development, participants from Kenya were younger and would probably report Black/African ethnicity, with a higher body mass index and prevalence of DM and hypertension. The mean absolute error was comparable or slightly greater for systolic BP, diastolic BP, glycated haemoglobin and estimated glomerular filtration rate. The model trained to identify DM had an area under the receiver operating curve of 0.762 (0.818 in the UK Biobank) and the hypertension model had an area under the receiver operating curve of 0.765 (0.738 in the UK Biobank).
CONCLUSIONS: In a Kenyan population, machine learning models estimated cardiovascular parameters with comparable or slightly lower accuracy than in the population where they were trained, suggesting model recalibration may be appropriate. This study represents an incremental step toward leveraging machine learning to make early cardiovascular screening more accessible, particularly in resource-limited settings.",True,other,Not specified
38616153,An explainable long short-term memory network for surgical site infection identification,"BACKGROUND: Currently, surgical site infection surveillance relies on labor-intensive manual chart review. Recently suggested solutions involve machine learning to identify surgical site infections directly from the medical record. Deep learning is a form of machine learning that has historically performed better than traditional methods while being harder to interpret. We propose a deep learning model, a long short-term memory network, for the identification of surgical site infection from the medical record with an attention layer for explainability.
METHODS: We retrieved structured data and clinical notes from the University of Utah Health System's electronic health care record for operative events randomly selected for manual chart review from January 2016 to June 2021. Surgical site infection occurring within 30 days of surgery was determined according to the National Surgical Quality Improvement Program definition. We trained the long short-term memory model along with traditional machine learning models for comparison. We calculated several performance metrics from a holdout test set and performed additional analyses to understand the performance of the long short-term memory, including an explainability analysis.
RESULTS: Surgical site infection was present in 4.7% of the total 9,185 operative events. The area under the receiver operating characteristic curve and sensitivity of the long short-term memory was higher (area under the receiver operating characteristic curve: 0.954, sensitivity: 0.920) compared to the top traditional model (area under the receiver operating characteristic curve: 0.937, sensitivity: 0.736). The top 5 features of the long short-term memory included 2 procedure codes and 3 laboratory values.
CONCLUSION: Surgical site infection surveillance is vital for the reduction of surgical site infection rates. Our explainable long short-term memory achieved a comparable area under the receiver operating characteristic curve and greater sensitivity when compared to traditional machine learning methods. With explainable deep learning, automated surgical site infection surveillance could replace burdensome manual chart review processes.",True,other,RNN
38614870,How does deep learning/machine learning perform in comparison to radiologists in distinguishing glioblastomas (or grade IV astrocytomas) from primary CNS lymphomas?: a meta-analysis and systematic review,"BACKGROUND: Several studies have been published comparing deep learning (DL)/machine learning (ML) to radiologists in differentiating PCNSLs from GBMs with equivocal results. We aimed to perform this meta-analysis to evaluate the diagnostic accuracy of ML/DL versus radiologists in classifying PCNSL versus GBM using MRI.
METHODOLOGY: The study was performed in accordance with PRISMA guidelines. Data was extracted and interpreted by two researchers with 12 and 23 years' experience, respectively, and QUADAS-2 tool was used for quality and risk-bias assessment. We constructed contingency tables to derive sensitivity, specificity accuracy, summary receiver operating characteristic (SROC) curve, and the area under the curve (AUC).
RESULTS: Our search identified 11 studies, of which 8 satisfied our inclusion criteria and restricted the analysis in each study to reporting the model showing highest accuracy, with a total sample size of 1159 patients. The random effects model showed a pooled sensitivity of 0.89 [95% CI:0.84-0.92] for ML and 0.82 [95% CI:0.76-0.87] for radiologists. Pooled specificity was 0.88 [95% CI: 0.84-0.91] for ML and 0.90 [95% CI: 0.81-0.95] for radiologists. Pooled accuracy was 0.88 [95% CI: 0.86-0.90] for ML and 0.86 [95% CI: 0.78-0.91] for radiologists. Pooled AUC of ML was 0.94 [95% CI:0.92-0.96]and for radiologists, it was 0.90 [95% CI: 0.84-0.93].
CONCLUSIONS: MRI-based ML/DL techniques can complement radiologists to improve the accuracy of classifying GBMs from PCNSL, possibly reduce the need for a biopsy, and avoid any unwanted neurosurgical resection of a PCNSL.",True,other,RNN
38598563,DeepDynaForecast: Phylogenetic-informed graph deep learning for epidemic transmission dynamic prediction,"In the midst of an outbreak or sustained epidemic, reliable prediction of transmission risks and patterns of spread is critical to inform public health programs. Projections of transmission growth or decline among specific risk groups can aid in optimizing interventions, particularly when resources are limited. Phylogenetic trees have been widely used in the detection of transmission chains and high-risk populations. Moreover, tree topology and the incorporation of population parameters (phylodynamics) can be useful in reconstructing the evolutionary dynamics of an epidemic across space and time among individuals. We now demonstrate the utility of phylodynamic trees for transmission modeling and forecasting, developing a phylogeny-based deep learning system, referred to as DeepDynaForecast. Our approach leverages a primal-dual graph learning structure with shortcut multi-layer aggregation, which is suited for the early identification and prediction of transmission dynamics in emerging high-risk groups. We demonstrate the accuracy of DeepDynaForecast using simulated outbreak data and the utility of the learned model using empirical, large-scale data from the human immunodeficiency virus epidemic in Florida between 2012 and 2020. Our framework is available as open-source software (MIT license) at github.com/lab-smile/DeepDynaForcast.",True,text mining,Not specified
38597785,A Semiautonomous Deep Learning System to Reduce False Positives in Screening Mammography,"Purpose To evaluate the ability of a semiautonomous artificial intelligence (AI) model to identify screening mammograms not suspicious for breast cancer and reduce the number of false-positive examinations. Materials and Methods The deep learning algorithm was trained using 123 248 two-dimensional digital mammograms (6161 cancers) and a retrospective study was performed on three nonoverlapping datasets of 14 831 screening mammography examinations (1026 cancers) from two U.S. institutions and one U.K. institution (2008-2017). The stand-alone performance of humans and AI was compared. Human plus AI performance was simulated to examine reductions in the cancer detection rate, number of examinations, false-positive callbacks, and benign biopsies. Metrics were adjusted to mimic the natural distribution of a screening population, and bootstrapped CIs and P values were calculated. Results Retrospective evaluation on all datasets showed minimal changes to the cancer detection rate with use of the AI device (noninferiority margin of 0.25 cancers per 1000 examinations: U.S. dataset 1, P = .02; U.S. dataset 2, P &lt; .001; U.K. dataset, P &lt; .001). On U.S. dataset 1 (11 592 mammograms; 101 cancers; 3810 female patients; mean age, 57.3 years ± 10.0 [SD]), the device reduced screening examinations requiring radiologist interpretation by 41.6% (95% CI: 40.6%, 42.4%; P &lt; .001), diagnostic examinations callbacks by 31.1% (95% CI: 28.7%, 33.4%; P &lt; .001), and benign needle biopsies by 7.4% (95% CI: 4.1%, 12.4%; P &lt; .001). U.S. dataset 2 (1362 mammograms; 330 cancers; 1293 female patients; mean age, 55.4 years ± 10.5) was reduced by 19.5% (95% CI: 16.9%, 22.1%; P &lt; .001), 11.9% (95% CI: 8.6%, 15.7%; P &lt; .001), and 6.5% (95% CI: 0.0%, 19.0%; P = .08), respectively. The U.K. dataset (1877 mammograms; 595 cancers; 1491 female patients; mean age, 63.5 years ± 7.1) was reduced by 36.8% (95% CI: 34.4%, 39.7%; P &lt; .001), 17.1% (95% CI: 5.9%, 30.1%: P &lt; .001), and 5.9% (95% CI: 2.9%, 11.5%; P &lt; .001), respectively. Conclusion This work demonstrates the potential of a semiautonomous breast cancer screening system to reduce false positives, unnecessary procedures, patient anxiety, and medical expenses. Keywords: Artificial Intelligence, Semiautonomous Deep Learning, Breast Cancer, Screening Mammography Supplemental material is available for this article. Published under a CC BY 4.0 license.",True,other,Not specified
38597129,Bayesian and deep-learning models applied to the early detection of ovarian cancer using multiple longitudinal biomarkers,"BACKGROUND: Ovarian cancer is the most lethal of all gynecological cancers. Cancer Antigen 125 (CA125) is the best-performing ovarian cancer biomarker which however is still not effective as a screening test in the general population. Recent literature reports additional biomarkers with the potential to improve on CA125 for early detection when using longitudinal multimarker models.
METHODS: Our data comprised 180 controls and 44 cases with serum samples sourced from the multimodal arm of UK Collaborative Trial of Ovarian Cancer Screening (UKCTOCS). Our models were based on Bayesian change-point detection and recurrent neural networks.
RESULTS: We obtained a significantly higher performance for CA125-HE4 model using both methodologies (AUC 0.971, sensitivity 96.7% and AUC 0.987, sensitivity 96.7%) with respect to CA125 (AUC 0.949, sensitivity 90.8% and AUC 0.953, sensitivity 92.1%) for Bayesian change-point model (BCP) and recurrent neural networks (RNN) approaches, respectively. One year before diagnosis, the CA125-HE4 model also ranked as the best, whereas at 2 years before diagnosis no multimarker model outperformed CA125.
CONCLUSIONS: Our study identified and tested different combination of biomarkers using longitudinal multivariable models that outperformed CA125 alone. We showed the potential of multivariable models and candidate biomarkers to increase the detection rate of ovarian cancer.",True,both,Not specified
38592541,Clinical evaluation of deep learning-based risk profiling in breast cancer histopathology and comparison to an established multigene assay,"PURPOSE: To evaluate the Stratipath Breast tool for image-based risk profiling and compare it with an established prognostic multigene assay for risk profiling in a real-world case series of estrogen receptor (ER)-positive and human epidermal growth factor receptor 2 (HER2)-negative early breast cancer patients categorized as intermediate risk based on classic clinicopathological variables and eligible for chemotherapy.
METHODS: In a case series comprising 234 invasive ER-positive/HER2-negative tumors, clinicopathological data including Prosigna results and corresponding HE-stained tissue slides were retrieved. The digitized HE slides were analysed by Stratipath Breast.
RESULTS: Our findings showed that the Stratipath Breast analysis identified 49.6% of the clinically intermediate tumors as low risk and 50.4% as high risk. The Prosigna assay classified 32.5%, 47.0% and 20.5% tumors as low, intermediate and high risk, respectively. Among Prosigna intermediate-risk tumors, 47.3% were stratified as Stratipath low risk and 52.7% as high risk. In addition, 89.7% of Stratipath low-risk cases were classified as Prosigna low/intermediate risk. The overall agreement between the two tests for low-risk and high-risk groups (N = 124) was 71.0%, with a Cohen's kappa of 0.42. For both risk profiling tests, grade and Ki67 differed significantly between risk groups.
CONCLUSION: The results from this clinical evaluation of image-based risk stratification shows a considerable agreement to an established gene expression assay in routine breast pathology.",True,both,Not specified
38562791,Utilizing multimodal AI to improve genetic analyses of cardiovascular traits,"Electronic health records, biobanks, and wearable biosensors contain multiple high-dimensional clinical data (HDCD) modalities (e.g., ECG, Photoplethysmography (PPG), and MRI) for each individual. Access to multimodal HDCD provides a unique opportunity for genetic studies of complex traits because different modalities relevant to a single physiological system (e.g., circulatory system) encode complementary and overlapping information. We propose a novel multimodal deep learning method, M-REGLE, for discovering genetic associations from a joint representation of multiple complementary HDCD modalities. We showcase the effectiveness of this model by applying it to several cardiovascular modalities. M-REGLE jointly learns a lower representation (i.e., latent factors) of multimodal HDCD using a convolutional variational autoencoder, performs genome wide association studies (GWAS) on each latent factor, then combines the results to study the genetics of the underlying system. To validate the advantages of M-REGLE and multimodal learning, we apply it to common cardiovascular modalities (PPG and ECG), and compare its results to unimodal learning methods in which representations are learned from each data modality separately, but the downstream genetic analyses are performed on the combined unimodal representations. M-REGLE identifies 19.3% more loci on the 12-lead ECG dataset, 13.0% more loci on the ECG lead I + PPG dataset, and its genetic risk score significantly outperforms the unimodal risk score at predicting cardiac phenotypes, such as atrial fibrillation (Afib), in multiple biobanks.",True,other,Not specified
38552994,Computational frameworks integrating deep learning and statistical models in mining multimodal omics data,"BACKGROUND: In health research, multimodal omics data analysis is widely used to address important clinical and biological questions. Traditional statistical methods rely on the strong assumptions of distribution. Statistical methods such as testing and differential expression are commonly used in omics analysis. Deep learning, on the other hand, is an advanced computer science technique that is powerful in mining high-dimensional omics data for prediction tasks. Recently, integrative frameworks or methods have been developed for omics studies that combine statistical models and deep learning algorithms.
METHODS AND RESULTS: The aim of these integrative frameworks is to combine the strengths of both statistical methods and deep learning algorithms to improve prediction accuracy while also providing interpretability and explainability. This review report discusses the current state-of-the-art integrative frameworks, their limitations, and potential future directions in survival and time-to-event longitudinal analysis, dimension reduction and clustering, regression and classification, feature selection, and causal and transfer learning.",True,other,convolutional neural network
38533807,Artificial intelligence and machine learning in axial spondyloarthritis,"PURPOSE OF REVIEW: To evaluate the current applications and prospects of artificial intelligence and machine learning in diagnosing and managing axial spondyloarthritis (axSpA), focusing on their role in medical imaging, predictive modelling, and patient monitoring.
RECENT FINDINGS: Artificial intelligence, particularly deep learning, is showing promise in diagnosing axSpA assisting with X-ray, computed tomography (CT) and MRI analyses, with some models matching or outperforming radiologists in detecting sacroiliitis and markers. Moreover, it is increasingly being used in predictive modelling of disease progression and personalized treatment, and could aid risk assessment, treatment response and clinical subtype identification. Variable study designs, sample sizes and the predominance of retrospective, single-centre studies still limit the generalizability of results.
SUMMARY: Artificial intelligence technologies have significant potential to advance the diagnosis and treatment of axSpA, providing more accurate, efficient and personalized healthcare solutions. However, their integration into clinical practice requires rigorous validation, ethical and legal considerations, and comprehensive training for healthcare professionals. Future advances in artificial intelligence could complement clinical expertise and improve patient care through improved diagnostic accuracy and tailored therapeutic strategies, but the challenge remains to ensure that these technologies are validated in prospective multicentre trials and ethically integrated into patient care.",True,other,Not specified
38531985,"Author Correction: Deep learning, computer-aided radiography reading for tuberculosis: a diagnostic accuracy study from a tertiary hospital in India",,True,other,GAN
38527287,Deep Learning to Estimate Cardiovascular Risk From Chest Radiographs : A Risk Prediction Study,"BACKGROUND: Guidelines for primary prevention of atherosclerotic cardiovascular disease (ASCVD) recommend a risk calculator (ASCVD risk score) to estimate 10-year risk for major adverse cardiovascular events (MACE). Because the necessary inputs are often missing, complementary approaches for opportunistic risk assessment are desirable.
OBJECTIVE: To develop and test a deep-learning model (CXR CVD-Risk) that estimates 10-year risk for MACE from a routine chest radiograph (CXR) and compare its performance with that of the traditional ASCVD risk score for implications for statin eligibility.
DESIGN: Risk prediction study.
SETTING: Outpatients potentially eligible for primary cardiovascular prevention.
PARTICIPANTS: The CXR CVD-Risk model was developed using data from a cancer screening trial. It was externally validated in 8869 outpatients with unknown ASCVD risk because of missing inputs to calculate the ASCVD risk score and in 2132 outpatients with known risk whose ASCVD risk score could be calculated.
MEASUREMENTS: 10-year MACE predicted by CXR CVD-Risk versus the ASCVD risk score.
RESULTS: Among 8869 outpatients with unknown ASCVD risk, those with a risk of 7.5% or higher as predicted by CXR CVD-Risk had higher 10-year risk for MACE after adjustment for risk factors (adjusted hazard ratio [HR], 1.73 [95% CI, 1.47 to 2.03]). In the additional 2132 outpatients with known ASCVD risk, CXR CVD-Risk predicted MACE beyond the traditional ASCVD risk score (adjusted HR, 1.88 [CI, 1.24 to 2.85]).
LIMITATION: Retrospective study design using electronic medical records.
CONCLUSION: On the basis of a single CXR, CXR CVD-Risk predicts 10-year MACE beyond the clinical standard and may help identify individuals at high risk whose ASCVD risk score cannot be calculated because of missing data.
PRIMARY FUNDING SOURCE: None.",True,other,Not specified
38521180,Developing deep learning-based strategies to predict the risk of hepatocellular carcinoma among patients with nonalcoholic fatty liver disease from electronic health records,"OBJECTIVE: The accuracy of deep learning models for many disease prediction problems is affected by time-varying covariates, rare incidence, covariate imbalance and delayed diagnosis when using structured electronic health records data. The situation is further exasperated when predicting the risk of one disease on condition of another disease, such as the hepatocellular carcinoma risk among patients with nonalcoholic fatty liver disease due to slow, chronic progression, the scarce of data with both disease conditions and the sex bias of the diseases. The goal of this study is to investigate the extent to which the aforementioned issues influence deep learning performance, and then devised strategies to tackle these challenges. These strategies were applied to improve hepatocellular carcinoma risk prediction among patients with nonalcoholic fatty liver disease.
METHODS: We evaluated two representative deep learning models in the task of predicting the occurrence of hepatocellular carcinoma in a cohort of patients with nonalcoholic fatty liver disease (n = 220,838) from a national EHR database. The disease prediction task was carefully formulated as a classification problem while taking censorship and the length of follow-up into consideration.
RESULTS: We developed a novel backward masking scheme to deal with the issue of delayed diagnosis which is very common in EHR data analysis and evaluate how the length of longitudinal information after the index date affects disease prediction. We observed that modeling time-varying covariates improved the performance of the algorithms and transfer learning mitigated reduced performance caused by the lack of data. In addition, covariate imbalance, such as sex bias in data impaired performance. Deep learning models trained on one sex and evaluated in the other sex showed reduced performance, indicating the importance of assessing covariate imbalance while preparing data for model training.
CONCLUSIONS: The strategies developed in this work can significantly improve the performance of hepatocellular carcinoma risk prediction among patients with nonalcoholic fatty liver disease. Furthermore, our novel strategies can be generalized to apply to other disease risk predictions using structured electronic health records, especially for disease risks on condition of another disease.",True,other,recurrent neural network
38514140,Association between deep learning measured retinal vessel calibre and incident myocardial infarction in a retrospective cohort from the UK Biobank,"BACKGROUND: Cardiovascular disease is a leading cause of global death. Prospective population-based studies have found that changes in retinal microvasculature are associated with the development of coronary artery disease. Recently, artificial intelligence deep learning (DL) algorithms have been developed for the fully automated assessment of retinal vessel calibres.
METHODS: In this study, we validate the association between retinal vessel calibres measured by a DL system (Singapore I Vessel Assessment) and incident myocardial infarction (MI) and assess its incremental performance in discriminating patients with and without MI when added to risk prediction models, using a large UK Biobank cohort.
RESULTS: Retinal arteriolar narrowing was significantly associated with incident MI in both the age, gender and fellow calibre-adjusted (HR=1.67 (95% CI: 1.19 to 2.36)) and multivariable models (HR=1.64 (95% CI: 1.16 to 2.32)) adjusted for age, gender and other cardiovascular risk factors such as blood pressure, diabetes mellitus (DM) and cholesterol status. The area under the receiver operating characteristic curve increased from 0.738 to 0.745 (p=0.018) in the age-gender-adjusted model and from 0.782 to 0.787 (p=0.010) in the multivariable model. The continuous net reclassification improvements (NRIs) were significant in the age and gender-adjusted (NRI=21.56 (95% CI: 3.33 to 33.42)) and the multivariable models (NRI=18.35 (95% CI: 6.27 to 32.61)). In the subgroup analysis, similar associations between retinal arteriolar narrowing and incident MI were observed, particularly for men (HR=1.62 (95% CI: 1.07 to 2.46)), non-smokers (HR=1.65 (95% CI: 1.13 to 2.42)), patients without DM (HR=1.73 (95% CI: 1.19 to 2.51)) and hypertensive patients (HR=1.95 (95% CI: 1.30 to 2.93)) in the multivariable models.
CONCLUSION: Our results support DL-based retinal vessel measurements as markers of incident MI in a predominantly Caucasian population.",True,other,Not specified
38510535,Role of artificial intelligence in digital pathology for gynecological cancers,"The diagnosis of cancer is typically based on histopathological sections or biopsies on glass slides. Artificial intelligence (AI) approaches have greatly enhanced our ability to extract quantitative information from digital histopathology images as a rapid growth in oncology data. Gynecological cancers are major diseases affecting women's health worldwide. They are characterized by high mortality and poor prognosis, underscoring the critical importance of early detection, treatment, and identification of prognostic factors. This review highlights the various clinical applications of AI in gynecological cancers using digitized histopathology slides. Particularly, deep learning models have shown promise in accurately diagnosing, classifying histopathological subtypes, and predicting treatment response and prognosis. Furthermore, the integration with transcriptomics, proteomics, and other multi-omics techniques can provide valuable insights into the molecular features of diseases. Despite the considerable potential of AI, substantial challenges remain. Further improvements in data acquisition and model optimization are required, and the exploration of broader clinical applications, such as the biomarker discovery, need to be explored.",True,other,Not specified
38504089,The development of a prediction model based on deep learning for prognosis prediction of gastrointestinal stromal tumor: a SEER-based study,"Accurately predicting the prognosis of Gastrointestinal stromal tumor (GIST) patients is an important task. The goal of this study was to create and assess models for GIST patients' survival patients using the Surveillance, Epidemiology, and End Results Program (SEER) database based on the three different deep learning models. Four thousand five hundred thirty-eight patients were enrolled in this study and divided into training and test cohorts with a 7:3 ratio; the training cohort was used to develop three different models, including Cox regression, RSF, and DeepSurv model. Test cohort was used to evaluate model performance using c-index, Brier scores, calibration, and the area under the curve (AUC). The net benefits at risk score stratification of GIST patients based on the optimal model was compared with the traditional AJCC staging system using decision curve analysis (DCA). The clinical usefulness of risk score stratification compared to AJCC tumor staging was further assessed using the Net Reclassification Index (NRI) and Integrated Discrimination Improvement (IDI). The DeepSurv model predicted cancer-specific survival (CSS) in GIST patients showed a higher c-index (0.825), lower Brier scores (0.142), and greater AUC of receiver operating characteristic (ROC) analysis (1-year ROC:0.898; 3-year:0.853, and 5-year ROC: 0.856). The calibration plots demonstrated good agreement between the DeepSurv model's forecast and actual results. The NRI values ( training cohort: 0.425 for 1-year, 0.329 for 3-year and 0.264 for 5-year CSS prediction; test cohort:0.552 for 1-year,0.309 for 3-year and 0.255 for 5-year CSS prediction) and IDI (training cohort: 0.130 for 1-year,0.141 for 5-year and 0.155 for 10-year CSS prediction; test cohort: 0.154 for 1-year,0.159 for 3-year and 0.159 for 5-year CSS prediction) indicated that the risk score stratification performed significantly better than the AJCC staging alone (P < 0.001). DCA demonstrated the risk score stratification as more clinically beneficial and discriminatory than AJCC staging. Finally, an interactive native web-based prediction tool was constructed for the survival prediction of GIST patients. This study established a high-performance prediction model for projecting GIST patients based on deep learning, which has advantages in predicting each person's prognosis and risk stratification.",True,other,Not specified
38491804,Construction and validation of machine learning models for predicting distant metastases in newly diagnosed colorectal cancer patients: A large-scale and real-world cohort study,"BACKGROUND: More accurate prediction of distant metastases (DM) in patients with colorectal cancer (CRC) would optimize individualized treatment and follow-up strategies. Multiple prediction models based on machine learning have been developed to assess the likelihood of developing DM.
METHODS: Clinicopathological features of patients with CRC were obtained from the National Cancer Center (NCC, China) and the Surveillance, Epidemiology, and End Results (SEER) database. The algorithms used to create the prediction models included random forest (RF), logistic regression, extreme gradient boosting, deep neural networks, and the K-Nearest Neighbor machine. The prediction models' performances were evaluated using receiver operating characteristic (ROC) curves.
RESULTS: In total, 200,958 patients, 3241 from NCC and 197,717 CRC from SEER were identified, of whom 21,736 (10.8%) developed DM. The machine-learning-based prediction models for DM were constructed with 12 features remaining after iterative filtering. The RF model performed the best, with areas under the ROC curve of 0.843, 0.793, and 0.806, respectively, on the training, test, and external validation sets. For the risk stratification analysis, the patients were separated into high-, middle-, and low-risk groups according to their risk scores. Patients in the high-risk group had the highest incidence of DM and the worst prognosis. Surgery, chemotherapy, and radiotherapy could significantly improve the prognosis of the high-risk and middle-risk groups, whereas the low-risk group only benefited from surgery and chemotherapy.
CONCLUSION: The RF-based model accurately predicted the likelihood of DM and identified patients with CRC in the high-risk group, providing guidance for personalized clinical decision-making.",True,other,recurrent neural network
38491097,Advancing mortality rate prediction in European population clusters: integrating deep learning and multiscale analysis,"Accurately predicting population mortality rates is crucial for effective retirement insurance and economic policy formulation. Recent advancements in deep learning time series forecasting (DLTSF) have led to improved mortality rate predictions compared to traditional models like Lee-Carter (LC). This study focuses on mortality rate prediction in large clusters across Europe. By utilizing PCA dimensionality reduction and statistical clustering techniques, we integrate age features from high-dimensional mortality data of multiple countries, analyzing their similarities and differences. To capture the heterogeneous characteristics, an adaptive adjustment matrix is generated, incorporating sequential variation and spatial geographical information. Additionally, a combination of graph neural networks and a transformer network with an adaptive adjustment matrix is employed to capture the spatiotemporal features between different clusters. Extensive numerical experiments using data from the Human Mortality Database validate the superiority of the proposed GT-A model over traditional LC models and other classic neural networks in terms of prediction accuracy. Consequently, the GT-A model serves as a powerful forecasting tool for global population studies and the international life insurance field.",True,other,Not specified
38483948,Deep learning in public health: Comparative predictive models for COVID-19 case forecasting,"The COVID-19 pandemic has had a significant impact on both the United Arab Emirates (UAE) and Malaysia, emphasizing the importance of developing accurate and reliable forecasting mechanisms to guide public health responses and policies. In this study, we compared several cutting-edge deep learning models, including Long Short-Term Memory (LSTM), bidirectional LSTM, Convolutional Neural Networks (CNN), hybrid CNN-LSTM, Multilayer Perceptron's, and Recurrent Neural Networks (RNN), to project COVID-19 cases in the aforementioned regions. These models were calibrated and evaluated using a comprehensive dataset that includes confirmed case counts, demographic data, and relevant socioeconomic factors. To enhance the performance of these models, Bayesian optimization techniques were employed. Subsequently, the models were re-evaluated to compare their effectiveness. Analytic approaches, both predictive and retrospective in nature, were used to interpret the data. Our primary objective was to determine the most effective model for predicting COVID-19 cases in the United Arab Emirates (UAE) and Malaysia. The findings indicate that the selected deep learning algorithms were proficient in forecasting COVID-19 cases, although their efficacy varied across different models. After a thorough evaluation, the model architectures most suitable for the specific conditions in the UAE and Malaysia were identified. Our study contributes significantly to the ongoing efforts to combat the COVID-19 pandemic, providing crucial insights into the application of sophisticated deep learning algorithms for the precise and timely forecasting of COVID-19 cases. These insights hold substantial value for shaping public health strategies, enabling authorities to develop targeted and evidence-based interventions to manage the virus spread and its impact on the populations of the UAE and Malaysia. The study confirms the usefulness of deep learning methodologies in efficiently processing complex datasets and generating reliable projections, a skill of great importance in healthcare and professional settings.",True,other,recurrent neural network
38483802,Long-Term Regional Influenza-Like-Illness Forecasting Using Exogenous Data,"Disease forecasting is a longstanding problem for the research community, which aims at informing and improving decisions with the best available evidence. Specifically, the interest in respiratory disease forecasting has dramatically increased since the beginning of the coronavirus pandemic, rendering the accurate prediction of influenza-like-illness (ILI) a critical task. Although methods for short-term ILI forecasting and nowcasting have achieved good accuracy, their performance worsens at long-term ILI forecasts. Machine learning models have outperformed conventional forecasting approaches enabling to utilize diverse exogenous data sources, such as social media, internet users' search query logs, and climate data. However, the most recent deep learning ILI forecasting models use only historical occurrence data achieving state-of-the-art results. Inspired by recent deep neural network architectures in time series forecasting, this work proposes the Regional Influenza-Like-Illness Forecasting (ReILIF) method for regional long-term ILI prediction. The proposed architecture takes advantage of diverse exogenous data, that are, meteorological and population data, introducing an efficient intermediate fusion mechanism to combine the different types of information with the aim to capture the variations of ILI from various views. The efficacy of the proposed approach compared to state-of-the-art ILI forecasting methods is confirmed by an extensive experimental study following standard evaluation measures.",True,other,recurrent neural network
38464019,Graph Structured Neural Networks for Perturbation Biology,"UNLABELLED: Computational modeling of perturbation biology identifies relationships between molecular elements and cellular response, and an accurate understanding of these systems will support the full realization of precision medicine. Traditional deep learning, while often accurate in predicting response, is unlikely to capture the true sequence of involved molecular interactions. Our work is motivated by two assumptions: 1) Methods that encourage mechanistic prediction logic are likely to be more trustworthy, and 2) problem-specific algorithms are likely to outperform generic algorithms. We present an alternative to Graph Neural Networks (GNNs) termed Graph Structured Neural Networks (GSNN), which uses cell signaling knowledge, encoded as a graph data structure, to add inductive biases to deep learning. We apply our method to perturbation biology using the LINCS L1000 dataset and literature-curated molecular interactions. We demonstrate that GSNNs outperform baseline algorithms in several prediction tasks, including 1) perturbed expression, 2) cell viability of drug combinations, and 3) disease-specific drug prioritization. We also present a method called GSNNExplainer to explain GSNN predictions in a biologically interpretable form. This work has broad application in basic biological research and pre-clincal drug repurposing. Further refinement of these methods may produce trustworthy models of drug response suitable for use as clinical decision aids.
AVAILABILITY AND IMPLEMENTATION: Our implementation of the GSNN method is available at https://github.com/nathanieljevans/GSNN. All data used in this work is publicly available.",True,other,convolutional neural network
38452227,Deep Learning-based Segmentation of Computed Tomography Scans Predicts Disease Progression and Mortality in Idiopathic Pulmonary Fibrosis,"Rationale: Despite evidence demonstrating a prognostic role for computed tomography (CT) scans in idiopathic pulmonary fibrosis (IPF), image-based biomarkers are not routinely used in clinical practice or trials. Objectives: To develop automated imaging biomarkers using deep learning-based segmentation of CT scans. Methods: We developed segmentation processes for four anatomical biomarkers, which were applied to a unique cohort of treatment-naive patients with IPF enrolled in the PROFILE (Prospective Observation of Fibrosis in the Lung Clinical Endpoints) study and tested against a further United Kingdom cohort. The relationships among CT biomarkers, lung function, disease progression, and mortality were assessed. Measurements and Main Results: Data from 446 PROFILE patients were analyzed. Median follow-up duration was 39.1 months (interquartile range, 18.1-66.4 mo), with a cumulative incidence of death of 277 (62.1%) over 5 years. Segmentation was successful on 97.8% of all scans, across multiple imaging vendors, at slice thicknesses of 0.5-5 mm. Of four segmentations, lung volume showed the strongest correlation with FVC (r = 0.82; P &lt; 0.001). Lung, vascular, and fibrosis volumes were consistently associated across cohorts with differential 5-year survival, which persisted after adjustment for baseline gender, age, and physiology score. Lower lung volume (hazard ratio [HR], 0.98 [95% confidence interval (CI), 0.96-0.99]; P = 0.001), increased vascular volume (HR, 1.30 [95% CI, 1.12-1.51]; P = 0.001), and increased fibrosis volume (HR, 1.17 [95% CI, 1.12-1.22]; P &lt; 0.001) were associated with reduced 2-year progression-free survival in the pooled PROFILE cohort. Longitudinally, decreasing lung volume (HR, 3.41 [95% CI, 1.36-8.54]; P = 0.009) and increasing fibrosis volume (HR, 2.23 [95% CI, 1.22-4.08]; P = 0.009) were associated with differential survival. Conclusions: Automated models can rapidly segment IPF CT scans, providing prognostic near and long-term information, which could be used in routine clinical practice or as key trial endpoints.",True,other,Not specified
38449285,iNGNN-DTI: prediction of drug-target interaction with interpretable nested graph neural network and pretrained molecule models,"MOTIVATION: Drug-target interaction (DTI) prediction aims to identify interactions between drugs and protein targets. Deep learning can automatically learn discriminative features from drug and protein target representations for DTI prediction, but challenges remain, making it an open question. Existing approaches encode drugs and targets into features using deep learning models, but they often lack explanations for underlying interactions. Moreover, limited labeled DTIs in the chemical space can hinder model generalization.
RESULTS: We propose an interpretable nested graph neural network for DTI prediction (iNGNN-DTI) using pre-trained molecule and protein models. The analysis is conducted on graph data representing drugs and targets by using a specific type of nested graph neural network, in which the target graphs are created based on 3D structures using Alphafold2. This architecture is highly expressive in capturing substructures of the graph data. We use a cross-attention module to capture interaction information between the substructures of drugs and targets. To improve feature representations, we integrate features learned by models that are pre-trained on large unlabeled small molecule and protein datasets, respectively. We evaluate our model on three benchmark datasets, and it shows a consistent improvement on all baseline models in all datasets. We also run an experiment with previously unseen drugs or targets in the test set, and our model outperforms all of the baselines. Furthermore, the iNGNN-DTI can provide more insights into the interaction by visualizing the weights learned by the cross-attention module.
AVAILABILITY AND IMPLEMENTATION: The source code of the algorithm is available at https://github.com/syan1992/iNGNN-DTI.",True,other,convolutional neural network
38448849,Development and validation of a deep learning model for predicting postoperative survival of patients with gastric cancer,"BACKGROUND: Deep learning (DL), a specialized form of machine learning (ML), is valuable for forecasting survival in various diseases. Its clinical applicability in real-world patients with gastric cancer (GC) has yet to be extensively validated.
METHODS: A combined cohort of 11,414 GC patients from the Surveillance, Epidemiology and End Results (SEER) database and 2,846 patients from a Chinese dataset were utilized. The internal validation of different algorithms, including DL model, traditional ML models, and American Joint Committee on Cancer (AJCC) stage model, was conducted by training and testing sets on the SEER database, followed by external validation on the Chinese dataset. The performance of the algorithms was assessed using the area under the receiver operating characteristic curve, decision curve, and calibration curve.
RESULTS: DL model demonstrated superior performance in terms of the area under the curve (AUC) at 1, 3, and, 5 years post-surgery across both datasets, surpassing other ML models and AJCC stage model, with AUCs of 0.77, 0.80, and 0.82 in the SEER dataset and 0.77, 0.76, and 0.75 in the Chinese dataset, respectively. Furthermore, decision curve analysis revealed that the DL model yielded greater net gains at 3 years than other ML models and AJCC stage model, and calibration plots at 3 years indicated a favorable level of consistency between the ML and actual observations during external validation.
CONCLUSIONS: DL-based model was established to accurately predict the survival rate of postoperative patients with GC.",True,other,Not specified
38445478,Deep learning-based multi-model prediction for disease-free survival status of patients with clear cell renal cell carcinoma after surgery: a multicenter cohort study,"BACKGROUND: Although separate analysis of individual factor can somewhat improve the prognostic performance, integration of multimodal information into a single signature is necessary to stratify patients with clear cell renal cell carcinoma (ccRCC) for adjuvant therapy after surgery.
METHODS: A total of 414 patients with whole slide images, computed tomography images, and clinical data from three patient cohorts were retrospectively analyzed. The authors performed deep learning and machine learning algorithm to construct three single-modality prediction models for disease-free survival of ccRCC based on whole slide images, cell segmentation, and computed tomography images, respectively. A multimodel prediction signature (MMPS) for disease-free survival were further developed by combining three single-modality prediction models and tumor stage/grade system. Prognostic performance of the prognostic model was also verified in two independent validation cohorts.
RESULTS: Single-modality prediction models performed well in predicting the disease-free survival status of ccRCC. The MMPS achieved higher area under the curve value of 0.742, 0.917, and 0.900 in three independent patient cohorts, respectively. MMPS could distinguish patients with worse disease-free survival, with HR of 12.90 (95% CI: 2.443-68.120, P <0.0001), 11.10 (95% CI: 5.467-22.520, P <0.0001), and 8.27 (95% CI: 1.482-46.130, P <0.0001) in three different patient cohorts. In addition, MMPS outperformed single-modality prediction models and current clinical prognostic factors, which could also provide complements to current risk stratification for adjuvant therapy of ccRCC.
CONCLUSION: Our novel multimodel prediction analysis for disease-free survival exhibited significant improvements in prognostic prediction for patients with ccRCC. After further validation in multiple centers and regions, the multimodal system could be a potential practical tool for clinicians in the treatment for ccRCC patients.",True,both,Not specified
38443092,Systemic lupus in the era of machine learning medicine,"Artificial intelligence and machine learning applications are emerging as transformative technologies in medicine. With greater access to a diverse range of big datasets, researchers are turning to these powerful techniques for data analysis. Machine learning can reveal patterns and interactions between variables in large and complex datasets more accurately and efficiently than traditional statistical methods. Machine learning approaches open new possibilities for studying SLE, a multifactorial, highly heterogeneous and complex disease. Here, we discuss how machine learning methods are rapidly being integrated into the field of SLE research. Recent reports have focused on building prediction models and/or identifying novel biomarkers using both supervised and unsupervised techniques for understanding disease pathogenesis, early diagnosis and prognosis of disease. In this review, we will provide an overview of machine learning techniques to discuss current gaps, challenges and opportunities for SLE studies. External validation of most prediction models is still needed before clinical adoption. Utilisation of deep learning models, access to alternative sources of health data and increased awareness of the ethics, governance and regulations surrounding the use of artificial intelligence in medicine will help propel this exciting field forward.",True,other,recurrent neural network
38438528,Predictive healthcare modeling for early pandemic assessment leveraging deep auto regressor neural prophet,"In this paper, NeuralProphet (NP), an explainable hybrid modular framework, enhances the forecasting performance of pandemics by adding two neural network modules; auto-regressor (AR) and lagged-regressor (LR). An advanced deep auto-regressor neural network (Deep-AR-Net) model is employed to implement these two modules. The enhanced NP is optimized via AdamW and Huber loss function to perform multivariate multi-step forecasting contrast to Prophet. The models are validated with COVID-19 time-series datasets. The NP's efficiency is studied component-wise for a long-term forecast for India and an overall reduction of 60.36% and individually 34.7% by AR-module, 53.4% by LR-module in MASE compared to Prophet. The Deep-AR-Net model reduces the forecasting error of NP for all five countries, on average, by 49.21% and 46.07% for short-and-long-term, respectively. The visualizations confirm that forecasting curves are closer to the actual cases but significantly different from Prophet. Hence, it can develop a real-time decision-making system for highly infectious diseases.",True,other,recurrent neural network
38436551,Multitask deep learning for prediction of microvascular invasion and recurrence-free survival in hepatocellular carcinoma based on MRI images,"BACKGROUND AND AIMS: Accurate preoperative prediction of microvascular invasion (MVI) and recurrence-free survival (RFS) is vital for personalised hepatocellular carcinoma (HCC) management. We developed a multitask deep learning model to predict MVI and RFS using preoperative MRI scans.
METHODS: Utilising a retrospective dataset of 725 HCC patients from seven institutions, we developed and validated a multitask deep learning model focused on predicting MVI and RFS. The model employs a transformer architecture to extract critical features from preoperative MRI scans. It was trained on a set of 234 patients and internally validated on a set of 58 patients. External validation was performed using three independent sets (n = 212, 111, 110).
RESULTS: The multitask deep learning model yielded high MVI prediction accuracy, with AUC values of 0.918 for the training set and 0.800 for the internal test set. In external test sets, AUC values were 0.837, 0.815 and 0.800. Radiologists' sensitivity and inter-rater agreement for MVI prediction improved significantly when integrated with the model. For RFS, the model achieved C-index values of 0.763 in the training set and ranged between 0.628 and 0.728 in external test sets. Notably, PA-TACE improved RFS only in patients predicted to have high MVI risk and low survival scores (p < .001).
CONCLUSIONS: Our deep learning model allows accurate MVI and survival prediction in HCC patients. Prospective studies are warranted to assess the clinical utility of this model in guiding personalised treatment in conjunction with clinical criteria.",True,other,Not specified
38424093,Author Correction: Regression-based Deep-Learning predicts molecular biomarkers from pathology slides,,True,other,GAN
38416134,Deep-Learning Model for Tumor-Type Prediction Using Targeted Clinical Genomic Sequencing Data,"UNLABELLED: Tumor type guides clinical treatment decisions in cancer, but histology-based diagnosis remains challenging. Genomic alterations are highly diagnostic of tumor type, and tumor-type classifiers trained on genomic features have been explored, but the most accurate methods are not clinically feasible, relying on features derived from whole-genome sequencing (WGS), or predicting across limited cancer types. We use genomic features from a data set of 39,787 solid tumors sequenced using a clinically targeted cancer gene panel to develop Genome-Derived-Diagnosis Ensemble (GDD-ENS): a hyperparameter ensemble for classifying tumor type using deep neural networks. GDD-ENS achieves 93% accuracy for high-confidence predictions across 38 cancer types, rivaling the performance of WGS-based methods. GDD-ENS can also guide diagnoses of rare type and cancers of unknown primary and incorporate patient-specific clinical information for improved predictions. Overall, integrating GDD-ENS into prospective clinical sequencing workflows could provide clinically relevant tumor-type predictions to guide treatment decisions in real time.
SIGNIFICANCE: We describe a highly accurate tumor-type prediction model, designed specifically for clinical implementation. Our model relies only on widely used cancer gene panel sequencing data, predicts across 38 distinct cancer types, and supports integration of patient-specific nongenomic information for enhanced decision support in challenging diagnostic situations. See related commentary by Garg, p. 906. This article is featured in Selected Articles from This Issue, p. 897.",True,other,Not specified
38403235,ECG-only explainable deep learning algorithm predicts the risk for malignant ventricular arrhythmia in phospholamban cardiomyopathy,"BACKGROUND: Phospholamban (PLN) p.(Arg14del) variant carriers are at risk for development of malignant ventricular arrhythmia (MVA). Accurate risk stratification allows timely implantation of intracardiac defibrillators and is currently performed with a multimodality prediction model.
OBJECTIVE: This study aimed to investigate whether an explainable deep learning-based approach allows risk prediction with only electrocardiogram (ECG) data.
METHODS: A total of 679 PLN p.(Arg14del) carriers without MVA at baseline were identified. A deep learning-based variational auto-encoder, trained on 1.1 million ECGs, was used to convert the 12-lead baseline ECG into its FactorECG, a compressed version of the ECG that summarizes it into 32 explainable factors. Prediction models were developed by Cox regression.
RESULTS: The deep learning-based ECG-only approach was able to predict MVA with a C statistic of 0.79 (95% CI, 0.76-0.83), comparable to the current prediction model (C statistic, 0.83 [95% CI, 0.79-0.88]; P = .054) and outperforming a model based on conventional ECG parameters (low-voltage ECG and negative T waves; C statistic, 0.65 [95% CI, 0.58-0.73]; P < .001). Clinical simulations showed that a 2-step approach, with ECG-only screening followed by a full workup, resulted in 60% less additional diagnostics while outperforming the multimodal prediction model in all patients. A visualization tool was created to provide interactive visualizations (https://pln.ecgx.ai).
CONCLUSION: Our deep learning-based algorithm based on ECG data only accurately predicts the occurrence of MVA in PLN p.(Arg14del) carriers, enabling more efficient stratification of patients who need additional diagnostic testing and follow-up.",True,other,Not specified
38381386,DeepCSFusion: Deep Compressive Sensing Fusion for Efficient COVID-19 Classification,"Worldwide, the COVID-19 epidemic, which started in 2019, has resulted in millions of deaths. The medical research community has widely used computer analysis of medical data during the pandemic, specifically deep learning models. Deploying models on devices with constrained resources is a significant challenge due to the increased storage demands associated with larger deep learning models. Accordingly, in this paper, we propose a novel compression strategy that compresses deep features with a compression ratio of 10 to 90% to accurately classify the COVID-19 and non-COVID-19 computed tomography scans. Additionally, we extensively validated the compression using various available deep learning methods to extract the most suitable features from different models. Finally, the suggested DeepCSFusion model compresses the extracted features and applies fusion to achieve the highest classification accuracy with fewer features. The proposed DeepCSFusion model was validated on the publicly available dataset ""SARS-CoV-2 CT"" scans composed of 1252 CT. This study demonstrates that the proposed DeepCSFusion reduced the computational time with an overall accuracy of 99.3%. Also, it outperforms state-of-the-art pipelines in terms of various classification measures.",True,other,recurrent neural network
38370127,shinyDeepDR: A user-friendly R Shiny app for predicting anti-cancer drug response using deep learning,"Advancing precision oncology requires accurate prediction of treatment response and accessible prediction models. To this end, we present shinyDeepDR, a user-friendly implementation of our innovative deep learning model, DeepDR, for predicting anti-cancer drug sensitivity. The web tool makes DeepDR more accessible to researchers without extensive programming experience. Using shinyDeepDR, users can upload mutation and/or gene expression data from a cancer sample (cell line or tumor) and perform two main functions: ""Find Drug,"" which predicts the sample's response to 265 approved and investigational anti-cancer compounds, and ""Find Sample,"" which searches for cell lines in the Cancer Cell Line Encyclopedia (CCLE) and tumors in The Cancer Genome Atlas (TCGA) with genomics profiles similar to those of the query sample to study potential effective treatments. shinyDeepDR provides an interactive interface to interpret prediction results and to investigate individual compounds. In conclusion, shinyDeepDR is an intuitive and free-to-use web tool for in silico anti-cancer drug screening.",True,other,Not specified
38366403,"Exploring the potential of learning methods and recurrent dynamic model with vaccination: A comparative case study of COVID-19 in Austria, Brazil, and China","In order to effectively manage infectious diseases, it is crucial to understand the interplay between disease dynamics and human conduct. Various factors can impact the control of an epidemic, including social interventions, adherence to health protocols, mask-wearing, and vaccination. This article presents the development of an innovative hybrid model, known as the Combined Dynamic-Learning Model, that integrates classical recurrent dynamic models with four different learning methods. The model is composed of two approaches: The first approach introduces a traditional dynamic model that focuses on analyzing the impact of vaccination on the occurrence of an epidemic, and the second approach employs various learning methods to forecast the potential outcomes of an epidemic. Furthermore, our numerical results offer an interesting comparison between the traditional approach and modern learning techniques. Our classic dynamic model is a compartmental model that aims to analyze and forecast the diffusion of epidemics. The model we propose has a recurrent structure with piecewise constant parameters and includes compartments for susceptible, exposed, vaccinated, infected, and recovered individuals. This model can accurately mirror the dynamics of infectious diseases, which enables us to evaluate the impact of restrictive measures on the spread of diseases. We conduct a comprehensive dynamic analysis of our model. Additionally, we suggest an optimal numerical design to determine the parameters of the system. Also, we use regression tree learning, bidirectional long short-term memory, gated recurrent unit, and a combined deep learning method for training and evaluation of an epidemic. In the final section of our paper, we apply these methods to recently published data on COVID-19 in Austria, Brazil, and China from 26 February 2021 to 4 August 2021, which is when vaccination efforts began. To evaluate the numerical results, we utilized various metrics such as RMSE and R-squared. Our findings suggest that the dynamic model is ideal for long-term analysis, data fitting, and identifying parameters that impact epidemics. However, it is not as effective as the supervised learning method for making long-term forecasts. On the other hand, supervised learning techniques, compared to dynamic models, are more effective for predicting the spread of diseases, but not for analyzing the behavior of epidemics.",True,computer vision,Not specified
38350397,Predicting Drug-Protein Interactions through Branch-Chain Mining and multi-dimensional attention network,"Identifying drug-protein interactions (DPIs) is crucial in drug discovery and repurposing. Computational methods for precise DPI identification can expedite development timelines and reduce expenses compared with conventional experimental methods. Lately, deep learning techniques have been employed for predicting DPIs, enhancing these processes. Nevertheless, the limitations observed in prior studies, where many extract features from complete drug and protein entities, overlooking the crucial theoretical foundation that pharmacological responses are often correlated with specific substructures, can lead to poor predictive performance. Furthermore, certain substructure-focused research confines its exploration to a solitary fragment category, such as a functional group. In this study, addressing these constraints, we present an end-to-end framework termed BCMMDA for predicting DPIs. The framework considers various substructure types, including branch chains, common substructures, and specific fragments. We designed a specific feature learning module by combining our proposed multi-dimensional attention mechanism with convolutional neural networks (CNNs). Deep CNNs assist in capturing the synergistic effects among these fragment sets, enabling the extraction of relevant features of drugs and proteins. Meanwhile, the multi-dimensional attention mechanism refines the relationship between drug and protein features by assigning attention vectors to each drug compound and amino acid. This mechanism empowers the model to further concentrate on pivotal substructures and elements, thereby improving its ability to identify essential interactions in DPI prediction. We evaluated the performance of BCMMDA on four well-known benchmark datasets. The results indicated that BCMMDA outperformed state-of-the-art baseline models, demonstrating significant improvement in performance.",True,other,Not specified
38348900,A computed tomography-based multitask deep learning model for predicting tumour stroma ratio and treatment outcomes in patients with colorectal cancer: a multicentre cohort study,"BACKGROUND: Tumour-stroma interactions, as indicated by tumour-stroma ratio (TSR), offer valuable prognostic stratification information. Current histological assessment of TSR is limited by tissue accessibility and spatial heterogeneity. The authors aimed to develop a multitask deep learning (MDL) model to noninvasively predict TSR and prognosis in colorectal cancer (CRC).
MATERIALS AND METHODS: In this retrospective study including 2268 patients with resected CRC recruited from four centres, the authors developed an MDL model using preoperative computed tomography (CT) images for the simultaneous prediction of TSR and overall survival. Patients in the training cohort ( n =956) and internal validation cohort (IVC, n =240) were randomly selected from centre I. Patients in the external validation cohort 1 (EVC1, n =509), EVC2 ( n =203), and EVC3 ( n =360) were recruited from other three centres. Model performance was evaluated with respect to discrimination and calibration. Furthermore, the authors evaluated whether the model could predict the benefit from adjuvant chemotherapy.
RESULTS: The MDL model demonstrated strong TSR discrimination, yielding areas under the receiver operating curves (AUCs) of 0.855 (95% CI, 0.800-0.910), 0.838 (95% CI, 0.802-0.874), and 0.857 (95% CI, 0.804-0.909) in the three validation cohorts, respectively. The MDL model was also able to predict overall survival and disease-free survival across all cohorts. In multivariable Cox analysis, the MDL score (MDLS) remained an independent prognostic factor after adjusting for clinicopathological variables (all P <0.05). For stage II and stage III disease, patients with a high MDLS benefited from adjuvant chemotherapy [hazard ratio (HR) 0.391 (95% CI, 0.230-0.666), P =0.0003; HR=0.467 (95% CI, 0.331-0.659), P <0.0001, respectively], whereas those with a low MDLS did not.
CONCLUSION: The multitask DL model based on preoperative CT images effectively predicted TSR status and survival in CRC patients, offering valuable guidance for personalized treatment. Prospective studies are needed to confirm its potential to select patients who might benefit from chemotherapy.",True,other,Not specified
38341402,Regression-based Deep-Learning predicts molecular biomarkers from pathology slides,"Deep Learning (DL) can predict biomarkers from cancer histopathology. Several clinically approved applications use this technology. Most approaches, however, predict categorical labels, whereas biomarkers are often continuous measurements. We hypothesize that regression-based DL outperforms classification-based DL. Therefore, we develop and evaluate a self-supervised attention-based weakly supervised regression method that predicts continuous biomarkers directly from 11,671 images of patients across nine cancer types. We test our method for multiple clinically and biologically relevant biomarkers: homologous recombination deficiency score, a clinically used pan-cancer biomarker, as well as markers of key biological processes in the tumor microenvironment. Using regression significantly enhances the accuracy of biomarker prediction, while also improving the predictions' correspondence to regions of known clinical relevance over classification. In a large cohort of colorectal cancer patients, regression-based prediction scores provide a higher prognostic value than classification-based scores. Our open-source regression approach offers a promising alternative for continuous biomarker analysis in computational pathology.",True,other,Not specified
38316534,Prediction of retinopathy progression using deep learning on retinal images within the Scottish screening programme,"BACKGROUND/AIMS: National guidelines of many countries set screening intervals for diabetic retinopathy (DR) based on grading of the last screening retinal images. We explore the potential of deep learning (DL) on images to predict progression to referable DR beyond DR grading, and the potential impact on assigned screening intervals, within the Scottish screening programme.
METHODS: We consider 21 346 and 247 233 people with type 1 diabetes mellitus (T1DM) and type 2 diabetes mellitus (T2DM), respectively, each contributing on average 4.8 and 4.4 screening intervals of which 1339 and 4675 intervals concluded with a referable screening episode. Information extracted from fundus images using DL was used to predict referable status at the end of interval and its predictive value in comparison to screening-assigned DR grade was assessed.
RESULTS: The DL predictor increased the area under the receiver operating characteristic curve in comparison to a predictor using current DR grades from 0.809 to 0.87 for T1DM and from 0.825 to 0.87 for T2DM. Expected sojourn time-the time from becoming referable to being rescreened-was found to be 3.4 (T1DM) and 2.7 (T2DM) weeks less for a DL-derived policy compared with the current recall policy.
CONCLUSIONS: We showed that, compared with using the current retinopathy grade, DL of fundus images significantly improves the prediction of incident referable retinopathy before the next screening episode. This can impact screening recall interval policy positively, for example, by reducing the expected time with referable disease for a fixed workload-which we show as an exemplar. Additionally, it could be used to optimise workload for a fixed sojourn time.",True,both,Not specified
38308870,Systematic comparison of 3D Deep learning and classical machine learning explanations for Alzheimer's Disease detection,"Black-box deep learning (DL) models trained for the early detection of Alzheimer's Disease (AD) often lack systematic model interpretation. This work computes the activated brain regions during DL and compares those with classical Machine Learning (ML) explanations. The architectures used for DL were 3D DenseNets, EfficientNets, and Squeeze-and-Excitation (SE) networks. The classical models include Random Forests (RFs), Support Vector Machines (SVMs), eXtreme Gradient Boosting (XGBoost), Light Gradient Boosting (LightGBM), Decision Trees (DTs), and Logistic Regression (LR). For explanations, SHapley Additive exPlanations (SHAP) values, Local Interpretable Model-agnostic Explanations (LIME), Gradient-weighted Class Activation Mapping (GradCAM), GradCAM++ and permutation-based feature importance were implemented. During interpretation, correlated features were consolidated into aspects. All models were trained on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. The validation includes internal and external validation on the Australian Imaging and Lifestyle flagship study of Ageing (AIBL) and the Open Access Series of Imaging Studies (OASIS). DL and ML models reached similar classification performances. Regarding the brain regions, both types focus on different regions. The ML models focus on the inferior and middle temporal gyri, and the hippocampus, and amygdala regions previously associated with AD. The DL models focus on a wider range of regions including the optical chiasm, the entorhinal cortices, the left and right vessels, and the 4th ventricle which were partially associated with AD. One explanation for the differences is the input features (textures vs. volumes). Both types show reasonable similarity to a ground truth Voxel-Based Morphometry (VBM) analysis. Slightly higher similarities were measured for ML models.",True,other,recurrent neural network
38302850,Validating the accuracy of deep learning for the diagnosis of pneumonia on chest x-ray against a robust multimodal reference diagnosis: a post hoc analysis of two prospective studies,"BACKGROUND: Artificial intelligence (AI) seems promising in diagnosing pneumonia on chest x-rays (CXR), but deep learning (DL) algorithms have primarily been compared with radiologists, whose diagnosis can be not completely accurate. Therefore, we evaluated the accuracy of DL in diagnosing pneumonia on CXR using a more robust reference diagnosis.
METHODS: We trained a DL convolutional neural network model to diagnose pneumonia and evaluated its accuracy in two prospective pneumonia cohorts including 430 patients, for whom the reference diagnosis was determined a posteriori by a multidisciplinary expert panel using multimodal data. The performance of the DL model was compared with that of senior radiologists and emergency physicians reviewing CXRs and that of radiologists reviewing computed tomography (CT) performed concomitantly.
RESULTS: Radiologists and DL showed a similar accuracy on CXR for both cohorts (p ≥ 0.269): cohort 1, radiologist 1 75.5% (95% confidence interval 69.1-80.9), radiologist 2 71.0% (64.4-76.8), DL 71.0% (64.4-76.8); cohort 2, radiologist 70.9% (64.7-76.4), DL 72.6% (66.5-78.0). The accuracy of radiologists and DL was significantly higher (p ≤ 0.022) than that of emergency physicians (cohort 1 64.0% [57.1-70.3], cohort 2 63.0% [55.6-69.0]). Accuracy was significantly higher for CT (cohort 1 79.0% [72.8-84.1], cohort 2 89.6% [84.9-92.9]) than for CXR readers including radiologists, clinicians, and DL (all p-values < 0.001).
CONCLUSIONS: When compared with a robust reference diagnosis, the performance of AI models to identify pneumonia on CXRs was inferior than previously reported but similar to that of radiologists and better than that of emergency physicians.
RELEVANCE STATEMENT: The clinical relevance of AI models for pneumonia diagnosis may have been overestimated. AI models should be benchmarked against robust reference multimodal diagnosis to avoid overestimating its performance.
TRIAL REGISTRATION: NCT02467192 , and NCT01574066 .
KEY POINT: • We evaluated an openly-access convolutional neural network (CNN) model to diagnose pneumonia on CXRs. • CNN was validated against a strong multimodal reference diagnosis. • In our study, the CNN performance (area under the receiver operating characteristics curve 0.74) was lower than that previously reported when validated against radiologists' diagnosis (0.99 in a recent meta-analysis). • The CNN performance was significantly higher than emergency physicians' (p ≤ 0.022) and comparable to that of board-certified radiologists (p ≥ 0.269).",True,other,Not specified
38296982,Incorporating longitudinal history of risk factors into atherosclerotic cardiovascular disease risk prediction using deep learning,"It is increasingly clear that longitudinal risk factor levels and trajectories are related to risk for atherosclerotic cardiovascular disease (ASCVD) above and beyond single measures. Currently used in clinical care, the Pooled Cohort Equations (PCE) are based on regression methods that predict ASCVD risk based on cross-sectional risk factor levels. Deep learning (DL) models have been developed to incorporate longitudinal data for risk prediction but its benefit for ASCVD risk prediction relative to the traditional Pooled Cohort Equations (PCE) remain unknown. Our study included 15,565 participants from four cardiovascular disease cohorts free of baseline ASCVD who were followed for adjudicated ASCVD. Ten-year ASCVD risk was calculated in the training set using our benchmark, the PCE, and a longitudinal DL model, Dynamic-DeepHit. Predictors included those incorporated in the PCE: sex, race, age, total cholesterol, high density lipid cholesterol, systolic and diastolic blood pressure, diabetes, hypertension treatment and smoking. The discrimination and calibration performance of the two models were evaluated in an overall hold-out testing dataset. Of the 15,565 participants in our dataset, 2170 (13.9%) developed ASCVD. The performance of the longitudinal DL model that incorporated 8 years of longitudinal risk factor data improved upon that of the PCE [AUROC: 0.815 (CI 0.782-0.844) vs 0.792 (CI 0.760-0.825)] and the net reclassification index was 0.385. The brier score for the DL model was 0.0514 compared with 0.0542 in the PCE. Incorporating longitudinal risk factors in ASCVD risk prediction using DL can improve model discrimination and calibration.",True,other,Not specified
38295474,DeBERTa-BiLSTM: A multi-label classification model of Arabic medical questions using pre-trained models and deep learning,"It is wise to investigate past and present epidemics in the hopes of profiting from them and being better prepared for future ones. COVID-19 is one of the most recent and well-known pandemics; its effects are still felt today. Most or nearly all governments have announced various measures to combat the virus, making it challenging to keep people aware of the most up-to-date and relevant information. As a result, many websites have created and maintained Frequently Asked Questions (FAQs) regarding the pandemic. People naturally tend to ask about multiple points in one question, leading to multi-label questions. Multi-label questions classification is one of Natural Language Processing's (NLP) most common and complicated tasks. One of classification's most significant contributions to advancing medical care and facilities is the development of automated question-and-answer systems. These systems can improve the efficiency of healthcare by reducing the burden on healthcare professionals and providing patients with timely and reliable answers to their questions. Due to the Arabic language's intricate morphology and structure, such a task becomes more challenging when dealing with Arabic text. This study aims to build a multi-label classification model for Arabic medical questions. The investigation of pre-trained neural models significantly improved NLP performance. Recently, pre-trained models have been used in multi-label classification. This study proposes a deep learning model for classifying Arabic multi-label COVID-19 questions by combining the strengths of DeBERTa (Decoding-enhanced BERT with Disentangled Attention) and BiLSTM (Bidirectional Long Short-Term Memory) networks. Deep learning methods are prevalent because they generate dense feature representations automatically and implicitly capture hidden relationships. The DeBERTa model is fine-tuned to generate the representation of word vectors. The BiLSTM model is fed word vectors to extract and represent features deeply. The proposed multi-label classification model categorizes questions into one or more available ten categories. The deep learning model is evaluated using hamming loss, micro-precision, micro-recall, micro-F1, subset accuracy, AUC, and Jaccard index. It showed an effective classification for Arabic questions with encouraging performance. The proposed model achieved values of 0.042 for hamming loss, 0.84 for micro-precision, micro-recall, and micro-F1, 0.71 for subset accuracy, 0.89 for AUC, and 0.72 for Jaccard index. Therefore, this paves the way for adopting an automated multi-label classification model for medical questions in health facilities. Which can help telehealth medical providers present more reliable and effective consultations.",True,both,Not specified
38287342,Development and prognostic validation of a three-level NHG-like deep learning-based model for histological grading of breast cancer,"BACKGROUND: Histological grade is a well-known prognostic factor that is routinely assessed in breast tumours. However, manual assessment of Nottingham Histological Grade (NHG) has high inter-assessor and inter-laboratory variability, causing uncertainty in grade assignments. To address this challenge, we developed and validated a three-level NHG-like deep learning-based histological grade model (predGrade). The primary performance evaluation focuses on prognostic performance.
METHODS: This observational study is based on two patient cohorts (SöS-BC-4, N = 2421 (training and internal test); SCAN-B-Lund, N = 1262 (test)) that include routine histological whole-slide images (WSIs) together with patient outcomes. A deep convolutional neural network (CNN) model with an attention mechanism was optimised for the classification of the three-level histological grading (NHG) from haematoxylin and eosin-stained WSIs. The prognostic performance was evaluated by time-to-event analysis of recurrence-free survival and compared to clinical NHG grade assignments in the internal test set as well as in the fully independent external test cohort.
RESULTS: We observed effect sizes (hazard ratio) for grade 3 versus 1, for the conventional NHG method (HR = 2.60 (1.18-5.70 95%CI, p-value = 0.017)) and the deep learning model (HR = 2.27, 95%CI 1.07-4.82, p-value = 0.033) on the internal test set after adjusting for established clinicopathological risk factors. In the external test set, the unadjusted HR for clinical NHG 2 versus 1 was estimated to be 2.59 (p-value = 0.004) and clinical NHG 3 versus 1 was estimated to be 3.58 (p-value < 0.001). For predGrade, the unadjusted HR for predGrade 2 versus 1 HR = 2.52 (p-value = 0.030), and 4.07 (p-value = 0.001) for preGrade 3 versus 1 was observed in the independent external test set. In multivariable analysis, HR estimates for neither clinical NHG nor predGrade were found to be significant (p-value > 0.05). We tested for differences in HR estimates between NHG and predGrade in the independent test set and found no significant difference between the two classification models (p-value > 0.05), confirming similar prognostic performance between conventional NHG and predGrade.
CONCLUSION: Routine histopathology assessment of NHG has a high degree of inter-assessor variability, motivating the development of model-based decision support to improve reproducibility in histological grading. We found that the proposed model (predGrade) provides a similar prognostic performance as clinical NHG. The results indicate that deep CNN-based models can be applied for breast cancer histological grading.",True,other,Not specified
38287149,Survival prediction of glioblastoma patients using modern deep learning and machine learning techniques,"In this study, we utilized data from the Surveillance, Epidemiology, and End Results (SEER) database to predict the glioblastoma patients' survival outcomes. To assess dataset skewness and detect feature importance, we applied Pearson's second coefficient test of skewness and the Ordinary Least Squares method, respectively. Using two sampling strategies, holdout and five-fold cross-validation, we developed five machine learning (ML) models alongside a feed-forward deep neural network (DNN) for the multiclass classification and regression prediction of glioblastoma patient survival. After balancing the classification and regression datasets, we obtained 46,340 and 28,573 samples, respectively. Shapley additive explanations (SHAP) were then used to explain the decision-making process of the best model. In both classification and regression tasks, as well as across holdout and cross-validation sampling strategies, the DNN consistently outperformed the ML models. Notably, the accuracy were 90.25% and 90.22% for holdout and five-fold cross-validation, respectively, while the corresponding R2 values were 0.6565 and 0.6622. SHAP analysis revealed the importance of age at diagnosis as the most influential feature in the DNN's survival predictions. These findings suggest that the DNN holds promise as a practical auxiliary tool for clinicians, aiding them in optimal decision-making concerning the treatment and care trajectories for glioblastoma patients.",True,other,recurrent neural network
38287144,Generative deep learning furthers the understanding of local distributions of fat and muscle on body shape and health using 3D surface scans,"BACKGROUND: Body shape, an intuitive health indicator, is deterministically driven by body composition. We developed and validated a deep learning model that generates accurate dual-energy X-ray absorptiometry (DXA) scans from three-dimensional optical body scans (3DO), enabling compositional analysis of the whole body and specified subregions. Previous works on generative medical imaging models lack quantitative validation and only report quality metrics.
METHODS: Our model was self-supervised pretrained on two large clinical DXA datasets and fine-tuned using the Shape Up! Adults study dataset. Model-predicted scans from a holdout test set were evaluated using clinical commercial DXA software for compositional accuracy.
RESULTS: Predicted DXA scans achieve R2 of 0.73, 0.89, and 0.99 and RMSEs of 5.32, 6.56, and 4.15 kg for total fat mass (FM), fat-free mass (FFM), and total mass, respectively. Custom subregion analysis results in R2s of 0.70-0.89 for left and right thigh composition. We demonstrate the ability of models to produce quantitatively accurate visualizations of soft tissue and bone, confirming a strong relationship between body shape and composition.
CONCLUSIONS: This work highlights the potential of generative models in medical imaging and reinforces the importance of quantitative validation for assessing their clinical utility.",True,other,Not specified
38273847,Deep-learning models for image-based gynecological cancer diagnosis: a systematic review and meta- analysis,"INTRODUCTION: Gynecological cancers pose a significant threat to women worldwide, especially those in resource-limited settings. Human analysis of images remains the primary method of diagnosis, but it can be inconsistent and inaccurate. Deep learning (DL) can potentially enhance image-based diagnosis by providing objective and accurate results. This systematic review and meta-analysis aimed to summarize the recent advances of deep learning (DL) techniques for gynecological cancer diagnosis using various images and explore their future implications.
METHODS: The study followed the PRISMA-2 guidelines, and the protocol was registered in PROSPERO. Five databases were searched for articles published from January 2018 to December 2022. Articles that focused on five types of gynecological cancer and used DL for diagnosis were selected. Two reviewers assessed the articles for eligibility and quality using the QUADAS-2 tool. Data was extracted from each study, and the performance of DL techniques for gynecological cancer classification was estimated by pooling and transforming sensitivity and specificity values using a random-effects model.
RESULTS: The review included 48 studies, and the meta-analysis included 24 studies. The studies used different images and models to diagnose different gynecological cancers. The most popular models were ResNet, VGGNet, and UNet. DL algorithms showed more sensitivity but less specificity compared to machine learning (ML) methods. The AUC of the summary receiver operating characteristic plot was higher for DL algorithms than for ML methods. Of the 48 studies included, 41 were at low risk of bias.
CONCLUSION: This review highlights the potential of DL in improving the screening and diagnosis of gynecological cancer, particularly in resource-limited settings. However, the high heterogeneity and quality of the studies could affect the validity of the results. Further research is necessary to validate the findings of this study and to explore the potential of DL in improving gynecological cancer diagnosis.",True,other,Not specified
38265399,Current Development of Data Resources and Bioinformatics Tools for Anticoronavirus Peptide,"BACKGROUND: Since December 2019, the emergence of severe acute respiratory syndrome coronavirus 2, which gave rise to coronavirus disease 2019 (COVID-19), has considerably impacted global health. The identification of effective anticoronavirus peptides (ACVPs) and the establishment of robust data storage methods are critical in the fight against COVID-19. Traditional wet-lab peptide discovery approaches are timeconsuming and labor-intensive. With advancements in computer technology and bioinformatics, machine learning has gained prominence in the extraction of functional peptides from extensive datasets.
METHODS: In this study, we comprehensively review data resources and predictors related to ACVPs published over the past two decades. In addition, we analyze the influence of various factors on model performance.
RESULTS: We have reviewed nine ACVP-containing databases, which integrate detailed information on protein fragments effective against coronaviruses, providing crucial references for the development of antiviral drugs and vaccines. Additionally, we have assessed 15 peptide predictors for antiviral or specifically anticoronavirus activity. These predictors employ computational models to swiftly screen potential antiviral candidates, offering an efficient pathway for drug development.
CONCLUSION: Our study provides conclusive results and insights into the performance of different computational methods, and sheds light on the future trajectory of bioinformatics tools for ACVPs. This work offers a representative overview of contributions to the field, with an emphasis on the crucial role of ACVPs in combating COVID-19.",True,other,Not specified
38241853,A deep learning-based algorithm improves radiology residents' diagnoses of acute pulmonary embolism on CT pulmonary angiograms,"PURPOSE: To compare radiology residents' diagnostic performances to detect pulmonary emboli (PEs) on CT pulmonary angiographies (CTPAs) with deep-learning (DL)-based algorithm support and without.
METHODS: Fully anonymized CTPAs (n = 207) of patients suspected of having acute PE served as input for PE detection using a previously trained and validated DL-based algorithm. Three residents in their first three years of training, blinded to the index report and clinical history, read the CTPAs first without, and 2 months later with the help of artificial intelligence (AI) output, to diagnose PE as present, absent or indeterminate. We evaluated concordances and discordances with the consensus-reading results of two experts in chest imaging.
RESULTS: Because the AI algorithm failed to analyze 11 CTPAs, 196 CTPAs were analyzed; 31 (15.8 %) were PE-positive. Good-classification performance was higher for residents with AI-algorithm support than without (AUROCs: 0.958 [95 % CI: 0.921-0.979] vs. 0.894 [95 % CI: 0.850-0.931], p < 0.001, respectively). The main finding was the increased sensitivity of residents' diagnoses using the AI algorithm (92.5 % vs. 81.7 %, respectively). Concordance between residents (kappa: 0.77 [95 % CI: 0.76-0.78]; p < 0.001) improved with AI-algorithm use (kappa: 0.88 [95 % CI: 0.87-0.89]; p < 0.001).
CONCLUSION: The AI algorithm we used improved between-resident agreements to interpret CTPAs for suspected PE and, hence, their diagnostic performances.",True,other,RNN
38241392,PandoGen: Generating complete instances of future SARS-CoV-2 sequences using Deep Learning,"One of the challenges in a viral pandemic is the emergence of novel variants with different phenotypical characteristics. An ability to forecast future viral individuals at the sequence level enables advance preparation by characterizing the sequences and closing vulnerabilities in current preventative and therapeutic methods. In this article, we explore, in the context of a viral pandemic, the problem of generating complete instances of undiscovered viral protein sequences, which have a high likelihood of being discovered in the future using protein language models. Current approaches to training these models fit model parameters to a known sequence set, which does not suit pandemic forecasting as future sequences differ from known sequences in some respects. To address this, we develop a novel method, called PandoGen, to train protein language models towards the pandemic protein forecasting task. PandoGen combines techniques such as synthetic data generation, conditional sequence generation, and reward-based learning, enabling the model to forecast future sequences, with a high propensity to spread. Applying our method to modeling the SARS-CoV-2 Spike protein sequence, we find empirically that our model forecasts twice as many novel sequences with five times the case counts compared to a model that is 30× larger. Our method forecasts unseen lineages months in advance, whereas models 4× and 30× larger forecast almost no new lineages. When trained on data available up to a month before the onset of important Variants of Concern, our method consistently forecasts sequences belonging to those variants within tight sequence budgets.",True,other,Not specified
38240867,Ultrasound-based deep learning radiomics nomogram for risk stratification of testicular masses: a two-center study,"OBJECTIVE: To develop an ultrasound-driven clinical deep learning radiomics (CDLR) model for stratifying the risk of testicular masses, aiming to guide individualized treatment and minimize unnecessary procedures.
METHODS: We retrospectively analyzed 275 patients with confirmed testicular lesions (January 2018 to April 2023) from two hospitals, split into training (158 cases), validation (68 cases), and external test cohorts (49 cases). Radiomics and deep learning (DL) features were extracted from preoperative ultrasound images. Following feature selection, we utilized logistic regression (LR) to establish a deep learning radiomics (DLR) model and subsequently derived its signature. Clinical data underwent univariate and multivariate LR analyses, forming the ""clinic signature."" By integrating the DLR and clinic signatures using multivariable LR, we formulated the CDLR nomogram for testicular mass risk stratification. The model's efficacy was gauged using the area under the receiver operating characteristic curve (AUC), while its clinical utility was appraised with decision curve analysis(DCA). Additionally, we compared these models with two radiologists' assessments (5-8 years of practice).
RESULTS: The CDLR nomogram showcased exceptional precision in distinguishing testicular tumors from non-tumorous lesions, registering AUCs of 0.909 (internal validation) and 0.835 (external validation). It also excelled in discerning malignant from benign testicular masses, posting AUCs of 0.851 (internal validation) and 0.834 (external validation). Notably, CDLR surpassed the clinical model, standalone DLR, and the evaluations of the two radiologists.
CONCLUSION: The CDLR nomogram offers a reliable tool for differentiating risks associated with testicular masses. It augments radiological diagnoses, facilitates personalized treatment approaches, and curtails unwarranted medical procedures.",True,other,Not specified
38227569,Deep learning to estimate impaired glucose metabolism from Magnetic Resonance Imaging of the liver: An opportunistic population screening approach,"AIM: Diabetes is a global health challenge, and many individuals are undiagnosed and not aware of their increased risk of morbidity/mortality although dedicated tests are available, which indicates the need for novel population-wide screening approaches. Here, we developed a deep learning pipeline for opportunistic screening of impaired glucose metabolism using routine magnetic resonance imaging (MRI) of the liver and tested its prognostic value in a general population setting.
METHODS: In this retrospective study a fully automatic deep learning pipeline was developed to quantify liver shape features on routine MR imaging using data from a prospective population study. Subsequently, the association between liver shape features and impaired glucose metabolism was investigated in individuals with prediabetes, type 2 diabetes and healthy controls without prior cardiovascular diseases. K-medoids clustering (3 clusters) with a dissimilarity matrix based on Euclidean distance and ordinal regression was used to assess the association between liver shape features and glycaemic status.
RESULTS: The deep learning pipeline showed a high performance for liver shape analysis with a mean Dice score of 97.0±0.01. Out of 339 included individuals (mean age 56.3±9.1 years; males 58.1%), 79 (23.3%) and 46 (13.6%) were classified as having prediabetes and type 2 diabetes, respectively. Individuals in the high risk cluster using all liver shape features (n = 14) had a 2.4 fold increased risk of impaired glucose metabolism after adjustment for cardiometabolic risk factors (age, sex, BMI, total cholesterol, alcohol consumption, hypertension, smoking and hepatic steatosis; OR 2.44 [95% CI 1.12-5.38]; p = 0.03). Based on individual shape features, the strongest association was found between liver volume and impaired glucose metabolism after adjustment for the same risk factors (OR 1.97 [1.38-2.85]; p<0.001).
CONCLUSIONS: Deep learning can estimate impaired glucose metabolism on routine liver MRI independent of cardiometabolic risk factors and hepatic steatosis.",True,other,Not specified
38226168,Deep learning enhanced the diagnostic merit of serum glycome for multiple cancers,"Protein glycosylation is associated with the pathogenesis of various cancers. The utilization of certain glycans in cancer diagnosis models holds promise, yet their accuracy is not always guaranteed. Here, we investigated the utility of deep learning techniques, specifically random forests combined with transfer learning, in enhancing serum glycome's discriminative power for cancer diagnosis (including ovarian cancer, non-small cell lung cancer, gastric cancer, and esophageal cancer). We started with ovarian cancer and demonstrated that transfer learning can achieve superior performance in data-disadvantaged cohorts (AUROC >0.9), outperforming the approach of PLS-DA. We identified a serum glycan-biomarker panel including 18 serum N-glycans and 4 glycan derived traits, most of which were featured with sialylation. Furthermore, we validated advantage of the transfer learning scheme across other cancer groups. These findings highlighted the superiority of transfer learning in improving the performance of glycans-based cancer diagnosis model and identifying cancer biomarkers, providing a new high-fidelity cancer diagnosis venue.",True,other,Not specified
38207093,Deep Learning Classification of Usual Interstitial Pneumonia Predicts Outcomes,"Rationale: Computed tomography (CT) enables noninvasive diagnosis of usual interstitial pneumonia (UIP), but enhanced image analyses are needed to overcome the limitations of visual assessment. Objectives: Apply multiple instance learning (MIL) to develop an explainable deep learning algorithm for prediction of UIP from CT and validate its performance in independent cohorts. Methods: We trained an MIL algorithm using a pooled dataset (n = 2,143) and tested it in three independent populations: data from a prior publication (n = 127), a single-institution clinical cohort (n = 239), and a national registry of patients with pulmonary fibrosis (n = 979). We tested UIP classification performance using receiver operating characteristic analysis, with histologic UIP as ground truth. Cox proportional hazards and linear mixed-effects models were used to examine associations between MIL predictions and survival or longitudinal FVC. Measurements and Main Results: In two cohorts with biopsy data, MIL improved accuracy for histologic UIP (area under the curve, 0.77 [n = 127] and 0.79 [n = 239]) compared with visual assessment (area under the curve, 0.65 and 0.71). In cohorts with survival data, MIL-UIP classifications were significant for mortality (n = 239, mortality to April 2021: unadjusted hazard ratio, 3.1; 95% confidence interval [CI], 1.96-4.91; P &lt; 0.001; and n = 979, mortality to July 2022: unadjusted hazard ratio, 3.64; 95% CI, 2.66-4.97; P &lt; 0.001). Individuals classified as UIP positive by the algorithm had a significantly greater annual decline in FVC than those classified as UIP negative (-88 ml/yr vs. -45 ml/yr; n = 979; P &lt; 0.01), adjusting for extent of lung fibrosis. Conclusions: Computerized assessment using MIL identifies clinically significant features of UIP on CT. Such a method could improve confidence in radiologic assessment of patients with interstitial lung disease, potentially enabling earlier and more precise diagnosis.",True,other,Not specified
38189575,Deep Learning and Likelihood Approaches for Viral Phylogeography Converge on the Same Answers Whether the Inference Model Is Right or Wrong,"Analysis of phylogenetic trees has become an essential tool in epidemiology. Likelihood-based methods fit models to phylogenies to draw inferences about the phylodynamics and history of viral transmission. However, these methods are often computationally expensive, which limits the complexity and realism of phylodynamic models and makes them ill-suited for informing policy decisions in real-time during rapidly developing outbreaks. Likelihood-free methods using deep learning are pushing the boundaries of inference beyond these constraints. In this paper, we extend, compare, and contrast a recently developed deep learning method for likelihood-free inference from trees. We trained multiple deep neural networks using phylogenies from simulated outbreaks that spread among 5 locations and found they achieve close to the same levels of accuracy as Bayesian inference under the true simulation model. We compared robustness to model misspecification of a trained neural network to that of a Bayesian method. We found that both models had comparable performance, converging on similar biases. We also implemented a method of uncertainty quantification called conformalized quantile regression that we demonstrate has similar patterns of sensitivity to model misspecification as Bayesian highest posterior density (HPD) and greatly overlap with HPDs, but have lower precision (more conservative). Finally, we trained and tested a neural network against phylogeographic data from a recent study of the SARS-Cov-2 pandemic in Europe and obtained similar estimates of region-specific epidemiological parameters and the location of the common ancestor in Europe. Along with being as accurate and robust as likelihood-based methods, our trained neural networks are on average over 3 orders of magnitude faster after training. Our results support the notion that neural networks can be trained with simulated data to accurately mimic the good and bad statistical properties of the likelihood functions of generative phylogenetic models.",True,text mining,Not specified
38182734,Autosurv: interpretable deep learning framework for cancer survival analysis incorporating clinical and multi-omics data,"Accurate prognosis for cancer patients can provide critical information for optimizing treatment plans and improving life quality. Combining omics data and demographic/clinical information can offer a more comprehensive view of cancer prognosis than using omics or clinical data alone and can also reveal the underlying disease mechanisms at the molecular level. In this study, we developed and validated a deep learning framework to extract information from high-dimensional gene expression and miRNA expression data and conduct prognosis prediction for breast cancer and ovarian-cancer patients using multiple independent multi-omics datasets. Our model achieved significantly better prognosis prediction than the current machine learning and deep learning approaches in various settings. Moreover, an interpretation method was applied to tackle the ""black-box"" nature of deep neural networks and we identified features (i.e., genes, miRNA, demographic/clinical variables) that were important to distinguish predicted high- and low-risk patients. The significance of the identified features was partially supported by previous studies.",True,other,Not specified
38162619,Predicting COVID-19 pandemic waves including vaccination data with deep learning,"INTRODUCTION: During the recent COVID-19 pandemics, many models were developed to predict the number of new infections. After almost a year, models had also the challenge to include information about the waning effect of vaccines and by infection, and also how this effect start to disappear.
METHODS: We present a deep learning-based approach to predict the number of daily COVID-19 cases in 30 countries, considering the non-pharmaceutical interventions (NPIs) applied in those countries and including vaccination data of the most used vaccines.
RESULTS: We empirically validate the proposed approach for 4 months between January and April 2021, once vaccination was available and applied to the population and the COVID-19 variants were closer to the one considered for developing the vaccines. With the predictions of new cases, we can prescribe NPIs plans that present the best trade-off between the expected number of COVID-19 cases and the social and economic cost of applying such interventions.
DISCUSSION: Whereas, mathematical models which include the effect of vaccines in the spread of the SARS-COV-2 pandemic are available, to the best of our knowledge we are the first to propose a data driven method based on recurrent neural networks that considers the waning effect of the immunization acquired either by vaccine administration or by recovering from the illness. This work contributes with an accurate, scalable, data-driven approach to modeling the pandemic curves of cases when vaccination data is available.",True,other,Not specified
38162122,Efficient semi-supervised semantic segmentation of electron microscopy cancer images with sparse annotations,"Electron microscopy (EM) enables imaging at a resolution of nanometers and can shed light on how cancer evolves to develop resistance to therapy. Acquiring these images has become a routine task.However, analyzing them is now a bottleneck, as manual structure identification is very time-consuming and can take up to several months for a single sample. Deep learning approaches offer a suitable solution to speed up the analysis. In this work, we present a study of several state-of-the-art deep learning models for the task of segmenting nuclei and nucleoli in volumes from tumor biopsies. We compared previous results obtained with the ResUNet architecture to the more recent UNet++, FracTALResNet, SenFormer, and CEECNet models. In addition, we explored the utilization of unlabeled images through semi-supervised learning with Cross Pseudo Supervision. We have trained and evaluated all of the models on sparse manual labels from three fully annotated in-house datasets that we have made available on demand, demonstrating improvements in terms of 3D Dice score. From the analysis of these results, we drew conclusions on the relative gains of using more complex models, and semi-supervised learning as well as the next steps for the mitigation of the manual segmentation bottleneck.",True,other,Not specified
38155182,Utilizing a novel high-resolution malaria dataset for climate-informed predictions with a deep learning transformer model,"Climatic factors influence malaria transmission via the effect on the Anopheles vector and Plasmodium parasite. Modelling and understanding the complex effects that climate has on malaria incidence can enable important early warning capabilities. Deep learning applications across fields are proving valuable, however the field of epidemiological forecasting is still in its infancy with a lack of applied deep learning studies for malaria in southern Africa which leverage quality datasets. Using a novel high resolution malaria incidence dataset containing 23 years of daily data from 1998 to 2021, a statistical model and XGBOOST machine learning model were compared to a deep learning Transformer model by assessing the accuracy of their numerical predictions. A novel loss function, used to account for the variable nature of the data yielded performance around + 20% compared to the standard MSE loss. When numerical predictions were converted to alert thresholds to mimic use in a real-world setting, the Transformer's performance of 80% according to AUROC was 20-40% higher than the statistical and XGBOOST models and it had the highest overall accuracy of 98%. The Transformer performed consistently with increased accuracy as more climate variables were used, indicating further potential for this prediction framework to predict malaria incidence at a daily level using climate data for southern Africa.",True,other,Not specified
38124558,Research hotspots and trends of artificial intelligence in rheumatoid arthritis: A bibliometric and visualized study,"Artificial intelligence (AI) applications on rheumatoid arthritis (RA) are becoming increasingly popular. In this bibliometric study, we aimed to analyze the characteristics of publications relevant to the research of AI in RA, thereby developing a thorough overview of this research topic. Web of Science was used to retrieve publications on the application of AI in RA from 2003 to 2022. Bibliometric analysis and visualization were performed using Microsoft Excel (2019), R software (4.2.2) and VOSviewer (1.6.18). The overall distribution of yearly outputs, leading countries, top institutions and authors, active journals, co-cited references and keywords were analyzed. A total of 859 relevant articles were identified in the Web of Science with an increasing trend. USA and China were the leading countries in this field, accounting for 71.59% of publications in total. Harvard University was the most influential institution. Arthritis Research & Therapy was the most active journal. Primary topics in this field focused on estimating the risk of developing RA, diagnosing RA using sensor, clinical, imaging and omics data, identifying the phenotype of RA patients using electronic health records, predicting treatment response, tracking the progression of the disease and predicting prognosis and developing new drugs. Machine learning and deep learning algorithms were the recent research hotspots and trends in this field. AI has potential applications in various fields of RA, including the risk assessment, screening, early diagnosis, monitoring, prognosis determination, achieving optimal therapeutic outcomes and new drug development for RA patients. Incorporating machine learning and deep learning algorithms into real-world clinical practice will be a future research hotspot and trend for AI in RA. Extensive collaboration to improve model maturity and robustness will be a critical step in the advancement of AI in healthcare.",True,both,Not specified
38112764,Deep learning-based prognostication in idiopathic pulmonary fibrosis using chest radiographs,"OBJECTIVES: To develop and validate a deep learning-based prognostic model in patients with idiopathic pulmonary fibrosis (IPF) using chest radiographs.
METHODS: To develop a deep learning-based prognostic model using chest radiographs (DLPM), the patients diagnosed with IPF during 2011-2021 were retrospectively collected and were divided into training (n = 1007), validation (n = 117), and internal test (n = 187) datasets. Up to 10 consecutive radiographs were included for each patient. For external testing, three cohorts from independent institutions were collected (n = 152, 141, and 207). The discrimination performance of DLPM was evaluated using areas under the time-dependent receiver operating characteristic curves (TD-AUCs) for 3-year survival and compared with that of forced vital capacity (FVC). Multivariable Cox regression was performed to investigate whether the DLPM was an independent prognostic factor from FVC. We devised a modified gender-age-physiology (GAP) index (GAP-CR), by replacing D<sub>LCO</sub> with DLPM.
RESULTS: DLPM showed similar-to-higher performance at predicting 3-year survival than FVC in three external test cohorts (TD-AUC: 0.83 [95% CI: 0.76-0.90] vs. 0.68 [0.59-0.77], p < 0.001; 0.76 [0.68-0.85] vs. 0.70 [0.60-0.80], p = 0.21; 0.79 [0.72-0.86] vs. 0.76 [0.69-0.83], p = 0.41). DLPM worked as an independent prognostic factor from FVC in all three cohorts (ps < 0.001). The GAP-CR index showed a higher 3-year TD-AUC than the original GAP index in two of the three external test cohorts (TD-AUC: 0.85 [0.80-0.91] vs. 0.79 [0.72-0.86], p = 0.02; 0.72 [0.64-0.80] vs. 0.69 [0.61-0.78], p = 0.56; 0.76 [0.69-0.83] vs. 0.68 [0.60-0.76], p = 0.01).
CONCLUSIONS: A deep learning model successfully predicted survival in patients with IPF from chest radiographs, comparable to and independent of FVC.
CLINICAL RELEVANCE STATEMENT: Deep learning-based prognostication from chest radiographs offers comparable-to-higher prognostic performance than forced vital capacity.
KEY POINTS: • A deep learning-based prognostic model for idiopathic pulmonary fibrosis was developed using 6063 radiographs. • The prognostic performance of the model was comparable-to-higher than forced vital capacity, and was independent from FVC in all three external test cohorts. • A modified gender-age-physiology index replacing diffusing capacity for carbon monoxide with the deep learning model showed higher performance than the original index in two external test cohorts.",True,text mining,RNN
38101690,Deep learning uncertainty quantification for clinical text classification,"INTRODUCTION: Machine learning algorithms are expected to work side-by-side with humans in decision-making pipelines. Thus, the ability of classifiers to make reliable decisions is of paramount importance. Deep neural networks (DNNs) represent the state-of-the-art models to address real-world classification. Although the strength of activation in DNNs is often correlated with the network's confidence, in-depth analyses are needed to establish whether they are well calibrated.
METHOD: In this paper, we demonstrate the use of DNN-based classification tools to benefit cancer registries by automating information extraction of disease at diagnosis and at surgery from electronic text pathology reports from the US National Cancer Institute (NCI) Surveillance, Epidemiology, and End Results (SEER) population-based cancer registries. In particular, we introduce multiple methods for selective classification to achieve a target level of accuracy on multiple classification tasks while minimizing the rejection amount-that is, the number of electronic pathology reports for which the model's predictions are unreliable. We evaluate the proposed methods by comparing our approach with the current in-house deep learning-based abstaining classifier.
RESULTS: Overall, all the proposed selective classification methods effectively allow for achieving the targeted level of accuracy or higher in a trade-off analysis aimed to minimize the rejection rate. On in-distribution validation and holdout test data, with all the proposed methods, we achieve on all tasks the required target level of accuracy with a lower rejection rate than the deep abstaining classifier (DAC). Interpreting the results for the out-of-distribution test data is more complex; nevertheless, in this case as well, the rejection rate from the best among the proposed methods achieving 97% accuracy or higher is lower than the rejection rate based on the DAC.
CONCLUSIONS: We show that although both approaches can flag those samples that should be manually reviewed and labeled by human annotators, the newly proposed methods retain a larger fraction and do so without retraining-thus offering a reduced computational cost compared with the in-house deep learning-based abstaining classifier.",True,other,convolutional neural network
38093373,Deep learning prediction of hospital readmissions for asthma and COPD,"QUESTION: Severe asthma and COPD exacerbations requiring hospitalization are linked to increased disease morbidity and healthcare costs. We sought to identify Electronic Health Record (EHR) features of severe asthma and COPD exacerbations and evaluate the performance of four machine learning (ML) and one deep learning (DL) model in predicting readmissions using EHR data.
STUDY DESIGN AND METHODS: Observational study between September 30, 2012, and December 31, 2017, of patients hospitalized with asthma and COPD exacerbations.
RESULTS: This study included 5,794 patients, 1,893 with asthma and 3,901 with COPD. Patients with asthma were predominantly female (n = 1288 [68%]), 35% were Black (n = 669), and 25% (n = 479) were Hispanic. Black (44 vs. 33%, p = 0.01) and Hispanic patients (30 vs. 24%, p = 0.02) were more likely to be readmitted for asthma. Similarly, patients with COPD readmissions included a large percentage of Blacks (18 vs. 10%, p < 0.01) and Hispanics (8 vs. 5%, p < 0.01). To identify patients at high risk of readmission index hospitalization data of a subset of 2,682 patients, 777 with asthma and 1,905 with COPD, was analyzed with four ML models, and one DL model. We found that multilayer perceptron, the DL method, had the best sensitivity and specificity compared to the four ML methods implemented in the same dataset.
INTERPRETATION: Multilayer perceptron, a deep learning method, had the best performance in predicting asthma and COPD readmissions, demonstrating that EHR and deep learning integration can improve high-risk patient detection.",True,other,Not specified
38079169,Risk Stratification for Diabetic Retinopathy Screening Order Using Deep Learning: A Multicenter Prospective Study,"PURPOSE: Real-world evaluation of a deep learning model that prioritizes patients based on risk of progression to moderate or worse (MOD+) diabetic retinopathy (DR).
METHODS: This nonrandomized, single-arm, prospective, interventional study included patients attending DR screening at four centers across Thailand from September 2019 to January 2020, with mild or no DR. Fundus photographs were input into the model, and patients were scheduled for their subsequent screening from September 2020 to January 2021 in order of predicted risk. Evaluation focused on model sensitivity, defined as correctly ranking patients that developed MOD+ within the first 50% of subsequent screens.
RESULTS: We analyzed 1,757 patients, of which 52 (3.0%) developed MOD+. Using the model-proposed order, the model's sensitivity was 90.4%. Both the model-proposed order and mild/no DR plus HbA1c had significantly higher sensitivity than the random order (P < 0.001). Excluding one major (rural) site that had practical implementation challenges, the remaining sites included 567 patients and 15 (2.6%) developed MOD+. Here, the model-proposed order achieved 86.7% versus 73.3% for the ranking that used DR grade and hemoglobin A1c.
CONCLUSIONS: The model can help prioritize follow-up visits for the largest subgroups of DR patients (those with no or mild DR). Further research is needed to evaluate the impact on clinical management and outcomes.
TRANSLATIONAL RELEVANCE: Deep learning demonstrated potential for risk stratification in DR screening. However, real-world practicalities must be resolved to fully realize the benefit.",True,both,Not specified
38042608,A comprehensive review on federated learning based models for healthcare applications,"A disease is an abnormal condition that negatively impacts the functioning of the human body. Pathology determines the causes behind the disease and identifies its development mechanism and functional consequences. Each disease has different identification methods, including X-ray scans for pneumonia, covid-19, and lung cancer, whereas biopsy and CT-scan can identify the presence of skin cancer and Alzheimer's disease, respectively. Early disease detection leads to effective treatment and avoids abiding complications. Deep learning has provided a vast number of applications in medical sectors resulting in accurate and reliable early disease predictions. These models are utilized in the healthcare industry to provide supplementary assistance to doctors in identifying the presence of diseases. Majorly, these models are trained through secondary data sources since healthcare institutions refrain from sharing patients' private data to ensure confidentiality, which limits the effectiveness of deep learning models due to the requirement of extensive datasets for training to achieve optimal results. Federated learning deals with the data in such a way that it doesn't exploit the privacy of a patient's data. In this work, a wide variety of disease detection models trained through federated learning have been rigorously reviewed. This meta-analysis provides an in-depth review of the federated learning architectures, federated learning types, hyperparameters, dataset utilization details, aggregation techniques, performance measures, and augmentation methods applied in the existing models during the development phase. The review also highlights various open challenges associated with the disease detection models trained through federated learning for future research.",True,other,Not specified
38041105,Prediction of the number of asthma patients using environmental factors based on deep learning algorithms,"BACKGROUND: Air pollution, weather, pollen, and influenza are typical aggravating factors for asthma. Previous studies have identified risk factors using regression-based and ensemble models. However, studies that consider complex relationships and interactions among these factors have yet to be conducted. Although deep learning algorithms can address this problem, further research on modeling and interpreting the results is warranted.
METHODS: In this study, from 2015 to 2019, information about air pollutants, weather conditions, pollen, and influenza were utilized to predict the number of emergency room patients and outpatients with asthma using recurrent neural network, long short-term memory (LSTM), and gated recurrent unit models. The relative importance of the environmental factors in asthma exacerbation was quantified through a feature importance analysis.
RESULTS: We found that LSTM was the best algorithm for modeling patients with asthma. Our results demonstrated that influenza, temperature, PM<sub>10</sub>, NO<sub>2,</sub> CO, and pollen had a significant impact on asthma exacerbation. In addition, the week of the year and the number of holidays per week were an important factor to model the seasonality of the number of asthma patients and the effect of holiday clinic closures, respectively.
CONCLUSION: LSTM is an excellent algorithm for modeling complex epidemiological relationships, encompassing nonlinearity, lagged responses, and interactions. Our study findings can guide policymakers in their efforts to understand the environmental factors of asthma exacerbation.",True,other,Not specified
38041071,HostNet: improved sequence representation in deep neural networks for virus-host prediction,"BACKGROUND: The escalation of viruses over the past decade has highlighted the need to determine their respective hosts, particularly for emerging ones that pose a potential menace to the welfare of both human and animal life. Yet, the traditional means of ascertaining the host range of viruses, which involves field surveillance and laboratory experiments, is a laborious and demanding undertaking. A computational tool with the capability to reliably predict host ranges for novel viruses can provide timely responses in the prevention and control of emerging infectious diseases. The intricate nature of viral-host prediction involves issues such as data imbalance and deficiency. Therefore, developing highly accurate computational tools capable of predicting virus-host associations is a challenging and pressing demand.
RESULTS: To overcome the challenges of virus-host prediction, we present HostNet, a deep learning framework that utilizes a Transformer-CNN-BiGRU architecture and two enhanced sequence representation modules. The first module, k-mer to vector, pre-trains a background vector representation of k-mers from a broad range of virus sequences to address the issue of data deficiency. The second module, an adaptive sliding window, truncates virus sequences of various lengths to create a uniform number of informative and distinct samples for each sequence to address the issue of data imbalance. We assess HostNet's performance on a benchmark dataset of ""Rabies lyssavirus"" and an in-house dataset of ""Flavivirus"". Our results show that HostNet surpasses the state-of-the-art deep learning-based method in host-prediction accuracies and F1 score. The enhanced sequence representation modules, significantly improve HostNet's training generalization, performance in challenging classes, and stability.
CONCLUSION: HostNet is a promising framework for predicting virus hosts from genomic sequences, addressing challenges posed by sparse and varying-length virus sequence data. Our results demonstrate its potential as a valuable tool for virus-host prediction in various biological contexts. Virus-host prediction based on genomic sequences using deep neural networks is a promising approach to identifying their potential hosts accurately and efficiently, with significant impacts on public health, disease prevention, and vaccine development.",True,other,Not specified
38034402,SIGANEO: Similarity network with GAN enhancement for immunogenic neoepitope prediction,"Target selection of the personalized cancer neoantigen vaccine, which is highly dependent on computational prediction algorithms, is crucial for its clinical efficacy. Due to the limited number of experimentally validated immunogenic neoepitopes as well as the complexity of neoantigens in eliciting T cell response, the accuracy of neoepitope immunogenicity prediction methods requires persistent efforts for improvement. We present a deep learning framework for neoepitope immunogenicity prediction - SIGANEO by integrating GAN-like network with similarity network to address issues of missing values and limited data concerning neoantigen prediction. This framework exhibits superior performance over competing machine-learning-based neoantigen prediction algorithms over an independent test dataset from TESLA consortium. Particularly for the clinical setting of neoantigen vaccine where only the top 10 and 20 predictions are selected for vaccine production, SIGANEO achieves significantly better accuracy for predicting experimentally validated neoepitopes. Our work demonstrates that deep learning techniques can greatly boost the accuracy of target identification for cancer neoantigen vaccine.",True,other,Not specified
38032977,Examination of alternative eGFR definitions on the performance of deep learning models for detection of chronic kidney disease from fundus photographs,"Deep learning (DL) models have shown promise in detecting chronic kidney disease (CKD) from fundus photographs. However, previous studies have utilized a serum creatinine-only estimated glomerular rate (eGFR) equation to measure kidney function despite the development of more up-to-date methods. In this study, we developed two sets of DL models using fundus images from the UK Biobank to ascertain the effects of using a creatinine and cystatin-C eGFR equation over the baseline creatinine-only eGFR equation on fundus image-based DL CKD predictors. Our results show that a creatinine and cystatin-C eGFR significantly improved classification performance over the baseline creatinine-only eGFR when the models were evaluated conventionally. However, these differences were no longer significant when the models were assessed on clinical labels based on ICD10. Furthermore, we also observed variations in model performance and systemic condition incidence between our study and the ones conducted previously. We hypothesize that limitations in existing eGFR equations and the paucity of retinal features uniquely indicative of CKD may contribute to these inconsistencies. These findings emphasize the need for developing more transparent models to facilitate a better understanding of the mechanisms underpinning the ability of DL models to detect CKD from fundus images.",True,other,Not specified
38030951,Deep-learning-based survival prediction of patients with lower limb melanoma,"BACKGROUND: For the purpose to examine lower limb melanoma (LLM) and its long-term survival rate, we used data from the Surveillance, Epidemiology and End Results (SEER) database. To estimate the prognosis of LLM patients and assess its efficacy, we used a powerful deep learning and neural network approach called DeepSurv.
METHODS: We gathered data on those who had an LLM diagnosis between 2000 and 2019 from the SEER database. We divided the people into training and testing cohorts at a 7:3 ratio using a random selection technique. To assess the likelihood that LLM patients would survive, we compared the results of the DeepSurv model with those of the Cox proportional-hazards (CoxPH) model. Calibration curves, the time-dependent area under the receiver operating characteristic curve (AUC), and the concordance index (C-index) were all used to assess how accurate the predictions were.
RESULTS: In this study, a total of 26,243 LLM patients were enrolled, with 7873 serving as the testing cohort and 18,370 as the training cohort. Significant correlations with age, gender, AJCC stage, chemotherapy status, surgery status, regional lymph node removal and the survival outcomes of LLM patients were found by the CoxPH model. The CoxPH model's C-index was 0.766, which signifies a good degree of predicted accuracy. Additionally, we created the DeepSurv model using the training cohort data, which had a higher C-index of 0.852. In addition to calculating the 3-, 5-, and 8-year AUC values, the predictive performance of both models was evaluated. The equivalent AUC values for the CoxPH model were 0.795, 0.767, and 0.847, respectively. The DeepSurv model, in comparison, had better AUC values of 0.872, 0.858, and 0.847. In comparison to the CoxPH model, the DeepSurv model demonstrated greater prediction performance for LLM patients, as shown by the AUC values and the calibration curve.
CONCLUSION: We created the DeepSurv model using LLM patient data from the SEER database, which performed better than the CoxPH model in predicting the survival time of LLM patients.",True,other,Not specified
37996126,Performances of machine learning algorithms in discriminating sacroiliitis features on MRI: a systematic review,"OBJECTIVES: Summarise the evidence of the performance of the machine learning algorithm in discriminating sacroiliitis features on MRI and compare it with the accuracy of human physicians.
METHODS: MEDLINE, EMBASE, CIHNAL, Web of Science, IEEE, American College of Rheumatology and European Alliance of Associations for Rheumatology abstract archives were searched for studies published between 2008 and 4 June 2023. Two authors independently screened and extracted the variables, and the results are presented using tables and forest plots.
RESULTS: Ten studies were selected from 2381. Over half of the studies used deep learning models, using Assessment of Spondyloarthritis International Society sacroiliitis criteria as the ground truth, and manually extracted the regions of interest. All studies reported the area under the curve as a performance index, ranging from 0.76 to 0.99. Sensitivity and specificity were the second-most commonly reported indices, with sensitivity ranging from 0.56 to 1.00 and specificity ranging from 0.67 to 1.00; these results are comparable to a radiologist's sensitivity of 0.67-1.00 and specificity of 0.78-1.00 in the same cohort. More than half of the studies showed a high risk of bias in the analysis domain of quality appraisal owing to the small sample size or overfitting issues.
CONCLUSION: The performance of machine learning algorithms in discriminating sacroiliitis features on MRI varied owing to the high heterogeneity between studies and the small sample sizes, overfitting, and under-reporting issues of individual studies. Further well-designed and transparent studies are required.",True,other,recurrent neural network
37976312,"Deep learning framework for epidemiological forecasting: A study on COVID-19 cases and deaths in the Amazon state of Pará, Brazil","Modeling time series has been a particularly challenging aspect due to the need for constant adjustments in a rapidly changing environment, data uncertainty, dependencies between variables, volatile fluctuations, and the need to identify ideal hyperparameters. The present study presents a Framework capable of making projections from time series related to cases and deaths by COVID-19 in the Amazonian state of Pará, in Brazil. For the first time, deep learning models such as TCN, TRANSFORMER, TFT, N-BEATS, and N-HiTS were assessed for this purpose. The ARIMA statistical model was also used in post-processing for residual adjustment and short-term smoothing of the generated forecasts. The Framework generates probabilistic forecasts, with multivariate support, considering the following variables: daily cases per day of the first symptom, cases published daily, the occurrence of deaths, deaths published daily, and percentage of daily vaccination. The generated predictions are statistically evaluated by determining the best model for 7-day moving average projections using evaluating metrics such as MSE, RMSE, MAPE, sMAPE, r2, Coefficient of Variation, and residual analysis. As a result, the generated projections showed an average error of 5.4% for Cases Publication, 8.0% for Cases Symptoms, 11.12% for Deaths Publication, and 4.6% for Deaths Occurrence, with the N-HiTS and N-BEATS models obtaining better results. In general terms, the use of deep learning models to predict cases and deaths from COVID-19 has proven to be a valuable practice for analyzing the spread of the virus, which allows health managers to better understand and respond to this kind of pandemic outbreak.",True,other,recurrent neural network
37966063,Correlating Deep Learning-Based Automated Reference Kidney Histomorphometry with Patient Demographics and Creatinine,"KEY POINTS: The authors leverage the unique benefits of panoptic segmentation to perform the largest ever quantitation of reference kidney morphometry. Kidney features vary with age and sex; and glomeruli size may intricately link to creatinine, defying prior notions.
BACKGROUND: Reference histomorphometric data of healthy human kidneys are largely lacking because of laborious quantitation requirements. Correlating histomorphometric features with clinical parameters through machine learning approaches can provide valuable information about natural population variance. To this end, we leveraged deep learning (DL), computational image analysis, and feature analysis to associate the relationship of histomorphometry with patient age, sex, serum creatinine (SCr), and eGFR in a multinational set of reference kidney tissue sections.
METHODS: A panoptic segmentation neural network was developed and used to segment viable and sclerotic glomeruli, cortical and medullary interstitia, tubules, and arteries/arterioles in the digitized images of 79 periodic acid–Schiff-stained human nephrectomy sections showing minimal pathologic changes. Simple morphometrics (e.g., area, radius, density) were quantified from the segmented classes. Regression analysis aided in determining the association of histomorphometric parameters with age, sex, SCr, and eGFR.
RESULTS: Our DL model achieved high segmentation performance for all test compartments. The size and density of glomeruli, tubules, and arteries/arterioles varied significantly among healthy humans, with potentially large differences between geographically diverse patients. Glomerular size was significantly correlated with SCr and eGFR. Slight, albeit significant, differences in renal vasculature were observed between sexes. Glomerulosclerosis percentage increased, and cortical density of arteries/arterioles decreased, as a function of increasing age.
CONCLUSIONS: Using DL, we automated precise measurements of kidney histomorphometric features. In the reference kidney tissue, several histomorphometric features demonstrated significant correlation to patient demographics, SCr, and eGFR. DL tools can increase the efficiency and rigor of histomorphometric analysis.",True,other,Not specified
37964658,Prediction of multiclass surgical outcomes in glaucoma using multimodal deep learning based on free-text operative notes and structured EHR data,"OBJECTIVE: Surgical outcome prediction is challenging but necessary for postoperative management. Current machine learning models utilize pre- and post-op data, excluding intraoperative information in surgical notes. Current models also usually predict binary outcomes even when surgeries have multiple outcomes that require different postoperative management. This study addresses these gaps by incorporating intraoperative information into multimodal models for multiclass glaucoma surgery outcome prediction.
MATERIALS AND METHODS: We developed and evaluated multimodal deep learning models for multiclass glaucoma trabeculectomy surgery outcomes using both structured EHR data and free-text operative notes. We compare those to baseline models that use structured EHR data exclusively, or neural network models that leverage only operative notes.
RESULTS: The multimodal neural network had the highest performance with a macro AUROC of 0.750 and F1 score of 0.583. It outperformed the baseline machine learning model with structured EHR data alone (macro AUROC of 0.712 and F1 score of 0.486). Additionally, the multimodal model achieved the highest recall (0.692) for hypotony surgical failure, while the surgical success group had the highest precision (0.884) and F1 score (0.775).
DISCUSSION: This study shows that operative notes are an important source of predictive information. The multimodal predictive model combining perioperative notes and structured pre- and post-op EHR data outperformed other models. Multiclass surgical outcome prediction can provide valuable insights for clinical decision-making.
CONCLUSIONS: Our results show the potential of deep learning models to enhance clinical decision-making for postoperative management. They can be applied to other specialties to improve surgical outcome predictions.",True,other,Not specified
37961180,Efficient semi-supervised semantic segmentation of electron microscopy cancer images with sparse annotations,"Electron microscopy (EM) enables imaging at nanometer resolution and can shed light on how cancer evolves to develop resistance to therapy. Acquiring these images has become a routine task; however, analyzing them is now the bottleneck, as manual structure identification is very time-consuming and can take up to several months for a single sample. Deep learning approaches offer a suitable solution to speed up the analysis. In this work, we present a study of several state-of-the-art deep learning models for the task of segmenting nuclei and nucleoli in volumes from tumor biopsies. We compared previous results obtained with the ResUNet architecture to the more recent UNet++, FracTALResNet, SenFormer, and CEECNet models. In addition, we explored the utilization of unlabeled images through semi-supervised learning with Cross Pseudo Supervision. We have trained and evaluated all of the models on sparse manual labels from three fully annotated in-house datasets that we have made available on demand, demonstrating improvements in terms of 3D Dice score. From the analysis of these results, we drew conclusions on the relative gains of using more complex models, semi-supervised learning as well as next steps for the mitigation of the manual segmentation bottleneck.",True,other,Not specified
37961168,Forecasting dominance of SARS-CoV-2 lineages by anomaly detection using deep AutoEncoders,"The coronavirus disease of 2019 (COVID-19) pandemic is characterized by sequential emergence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) variants, lineages, and sublineages, outcompeting previously circulating ones because of, among other factors, increased transmissibility and immune escape. We propose DeepAutoCoV, an unsupervised deep learning anomaly detection system to predict future dominant lineages (FDLs). We define FDLs as viral (sub)lineages that will constitute more than 10% of all the viral sequences added to the GISAID database on a given week. DeepAutoCoV is trained and validated by assembling global and country-specific data sets from over 16 million Spike protein sequences sampled over a period of about 4 years. DeepAutoCoV successfully flags FDLs at very low frequencies (0.01% - 3%), with median lead times of 4-17 weeks, and predicts FDLs ~5 and ~25 times better than a baseline approach For example, the B.1.617.2 vaccine reference strain was flagged as FDL when its frequency was only 0.01%, more than a year before it was considered for an updated COVID-19 vaccine. Furthermore, DeepAutoCoV outputs interpretable results by pinpointing specific mutations potentially linked to increased fitness, and may provide significant insights for the optimization of public health pre-emptive intervention strategies.",True,other,Not specified
37948388,Predicting incident cardiovascular disease among African-American adults: A deep learning approach to evaluate social determinants of health in the Jackson heart study,"The present study sought to leverage machine learning approaches to determine whether social determinants of health improve prediction of incident cardiovascular disease (CVD). Participants in the Jackson Heart study with no history of CVD at baseline were followed over a 10-year period to determine first CVD events (i.e., coronary heart disease, stroke, heart failure). Three modeling algorithms (i.e., Deep Neural Network, Random Survival Forest, Penalized Cox Proportional Hazards) were used to evaluate three feature sets (i.e., demographics and standard/biobehavioral CVD risk factors [FS1], FS1 combined with psychosocial and socioeconomic CVD risk factors [FS2], and FS2 combined with environmental features [FS3]) as predictors of 10-year CVD risk. Contrary to hypothesis, overall predictive accuracy did not improve when adding social determinants of health. However, social determinants of health comprised eight of the top 15 predictors of first CVD events. The social determinates of health indicators included four socioeconomic factors (insurance status and types), one psychosocial factor (discrimination burden), and three environmental factors (density of outdoor physical activity resources, including instructional and water activities; modified retail food environment index excluding alcohol; and favorable food stores). Findings suggest that whereas understanding biological determinants may identify who is currently at risk for developing CVD and in need of secondary prevention, understanding upstream social determinants of CVD risk could guide primary prevention efforts by identifying where and how policy and community-level interventions could be targeted to facilitate changes in individual health behaviors.",True,other,RNN
37926737,Deep-learning-based natural-language-processing models to identify cardiovascular disease hospitalisations of patients with diabetes from routine visits' text,"Writing notes is the most widespread method to report clinical events. Therefore, most of the information about the disease history of a patient remains locked behind free-form text. Natural language processing (NLP) provides a solution to automatically transform free-form text into structured data. In the present work, electronic healthcare records data of patients with diabetes were used to develop deep-learning based NLP models to automatically identify, within free-form text describing routine visits, the occurrence of hospitalisations related to cardiovascular disease (CVDs), an outcome of diabetes. Four possible time windows of increasing level of expected difficulty were considered: infinite, 24 months, 12 months, and 6 months. Model performance was evaluated by means of the area under the precision recall curve, as well as precision, recall, and F1-score after thresholding. Results showed that the proposed NLP approach was successful for both the infinite and 24-month windows, while, as expected, performance deteriorated with shorter time windows. Possible clinical applications of tools based on the proposed NLP approach include the retrospective filling of medical records with respect to a patient's CVD history for epidemiological and research purposes as well as for clinical decision making.",True,text mining,RNN
37920015,SEINN: A deep learning algorithm for the stochastic epidemic model,"Stochastic modeling predicts various outcomes from stochasticity in the data, parameters and dynamical system. Stochastic models are deemed more appropriate than deterministic models accounting in terms of essential and practical information about a system. The objective of the current investigation is to address the issue above through the development of a novel deep neural network referred to as a stochastic epidemiology-informed neural network. This network learns knowledge about the parameters and dynamics of a stochastic epidemic vaccine model. Our analysis centers on examining the nonlinear incidence rate of the model from the perspective of the combined effects of vaccination and stochasticity. Based on empirical evidence, stochastic models offer a more comprehensive understanding than deterministic models, mainly when we use error metrics. The findings of our study indicate that a decrease in randomness and an increase in vaccination rates are associated with a better prediction of nonlinear incidence rates. Adopting a nonlinear incidence rate enables a more comprehensive representation of the complexities of transmitting diseases. The computational analysis of the proposed method, focusing on sensitivity analysis and overfitting analysis, shows that the proposed method is efficient. Our research aims to guide policymakers on the effects of stochasticity in epidemic models, thereby aiding the development of effective vaccination and mitigation policies. Several case studies have been conducted on nonlinear incidence rates using data from Tennessee, USA.",True,text mining,recurrent neural network
37908549,Predictive Value of Deep Learning-derived CT Pectoralis Muscle and Adipose Measurements for Incident Heart Failure: Multi-Ethnic Study of Atherosclerosis,"PURPOSE: To develop a deep learning algorithm capable of extracting pectoralis muscle and adipose measurements and to longitudinally investigate associations between these measurements and incident heart failure (HF) in participants from the Multi-Ethnic Study of Atherosclerosis (MESA).
MATERIALS AND METHODS: MESA is a prospective study of subclinical cardiovascular disease characteristics and risk factors for progression to clinically overt disease approved by institutional review boards of six participating centers (ClinicalTrials.gov identifier: NCT00005487). All participants with adequate imaging and clinical data from the fifth examination of MESA were included in this study. Hence, in this secondary analysis, manual segmentations of 600 chest CT examinations (between the years 2010 and 2012) were used to train and validate a convolutional neural network, which subsequently extracted pectoralis muscle and adipose (intermuscular adipose tissue (IMAT), perimuscular adipose tissue (PAT), extramyocellular lipids and subcutaneous adipose tissue) area measurements from 3031 CT examinations using individualized thresholds for adipose segmentation. Next, 1781 participants without baseline HF were longitudinally investigated for associations between baseline pectoralis muscle and adipose measurements and incident HF using crude and adjusted Cox proportional hazards models. The full models were adjusted for variables in categories of demographic (age, race, sex, income), clinical/laboratory (including physical activity, BMI, and smoking), CT (coronary artery calcium score), and cardiac MRI (left ventricular ejection fraction and mass (% of predicted)) data.
RESULTS: In 1781 participants (median age, 68 (IQR,61, 75) years; 907 [51%] females), 41 incident HF events occurred over a median 6.5-year follow-up. IMAT predicted incident HF in unadjusted (hazard ratio [HR]:1.14; 95% CI: 1.03-1.26) and fully adjusted (HR:1.16, 95% CI: 1.03-1.31) models. PAT also predicted incident HF in crude (HR:1.19; 95% CI: 1.06-1.35) and fully adjusted (HR:1.25; 95% CI: 1.07-1.46) models.
CONCLUSION: The study demonstrates that fast and reliable deep learning-derived pectoralis muscle and adipose measurements are obtainable from conventional chest CT, which may be predictive of incident HF.©RSNA, 2023.",True,other,Not specified
37904407,COVID-19 studies involving machine learning methods: A bibliometric study,"BACKGROUND: Machine learning (ML) and artificial intelligence (AI) techniques are gaining popularity as effective tools for coronavirus disease of 2019 (COVID-19) research. These strategies can be used in diagnosis, prognosis, therapy, and public health management. Bibliometric analysis quantifies the quality and impact of scholarly publications. ML in COVID-19 research is the focus of this bibliometric analysis.
METHODS: A comprehensive literature study found ML-based COVID-19 research. Web of Science (WoS) was used for the study. The searches included ""machine learning,"" ""artificial intelligence,"" and COVID-19. To find all relevant studies, 2 reviewers searched independently. The network visualization was analyzed using VOSviewer 1.6.19.
RESULTS: In the WoS Core, the average citation count was 13.6 ± 41.3. The main research areas were computer science, engineering, and science and technology. According to document count, Tao Huang wrote 14 studies, Fadi Al-Turjman wrote 11, and Imran Ashraf wrote 11. The US, China, and India produced the most studies and citations. The most prolific research institutions were Harvard Medical School, Huazhong University of Science and Technology, and King Abdulaziz University. In contrast, Nankai University, Oxford, and Imperial College London were the most mentioned organizations, reflecting their significant research contributions. First, ""Covid-19"" appeared 1983 times, followed by ""machine learning"" and ""deep learning."" The US Department of Health and Human Services funded this topic most heavily. Huang Tao, Feng Kaiyan, and Ashraf Imran pioneered bibliographic coupling.
CONCLUSION: This study provides useful insights for academics and clinicians studying COVID-19 using ML. Through bibliometric data analysis, scholars can learn about highly recognized and productive authors and countries, as well as the publications with the most citations and keywords. New data and methodologies from the pandemic are expected to advance ML and AI modeling. It is crucial to recognize that these studies will pioneer this subject.",True,other,convolutional neural network
37881381,Developing a Risk Stratification Model Based on Machine Learning for Targeted Screening of Diabetic Retinopathy in the Indian Population,"OBJECTIVE: This study aimed to develop a predictive risk score model based on deep learning (DL) independent of fundus photography, totally reliant on systemic data through targeted screening from a population-based study to diagnose diabetic retinopathy (DR) in the Indian population.
METHODS: It involved machine learning application on datasets of a cross-sectional population-based study. A total of 1425 subjects (1175 subjects with known diabetes and 250 with newly diagnosed diabetes) were included in the study. We applied five machine learning algorithms, random forest (RF), logistic regression (LR), support vector machines (SVM), artificial neural networks (ANN), and decision trees (DT), to predict diabetic retinopathy in our datasets. We incorporated a percentage split in the first experiment and randomly divided our data set into 80% as a training set and 20% as a test set. We performed a three-way data split in the second experiment to prevent overestimating predictive performance. We randomly divided our data set into 60% as a training set, 20% as a validation set, and 20% as the test set. Furthermore, we integrated five-fold cross-validation to split the percentage to evaluate our method. We judged the predictive performance based on the receiver operating characteristic (ROC) curve, the area under the curve (AUC), accuracy (Acc), sensitivity, and specificity.
RESULTS: The RF classifier achieved the best prediction performance with AUC, Acc, and sensitivity values of 0.91, 0.89, and 0.90, respectively, in the percentage split. Similarly, a three-way data split attained an outcome of 0.86 and 0.85 in AUC and Acc. Likewise, the five-fold cross-validation performed the best with results of 0.90, 0.97, 0.91, and 0.75 in AUC, Acc, sensitivity, and specificity, respectively.
CONCLUSION: Since the RF classifier achieved the best performance, we propose it to identify diabetic retinopathy for targeted screening in the general population.",True,other,recurrent neural network
37872390,Real-time dual prediction of intradialytic hypotension and hypertension using an explainable deep learning model,"Both intradialytic hypotension (IDH) and hypertension (IDHTN) are associated with poor outcomes in hemodialysis patients, but a model predicting dual outcomes in real-time has never been developed. Herein, we developed an explainable deep learning model with a sequence-to-sequence-based attention network to predict both of these events simultaneously. We retrieved 302,774 hemodialysis sessions from the electronic health records of 11,110 patients, and these sessions were split into training (70%), validation (10%), and test (20%) datasets through patient randomization. The outcomes were defined when nadir systolic blood pressure (BP) < 90 mmHg (termed IDH-1), a decrease in systolic BP ≥ 20 mmHg and/or a decrease in mean arterial pressure ≥ 10 mmHg (termed IDH-2), or an increase in systolic BP ≥ 10 mmHg (i.e., IDHTN) occurred within 1 h. We developed a temporal fusion transformer (TFT)-based model and compared its performance in the test dataset, including receiver operating characteristic curve (AUROC) and area under the precision-recall curves (AUPRC), with those of other machine learning models, such as recurrent neural network, light gradient boosting machine, random forest, and logistic regression. Among all models, the TFT-based model achieved the highest AUROCs of 0.953 (0.952-0.954), 0.892 (0.891-0.893), and 0.889 (0.888-0.890) in predicting IDH-1, IDH-2, and IDHTN, respectively. The AUPRCs in the TFT-based model for these outcomes were higher than the other models. The factors that contributed the most to the prediction were age and previous session, which were time-invariant variables, as well as systolic BP and elapsed time, which were time-varying variables. The present TFT-based model predicts both IDH and IDHTN in real time and offers explainable variable importance.",True,other,Not specified
37871512,Machine Learning for Predicting Postoperative Atrial Fibrillation After Cardiac Surgery: A Scoping Review of Current Literature,"Postoperative atrial fibrillation (POAF) occurs in up to 20% to 55% of patients who underwent cardiac surgery. Machine learning (ML) has been increasingly employed in monitoring, screening, and identifying different cardiovascular clinical conditions. It was proposed that ML may be a useful tool for predicting POAF after cardiac surgery. An electronic database search was conducted on Medline, EMBASE, Cochrane, Google Scholar, and ClinicalTrials.gov to identify primary studies that investigated the role of ML in predicting POAF after cardiac surgery. A total of 5,955 citations were subjected to title and abstract screening, and ultimately 5 studies were included. The reported incidence of POAF ranged from 21.5% to 37.1%. The studied ML models included: deep learning, decision trees, logistic regression, support vector machines, gradient boosting decision tree, gradient-boosted machine, K-nearest neighbors, neural network, and random forest models. The sensitivity of the reported ML models ranged from 0.22 to 0.91, the specificity from 0.64 to 0.84, and the area under the receiver operating characteristic curve from 0.67 to 0.94. Age, gender, left atrial diameter, glomerular filtration rate, and duration of mechanical ventilation were significant clinical risk factors for POAF. Limited evidence suggest that machine learning models may play a role in predicting atrial fibrillation after cardiac surgery because of their ability to detect different patterns of correlations and the incorporation of several demographic and clinical variables. However, the heterogeneity of the included studies and the lack of external validation are the most important limitations against the routine incorporation of these models in routine practice. Artificial intelligence, cardiac surgery, decision tree, deep learning, gradient-boosted machine, gradient boosting decision tree, k-nearest neighbors, logistic regression, machine learning, neural network, postoperative atrial fibrillation, postoperative complications, random forest, risk scores, scoping review, support vector machine.",True,other,Not specified
37863921,A novel bidirectional LSTM deep learning approach for COVID-19 forecasting,"COVID-19 has resulted in significant morbidity and mortality globally. We develop a model that uses data from thirty days before a fixed time point to forecast the daily number of new COVID-19 cases fourteen days later in the early stages of the pandemic. Various time-dependent factors including the number of daily confirmed cases, reproduction number, policy measures, mobility and flight numbers were collected. A deep-learning model using Bidirectional Long-Short Term Memory (Bi-LSTM) architecture was trained on data from 22nd Jan 2020 to 8 Jan 2021 to forecast the new daily number of COVID-19 cases 14 days in advance across 190 countries, from 9 to 31 Jan 2021. A second model with fewer variables but similar architecture was developed. Results were summarised by mean absolute error (MAE), root mean squared error (RMSE), mean absolute percentage error (MAPE), and total absolute percentage error and compared against results from a classical ARIMA model. Median MAE was 157 daily cases (IQR: 26-666) under the first model, and 150 (IQR: 26-716) under the second. Countries with more accurate forecasts had more daily cases and experienced more waves of COVID-19 infections. Among countries with over 10,000 cases over the prediction period, median total absolute percentage error was 33% (IQR: 18-59%) and 34% (IQR: 16-66%) for the first and second models respectively. Both models had comparable median total absolute percentage errors but lower maximum total absolute percentage errors as compared to the classical ARIMA model. A deep-learning approach using Bi-LSTM architecture and open-source data was validated on 190 countries to forecast the daily number of cases in the early stages of the COVID-19 outbreak. Fewer variables could potentially be used without impacting prediction accuracy.",True,other,recurrent neural network
37851434,Deep Learning of Electrocardiograms in Sinus Rhythm From US Veterans to Predict Atrial Fibrillation,"IMPORTANCE: Early detection of atrial fibrillation (AF) may help prevent adverse cardiovascular events such as stroke. Deep learning applied to electrocardiograms (ECGs) has been successfully used for early identification of several cardiovascular diseases.
OBJECTIVE: To determine whether deep learning models applied to outpatient ECGs in sinus rhythm can predict AF in a large and diverse patient population.
DESIGN, SETTING, AND PARTICIPANTS: This prognostic study was performed on ECGs acquired from January 1, 1987, to December 31, 2022, at 6 US Veterans Affairs (VA) hospital networks and 1 large non-VA academic medical center. Participants included all outpatients with 12-lead ECGs in sinus rhythm.
MAIN OUTCOMES AND MEASURES: A convolutional neural network using 12-lead ECGs from 2 US VA hospital networks was trained to predict the presence of AF within 31 days of sinus rhythm ECGs. The model was tested on ECGs held out from training at the 2 VA networks as well as 4 additional VA networks and 1 large non-VA academic medical center.
RESULTS: A total of 907 858 ECGs from patients across 6 VA sites were included in the analysis. These patients had a mean (SD) age of 62.4 (13.5) years, 6.4% were female, and 93.6% were male, with a mean (SD) CHA2DS2-VASc (congestive heart failure, hypertension, age, diabetes mellitus, prior stroke or transient ischemic attack or thromboembolism, vascular disease, age, sex category) score of 1.9 (1.6). A total of 0.2% were American Indian or Alaska Native, 2.7% were Asian, 10.7% were Black, 4.6% were Latinx, 0.7% were Native Hawaiian or Other Pacific Islander, 62.4% were White, 0.4% were of other race or ethnicity (which is not broken down into subcategories in the VA data set), and 18.4% were of unknown race or ethnicity. At the non-VA academic medical center (72 483 ECGs), the mean (SD) age was 59.5 (15.4) years and 52.5% were female, with a mean (SD) CHA2DS2-VASc score of 1.6 (1.4). A total of 0.1% were American Indian or Alaska Native, 7.9% were Asian, 9.4% were Black, 2.9% were Latinx, 0.03% were Native Hawaiian or Other Pacific Islander, 74.8% were White, 0.1% were of other race or ethnicity, and 4.7% were of unknown race or ethnicity. A deep learning model predicted the presence of AF within 31 days of a sinus rhythm ECG on held-out test ECGs at VA sites with an area under the receiver operating characteristic curve (AUROC) of 0.86 (95% CI, 0.85-0.86), accuracy of 0.78 (95% CI, 0.77-0.78), and F1 score of 0.30 (95% CI, 0.30-0.31). At the non-VA site, AUROC was 0.93 (95% CI, 0.93-0.94); accuracy, 0.87 (95% CI, 0.86-0.88); and F1 score, 0.46 (95% CI, 0.44-0.48). The model was well calibrated, with a Brier score of 0.02 across all sites. Among individuals deemed high risk by deep learning, the number needed to screen to detect a positive case of AF was 2.47 individuals for a testing sensitivity of 25% and 11.48 for 75%. Model performance was similar in patients who were Black, female, or younger than 65 years or who had CHA2DS2-VASc scores of 2 or greater.
CONCLUSIONS AND RELEVANCE: Deep learning of outpatient sinus rhythm ECGs predicted AF within 31 days in populations with diverse demographics and comorbidities. Similar models could be used in future AF screening efforts to reduce adverse complications associated with this disease.",True,other,RNN
37847669,Pivotal trial of a deep-learning-based retinal biomarker (Reti-CVD) in the prediction of cardiovascular disease: data from CMERC-HI,"OBJECTIVE: The potential of using retinal images as a biomarker of cardiovascular disease (CVD) risk has gained significant attention, but regulatory approval of such artificial intelligence (AI) algorithms is lacking. In this regulated pivotal trial, we validated the efficacy of Reti-CVD, an AI-Software as a Medical Device (AI-SaMD), that utilizes retinal images to stratify CVD risk.
MATERIALS AND METHODS: In this retrospective study, we used data from the Cardiovascular and Metabolic Diseases Etiology Research Center-High Risk (CMERC-HI) Cohort. Cox proportional hazard model was used to estimate hazard ratio (HR) trend across the 3-tier CVD risk groups (low-, moderate-, and high-risk) according to Reti-CVD in prediction of CVD events. The cardiac computed tomography-measured coronary artery calcium (CAC), carotid intima-media thickness (CIMT), and brachial-ankle pulse wave velocity (baPWV) were compared to Reti-CVD.
RESULTS: A total of 1106 participants were included, with 33 (3.0%) participants experiencing CVD events over 5 years; the Reti-CVD-defined risk groups (low, moderate, and high) were significantly associated with increased CVD risk (HR trend, 2.02; 95% CI, 1.26-3.24). When all variables of Reti-CVD, CAC, CIMT, baPWV, and other traditional risk factors were incorporated into one Cox model, the Reti-CVD risk groups were only significantly associated with increased CVD risk (HR = 2.40 [0.82-7.03] in moderate risk and HR = 3.56 [1.34-9.51] in high risk using low-risk as a reference).
DISCUSSION: This regulated pivotal study validated an AI-SaMD, retinal image-based, personalized CVD risk scoring system (Reti-CVD).
CONCLUSION: These results led the Korean regulatory body to authorize Reti-CVD.",True,other,Not specified
37847532,Influenza Epidemic Trend Surveillance and Prediction Based on Search Engine Data: Deep Learning Model Study,"BACKGROUND: Influenza outbreaks pose a significant threat to global public health. Traditional surveillance systems and simple algorithms often struggle to predict influenza outbreaks in an accurate and timely manner. Big data and modern technology have offered new modalities for disease surveillance and prediction. Influenza-like illness can serve as a valuable surveillance tool for emerging respiratory infectious diseases like influenza and COVID-19, especially when reported case data may not fully reflect the actual epidemic curve.
OBJECTIVE: This study aimed to develop a predictive model for influenza outbreaks by combining Baidu search query data with traditional virological surveillance data. The goal was to improve early detection and preparedness for influenza outbreaks in both northern and southern China, providing evidence for supplementing modern intelligence epidemic surveillance methods.
METHODS: We collected virological data from the National Influenza Surveillance Network and Baidu search query data from January 2011 to July 2018, totaling 3,691,865 and 1,563,361 respective samples. Relevant search terms related to influenza were identified and analyzed for their correlation with influenza-positive rates using Pearson correlation analysis. A distributed lag nonlinear model was used to assess the lag correlation of the search terms with influenza activity. Subsequently, a predictive model based on the gated recurrent unit and multiple attention mechanisms was developed to forecast the influenza-positive trend.
RESULTS: This study revealed a high correlation between specific Baidu search terms and influenza-positive rates in both northern and southern China, except for 1 term. The search terms were categorized into 4 groups: essential facts on influenza, influenza symptoms, influenza treatment and medicine, and influenza prevention, all of which showed correlation with the influenza-positive rate. The influenza prevention and influenza symptom groups had a lag correlation of 1.4-3.2 and 5.0-8.0 days, respectively. The Baidu search terms could help predict the influenza-positive rate 14-22 days in advance in southern China but interfered with influenza surveillance in northern China.
CONCLUSIONS: Complementing traditional disease surveillance systems with information from web-based data sources can aid in detecting warning signs of influenza outbreaks earlier. However, supplementation of modern surveillance with search engine information should be approached cautiously. This approach provides valuable insights for digital epidemiology and has the potential for broader application in respiratory infectious disease surveillance. Further research should explore the optimization and customization of search terms for different regions and languages to improve the accuracy of influenza prediction models.",True,other,CNN
37844797,A Deep Learning-Based Radiomic Classifier for Usual Interstitial Pneumonia,"BACKGROUND: Because chest CT scan has largely supplanted surgical lung biopsy for diagnosing most cases of interstitial lung disease (ILD), tools to standardize CT scan interpretation are urgently needed.
RESEARCH QUESTION: Does a deep learning (DL)-based classifier for usual interstitial pneumonia (UIP) derived using CT scan features accurately discriminate radiologist-determined visual UIP?
STUDY DESIGN AND METHODS: A retrospective cohort study was performed. Chest CT scans acquired in individuals with and without ILD were drawn from a variety of public and private data sources. Using radiologist-determined visual UIP as ground truth, a convolutional neural network was used to learn discrete CT scan features of UIP, with outputs used to predict the likelihood of UIP using a linear support vector machine. Test performance characteristics were assessed in an independent performance cohort and multicenter ILD clinical cohort. Transplant-free survival was compared between UIP classification approaches using the Kaplan-Meier estimator and Cox proportional hazards regression.
RESULTS: A total of 2,907 chest CT scans were included in the training (n = 1,934), validation (n = 408), and performance (n = 565) data sets. The prevalence of radiologist-determined visual UIP was 12.4% and 37.1% in the performance and ILD clinical cohorts, respectively. The DL-based UIP classifier predicted visual UIP in the performance cohort with sensitivity and specificity of 93% and 86%, respectively, and in the multicenter ILD clinical cohort with 81% and 77%, respectively. DL-based and visual UIP classification similarly discriminated survival, and outcomes were consistent among cases with positive DL-based UIP classification irrespective of visual classification.
INTERPRETATION: A DL-based classifier for UIP demonstrated good test performance across a wide range of UIP prevalence and similarly discriminated survival when compared with radiologist-determined UIP. This automated tool could efficiently screen for UIP in patients undergoing chest CT scan and identify a high-risk phenotype among those with known ILD.",True,other,Not specified
37835451,A Study on Survival Analysis Methods Using Neural Network to Prevent Cancers,"Background: Cancer is one of the main global health threats. Early personalized prediction of cancer incidence is crucial for the population at risk. This study introduces a novel cancer prediction model based on modern recurrent survival deep learning algorithms. Methods: The study includes 160,407 participants from the blood-based cohort of the Korea Cancer Prevention Research-II Biobank, which has been ongoing since 2004. Data linkages were designed to ensure anonymity, and data collection was carried out through nationwide medical examinations. Predictive performance on ten cancer sites, evaluated using the concordance index (c-index), was compared among nDeep and its multitask variation, Cox proportional hazard (PH) regression, DeepSurv, and DeepHit. Results: Our models consistently achieved a c-index of over 0.8 for all ten cancers, with a peak of 0.8922 for lung cancer. They outperformed Cox PH regression and other survival deep neural networks. Conclusion: This study presents a survival deep learning model that demonstrates the highest predictive performance on censored health dataset, to the best of our knowledge. In the future, we plan to investigate the causal relationship between explanatory variables and cancer to reduce cancer incidence and mortality.",True,other,Not specified
37808872,Disease-driven domain generalization for neuroimaging-based assessment of Alzheimer's disease,"Development of deep learning models to assess the degree of cognitive impairment on magnetic resonance imaging (MRI) scans has high translational significance. Performance of such models is often affected by potential variabilities stemming from independent protocols for data generation, imaging equipment, radiology artifacts, and demographic distributional shifts. Domain generalization (DG) frameworks have the potential to overcome these issues by learning signal from one or more source domains that can be transferable to unseen target domains. We developed an approach that leverages model interpretability as a means to improve generalizability of classification models across multiple cohorts. Using MRI scans and clinical diagnosis obtained from four independent cohorts (Alzheimer's Disease Neuroimaging Initiative (ADNI, n = 1,821), the Framingham Heart Study (FHS, n = 304), the Australian Imaging Biomarkers and Lifestyle Study of Ageing (AIBL, n = 661), and the National Alzheimer's Coordinating Center (NACC, n = 4,647)), we trained a deep neural network that used model-identified regions of disease relevance to inform model training. We trained a classifier to distinguish persons with normal cognition (NC) from those with mild cognitive impairment (MCI) and Alzheimer's disease (AD) by aligning class-wise attention with a unified visual saliency prior computed offline per class over all training data. Our proposed method competes with state-of-the-art methods with improved correlation with postmortem histology, thus grounding our findings with gold standard evidence and paving a way towards validating DG frameworks.",True,other,convolutional neural network
37799217,Reimagining Healthcare: Unleashing the Power of Artificial Intelligence in Medicine,"Artificial intelligence (AI) has opened new medical avenues and revolutionized diagnostic and therapeutic practices, allowing healthcare providers to overcome significant challenges associated with cost, disease management, accessibility, and treatment optimization. Prominent AI technologies such as machine learning (ML) and deep learning (DL) have immensely influenced diagnostics, patient monitoring, novel pharmaceutical discoveries, drug development, and telemedicine. Significant innovations and improvements in disease identification and early intervention have been made using AI-generated algorithms for clinical decision support systems and disease prediction models. AI has remarkably impacted clinical drug trials by amplifying research into drug efficacy, adverse events, and candidate molecular design. AI's precision and analysis regarding patients' genetic, environmental, and lifestyle factors have led to individualized treatment strategies. During the COVID-19 pandemic, AI-assisted telemedicine set a precedent for remote healthcare delivery and patient follow-up. Moreover, AI-generated applications and wearable devices have allowed ambulatory monitoring of vital signs. However, apart from being immensely transformative, AI's contribution to healthcare is subject to ethical and regulatory concerns. AI-backed data protection and algorithm transparency should be strictly adherent to ethical principles. Vigorous governance frameworks should be in place before incorporating AI in mental health interventions through AI-operated chatbots, medical education enhancements, and virtual reality-based training. The role of AI in medical decision-making has certain limitations, necessitating the importance of hands-on experience. Therefore, reaching an optimal balance between AI's capabilities and ethical considerations to ensure impartial and neutral performance in healthcare applications is crucial. This narrative review focuses on AI's impact on healthcare and the importance of ethical and balanced incorporation to make use of its full potential.",True,other,Not specified
37780897,"Transforming clinical virology with AI, machine learning and deep learning: a comprehensive review and outlook","In the rapidly evolving field of clinical virology, technological advancements have always played a pivotal role in driving transformative changes. This comprehensive review delves into the burgeoning integration of artificial intelligence (AI), machine learning, and deep learning into virological research and practice. As we elucidate, these computational tools have significantly enhanced diagnostic precision, therapeutic interventions, and epidemiological monitoring. Through in-depth analyses of notable case studies, we showcase how algorithms can optimize viral genome sequencing, accelerate drug discovery, and offer predictive insights into viral outbreaks. However, with these advancements come inherent challenges, particularly in data security, algorithmic biases, and ethical considerations. Addressing these challenges head-on, we discuss potential remedial measures and underscore the significance of interdisciplinary collaboration between virologists, data scientists, and ethicists. Conclusively, this review posits an outlook that anticipates a symbiotic relationship between AI-driven tools and virology, heralding a new era of proactive and personalized patient care.",True,other,recurrent neural network
37774040,Deep-learning model for prenatal congenital heart disease screening generalizes to community setting and outperforms clinical detection,"OBJECTIVES: Despite nearly universal prenatal ultrasound screening programs, congenital heart defects (CHD) are still missed, which may result in severe morbidity or even death. Deep machine learning (DL) can automate image recognition from ultrasound. The main aim of this study was to assess the performance of a previously developed DL model, trained on images from a tertiary center, using fetal ultrasound images obtained during the second-trimester standard anomaly scan in a low-risk population. A secondary aim was to compare initial screening diagnosis, which made use of live imaging at the point-of-care, with diagnosis by clinicians evaluating only stored images.
METHODS: All pregnancies with isolated severe CHD in the Northwestern region of The Netherlands between 2015 and 2016 with available stored images were evaluated, as well as a sample of normal fetuses' examinations from the same region and time period. We compared the accuracy of the initial clinical diagnosis (made in real time with access to live imaging) with that of the model (which had only stored imaging available) and with the performance of three blinded human experts who had access only to the stored images (like the model). We analyzed performance according to ultrasound study characteristics, such as duration and quality (scored independently by investigators), number of stored images and availability of screening views.
RESULTS: A total of 42 normal fetuses and 66 cases of isolated CHD at birth were analyzed. Of the abnormal cases, 31 were missed and 35 were detected at the time of the clinical anatomy scan (sensitivity, 53%). Model sensitivity and specificity were 91% and 78%, respectively. Blinded human experts (n = 3) achieved mean ± SD sensitivity and specificity of 55 ± 10% (range, 47-67%) and 71 ± 13% (range, 57-83%), respectively. There was a statistically significant difference in model correctness according to expert-graded image quality (P = 0.03). The abnormal cases included 19 lesions that the model had not encountered during its training; the model's performance in these cases (16/19 correct) was not statistically significantly different from that for previously encountered lesions (P = 0.41).
CONCLUSIONS: A previously trained DL algorithm had higher sensitivity than initial clinical assessment in detecting CHD in a cohort in which over 50% of CHD cases were initially missed clinically. Notably, the DL algorithm performed well on community-acquired images in a low-risk population, including lesions to which it had not been exposed previously. Furthermore, when both the model and blinded human experts had access to only stored images and not the full range of images available to a clinician during a live scan, the model outperformed the human experts. Together, these findings support the proposition that use of DL models can improve prenatal detection of CHD. © 2023 International Society of Ultrasound in Obstetrics and Gynecology.",True,other,Not specified
37767905,CT-based volumetric measures obtained through deep learning: Association with biomarkers of neurodegeneration,"INTRODUCTION: Cranial computed tomography (CT) is an affordable and widely available imaging modality that is used to assess structural abnormalities, but not to quantify neurodegeneration. Previously we developed a deep-learning-based model that produced accurate and robust cranial CT tissue classification.
MATERIALS AND METHODS: We analyzed 917 CT and 744 magnetic resonance (MR) scans from the Gothenburg H70 Birth Cohort, and 204 CT and 241 MR scans from participants of the Memory Clinic Cohort, Singapore. We tested associations between six CT-based volumetric measures (CTVMs) and existing clinical diagnoses, fluid and imaging biomarkers, and measures of cognition.
RESULTS: CTVMs differentiated cognitively healthy individuals from dementia and prodromal dementia patients with high accuracy levels comparable to MR-based measures. CTVMs were significantly associated with measures of cognition and biochemical markers of neurodegeneration.
DISCUSSION: These findings suggest the potential future use of CT-based volumetric measures as an informative first-line examination tool for neurodegenerative disease diagnostics after further validation.
HIGHLIGHTS: Computed tomography (CT)-based volumetric measures can distinguish between patients with neurodegenerative disease and healthy controls, as well as between patients with prodromal dementia and controls. CT-based volumetric measures associate well with relevant cognitive, biochemical, and neuroimaging markers of neurodegenerative diseases. Model performance, in terms of brain tissue classification, was consistent across two cohorts of diverse nature. Intermodality agreement between our automated CT-based and established magnetic resonance (MR)-based image segmentations was stronger than the agreement between visual CT and MR imaging assessment.",True,other,Not specified
37761333,A Radiomic-Based Machine Learning System to Diagnose Age-Related Macular Degeneration from Ultra-Widefield Fundus Retinography,"The present study was conducted to investigate the potential of radiomics to develop an explainable AI-based system to be applied to ultra-widefield fundus retinographies (UWF-FRTs) with the objective of predicting the presence of the early signs of Age-related Macular Degeneration (AMD) and stratifying subjects with low- versus high-risk of AMD. The ultimate aim was to provide clinicians with an automatic classifier and a signature of objective quantitative image biomarkers of AMD. The use of Machine Learning (ML) and radiomics was based on intensity and texture analysis in the macular region, detected by a Deep Learning (DL)-based macular detector. Two-hundred and twenty six UWF-FRTs were retrospectively collected from two centres and manually annotated to train and test the algorithms. Notably, the combination of the ML-based radiomics model and the DL-based macular detector reported 93% sensitivity and 74% specificity when applied to the data of the centre used for external testing, capturing explainable features associated with drusen or pigmentary abnormalities. In comparison to the human operator's annotations, the system yielded a 0.79 Cohen κ, demonstrating substantial concordance. To our knowledge, these results are the first provided by a radiomic approach for AMD supporting the suitability of an explainable feature extraction method combined with ML for UWF-FRT.",True,both,LSTM
37736834,Improving genetic risk prediction across diverse population by disentangling ancestry representations,"Risk prediction models using genetic data have seen increasing traction in genomics. However, most of the polygenic risk models were developed using data from participants with similar (mostly European) ancestry. This can lead to biases in the risk predictors resulting in poor generalization when applied to minority populations and admixed individuals such as African Americans. To address this issue, largely due to the prediction models being biased by the underlying population structure, we propose a deep-learning framework that leverages data from diverse population and disentangles ancestry from the phenotype-relevant information in its representation. The ancestry disentangled representation can be used to build risk predictors that perform better across minority populations. We applied the proposed method to the analysis of Alzheimer's disease genetics. Comparing with standard linear and nonlinear risk prediction methods, the proposed method substantially improves risk prediction in minority populations, including admixed individuals, without needing self-reported ancestry information.",True,other,Not specified
37732244,Deep Learning Model for Tumor Type Prediction using Targeted Clinical Genomic Sequencing Data,"Tumor type guides clinical treatment decisions in cancer, but histology-based diagnosis remains challenging. Genomic alterations are highly diagnostic of tumor type, and tumor type classifiers trained on genomic features have been explored, but the most accurate methods are not clinically feasible, relying on features derived from whole genome sequencing (WGS), or predicting across limited cancer types. We use genomic features from a dataset of 39,787 solid tumors sequenced using a clinical targeted cancer gene panel to develop Genome-Derived-Diagnosis Ensemble (GDD-ENS): a hyperparameter ensemble for classifying tumor type using deep neural networks. GDD-ENS achieves 93% accuracy for high-confidence predictions across 38 cancer types, rivalling performance of WGS-based methods. GDD-ENS can also guide diagnoses on rare type and cancers of unknown primary, and incorporate patient-specific clinical information for improved predictions. Overall, integrating GDD-ENS into prospective clinical sequencing workflows has enabled clinically-relevant tumor type predictions to guide treatment decisions in real time.",True,other,Not specified
37721426,Comparison of machine-learning models for the prediction of 1-year adverse outcomes of patients undergoing primary percutaneous coronary intervention for acute ST-elevation myocardial infarction,"BACKGROUND: Acute ST-elevation myocardial infarction (STEMI) is a leading cause of mortality and morbidity worldwide, and primary percutaneous coronary intervention (PCI) is the preferred treatment option.
HYPOTHESIS: Machine learning (ML) models have the potential to predict adverse clinical outcomes in STEMI patients treated with primary PCI. However, the comparative performance of different ML models for this purpose is unclear.
METHODS: This study used a retrospective registry-based design to recruit consecutive hospitalized patients diagnosed with acute STEMI and treated with primary PCI from 2011 to 2019, at Tehran Heart Center, Tehran, Iran. Four ML models, namely Gradient Boosting Machine (GBM), Distributed Random Forest (DRF), Logistic Regression (LR), and Deep Learning (DL), were used to predict major adverse cardiovascular events (MACE) during 1-year follow-up.
RESULTS: A total of 4514 patients (3498 men and 1016 women) were enrolled, with MACE occurring in 610 (13.5%) subjects during follow-up. The mean age of the population was 62.1 years, and the MACE group was significantly older than the non-MACE group (66.2 vs. 61.5 years, p < .001). The learning process utilized 70% (n = 3160) of the total population, and the remaining 30% (n = 1354) served as the testing data set. DRF and GBM models demonstrated the best performance in predicting MACE, with an area under the curve of 0.92 and 0.91, respectively.
CONCLUSION: ML-based models, such as DRF and GBM, can effectively identify high-risk STEMI patients for adverse events during follow-up. These models can be useful for personalized treatment strategies, ultimately improving clinical outcomes and reducing the burden of disease.",True,other,Not specified
37704266,Deep learning detection of diabetic retinopathy in Scotland's diabetic eye screening programme,"BACKGROUND/AIMS: Support vector machine-based automated grading (known as iGradingM) has been shown to be safe, cost-effective and robust in the diabetic retinopathy (DR) screening (DES) programme in Scotland. It triages screening episodes as gradable with no DR versus manual grading required. The study aim was to develop a deep learning-based autograder using images and gradings from DES and to compare its performance with that of iGradingM.
METHODS: Retinal images, quality assurance (QA) data and routine DR grades were obtained from national datasets in 179 944 patients for years 2006-2016. QA grades were available for 744 images. We developed a deep learning-based algorithm to detect whether either eye contained ungradable images or any DR. The sensitivity and specificity were evaluated against consensus QA grades and routine grades.
RESULTS: Images used in QA which were ungradable or with DR were detected by deep learning with better specificity compared with manual graders (p<0.001) and with iGradingM (p<0.001) at the same sensitivities. Any DR according to the DES final grade was detected with 89.19% (270 392/303 154) sensitivity and 77.41% (500 945/647 158) specificity. Observable disease and referable disease were detected with sensitivities of 96.58% (16 613/17 201) and 98.48% (22 600/22 948), respectively. Overall, 43.84% of screening episodes would require manual grading.
CONCLUSION: A deep learning-based system for DR grading was evaluated in QA data and images from 11 years in 50% of people attending a national DR screening programme. The system could reduce the manual grading workload at the same sensitivity compared with the current automated grading system.",True,other,recurrent neural network
37682491,A comprehensive review of machine learning algorithms and their application in geriatric medicine: present and future,"The increasing access to health data worldwide is driving a resurgence in machine learning research, including data-hungry deep learning algorithms. More computationally efficient algorithms now offer unique opportunities to enhance diagnosis, risk stratification, and individualised approaches to patient management. Such opportunities are particularly relevant for the management of older patients, a group that is characterised by complex multimorbidity patterns and significant interindividual variability in homeostatic capacity, organ function, and response to treatment. Clinical tools that utilise machine learning algorithms to determine the optimal choice of treatment are slowly gaining the necessary approval from governing bodies and being implemented into healthcare, with significant implications for virtually all medical disciplines during the next phase of digital medicine. Beyond obtaining regulatory approval, a crucial element in implementing these tools is the trust and support of the people that use them. In this context, an increased understanding by clinicians of artificial intelligence and machine learning algorithms provides an appreciation of the possible benefits, risks, and uncertainties, and improves the chances for successful adoption. This review provides a broad taxonomy of machine learning algorithms, followed by a more detailed description of each algorithm class, their purpose and capabilities, and examples of their applications, particularly in geriatric medicine. Additional focus is given on the clinical implications and challenges involved in relying on devices with reduced interpretability and the progress made in counteracting the latter via the development of explainable machine learning.",True,other,RNN
37673824,A deep learning approach based on multi-omics data integration to construct a risk stratification prediction model for skin cutaneous melanoma,"PURPOSE: Skin cutaneous melanoma (SKCM) is a highly aggressive melanocytic carcinoma whose high heterogeneity and complex etiology make its prognosis difficult to predict. This study aimed to construct a risk subtype typing model for SKCM.
METHODS: The study proposes a deep learning framework combining early fusion feature autoencoder (AE) and late fusion feature AE for risk subtype prediction of SKCM. The deep learning framework integrates mRNA, miRNA, and DNA methylation data of SKCM patients from The Cancer Genome Atlas (TCGA), and clusters the screened multi-omics features associated with survival prognosis to identify risk subtypes. Differential expression analysis and functional enrichment analysis were performed between risk subtypes, while SVM classifiers were constructed between differentially expressed genes (DEGs) obtained by Least Absolute Shrinkage and Selection Operator (LASSO) logistic regression screening and risk subtype labels inferred from multi-omics data, and the predictive robustness of risk subtypes inferred from the risk subtype classification prediction model was validated using two independent datasets.
RESULTS: The deep learning framework that combined early fusion feature AE with late fusion feature AE distinguished the two best risk subtypes compared to the multi-omics integration approach with single strategy AE or PCA. A promising C-index (C-index = 0.748) and a significant difference in survival (log-rank P value = 4.61 × 10-9) were found between the identified risk subtypes. The DEGs with the top significance values together with differentially expressed miRNAs provided the biological interpretation of risk subtypes on SKCM. Finally, the framework was applied to predict risk subtypes in two independent test datasets of SKCM patients, all of which showed good predictive power (C-index &gt; 0.680) and significant survival differences (log-rank P value &lt; 0.01).
CONCLUSION: The SKCM risk subtypes identified by integrating multi-omics data based on deep learning can not only improve the understanding of the molecular mechanisms of SKCM, but also provide clinicians with assistance in treatment decisions.",True,other,Not specified
37659103,Deep learning algorithms to detect diabetic kidney disease from retinal photographs in multiethnic populations with diabetes,"OBJECTIVE: To develop a deep learning algorithm (DLA) to detect diabetic kideny disease (DKD) from retinal photographs of patients with diabetes, and evaluate performance in multiethnic populations.
MATERIALS AND METHODS: We trained 3 models: (1) image-only; (2) risk factor (RF)-only multivariable logistic regression (LR) model adjusted for age, sex, ethnicity, diabetes duration, HbA1c, systolic blood pressure; (3) hybrid multivariable LR model combining RF data and standardized z-scores from image-only model. Data from Singapore Integrated Diabetic Retinopathy Program (SiDRP) were used to develop (6066 participants with diabetes, primary-care-based) and internally validate (5-fold cross-validation) the models. External testing on 2 independent datasets: (1) Singapore Epidemiology of Eye Diseases (SEED) study (1885 participants with diabetes, population-based); (2) Singapore Macroangiopathy and Microvascular Reactivity in Type 2 Diabetes (SMART2D) (439 participants with diabetes, cross-sectional) in Singapore. Supplementary external testing on 2 Caucasian cohorts: (3) Australian Eye and Heart Study (AHES) (460 participants with diabetes, cross-sectional) and (4) Northern Ireland Cohort for the Longitudinal Study of Ageing (NICOLA) (265 participants with diabetes, cross-sectional).
RESULTS: In SiDRP validation, area under the curve (AUC) was 0.826(95% CI 0.818-0.833) for image-only, 0.847(0.840-0.854) for RF-only, and 0.866(0.859-0.872) for hybrid. Estimates with SEED were 0.764(0.743-0.785) for image-only, 0.802(0.783-0.822) for RF-only, and 0.828(0.810-0.846) for hybrid. In SMART2D, AUC was 0.726(0.686-0.765) for image-only, 0.701(0.660-0.741) in RF-only, 0.761(0.724-0.797) for hybrid.
DISCUSSION AND CONCLUSION: There is potential for DLA using retinal images as a screening adjunct for DKD among individuals with diabetes. This can value-add to existing DLA systems which diagnose diabetic retinopathy from retinal images, facilitating primary screening for DKD.",True,other,Not specified
37647308,Paying attention to cardiac surgical risk: An interpretable machine learning approach using an uncertainty-aware attentive neural network,"Machine learning (ML) is increasingly applied to predict adverse postoperative outcomes in cardiac surgery. Commonly used ML models fail to translate to clinical practice due to absent model explainability, limited uncertainty quantification, and no flexibility to missing data. We aimed to develop and benchmark a novel ML approach, the uncertainty-aware attention network (UAN), to overcome these common limitations. Two Bayesian uncertainty quantification methods were tested, generalized variational inference (GVI) or a posterior network (PN). The UAN models were compared with an ensemble of XGBoost models and a Bayesian logistic regression model (LR) with imputation. The derivation datasets consisted of 153,932 surgery events from the Australian and New Zealand Society of Cardiac and Thoracic Surgeons (ANZSCTS) Cardiac Surgery Database. An external validation consisted of 7343 surgery events which were extracted from the Medical Information Mart for Intensive Care (MIMIC) III critical care dataset. The highest performing model on the external validation dataset was a UAN-GVI with an area under the receiver operating characteristic curve (AUC) of 0.78 (0.01). Model performance improved on high confidence samples with an AUC of 0.81 (0.01). Confidence calibration for aleatoric uncertainty was excellent for all models. Calibration for epistemic uncertainty was more variable, with an ensemble of XGBoost models performing the best with an AUC of 0.84 (0.08). Epistemic uncertainty was improved using the PN approach, compared to GVI. UAN is able to use an interpretable and flexible deep learning approach to provide estimates of model uncertainty alongside state-of-the-art predictions. The model has been made freely available as an easy-to-use web application demonstrating that by designing uncertainty-aware models with innately explainable predictions deep learning may become more suitable for routine clinical use.",True,other,RNN
37646016,Deep learning for risk-based stratification of cognitively impaired individuals,"Quantifying the risk of progression to Alzheimer's disease (AD) could help identify persons who could benefit from early interventions. We used data from the Alzheimer's Disease Neuroimaging Initiative (ADNI, n = 544, discovery cohort) and the National Alzheimer's Coordinating Center (NACC, n = 508, validation cohort), subdividing individuals with mild cognitive impairment (MCI) into risk groups based on cerebrospinal fluid amyloid-β levels and identifying differential gray matter patterns. We then created models that fused neural networks with survival analysis, trained using non-parcellated T1-weighted brain MRIs from ADNI data, to predict the trajectories of MCI to AD conversion within the NACC cohort (integrated Brier score: 0.192 [discovery], and 0.108 [validation]). Using modern interpretability techniques, we verified that regions important for model prediction are classically associated with AD. We confirmed AD diagnosis labels using postmortem data. We conclude that our framework provides a strategy for risk-based stratification of individuals with MCI and for identifying regions key for disease prognosis.",True,other,convolutional neural network
37632091,Physics-Informed Neural Networks Integrating Compartmental Model for Analyzing COVID-19 Transmission Dynamics,"Modelling and predicting the behaviour of infectious diseases is essential for early warning and evaluating the most effective interventions to prevent significant harm. Compartmental models produce a system of ordinary differential equations (ODEs) that are renowned for simulating the transmission dynamics of infectious diseases. However, the parameters in compartmental models are often unknown, and they can even change over time in the real world, making them difficult to determine. This study proposes an advanced artificial intelligence approach based on physics-informed neural networks (PINNs) to estimate time-varying parameters from given data for the compartmental model. Our proposed PINNs method captures the complex dynamics of COVID-19 by integrating a modified Susceptible-Exposed-Infectious-Recovered-Death (SEIRD) compartmental model with deep neural networks. Specifically, we modelled the system of ODEs as one network and the time-varying parameters as another network to address significant unknown parameters and limited data. Such structure of the PINNs method is in line with the prior epidemiological correlations and comprises the mismatch between available data and network output and the residual of ODEs. The experimental findings on real-world reported data data have demonstrated that our method robustly and accurately learns the dynamics and forecasts future states. Moreover, as more data becomes available, our proposed PINNs method can be successfully extended to other regions and infectious diseases.",True,text mining,recurrent neural network
37612313,Biology-guided deep learning predicts prognosis and cancer immunotherapy response,"Substantial progress has been made in using deep learning for cancer detection and diagnosis in medical images. Yet, there is limited success on prediction of treatment response and outcomes, which has important implications for personalized treatment strategies. A significant hurdle for clinical translation of current data-driven deep learning models is lack of interpretability, often attributable to a disconnect from the underlying pathobiology. Here, we present a biology-guided deep learning approach that enables simultaneous prediction of the tumor immune and stromal microenvironment status as well as treatment outcomes from medical images. We validate the model for predicting prognosis of gastric cancer and the benefit from adjuvant chemotherapy in a multi-center international study. Further, the model predicts response to immune checkpoint inhibitors and complements clinically approved biomarkers. Importantly, our model identifies a subset of mismatch repair-deficient tumors that are non-responsive to immunotherapy and may inform the selection of patients for combination treatments.",True,other,Not specified
37609286,AUTOSURV: INTERPRETABLE DEEP LEARNING FRAMEWORK FOR CANCER SURVIVAL ANALYSIS INCORPORATING CLINICAL AND MULTI-OMICS DATA,"Accurate prognosis for cancer patients can provide critical information for optimizing treatment plans and improving life quality. Combining omics data and demographic/clinical information can offer a more comprehensive view of cancer prognosis than using omics or clinical data alone and can reveal the underlying disease mechanisms at the molecular level. In this study, we developed a novel deep learning framework to extract information from high-dimensional gene expression and miRNA expression data and conduct prognosis prediction for breast cancer and ovarian cancer patients. Our model achieved significantly better prognosis prediction than the conventional Cox Proportional Hazard model and other competitive deep learning approaches in various settings. Moreover, an interpretation approach was applied to tackle the ""black-box"" nature of deep neural networks and we identified features (i.e., genes, miRNA, demographic/clinical variables) that made important contributions to distinguishing predicted high- and low-risk patients. The identified associations were partially supported by previous studies.",True,other,Not specified
37603758,Modeling islet enhancers using deep learning identifies candidate causal variants at loci associated with T2D and glycemic traits,"Genetic association studies have identified hundreds of independent signals associated with type 2 diabetes (T2D) and related traits. Despite these successes, the identification of specific causal variants underlying a genetic association signal remains challenging. In this study, we describe a deep learning (DL) method to analyze the impact of sequence variants on enhancers. Focusing on pancreatic islets, a T2D relevant tissue, we show that our model learns islet-specific transcription factor (TF) regulatory patterns and can be used to prioritize candidate causal variants. At 101 genetic signals associated with T2D and related glycemic traits where multiple variants occur in linkage disequilibrium, our method nominates a single causal variant for each association signal, including three variants previously shown to alter reporter activity in islet-relevant cell types. For another signal associated with blood glucose levels, we biochemically test all candidate causal variants from statistical fine-mapping using a pancreatic islet beta cell line and show biochemical evidence of allelic effects on TF binding for the model-prioritized variant. To aid in future research, we publicly distribute our model and islet enhancer perturbation scores across ~67 million genetic variants. We anticipate that DL methods like the one presented in this study will enhance the prioritization of candidate causal variants for functional studies.",True,other,Not specified
37600972,XMR: an explainable multimodal neural network for drug response prediction,"Introduction: Existing large-scale preclinical cancer drug response databases provide us with a great opportunity to identify and predict potentially effective drugs to combat cancers. Deep learning models built on these databases have been developed and applied to tackle the cancer drug-response prediction task. Their prediction has been demonstrated to significantly outperform traditional machine learning methods. However, due to the ""black box"" characteristic, biologically faithful explanations are hardly derived from these deep learning models. Interpretable deep learning models that rely on visible neural networks (VNNs) have been proposed to provide biological justification for the predicted outcomes. However, their performance does not meet the expectation to be applied in clinical practice. Methods: In this paper, we develop an XMR model, an eXplainable Multimodal neural network for drug Response prediction. XMR is a new compact multimodal neural network consisting of two sub-networks: a visible neural network for learning genomic features and a graph neural network (GNN) for learning drugs' structural features. Both sub-networks are integrated into a multimodal fusion layer to model the drug response for the given gene mutations and the drug's molecular structures. Furthermore, a pruning approach is applied to provide better interpretations of the XMR model. We use five pathway hierarchies (cell cycle, DNA repair, diseases, signal transduction, and metabolism), which are obtained from the Reactome Pathway Database, as the architecture of VNN for our XMR model to predict drug responses of triple negative breast cancer. Results: We find that our model outperforms other state-of-the-art interpretable deep learning models in terms of predictive performance. In addition, our model can provide biological insights into explaining drug responses for triple-negative breast cancer. Discussion: Overall, combining both VNN and GNN in a multimodal fusion layer, XMR captures key genomic and molecular features and offers reasonable interpretability in biology, thereby better predicting drug responses in cancer patients. Our model would also benefit personalized cancer therapy in the future.",True,other,convolutional neural network
37597705,A Deep Learning Model Enhances Clinicians' Diagnostic Accuracy to More Than 96% for Anterior Cruciate Ligament Ruptures on Magnetic Resonance Imaging,"PURPOSE: To develop a deep learning model to accurately detect anterior cruciate ligament (ACL) ruptures on magnetic resonance imaging (MRI) and to evaluate its effect on the diagnostic accuracy and efficiency of clinicians.
METHODS: A training dataset was built from MRIs acquired from January 2017 to June 2021, including patients with knee symptoms, irrespective of ACL ruptures. An external validation dataset was built from MRIs acquired from January 2021 to June 2022, including patients who underwent knee arthroscopy or arthroplasty. Patients with fractures or prior knee surgeries were excluded in both datasets. Subsequently, a deep learning model was developed and validated using these datasets. Clinicians of varying expertise levels in sports medicine and radiology were recruited, and their capacities in diagnosing ACL injuries in terms of accuracy and diagnosing time were evaluated both with and without artificial intelligence (AI) assistance.
RESULTS: A deep learning model was developed based on the training dataset of 22,767 MRIs from 5 centers and verified with external validation dataset of 4,086 MRIs from 6 centers. The model achieved an area under the receiver operating characteristic curve of 0.987 and a sensitivity and specificity of 95.1%. Thirty-eight clinicians from 25 centers were recruited to diagnose 3,800 MRIs. The AI assistance significantly improved the accuracy of all clinicians, exceeding 96%. Additionally, a notable reduction in diagnostic time was observed. The most significant improvements in accuracy and time efficiency were observed in the trainee groups, suggesting that AI support is particularly beneficial for clinicians with moderately limited diagnostic expertise.
CONCLUSIONS: This deep learning model demonstrated expert-level diagnostic performance for ACL ruptures, serving as a valuable tool to assist clinicians of various specialties and experience levels in making accurate and efficient diagnoses.
LEVEL OF EVIDENCE: Level III, retrospective comparative case series.",True,other,RNN
37578427,Multicenter Validation of Deep Learning Algorithm ROP.AI for the Automated Diagnosis of Plus Disease in ROP,"PURPOSE: Retinopathy of prematurity (ROP) is a sight-threatening vasoproliferative retinal disease affecting premature infants. The detection of plus disease, a severe form of ROP requiring treatment, remains challenging owing to subjectivity, frequency, and time intensity of retinal examinations. Recent artificial intelligence (AI) algorithms developed to detect plus disease aims to alleviate these challenges; however, they have not been tested against a diverse neonatal population. Our study aims to validate ROP.AI, an AI algorithm developed from a single cohort, against a multicenter Australian cohort to determine its performance in detecting plus disease.
METHODS: Retinal images captured during routine ROP screening from May 2021 to February 2022 across five major tertiary centers throughout Australia were collected and uploaded to ROP.AI. AI diagnostic output was compared with one of five ROP experts. Sensitivity, specificity, negative predictive value, and area under the receiver operator curve were determined.
RESULTS: We collected 8052 images. The area under the receiver operator curve for the diagnosis of plus disease was 0.75. ROP.AI achieved 84% sensitivity, 43% specificity, and 96% negative predictive value for the detection of plus disease after operating point optimization.
CONCLUSIONS: ROP.AI was able to detect plus disease in an external, multicenter cohort despite being trained from a single center. Algorithm performance was demonstrated without preprocessing or augmentation, simulating real-world clinical applicability. Further training may improve generalizability for clinical implementation.
TRANSLATIONAL RELEVANCE: These results demonstrate ROP.AI's potential as a screening tool for the detection of plus disease in future clinical practice and provides a solution to overcome current diagnostic challenges.",True,other,RNN
37557177,Non-invasive tumor microenvironment evaluation and treatment response prediction in gastric cancer using deep learning radiomics,"The tumor microenvironment (TME) plays a critical role in disease progression and is a key determinant of therapeutic response in cancer patients. Here, we propose a noninvasive approach to predict the TME status from radiological images by combining radiomics and deep learning analyses. Using multi-institution cohorts of 2,686 patients with gastric cancer, we show that the radiological model accurately predicted the TME status and is an independent prognostic factor beyond clinicopathologic variables. The model further predicts the benefit from adjuvant chemotherapy for patients with localized disease. In patients treated with checkpoint blockade immunotherapy, the model predicts clinical response and further improves predictive accuracy when combined with existing biomarkers. Our approach enables noninvasive assessment of the TME, which opens the door for longitudinal monitoring and tracking response to cancer therapy. Given the routine use of radiologic imaging in oncology, our approach can be extended to many other solid tumor types.",True,both,LSTM
37555737,Can Glaucoma Suspect Data Help to Improve the Performance of Glaucoma Diagnosis?,"PURPOSE: The presence of imbalanced datasets in medical applications can negatively affect deep learning methods. This study aims to investigate how the performance of convolutional neural networks (CNNs) for glaucoma diagnosis can be improved by addressing imbalanced learning issues through utilizing glaucoma suspect samples, which are often excluded from studies because they are a mixture of healthy and preperimetric glaucomatous eyes, in a semi-supervised learning approach.
METHODS: A baseline 3D CNN was developed and trained on a real-world glaucoma dataset, which is naturally imbalanced (like many other real-world medical datasets). Then, three methods, including reweighting samples, data resampling to form balanced batches, and semi-supervised learning on glaucoma suspect data were applied to practically assess their impacts on the performances of the trained methods.
RESULTS: The proposed method achieved a mean accuracy of 95.24%, an F1 score of 97.42%, and an area under the curve of receiver operating characteristic (AUC ROC) of 95.64%, whereas the corresponding results for the traditional supervised training using weighted cross-entropy loss were 92.88%, 96.12%, and 92.72%, respectively. The obtained results show statistically significant improvements in all metrics.
CONCLUSIONS: Exploiting glaucoma suspect eyes in a semi-supervised learning method coupled with resampling can improve glaucoma diagnosis performance by mitigating imbalanced learning issues.
TRANSLATIONAL RELEVANCE: Clinical imbalanced datasets may negatively affect medical applications of deep learning. Utilizing data with uncertain diagnosis, such as glaucoma suspects, through a combination of semi-supervised learning and class-imbalanced learning strategies can partially address the problems of having limited data and learning on imbalanced datasets.",True,other,convolutional neural network
37549921,Deep-learning based classification of a tumor marker for prognosis on Hodgkin's disease,"PURPOSE: Hodgkin's disease is a common malignant disorder in adolescent patients. Although most patients are cured, approximately 10%-15% of patients experience a relapse or have resistant disease. Furthermore, there are no definitive molecular predictors for early identification of patients at high risk of treatment failure to first line therapy. The aim of this study was to evaluate the deep learning-based classifier model of medical image classification to predict clinical outcome that may help in appropriate therapeutic decisions.
METHODS: Eighty-three FFPE biopsy specimens from patients with Hodgkin's disease were stratified according to the patient's qPET scores, stained with picrosirius red dye and digitalized by whole slide image scanning. The resulting whole slide images were cut into tiles and annotated by two classes based on the collagen fibers' degree of coloring with picrosirius red. The neural network (YOLOv4) was then trained with the annotated data. Training was performed with 30 cases. Prognostic power of the weakly stained picrosirius red fibers was evaluated with 53 cases. The same neural network was trained with MMP9 stained tissue slides from the same cases and the quantification results were compared with the variant from the picrosirius red cases.
RESULTS: There was a weak monotonically increasing relationship by parametric ANOVA between the qPET groups and the percentages of weakly stained fibers (p = .0185). The qPET-positive cases showed an average of 18% of weakly stained fibers, and the qPET-negative cases 10%-14%. Detection performance showed an AUC of 0.79.
CONCLUSIONS: Picrosirius red shows distinct associations as a prognostic metric candidate of disease progression in Hodgkin's disease cases using whole slide images but not sufficiently as a prognostic device.",True,other,Not specified
37538741,"An algebraic formula, deep learning and a novel SEIR-type model for the COVID-19 pandemic","The most extensively used mathematical models in epidemiology are the susceptible-exposed-infectious-recovered (SEIR) type models with constant coefficients. For the first wave of the COVID-19 epidemic, such models predict that at large times equilibrium is reached exponentially. However, epidemiological data from Europe suggest that this approach is algebraic. Indeed, accurate long-term predictions have been obtained via a forecasting model only if it uses an algebraic as opposed to the standard exponential formula. In this work, by allowing those parameters of the SEIR model that reflect behavioural aspects (e.g. spatial distancing) to vary nonlinearly with the extent of the epidemic, we construct a model which exhibits asymptoticly algebraic behaviour. Interestingly, the emerging power law is consistent with the typical dynamics observed in various social settings. In addition, using reliable epidemiological data, we solve in a numerically robust way the inverse problem of determining all model parameters characterizing our novel model. Finally, using deep learning, we demonstrate that the algebraic forecasting model used earlier is optimal.",True,text mining,Not specified
37537293,"Machine learning approaches that use clinical, laboratory, and electrocardiogram data enhance the prediction of obstructive coronary artery disease","Pretest probability (PTP) for assessing obstructive coronary artery disease (ObCAD) was updated to reduce overestimation. However, standard laboratory findings and electrocardiogram (ECG) raw data as first-line tests have not been evaluated for integration into the PTP estimation. Therefore, this study developed an ensemble model by adopting machine learning (ML) and deep learning (DL) algorithms with clinical, laboratory, and ECG data for the assessment of ObCAD. Data were extracted from the electronic medical records of patients with suspected ObCAD who underwent coronary angiography. With the ML algorithm, 27 clinical and laboratory data were included to identify ObCAD, whereas ECG waveform data were utilized with the DL algorithm. The ensemble method combined the clinical-laboratory and ECG models. We included 7907 patients between 2008 and 2020. The clinical and laboratory model showed an area under the curve (AUC) of 0.747; the ECG model had an AUC of 0.685. The ensemble model demonstrated the highest AUC of 0.767. The sensitivity, specificity, and F1 score of the ensemble model ObCAD were 0.761, 0.625, and 0.696, respectively. It demonstrated good performance and superior prediction over traditional PTP models. This may facilitate personalized decisions for ObCAD assessment and reduce PTP overestimation.",True,other,Not specified
37536450,"ConCreT, a 2D convolutional neural network for taxonomic classification applied to viruses in the phylum Cressdnaviricota","Taxonomic assignments allow scientists to communicate better with each other. In virology, taxonomy is continually improving towards a more precise and comprehensive framework. With the huge numbers of new viruses being described in metagenomic studies, automated taxonomy tools are urgently needed. A number of such tools have been proposed, and those applying machine learning (ML), mainly in the deep learning branch, stand out with accurate results. Still, there is a demand for tools that are less computationally intensive and that can classify viruses down to the ranks of genus and species. Cressdnaviruses are good subjects for testing such tools, due to their small, circular genomes and the existence of several families and genera with a highly imbalanced number of species. We developed a 2D convolutional neural network for virus taxonomy and tested it for classification of viruses from the phylum Cressdnaviricota. We obtained >98 % accuracy in the final pipeline tested, which we named ConCreT (Convolutional Neural Network for Cressdnavirus Taxonomy). The mixture of augmentation for more imbalanced groups with no augmentation for more balanced ones achieved the best score in the final test.",True,other,autoencoder
37527236,"Deep learning for COVID-19 topic modelling via Twitter: Alpha, Delta and Omicron","Topic modelling with innovative deep learning methods has gained interest for a wide range of applications that includes COVID-19. It can provide, psychological, social and cultural insights for understanding human behaviour in extreme events such as the COVID-19 pandemic. In this paper, we use prominent deep learning-based language models for COVID-19 topic modelling taking into account data from the emergence (Alpha) to the Omicron variant in India. Our results show that the topics extracted for the subsequent waves had certain overlapping themes such as governance, vaccination, and pandemic management while novel issues aroused in political, social and economic situations during the COVID-19 pandemic. We also find a strong correlation between the major topics with news media prevalent during the respective time period. Hence, our framework has the potential to capture major issues arising during different phases of the COVID-19 pandemic which can be extended to other countries and regions.",True,other,convolutional neural network
37516796,An innovative ensemble model based on deep learning for predicting COVID-19 infection,"Nowadays, global public health crises are occurring more frequently, and accurate prediction of these diseases can reduce the burden on the healthcare system. Taking COVID-19 as an example, accurate prediction of infection can assist experts in effectively allocating medical resources and diagnosing diseases. Currently, scholars worldwide use single model approaches or epidemiology models more often to predict the outbreak trend of COVID-19, resulting in poor prediction accuracy. Although a few studies have employed ensemble models, there is still room for improvement in their performance. In addition, there are only a few models that use the laboratory results of patients to predict COVID-19 infection. To address these issues, research efforts should focus on improving disease prediction performance and expanding the use of medical disease prediction models. In this paper, we propose an innovative deep learning model Whale Optimization Convolutional Neural Networks (CNN), Long-Short Term Memory (LSTM) and Artificial Neural Network (ANN) called WOCLSA which incorporates three models ANN, CNN and LSTM. The WOCLSA model utilizes the Whale Optimization Algorithm to optimize the neuron number, dropout and batch size parameters in the integrated model of ANN, CNN and LSTM, thereby finding the global optimal solution parameters. WOCLSA employs 18 patient indicators as predictors, and compares its results with three other ensemble deep learning models. All models were validated with train-test split approaches. We evaluate and compare our proposed model and other models using accuracy, F1 score, recall, AUC and precision metrics. Through many studies and tests, our results show that our prediction models can identify patients with COVID-19 infection at the AUC of 91%, 91%, and 93% respectively. Other prediction results achieve a respectable accuracy of 92.82%, 92.79%, and 91.66% respectively, f1-score of 93.41%, 92.79%, and 92.33% respectively, precision of 93.41%, 92.79%, and 92.33% respectively, recall of 93.41%, 92.79%, and 92.33% respectively. All of these exceed 91%, surpassing those of comparable models. The execution time of WOCLSA is also an advantage. Therefore, the WOCLSA ensemble model can be used to assist in verifying laboratory research results and predict and to judge various diseases in public health events.",True,computer vision,recurrent neural network
37489527,Hindsight2020: Characterizing Uncertainty in the COVID-19 Scientific Literature,"Following emerging, re-emerging, and endemic pathogen outbreaks, the rush to publish and the risk of data misrepresentation, misinterpretation, and even misinformation puts an even greater onus on methodological rigor, which includes revisiting initial assumptions as new evidence becomes available. This study sought to understand how and when early evidence emerges and evolves when addressing different types of recurring pathogen-related questions. By applying claim-matching by means of deep learning Natural Language Processing (NLP) of coronavirus disease 2019 (COVID-19) scientific literature against a set of expert-curated evidence, patterns in timing across different COVID-19 questions-and-answers were identified, to build a framework for characterizing uncertainty in emerging infectious disease (EID) research over time. COVID-19 was chosen as a use case for this framework given the large and accessible datasets curated for scientists during the beginning of the pandemic. Timing patterns in reliably answering broad COVID-19 questions often do not align with general publication patterns, but early expert-curated evidence was generally stable. Because instability in answers often occurred within the first 2 to 6 mo for specific COVID-19 topics, public health officials could apply more conservative policies at the start of future pandemics, to be revised as evidence stabilizes.",True,other,Not specified
37488222,Deep learning predicts patients outcome and mutations from digitized histology slides in gastrointestinal stromal tumor,"Risk assessment of gastrointestinal stromal tumor (GIST) according to the AFIP/Miettinen classification and mutational profiling are major tools for patient management. However, the AFIP/Miettinen classification depends heavily on mitotic counts, which is laborious and sometimes inconsistent between pathologists. It has also been shown to be imperfect in stratifying patients. Molecular testing is costly and time-consuming, therefore, not systematically performed in all countries. New methods to improve risk and molecular predictions are hence crucial to improve the tailoring of adjuvant therapy. We have built deep learning (DL) models on digitized HES-stained whole slide images (WSI) to predict patients' outcome and mutations. Models were trained with a cohort of 1233 GIST and validated on an independent cohort of 286 GIST. DL models yielded comparable results to the Miettinen classification for relapse-free-survival prediction in localized GIST without adjuvant Imatinib (C-index=0.83 in cross-validation and 0.72 for independent testing). DL splitted Miettinen intermediate risk GIST into high/low-risk groups (p value = 0.002 in the training set and p value = 0.29 in the testing set). DL models achieved an area under the receiver operating characteristic curve (AUC) of 0.81, 0.91, and 0.71 for predicting mutations in KIT, PDGFRA and wild type, respectively, in cross-validation and 0.76, 0.90, and 0.55 in independent testing. Notably, PDGFRA exon18 D842V mutation, which is resistant to Imatinib, was predicted with an AUC of 0.87 and 0.90 in cross-validation and independent testing, respectively. Additionally, novel histological criteria predictive of patients' outcome and mutations were identified by reviewing the tiles selected by the models. As a proof of concept, our study showed the possibility of implementing DL with digitized WSI and may represent a reproducible way to improve tailoring therapy and precision medicine for patients with GIST.",True,other,Not specified
37481666,Assessment of emerging pretraining strategies in interpretable multimodal deep learning for cancer prognostication,"BACKGROUND: Deep learning models can infer cancer patient prognosis from molecular and anatomic pathology information. Recent studies that leveraged information from complementary multimodal data improved prognostication, further illustrating the potential utility of such methods. However, current approaches: 1) do not comprehensively leverage biological and histomorphological relationships and 2) make use of emerging strategies to ""pretrain"" models (i.e., train models on a slightly orthogonal dataset/modeling objective) which may aid prognostication by reducing the amount of information required for achieving optimal performance. In addition, model interpretation is crucial for facilitating the clinical adoption of deep learning methods by fostering practitioner understanding and trust in the technology.
METHODS: Here, we develop an interpretable multimodal modeling framework that combines DNA methylation, gene expression, and histopathology (i.e., tissue slides) data, and we compare performance of crossmodal pretraining, contrastive learning, and transfer learning versus the standard procedure.
RESULTS: Our models outperform the existing state-of-the-art method (average 11.54% C-index increase), and baseline clinically driven models (average 11.7% C-index increase). Model interpretations elucidate consideration of biologically meaningful factors in making prognosis predictions.
DISCUSSION: Our results demonstrate that the selection of pretraining strategies is crucial for obtaining highly accurate prognostication models, even more so than devising an innovative model architecture, and further emphasize the all-important role of the tumor microenvironment on disease progression.",True,other,Not specified
37476610,CNN stability training improves robustness to scanner and IHC-based image variability for epithelium segmentation in cervical histology,"BACKGROUND: In digital pathology, image properties such as color, brightness, contrast and blurriness may vary based on the scanner and sample preparation. Convolutional Neural Networks (CNNs) are sensitive to these variations and may underperform on images from a different domain than the one used for training. Robustness to these image property variations is required to enable the use of deep learning in clinical practice and large scale clinical research.
AIMS: CNN Stability Training (CST) is proposed and evaluated as a method to increase CNN robustness to scanner and Immunohistochemistry (IHC)-based image variability.
METHODS: CST was applied to segment epithelium in immunohistological cervical Whole Slide Images (WSIs). CST randomly distorts input tiles and factors the difference between the CNN prediction for the original and distorted inputs within the loss function. CNNs were trained using 114 p16-stained WSIs from the same scanner, and evaluated on 6 WSI test sets, each with 23 to 24 WSIs of the same tissue but different scanner/IHC combinations. Relative robustness (rAUC) was measured as the difference between the AUC on the training domain test set (i.e., baseline test set) and the remaining test sets.
RESULTS: Across all test sets, The AUC of CST models outperformed ""No CST"" models (AUC: 0.940-0.989 vs. 0.905-0.986, p &lt; 1e - 8), and obtained an improved robustness (rAUC: [-0.038, -0.003] vs. [-0.081, -0.002]). At a WSI level, CST models showed an increase in performance in 124 of the 142 WSIs. CST models also outperformed models trained with random on-the-fly data augmentation (DA) in all test sets ([0.002, 0.021], p &lt; 1e-6).
CONCLUSION: CST offers a path to improve CNN performance without the need for more data and allows customizing distortions to specific use cases. A python implementation of CST is publicly available at https://github.com/TIGACenter/CST_v1.",True,other,CNN
37471397,Harnessing the power of AI: Advanced deep learning models optimization for accurate SARS-CoV-2 forecasting,"The pandemic has significantly affected many countries including the USA, UK, Asia, the Middle East and Africa region, and many other countries. Similarly, it has substantially affected Malaysia, making it crucial to develop efficient and precise forecasting tools for guiding public health policies and approaches. Our study is based on advanced deep-learning models to predict the SARS-CoV-2 cases. We evaluate the performance of Long Short-Term Memory (LSTM), Bi-directional LSTM, Convolutional Neural Networks (CNN), CNN-LSTM, Multilayer Perceptron, Gated Recurrent Unit (GRU), and Recurrent Neural Networks (RNN). We trained these models and assessed them using a detailed dataset of confirmed cases, demographic data, and pertinent socio-economic factors. Our research aims to determine the most reliable and accurate model for forecasting SARS-CoV-2 cases in the region. We were able to test and optimize deep learning models to predict cases, with each model displaying diverse levels of accuracy and precision. A comprehensive evaluation of the models' performance discloses the most appropriate architecture for Malaysia's specific situation. This study supports ongoing efforts to combat the pandemic by offering valuable insights into the application of sophisticated deep-learning models for precise and timely SARS-CoV-2 case predictions. The findings hold considerable implications for public health decision-making, empowering authorities to create targeted and data-driven interventions to limit the virus's spread and minimize its effects on Malaysia's population.",True,other,convolutional neural network
37467066,DeepTraSynergy: drug combinations using multimodal deep learning with transformers,"MOTIVATION: Screening bioactive compounds in cancer cell lines receive more attention. Multidisciplinary drugs or drug combinations have a more effective role in treatments and selectively inhibit the growth of cancer cells.
RESULTS: Hence, we propose a new deep learning-based approach for drug combination synergy prediction called DeepTraSynergy. Our proposed approach utilizes multimodal input including drug-target interaction, protein-protein interaction, and cell-target interaction to predict drug combination synergy. To learn the feature representation of drugs, we have utilized transformers. It is worth noting that our approach is a multitask approach that predicts three outputs including the drug-target interaction, its toxic effect, and drug combination synergy. In our approach, drug combination synergy is the main task and the two other ones are the auxiliary tasks that help the approach to learn a better model. In the proposed approach three loss functions are defined: synergy loss, toxic loss, and drug-protein interaction loss. The last two loss functions are designed as auxiliary losses to help learn a better solution. DeepTraSynergy outperforms the classic and state-of-the-art models in predicting synergistic drug combinations on the two latest drug combination datasets. The DeepTraSynergy algorithm achieves accuracy values of 0.7715 and 0.8052 (an improvement over other approaches) on the DrugCombDB and Oncology-Screen datasets, respectively. Also, we evaluate the contribution of each component of DeepTraSynergy to show its effectiveness in the proposed method. The introduction of the relation between proteins (PPI networks) and drug-protein interaction significantly improves the prediction of synergistic drug combinations.
AVAILABILITY AND IMPLEMENTATION: The source code and data are available at https://github.com/fatemeh-rafiei/DeepTraSynergy.",True,other,Not specified
37455284,"Stratification of diabetes in the context of comorbidities, using representation learning and topological data analysis","Diabetes is a heterogenous, multimorbid disorder with a large variation in manifestations, trajectories, and outcomes. The aim of this study is to validate a novel machine learning method for the phenotyping of diabetes in the context of comorbidities. Data from 9967 multimorbid patients with a new diagnosis of diabetes were extracted from Clinical Practice Research Datalink. First, using BEHRT (a transformer-based deep learning architecture), the embeddings corresponding to diabetes were learned. Next, topological data analysis (TDA) was carried out to test how different areas in high-dimensional manifold correspond to different risk profiles. The following endpoints were considered when profiling risk trajectories: major adverse cardiovascular events (MACE), coronary artery disease (CAD), stroke (CVA), heart failure (HF), renal failure (RF), diabetic neuropathy, peripheral arterial disease, reduced visual acuity and all-cause mortality. Kaplan Meier curves were plotted for each derived phenotype. Finally, we tested the performance of an established risk prediction model (QRISK) by adding TDA-derived features. We identified four subgroups of patients with diabetes and divergent comorbidity patterns differing in their risk of future cardiovascular, renal, and other microvascular outcomes. Phenotype 1 (young with chronic inflammatory conditions) and phenotype 2 (young with CAD) included relatively younger patients with diabetes compared to phenotypes 3 (older with hypertension and renal disease) and 4 (older with previous CVA), and those subgroups had a higher frequency of pre-existing cardio-renal diseases. Within ten years of follow-up, 2592 patients (26%) experienced MACE, 2515 patients (25%) died, and 2020 patients (20%) suffered RF. QRISK3 model's AUC was augmented from 67.26% (CI 67.25-67.28%) to 67.67% (CI 67.66-67.69%) by adding specific TDA-derived phenotype and the distances to both extremities of the TDA graph improving its performance in the prediction of CV outcomes. We confirmed the importance of accounting for multimorbidity when risk stratifying heterogenous cohort of patients with new diagnosis of diabetes. Our unsupervised machine learning method improved the prediction of clinical outcomes.",True,other,RNN
37446561,A Novel LSTM-Based Machine Learning Model for Predicting the Activity of Food Protein-Derived Antihypertensive Peptides,"Food protein-derived antihypertensive peptides are a representative type of bioactive peptides. Several models based on partial least squares regression have been constructed to delineate the relationship between the structure and activity of the peptides. Machine-learning-based models have been applied in broad areas, which also indicates their potential to be incorporated into the field of bioactive peptides. In this study, a long short-term memory (LSTM) algorithm-based deep learning model was constructed, which could predict the IC<sub>50</sub> value of the peptide in inhibiting ACE activity. In addition to the test dataset, the model was also validated using randomly synthesized peptides. The LSTM-based model constructed in this study provides an efficient and simplified method for screening antihypertensive peptides from food proteins.",True,other,Not specified
37443696,Recent Advances of Artificial Intelligence Applications in Interstitial Lung Diseases,"Interstitial lung diseases (ILDs) comprise a rather heterogeneous group of diseases varying in pathophysiology, presentation, epidemiology, diagnosis, treatment and prognosis. Even though they have been recognized for several years, there are still areas of research debate. In the majority of ILDs, imaging modalities and especially high-resolution Computed Tomography (CT) scans have been the cornerstone in patient diagnostic approach and follow-up. The intricate nature of ILDs and the accompanying data have led to an increasing adoption of artificial intelligence (AI) techniques, primarily on imaging data but also in genetic data, spirometry and lung diffusion, among others. In this literature review, we describe the most prominent applications of AI in ILDs presented approximately within the last five years. We roughly stratify these studies in three categories, namely: (i) screening, (ii) diagnosis and classification, (iii) prognosis.",True,other,Not specified
37442407,Toward advanced diagnosis and management of inherited arrhythmia syndromes: Harnessing the capabilities of artificial intelligence and machine learning,"The use of advanced computational technologies, such as artificial intelligence (AI), is now exerting a significant influence on various aspects of life, including health care and science. AI has garnered remarkable public notice with the release of deep learning models that can model anything from artwork to academic papers with minimal human intervention. Machine learning, a method that uses algorithms to extract information from raw data and represent it in a model, and deep learning, a method that uses multiple layers to progressively extract higher-level features from the raw input with minimal human intervention, are increasingly leveraged to tackle problems in the health sector, including utilization for clinical decision support in cardiovascular medicine. Inherited arrhythmia syndromes are a clinical domain where multiple unanswered questions remain despite unprecedented progress over the past 2 decades with the introduction of large panel genetic testing and the first steps in precision medicine. In particular, AI tools can help address gaps in clinical diagnosis by identifying individuals with concealed or transient phenotypes; enhance risk stratification by elevating recognition of underlying risk burden beyond widely recognized risk factors; improve prediction of response to therapy, and further prognostication. In this contemporary review, we provide a summary of the AI models developed to solve challenges in inherited arrhythmia syndromes and also outline gaps that can be filled with the development of intelligent AI models.",True,other,convolutional neural network
37440249,A Systematic Review and Meta-Analysis of Applying Deep Learning in the Prediction of the Risk of Cardiovascular Diseases From Retinal Images,"PURPOSE: The purpose of this study was to perform a systematic review and meta-analysis to synthesize evidence from studies using deep learning (DL) to predict cardiovascular disease (CVD) risk from retinal images.
METHODS: A systematic literature search was performed in MEDLINE, Scopus, and Web of Science up to June 2022. We extracted data pertaining to predicted outcomes, model development, and validation and model performance metrics. Included studies were graded using the Quality Assessment of Diagnostic Accuracies Studies 2 tool. Model performance was pooled across eligible studies using a random-effects meta-analysis model.
RESULTS: A total of 26 studies were included in the analysis. There were 42 CVD risk-related outcomes predicted from retinal images were identified, including 33 CVD risk factors, 4 cardiac imaging biomarkers, 2 CVD risk scores, the presence of CVD, and incident CVD. Three studies that aimed to predict the development of future CVD events reported an area under the receiver operating curve (AUROC) between 0.68 and 0.81. Models that used retinal images as input data had a pooled mean absolute error of 3.19 years (95% confidence interval [CI] = 2.95-3.43) for age prediction; a pooled AUROC of 0.96 (95% CI = 0.95-0.97) for gender classification; a pooled AUROC of 0.80 (95% CI = 0.73-0.86) for diabetes detection; and a pooled AUROC of 0.86 (95% CI = 0.81-0.92) for the detection of chronic kidney disease. We observed a high level of heterogeneity and variation in study designs.
CONCLUSIONS: Although DL models appear to have reasonably good performance when it comes to predicting CVD risk, further work is necessary to evaluate the real-world applicability and predictive accuracy.
TRANSLATIONAL RELEVANCE: DL-based CVD risk assessment from retinal images holds great promise to be translated to clinical practice as a novel approach for CVD risk assessment, given its simple, quick, and noninvasive nature.",True,other,Not specified
37440225,"Deep Learning, the Retina, and Parkinson Disease",,True,other,GAN
37429512,AD-BERT: Using pre-trained language model to predict the progression from mild cognitive impairment to Alzheimer's disease,"OBJECTIVE: We develop a deep learning framework based on the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model using unstructured clinical notes from electronic health records (EHRs) to predict the risk of disease progression from Mild Cognitive Impairment (MCI) to Alzheimer's Disease (AD).
METHODS: We identified 3657 patients diagnosed with MCI together with their progress notes from Northwestern Medicine Enterprise Data Warehouse (NMEDW) between 2000 and 2020. The progress notes no later than the first MCI diagnosis were used for the prediction. We first preprocessed the notes by deidentification, cleaning and splitting into sections, and then pre-trained a BERT model for AD (named AD-BERT) based on the publicly available Bio+Clinical BERT on the preprocessed notes. All sections of a patient were embedded into a vector representation by AD-BERT and then combined by global MaxPooling and a fully connected network to compute the probability of MCI-to-AD progression. For validation, we conducted a similar set of experiments on 2563 MCI patients identified at Weill Cornell Medicine (WCM) during the same timeframe.
RESULTS: Compared with the 7 baseline models, the AD-BERT model achieved the best performance on both datasets, with Area Under receiver operating characteristic Curve (AUC) of 0.849 and F1 score of 0.440 on NMEDW dataset, and AUC of 0.883 and F1 score of 0.680 on WCM dataset.
CONCLUSION: The use of EHRs for AD-related research is promising, and AD-BERT shows superior predictive performance in modeling MCI-to-AD progression prediction. Our study demonstrates the utility of pre-trained language models and clinical notes in predicting MCI-to-AD progression, which could have important implications for improving early detection and intervention for AD.",True,other,RNN
37428248,Deep learning model for predicting the survival of patients with primary gastrointestinal lymphoma based on the SEER database and a multicentre external validation cohort,"PURPOSE: Due to the rarity of primary gastrointestinal lymphoma (PGIL), the prognostic factors and optimal management of PGIL have not been clearly defined. We aimed to establish prognostic models using a deep learning algorithm for survival prediction.
METHODS: We collected 11,168 PGIL patients from the Surveillance, Epidemiology, and End Results (SEER) database to form the training and test cohorts. At the same time, we collected 82 PGIL patients from three medical centres to form the external validation cohort. We constructed a Cox proportional hazards (CoxPH) model, random survival forest (RSF) model, and neural multitask logistic regression (DeepSurv) model to predict PGIL patients' overall survival (OS).
RESULTS: The 1-, 3-, 5-, and 10-year OS rates of PGIL patients in the SEER database were 77.1%, 69.4%, 63.7%, and 50.3%, respectively. The RSF model based on all variables showed that the top three most important variables for predicting OS were age, histological type, and chemotherapy. The independent risk factors for PGIL patient prognosis included sex, age, race, primary site, Ann Arbor stage, histological type, symptom, radiotherapy, and chemotherapy, according to the Lasso regression analysis. Using these factors, we built the CoxPH and DeepSurv models. The DeepSurv model's C-index values were 0.760 in the training cohort, 0.742 in the test cohort, and 0.707 in the external validation cohort, which demonstrated that the DeepSurv model performed better compared to the RSF model (0.728) and the CoxPH model (0.724). The DeepSurv model accurately predicted 1-, 3-, 5- and 10-year OS. Both calibration curves and decision curve analysis curves demonstrated the superior performance of the DeepSurv model. We developed the DeepSurv model as an online web calculator for survival prediction, which can be accessed at http://124.222.228.112:8501/ .
CONCLUSIONS: This DeepSurv model with external validation is superior to previous studies in predicting short-term and long-term survival and can help us make better-individualized decisions for PGIL patients.",True,other,Not specified
37405023,Cardiovascular disease/stroke risk stratification in deep learning framework: a review,"The global mortality rate is known to be the highest due to cardiovascular disease (CVD). Thus, preventive, and early CVD risk identification in a non-invasive manner is vital as healthcare cost is increasing day by day. Conventional methods for risk prediction of CVD lack robustness due to the non-linear relationship between risk factors and cardiovascular events in multi-ethnic cohorts. Few recently proposed machine learning-based risk stratification reviews without deep learning (DL) integration. The proposed study focuses on CVD risk stratification by the use of techniques mainly solo deep learning (SDL) and hybrid deep learning (HDL). Using a PRISMA model, 286 DL-based CVD studies were selected and analyzed. The databases included were Science Direct, IEEE Xplore, PubMed, and Google Scholar. This review is focused on different SDL and HDL architectures, their characteristics, applications, scientific and clinical validation, along with plaque tissue characterization for CVD/stroke risk stratification. Since signal processing methods are also crucial, the study further briefly presented Electrocardiogram (ECG)-based solutions. Finally, the study presented the risk due to bias in AI systems. The risk of bias tools used were (I) ranking method (RBS), (II) region-based map (RBM), (III) radial bias area (RBA), (IV) prediction model risk of bias assessment tool (PROBAST), and (V) risk of bias in non-randomized studies-of interventions (ROBINS-I). The surrogate carotid ultrasound image was mostly used in the UNet-based DL framework for arterial wall segmentation. Ground truth (GT) selection is vital for reducing the risk of bias (RoB) for CVD risk stratification. It was observed that the convolutional neural network (CNN) algorithms were widely used since the feature extraction process was automated. The ensemble-based DL techniques for risk stratification in CVD are likely to supersede the SDL and HDL paradigms. Due to the reliability, high accuracy, and faster execution on dedicated hardware, these DL methods for CVD risk assessment are powerful and promising. The risk of bias in DL methods can be best reduced by considering multicentre data collection and clinical evaluation.",True,other,RNN
37395630,Deep neural networks with knockoff features identify nonlinear causal relations and estimate effect sizes in complex biological systems,"BACKGROUND: Learning the causal structure helps identify risk factors, disease mechanisms, and candidate therapeutics for complex diseases. However, although complex biological systems are characterized by nonlinear associations, existing bioinformatic methods of causal inference cannot identify the nonlinear relationships and estimate their effect size.
RESULTS: To overcome these limitations, we developed the first computational method that explicitly learns nonlinear causal relations and estimates the effect size using a deep neural network approach coupled with the knockoff framework, named causal directed acyclic graphs using deep learning variable selection (DAG-deepVASE). Using simulation data of diverse scenarios and identifying known and novel causal relations in molecular and clinical data of various diseases, we demonstrated that DAG-deepVASE consistently outperforms existing methods in identifying true and known causal relations. In the analyses, we also illustrate how identifying nonlinear causal relations and estimating their effect size help understand the complex disease pathobiology, which is not possible using other methods.
CONCLUSIONS: With these advantages, the application of DAG-deepVASE can help identify driver genes and therapeutic agents in biomedical studies and clinical trials.",True,other,convolutional neural network
37387140,An intrinsically interpretable neural network architecture for sequence-to-function learning,"MOTIVATION: Sequence-based deep learning approaches have been shown to predict a multitude of functional genomic readouts, including regions of open chromatin and RNA expression of genes. However, a major limitation of current methods is that model interpretation relies on computationally demanding post hoc analyses, and even then, one can often not explain the internal mechanics of highly parameterized models. Here, we introduce a deep learning architecture called totally interpretable sequence-to-function model (tiSFM). tiSFM improves upon the performance of standard multilayer convolutional models while using fewer parameters. Additionally, while tiSFM is itself technically a multilayer neural network, internal model parameters are intrinsically interpretable in terms of relevant sequence motifs.
RESULTS: We analyze published open chromatin measurements across hematopoietic lineage cell-types and demonstrate that tiSFM outperforms a state-of-the-art convolutional neural network model custom-tailored to this dataset. We also show that it correctly identifies context-specific activities of transcription factors with known roles in hematopoietic differentiation, including Pax5 and Ebf1 for B-cells, and Rorc for innate lymphoid cells. tiSFM's model parameters have biologically meaningful interpretations, and we show the utility of our approach on a complex task of predicting the change in epigenetic state as a function of developmental transition.
AVAILABILITY AND IMPLEMENTATION: The source code, including scripts for the analysis of key findings, can be found at https://github.com/boooooogey/ATAConv, implemented in Python.",True,other,recurrent neural network
37386680,Utilizing an artificial intelligence framework (conditional generative adversarial network) to enhance telemedicine strategies for cancer pain management,"BACKGROUND: The utilization of artificial intelligence (AI) in healthcare has significant potential to revolutionize the delivery of medical services, particularly in the field of telemedicine. In this article, we investigate the capabilities of a specific deep learning model, a generative adversarial network (GAN), and explore its potential for enhancing the telemedicine approach to cancer pain management.
MATERIALS AND METHODS: We implemented a structured dataset comprising demographic and clinical variables from 226 patients and 489 telemedicine visits for cancer pain management. The deep learning model, specifically a conditional GAN, was employed to generate synthetic samples that closely resemble real individuals in terms of their characteristics. Subsequently, four machine learning (ML) algorithms were used to assess the variables associated with a higher number of remote visits.
RESULTS: The generated dataset exhibits a distribution comparable to the reference dataset for all considered variables, including age, number of visits, tumor type, performance status, characteristics of metastasis, opioid dosage, and type of pain. Among the algorithms tested, random forest demonstrated the highest performance in predicting a higher number of remote visits, achieving an accuracy of 0.8 on the test data. The simulations based on ML indicated that individuals who are younger than 45 years old, and those experiencing breakthrough cancer pain, may require an increased number of telemedicine-based clinical evaluations.
CONCLUSION: As the advancement of healthcare processes relies on scientific evidence, AI techniques such as GANs can play a vital role in bridging knowledge gaps and accelerating the integration of telemedicine into clinical practice. Nonetheless, it is crucial to carefully address the limitations of these approaches.",True,other,convolutional neural network
37370031,Monkeypox detection using deep neural networks,"BACKGROUND: In May 2022, the World Health Organization (WHO) European Region announced an atypical Monkeypox epidemic in response to reports of numerous cases in some member countries unrelated to those where the illness is endemic. This issue has raised concerns about the widespread nature of this disease around the world. The experience with Coronavirus Disease 2019 (COVID-19) has increased awareness about pandemics among researchers and health authorities.
METHODS: Deep Neural Networks (DNNs) have shown promising performance in detecting COVID-19 and predicting its outcomes. As a result, researchers have begun applying similar methods to detect Monkeypox disease. In this study, we utilize a dataset comprising skin images of three diseases: Monkeypox, Chickenpox, Measles, and Normal cases. We develop seven DNN models to identify Monkeypox from these images. Two scenarios of including two classes and four classes are implemented.
RESULTS: The results show that our proposed DenseNet201-based architecture has the best performance, with Accuracy = 97.63%, F1-Score = 90.51%, and Area Under Curve (AUC) = 94.27% in two-class scenario; and Accuracy = 95.18%, F1-Score = 89.61%, AUC = 92.06% for four-class scenario. Comparing our study with previous studies with similar scenarios, shows that our proposed model demonstrates superior performance, particularly in terms of the F1-Score metric. For the sake of transparency and explainability, Local Interpretable Model-Agnostic Explanations (LIME) and Gradient-weighted Class Activation Mapping (Grad-Cam) were developed to interpret the results. These techniques aim to provide insights into the decision-making process, thereby increasing the trust of clinicians.
CONCLUSION: The DenseNet201 model outperforms the other models in terms of the confusion metrics, regardless of the scenario. One significant accomplishment of this study is the utilization of LIME and Grad-Cam to identify the affected areas and assess their significance in diagnosing diseases based on skin images. By incorporating these techniques, we enhance our understanding of the infected regions and their relevance in distinguishing Monkeypox from other similar diseases. Our proposed model can serve as a valuable auxiliary tool for diagnosing Monkeypox and distinguishing it from other related conditions.",True,other,Not specified
37354819,"Reviewing methods of deep learning for diagnosing COVID-19, its variants and synergistic medicine combinations","The COVID-19 pandemic has necessitated the development of reliable diagnostic methods for accurately detecting the novel coronavirus and its variants. Deep learning (DL) techniques have shown promising potential as screening tools for COVID-19 detection. In this study, we explore the realistic development of DL-driven COVID-19 detection methods and focus on the fully automatic framework using available resources, which can effectively investigate various coronavirus variants through modalities. We conducted an exploration and comparison of several diagnostic techniques that are widely used and globally validated for the detection of COVID-19. Furthermore, we explore review-based studies that provide detailed information on synergistic medicine combinations for the treatment of COVID-19. We recommend DL methods that effectively reduce time, cost, and complexity, providing valuable guidance for utilizing available synergistic combinations in clinical and research settings. This study also highlights the implication of innovative diagnostic technical and instrumental strategies, exploring public datasets, and investigating synergistic medicines using optimised DL rules. By summarizing these findings, we aim to assist future researchers in their endeavours by providing a comprehensive overview of the implication of DL techniques in COVID-19 detection and treatment. Integrating DL methods with various diagnostic approaches holds great promise in improving the accuracy and efficiency of COVID-19 diagnostics, thus contributing to effective control and management of the ongoing pandemic.",True,other,Not specified
37350910,Evaluate underdiagnosis and overdiagnosis bias of deep learning model on primary open-angle glaucoma diagnosis in under-served populations,"In the United States, primary open-angle glaucoma (POAG) is the leading cause of blindness, especially among African American and Hispanic individuals. Deep learning has been widely used to detect POAG using fundus images as its performance is comparable to or even surpasses diagnosis by clinicians. However, human bias in clinical diagnosis may be reflected and amplified in the widely-used deep learning models, thus impacting their performance. Biases may cause (1) underdiagnosis, increasing the risks of delayed or inadequate treatment, and (2) overdiagnosis, which may increase individuals' stress, fear, well-being, and unnecessary/costly treatment. In this study, we examined the underdiagnosis and overdiagnosis when applying deep learning in POAG detection based on the Ocular Hypertension Treatment Study (OHTS) from 22 centers across 16 states in the United States. Our results show that the widely-used deep learning model can underdiagnose or overdiagnose under-served populations. The most underdiagnosed group is female younger (< 60 yrs) group, and the most overdiagnosed group is Black older (≥ 60 yrs) group. Biased diagnosis through traditional deep learning methods may delay disease detection, treatment and create burdens among under-served populations, thereby, raising ethical concerns about using deep learning models in ophthalmology clinics.",True,other,Not specified
37349390,Rapid and stain-free quantification of viral plaque via lens-free holography and deep learning,"A plaque assay-the gold-standard method for measuring the concentration of replication-competent lytic virions-requires staining and usually more than 48 h of runtime. Here we show that lens-free holographic imaging and deep learning can be combined to expedite and automate the assay. The compact imaging device captures phase information label-free at a rate of approximately 0.32 gigapixels per hour per well, covers an area of about 30 × 30 mm2 and a 10-fold larger dynamic range of virus concentration than standard assays, and quantifies the infected area and the number of plaque-forming units. For the vesicular stomatitis virus, the automated plaque assay detected the first cell-lysing events caused by viral replication as early as 5 h after incubation, and in less than 20 h it detected plaque-forming units at rates higher than 90% at 100% specificity. Furthermore, it reduced the incubation time of the herpes simplex virus type 1 by about 48 h and that of the encephalomyocarditis virus by about 20 h. The stain-free assay should be amenable for use in virology research, vaccine development and clinical diagnosis.",True,both,Not specified
37329617,Geometric graph neural networks on multi-omics data to predict cancer survival outcomes,"The advance of sequencing technologies has enabled a thorough molecular characterization of the genome in human cancers. To improve patient prognosis predictions and subsequent treatment strategies, it is imperative to develop advanced computational methods to analyze large-scale, high-dimensional genomic data. However, traditional machine learning methods face a challenge in handling the high-dimensional, low-sample size problem that is shown in most genomic data sets. To address this, our group has developed geometric network analysis techniques on multi-omics data in connection with prior biological knowledge derived from protein-protein interactions (PPIs) or pathways. Geometric features obtained from the genomic network, such as Ollivier-Ricci curvature and the invariant measure of the associated Markov chain, have been shown to be predictive of survival outcomes in various cancers. In this study, we propose a novel supervised deep learning method called geometric graph neural network (GGNN) that incorporates such geometric features into deep learning for enhanced predictive power and interpretability. More specifically, we utilize a state-of-the-art graph neural network with sparse connections between the hidden layers based on known biology of the PPI network and pathway information. Geometric features along with multi-omics data are then incorporated into the corresponding layers. The proposed approach utilizes a local-global principle in such a manner that highly predictive features are selected at the front layers and fed directly to the last layer for multivariable Cox proportional-hazards regression modeling. The method was applied to multi-omics data from the CoMMpass study of multiple myeloma and ten major cancers in The Cancer Genome Atlas (TCGA). In most experiments, our method showed superior predictive performance compared to other alternative methods.",True,other,Not specified
37313740,Deep Learning Versus Neurologists: Functional Outcome Prediction in LVO Stroke Patients Undergoing Mechanical Thrombectomy,"BACKGROUND: Despite evolving treatments, functional recovery in patients with large vessel occlusion stroke remains variable and outcome prediction challenging. Can we improve estimation of functional outcome with interpretable deep learning models using clinical and magnetic resonance imaging data?
METHODS: In this observational study, we collected data of 222 patients with middle cerebral artery M1 segment occlusion who received mechanical thrombectomy. In a 5-fold cross validation, we evaluated interpretable deep learning models for predicting functional outcome in terms of modified Rankin scale at 3 months using clinical variables, diffusion weighted imaging and perfusion weighted imaging, and a combination thereof. Based on 50 test patients, we compared model performances to those of 5 experienced stroke neurologists. Prediction performance for ordinal (modified Rankin scale score, 0-6) and binary (modified Rankin scale score, 0-2 versus 3-6) functional outcome was assessed using discrimination and calibration measures like area under the receiver operating characteristic curve and accuracy (percentage of correctly classified patients).
RESULTS: In the cross validation, the model based on clinical variables and diffusion weighted imaging achieved the highest binary prediction performance (area under the receiver operating characteristic curve, 0.766 [0.727-0.803]). Performance of models using clinical variables or diffusion weighted imaging only was lower. Adding perfusion weighted imaging did not improve outcome prediction. On the test set of 50 patients, binary prediction performance between model (accuracy, 60% [55.4%-64.4%]) and neurologists (accuracy, 60% [55.8%-64.21%]) was similar when using clinical data. However, models significantly outperformed neurologists when imaging data were provided, alone or in combination with clinical variables (accuracy, 72% [67.8%-76%] versus 64% [59.8%-68.4%] with clinical and imaging data). Prediction performance of neurologists with comparable experience varied strongly.
CONCLUSIONS: We hypothesize that early prediction of functional outcome in large vessel occlusion stroke patients may be significantly improved if neurologists are supported by interpretable deep learning models.",True,other,Not specified
37312249,Survival analysis using deep learning with medical imaging,"There is widespread interest in using deep learning to build prediction models for medical imaging data. These deep learning methods capture the local structure of the image and require no manual feature extraction. Despite the importance of modeling survival in the context of medical data analysis, research on deep learning methods for modeling the relationship of imaging and time-to-event data is still under-developed. We provide an overview of deep learning methods for time-to-event outcomes and compare several deep learning methods to Cox model based methods through the analysis of a histology dataset of gliomas.",True,other,convolutional neural network
37304045,Deep-GA-Net for Accurate and Explainable Detection of Geographic Atrophy on OCT Scans,"OBJECTIVE: To propose Deep-GA-Net, a 3-dimensional (3D) deep learning network with 3D attention layer, for the detection of geographic atrophy (GA) on spectral domain OCT (SD-OCT) scans, explain its decision making, and compare it with existing methods.
DESIGN: Deep learning model development.
PARTICIPANTS: Three hundred eleven participants from the Age-Related Eye Disease Study 2 Ancillary SD-OCT Study.
METHODS: A dataset of 1284 SD-OCT scans from 311 participants was used to develop Deep-GA-Net. Cross-validation was used to evaluate Deep-GA-Net, where each testing set contained no participant from the corresponding training set. En face heatmaps and important regions at the B-scan level were used to visualize the outputs of Deep-GA-Net, and 3 ophthalmologists graded the presence or absence of GA in them to assess the explainability (i.e., understandability and interpretability) of its detections.
MAIN OUTCOME MEASURES: Accuracy, area under receiver operating characteristic curve (AUC), area under precision-recall curve (APR).
RESULTS: Compared with other networks, Deep-GA-Net achieved the best metrics, with accuracy of 0.93, AUC of 0.94, and APR of 0.91, and received the best gradings of 0.98 and 0.68 on the en face heatmap and B-scan grading tasks, respectively.
CONCLUSIONS: Deep-GA-Net was able to detect GA accurately from SD-OCT scans. The visualizations of Deep-GA-Net were more explainable, as suggested by 3 ophthalmologists. The code and pretrained models are publicly available at https://github.com/ncbi/Deep-GA-Net.
FINANCIAL DISCLOSURES: The author(s) have no proprietary or commercial interest in any materials discussed in this article.",True,other,convolutional neural network
37297547,Analysis and Prediction of COVID-19 Multivariate Data Using Deep Ensemble Learning Methods,"The global economy has suffered losses as a result of the COVID-19 epidemic. Accurate and effective predictive models are necessary for the governance and readiness of the healthcare system and its resources and, ultimately, for the prevention of the spread of illness. The primary objective of the project is to build a robust, universal method for predicting COVID-19-positive cases. Collaborators will benefit from this while developing and revising their pandemic response plans. For accurate prediction of the spread of COVID-19, the research recommends an adaptive gradient LSTM model (AGLSTM) using multivariate time series data. RNN, LSTM, LASSO regression, Ada-Boost, Light Gradient Boosting and KNN models are also used in the research, which accurately and reliably predict the course of this unpleasant disease. The proposed technique is evaluated under two different experimental conditions. The former uses case studies from India to validate the methodology, while the latter uses data fusion and transfer-learning techniques to reuse data and models to predict the onset of COVID-19. The model extracts important advanced features that influence the COVID-19 cases using a convolutional neural network and predicts the cases using adaptive LSTM after CNN processes the data. The experiment results show that the output of AGLSTM outperforms with an accuracy of 99.81% and requires only a short time for training and prediction.",True,text mining,recurrent neural network
37295898,Differential diagnosis of secondary hypertension based on deep learning,"Secondary hypertension is associated with higher risks of target organ damage and cardiovascular and cerebrovascular disease events. Early aetiology identification can eliminate aetiologies and control blood pressure. However, inexperienced doctors often fail to diagnose secondary hypertension, and comprehensively screening for all causes of high blood pressure increases health care costs. To date, deep learning has rarely been involved in the differential diagnosis of secondary hypertension. Relevant machine learning methods cannot combine textual information such as chief complaints with numerical information such as the laboratory examination results in electronic health records (EHRs), and the use of all features increases health care costs. To reduce redundant examinations and accurately identify secondary hypertension, we propose a two-stage framework that follows clinical procedures. The framework carries out an initial diagnosis process in the first stage, on which basis patients are recommended for disease-related examinations, followed by differential diagnoses of different diseases based on the different characteristics observed in the second stage. We convert the numerical examination results into descriptive sentences, thus blending textual and numerical characteristics. Medical guidelines are introduced through label embedding and attention mechanisms to obtain interactive features. Our model was trained and evaluated using a cross-sectional dataset containing 11,961 patients with hypertension from January 2013 to December 2019. The F1 scores of our model were 0.912, 0.921, 0.869 and 0.894 for primary aldosteronism, thyroid disease, nephritis and nephrotic syndrome and chronic kidney disease, respectively, which are four kinds of secondary hypertension with high incidence rates. The experimental results show that our model can powerfully use the textual and numerical data contained in EHRs to provide effective decision support for the differential diagnosis of secondary hypertension.",True,other,RNN
37292965,Correlating Deep Learning-Based Automated Reference Kidney Histomorphometry with Patient Demographics and Creatinine,"BACKGROUND: Reference histomorphometric data of healthy human kidneys are largely lacking due to laborious quantitation requirements. Correlating histomorphometric features with clinical parameters through machine learning approaches can provide valuable information about natural population variance. To this end, we leveraged deep learning, computational image analysis, and feature analysis to investigate the relationship of histomorphometry with patient age, sex, and serum creatinine (SCr) in a multinational set of reference kidney tissue sections.
METHODS: A panoptic segmentation neural network was developed and used to segment viable and sclerotic glomeruli, cortical and medullary interstitia, tubules, and arteries/arterioles in the digitized images of 79 periodic acid-Schiff-stained human nephrectomy sections showing minimal pathologic changes. Simple morphometrics (e.g., area, radius, density) were quantified from the segmented classes. Regression analysis aided in determining the relationship of histomorphometric parameters with age, sex, and SCr.
RESULTS: Our deep-learning model achieved high segmentation performance for all test compartments. The size and density of nephrons and arteries/arterioles varied significantly among healthy humans, with potentially large differences between geographically diverse patients. Nephron size was significantly dependent on SCr. Slight, albeit significant, differences in renal vasculature were observed between sexes. Glomerulosclerosis percentage increased, and cortical density of arteries/arterioles decreased, as a function of age.
CONCLUSIONS: Using deep learning, we automated precise measurements of kidney histomorphometric features. In the reference kidney tissue, several histomorphometric features demonstrated significant correlation to patient demographics and SCr. Deep learning tools can increase the efficiency and rigor of histomorphometric analysis.",True,other,convolutional neural network
37286945,Electrocardiogram-based deep learning algorithm for the screening of obstructive coronary artery disease,"BACKGROUND: Information on electrocardiogram (ECG) has not been quantified in obstructive coronary artery disease (ObCAD), despite the deep learning (DL) algorithm being proposed as an effective diagnostic tool for acute myocardial infarction (AMI). Therefore, this study adopted a DL algorithm to suggest the screening of ObCAD from ECG.
METHODS: ECG voltage-time traces within a week from coronary angiography (CAG) were extracted for the patients who received CAG for suspected CAD in a single tertiary hospital from 2008 to 2020. After separating the AMI group, those were classified into ObCAD and non-ObCAD groups based on the CAG results. A DL-based model adopting ResNet was built to extract information from ECG data in the patients with ObCAD relative to those with non-ObCAD, and compared the performance with AMI. Moreover, subgroup analysis was conducted using ECG patterns of computer-assisted ECG interpretation.
RESULTS: The DL model demonstrated modest performance in suggesting the probability of ObCAD but excellent performance in detecting AMI. The AUC of the ObCAD model adopting 1D ResNet was 0.693 and 0.923 in detecting AMI. The accuracy, sensitivity, specificity, and F1 score of the DL model for screening ObCAD were 0.638, 0.639, 0.636, and 0.634, respectively, while the figures were up to 0.885, 0.769, 0.921, and 0.758 for detecting AMI, respectively. Subgroup analysis showed that the difference between normal and abnormal/borderline ECG groups was not notable.
CONCLUSIONS: ECG-based DL model showed fair performance for assessing ObCAD and it may serve as an adjunct to the pre-test probability in patients with suspected ObCAD during the initial evaluation. With further refinement and evaluation, ECG coupled with the DL algorithm may provide potential front-line screening support in the resource-intensive diagnostic pathways.",True,other,Not specified
37285245,Construction of Gene Expression Patterns to Identify Critical Genes Under SARS-CoV-2 Infection Conditions,"Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) is a positive-stranded single-stranded RNA virus with an envelope frequently altered by unstable genetic material, making it extremely difficult for vaccines, drugs, and diagnostics to work. Understanding SARS-CoV-2 infection mechanisms requires studying gene expression changes. Deep learning methods are often considered for large-scale gene expression profiling data. Data feature-oriented analysis, however, neglects the biological process nature of gene expression, making it difficult to describe gene expression behaviors accurately. In this article, we propose a novel scheme for modeling gene expression during SARS-CoV-2 infection as networks (gene expression modes, GEM), to characterize their expression behaviors. On this basis, we investigated the relationships among GEMs to determine SARS-CoV-2's core radiation mode. Our final experiments identified key COVID-19 genes by gene function enrichment, protein interaction, and module mining. Experimental results show that ATG10, ATG14, MAP1LC3B, OPTN, WDR45, and WIPI1 genes contribute to SARS-CoV-2 virus spread by affecting autophagy.",True,other,Not specified
37277578,A deep-learning-based clinical risk stratification for overall survival in adolescent and young adult women with breast cancer,"OBJECTIVE: The objective of this study is to construct a novel clinical risk stratification for overall survival (OS) prediction in adolescent and young adult (AYA) women with breast cancer.
METHOD: From the Surveillance, Epidemiology, and End Results (SEER) database, AYA women with primary breast cancer diagnosed from 2010 to 2018 were included in our study. A deep learning algorithm, referred to as DeepSurv, was used to construct a prognostic predictive model based on 19 variables, including demographic and clinical information. Harrell's C-index, the receiver operating characteristic (ROC) curve, and calibration plots were adopted to comprehensively assess the predictive performance of the prognostic predictive model. Then, a novel clinical risk stratification was constructed based on the total risk score derived from the prognostic predictive model. The Kaplan-Meier method was used to plot survival curves for patients with different death risks, using the log-rank test to compared the survival disparities. Decision curve analyses (DCAs) were adopted to evaluate the clinical utility of the prognostic predictive model.
RESULTS: Among 14,243 AYA women with breast cancer finally included in this study, 10,213 (71.7%) were White and the median (interquartile range, IQR) age was 36 (32-38) years. The prognostic predictive model based on DeepSurv presented high C-indices in both the training cohort [0.831 (95% CI 0.819-0.843)] and the test cohort [0.791 (95% CI 0.764-0.818)]. Similar results were observed in ROC curves. The excellent agreement between the predicted and actual OS at 3 and 5 years were both achieved in the calibration plots. The obvious survival disparities were observed according to the clinical risk stratification based on the total risk score derived from the prognostic predictive model. DCAs also showed that the risk stratification possessed a significant positive net benefit in the practical ranges of threshold probabilities. Lastly, a user-friendly Web-based calculator was generated to visualize the prognostic predictive model.
CONCLUSION: A prognostic predictive model with sufficient prediction accuracy was construct for predicting OS of AYA women with breast cancer. Given its public accessibility and easy-to-use operation, the clinical risk stratification based on the total risk score derived from the prognostic predictive model may help clinicians to make better-individualized management.",True,other,Not specified
37276449,Performance of an automated deep learning algorithm to identify hepatic steatosis within noncontrast computed tomography scans among people with and without HIV,"PURPOSE: Hepatic steatosis (fatty liver disease) affects 25% of the world's population, particularly people with HIV (PWH). Pharmacoepidemiologic studies to identify medications associated with steatosis have not been conducted because methods to evaluate liver fat within digitized images have not been developed. We determined the accuracy of a deep learning algorithm (automatic liver attenuation region-of-interest-based measurement [ALARM]) to identify steatosis within clinically obtained noncontrast abdominal CT images compared to manual radiologist review and evaluated its performance by HIV status.
METHODS: We performed a cross-sectional study to evaluate the performance of ALARM within noncontrast abdominal CT images from a sample of patients with and without HIV in the US Veterans Health Administration. We evaluated the ability of ALARM to identify moderate-to-severe hepatic steatosis, defined by mean absolute liver attenuation <40 Hounsfield units (HU), compared to manual radiologist assessment.
RESULTS: Among 120 patients (51 PWH) who underwent noncontrast abdominal CT, moderate-to-severe hepatic steatosis was identified in 15 (12.5%) persons via ALARM and 12 (10%) by radiologist assessment. Percent agreement between ALARM and radiologist assessment of absolute liver attenuation <40 HU was 95.8%. Sensitivity, specificity, positive predictive value, and negative predictive value of ALARM were 91.7% (95%CI, 51.5%-99.8%), 96.3% (95%CI, 90.8%-99.0%), 73.3% (95%CI, 44.9%-92.2%), and 99.0% (95%CI, 94.8%-100%), respectively. No differences in performance were observed by HIV status.
CONCLUSIONS: ALARM demonstrated excellent accuracy for moderate-to-severe hepatic steatosis regardless of HIV status. Application of ALARM to radiographic repositories could facilitate real-world studies to evaluate medications associated with steatosis and assess differences by HIV status.",True,other,Not specified
37267604,Correction: Unassisted Clinicians Versus Deep Learning-Assisted Clinicians in Image-Based Cancer Diagnostics: Systematic Review With Meta-analysis,[This corrects the article DOI: 10.2196/43832.].,True,text mining,Not specified
37265875,Cardiovascular disease risk assessment using a deep-learning-based retinal biomarker: a comparison with existing risk scores,"AIMS: This study aims to evaluate the ability of a deep-learning-based cardiovascular disease (CVD) retinal biomarker, Reti-CVD, to identify individuals with intermediate- and high-risk for CVD.
METHODS AND RESULTS: We defined the intermediate- and high-risk groups according to Pooled Cohort Equation (PCE), QRISK3, and modified Framingham Risk Score (FRS). Reti-CVD's prediction was compared to the number of individuals identified as intermediate- and high-risk according to standard CVD risk assessment tools, and sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) were calculated to assess the results. In the UK Biobank, among 48 260 participants, 20 643 (42.8%) and 7192 (14.9%) were classified into the intermediate- and high-risk groups according to PCE, and QRISK3, respectively. In the Singapore Epidemiology of Eye Diseases study, among 6810 participants, 3799 (55.8%) were classified as intermediate- and high-risk group according to modified FRS. Reti-CVD identified PCE-based intermediate- and high-risk groups with a sensitivity, specificity, PPV, and NPV of 82.7%, 87.6%, 86.5%, and 84.0%, respectively. Reti-CVD identified QRISK3-based intermediate- and high-risk groups with a sensitivity, specificity, PPV, and NPV of 82.6%, 85.5%, 49.9%, and 96.6%, respectively. Reti-CVD identified intermediate- and high-risk groups according to the modified FRS with a sensitivity, specificity, PPV, and NPV of 82.1%, 80.6%, 76.4%, and 85.5%, respectively.
CONCLUSION: The retinal photograph biomarker (Reti-CVD) was able to identify individuals with intermediate and high-risk for CVD, in accordance with existing risk assessment tools.",True,other,recurrent neural network
37250800,Performance of deep learning algorithms to distinguish high-grade glioma from low-grade glioma: A systematic review and meta-analysis,"This study aims to evaluate deep learning (DL) performance in differentiating low- and high-grade glioma. Search online database for studies continuously published from 1st January 2015 until 16th August 2022. The random-effects model was used for synthesis, based on pooled sensitivity (SE), specificity (SP), and area under the curve (AUC). Heterogeneity was estimated using the Higgins inconsistency index (I2). 33 were ultimately included in the meta-analysis. The overall pooled SE and SP were 94% and 93%, with an AUC of 0.98. There was great heterogeneity in this field. Our evidence-based study shows DL achieves high accuracy in glioma grading. Subgroup analysis reveals several limitations in this field: 1) Diagnostic trials require standard method for data merging for AI; 2) small sample size; 3) poor-quality image preprocessing; 4) not standard algorithm development; 5) not standard data report; 6) different definition of HGG and LGG; and 7) poor extrapolation.",True,other,recurrent neural network
37248229,Evidence-driven spatiotemporal COVID-19 hospitalization prediction with Ising dynamics,"In this work, we aim to accurately predict the number of hospitalizations during the COVID-19 pandemic by developing a spatiotemporal prediction model. We propose HOIST, an Ising dynamics-based deep learning model for spatiotemporal COVID-19 hospitalization prediction. By drawing the analogy between locations and lattice sites in statistical mechanics, we use the Ising dynamics to guide the model to extract and utilize spatial relationships across locations and model the complex influence of granular information from real-world clinical evidence. By leveraging rich linked databases, including insurance claims, census information, and hospital resource usage data across the U.S., we evaluate the HOIST model on the large-scale spatiotemporal COVID-19 hospitalization prediction task for 2299 counties in the U.S. In the 4-week hospitalization prediction task, HOIST achieves 368.7 mean absolute error, 0.6 [Formula: see text] and 0.89 concordance correlation coefficient score on average. Our detailed number needed to treat (NNT) and cost analysis suggest that future COVID-19 vaccination efforts may be most impactful in rural areas. This model may serve as a resource for future county and state-level vaccination efforts.",True,computer vision,convolutional neural network
37238994,Classification of Highly Divergent Viruses from DNA/RNA Sequence Using Transformer-Based Models,"Viruses infect millions of people worldwide each year, and some can lead to cancer or increase the risk of cancer. As viruses have highly mutable genomes, new viruses may emerge in the future, such as COVID-19 and influenza. Traditional virology relies on predefined rules to identify viruses, but new viruses may be completely or partially divergent from the reference genome, rendering statistical methods and similarity calculations insufficient for all genome sequences. Identifying DNA/RNA-based viral sequences is a crucial step in differentiating different types of lethal pathogens, including their variants and strains. While various tools in bioinformatics can align them, expert biologists are required to interpret the results. Computational virology is a scientific field that studies viruses, their origins, and drug discovery, where machine learning plays a crucial role in extracting domain- and task-specific features to tackle this challenge. This paper proposes a genome analysis system that uses advanced deep learning to identify dozens of viruses. The system uses nucleotide sequences from the NCBI GenBank database and a BERT tokenizer to extract features from the sequences by breaking them down into tokens. We also generated synthetic data for viruses with small sample sizes. The proposed system has two components: a scratch BERT architecture specifically designed for DNA analysis, which is used to learn the next codons unsupervised, and a classifier that identifies important features and understands the relationship between genotype and phenotype. Our system achieved an accuracy of 97.69% in identifying viral sequences.",True,other,Not specified
37220017,Biologically Interpretable Deep Learning To Predict Response to Immunotherapy In Advanced Melanoma Using Mutations and Copy Number Variations,"Only 30-40% of advanced melanoma patients respond effectively to immunotherapy in clinical practice, so it is necessary to accurately identify the response of patients to immunotherapy pre-clinically. Here, we develop KP-NET, a deep learning model that is sparse on KEGG pathways, and combine it with transfer- learning to accurately predict the response of advanced melanomas to immunotherapy using KEGG pathway-level information enriched from gene mutation and copy number variation data. The KP-NET demonstrates best performance with AUROC of 0.886 on testing set and 0.803 on an unseen evaluation set when predicting responders (CR/PR/SD with PFS ≥6 mo) versus non-responders (PD/SD with PFS <6 mo) in anti-CTLA-4 treated melanoma patients. The model also achieves an AUROC of 0.917 and 0.833 in predicting CR/PR versus PD, respectively. Meanwhile, the AUROC is 0.913 when predicting responders versus non-responders in anti-PD-1/PD-L1 melanomas. Moreover, the KP-NET reveals some genes and pathways associated with response to anti-CTLA-4 treatment, such as genes PIK3CA, AOX1 and CBLB, and ErbB signaling pathway, T cell receptor signaling pathway, et al. In conclusion, the KP-NET can accurately predict the response of melanomas to immunotherapy and screen related biomarkers pre-clinically, which can contribute to precision medicine of melanoma.",True,other,Not specified
37216736,E2EFP-MIL: End-to-end and high-generalizability weakly supervised deep convolutional network for lung cancer classification from whole slide image,"Efficient and accurate distinction of histopathological subtype of lung cancer is quite critical for the individualized treatment. So far, artificial intelligence techniques have been developed, whose performance yet remained debatable on more heterogenous data, hindering their clinical deployment. Here, we propose an end-to-end, well-generalized and data-efficient weakly supervised deep learning-based method. The method, end-to-end feature pyramid deep multi-instance learning model (E2EFP-MIL), contains an iterative sampling module, a trainable feature pyramid module and a robust feature aggregation module. E2EFP-MIL uses end-to-end learning to extract generalized morphological features automatically and identify discriminative histomorphological patterns. This method is trained with 1007 whole slide images (WSIs) of lung cancer from TCGA, with AUCs of 0.95-0.97 in test sets. We validated E2EFP-MIL in 5 real-world external heterogenous cohorts including nearly 1600 WSIs from both United States and China with AUCs of 0.94-0.97, and found that 100-200 training images are enough to achieve an AUC of >0.9. E2EFP-MIL overperforms multiple state-of-the-art MIL-based methods with high accuracy and low hardware requirements. Excellent and robust results prove generalizability and effectiveness of E2EFP-MIL in clinical practice. Our code is available at https://github.com/raycaohmu/E2EFP-MIL.",True,other,recurrent neural network
37213516,Genomic representation predicts an asymptotic host adaptation of bat coronaviruses using deep learning,"INTRODUCTION: Coronaviruses (CoVs) are naturally found in bats and can occasionally cause infection and transmission in humans and other mammals. Our study aimed to build a deep learning (DL) method to predict the adaptation of bat CoVs to other mammals.
METHODS: The CoV genome was represented with a method of dinucleotide composition representation (DCR) for the two main viral genes, ORF1ab and Spike. DCR features were first analyzed for their distribution among adaptive hosts and then trained with a DL classifier of convolutional neural networks (CNN) to predict the adaptation of bat CoVs.
RESULTS AND DISCUSSION: The results demonstrated inter-host separation and intra-host clustering of DCR-represented CoVs for six host types: Artiodactyla, Carnivora, Chiroptera, Primates, Rodentia/Lagomorpha, and Suiformes. The DCR-based CNN with five host labels (without Chiroptera) predicted a dominant adaptation of bat CoVs to Artiodactyla hosts, then to Carnivora and Rodentia/Lagomorpha mammals, and later to primates. Moreover, a linear asymptotic adaptation of all CoVs (except Suiformes) from Artiodactyla to Carnivora and Rodentia/Lagomorpha and then to Primates indicates an asymptotic bats-other mammals-human adaptation.
CONCLUSION: Genomic dinucleotides represented as DCR indicate a host-specific separation, and clustering predicts a linear asymptotic adaptation shift of bat CoVs from other mammals to humans via deep learning.",True,other,Not specified
37213271,Interpretable deep learning survival predictive tool for small cell lung cancer,"BACKGROUND: Small cell lung cancer (SCLC) is an aggressive and almost universally lethal neoplasm. There is no accurate predictive method for its prognosis. Artificial intelligence deep learning may bring new hope.
METHODS: By searching the Surveillance, Epidemiology, and End Results database (SEER), 21,093 patients' clinical data were eventually included. Data were then divided into two groups (train dataset/test dataset). The train dataset (diagnosed in 2010-2014, N = 17,296) was utilized to conduct a deep learning survival model, validated by itself and the test dataset (diagnosed in 2015, N = 3,797) in parallel. According to clinical experience, age, sex, tumor site, T, N, M stage (7th American Joint Committee on Cancer TNM stage), tumor size, surgery, chemotherapy, radiotherapy, and history of malignancy were chosen as predictive clinical features. The C-index was the main indicator to evaluate model performance.
RESULTS: The predictive model had a 0.7181 C-index (95% confidence intervals, CIs, 0.7174-0.7187) in the train dataset and a 0.7208 C-index (95% CIs, 0.7202-0.7215) in the test dataset. These indicated that it had a reliable predictive value on OS for SCLC, so it was then packaged as a Windows software which is free for doctors, researchers, and patients to use.
CONCLUSION: The interpretable deep learning survival predictive tool for small cell lung cancer developed by this study had a reliable predictive value on their overall survival. More biomarkers may help improve the prognostic predictive performance of small cell lung cancer.",True,other,Not specified
37209993,Comparison of evaluation metrics of deep learning for imbalanced imaging data in osteoarthritis studies,"PURPOSE: To compare the evaluation metrics for deep learning methods that were developed using imbalanced imaging data in osteoarthritis studies.
MATERIALS AND METHODS: This retrospective study utilized 2996 sagittal intermediate-weighted fat-suppressed knee MRIs with MRI Osteoarthritis Knee Score readings from 2467 participants in the Osteoarthritis Initiative study. We obtained probabilities of the presence of bone marrow lesions (BMLs) from MRIs in the testing dataset at the sub-region (15 sub-regions), compartment, and whole-knee levels based on the trained deep learning models. We compared different evaluation metrics (e.g., receiver operating characteristic (ROC) and precision-recall (PR) curves) in the testing dataset with various class ratios (presence of BMLs vs. absence of BMLs) at these three data levels to assess the model's performance.
RESULTS: In a subregion with an extremely high imbalance ratio, the model achieved a ROC-AUC of 0.84, a PR-AUC of 0.10, a sensitivity of 0, and a specificity of 1.
CONCLUSION: The commonly used ROC curve is not sufficiently informative, especially in the case of imbalanced data. We provide the following practical suggestions based on our data analysis: 1) ROC-AUC is recommended for balanced data, 2) PR-AUC should be used for moderately imbalanced data (i.e., when the proportion of the minor class is above 5% and less than 50%), and 3) for severely imbalanced data (i.e., when the proportion of the minor class is below 5%), it is not practical to apply a deep learning model, even with the application of techniques addressing imbalanced data issues.",True,other,Not specified
37209183,Breast cancer risk prediction combining a convolutional neural network-based mammographic evaluation with clinical factors,"PURPOSE: Deep learning techniques, including convolutional neural networks (CNN), have the potential to improve breast cancer risk prediction compared to traditional risk models. We assessed whether combining a CNN-based mammographic evaluation with clinical factors in the Breast Cancer Surveillance Consortium (BCSC) model improved risk prediction.
METHODS: We conducted a retrospective cohort study among 23,467 women, age 35-74, undergoing screening mammography (2014-2018). We extracted electronic health record (EHR) data on risk factors. We identified 121 women who subsequently developed invasive breast cancer at least 1 year after the baseline mammogram. Mammograms were analyzed with a pixel-wise mammographic evaluation using CNN architecture. We used logistic regression models with breast cancer incidence as the outcome and predictors including clinical factors only (BCSC model) or combined with CNN risk score (hybrid model). We compared model prediction performance via area under the receiver operating characteristics curves (AUCs).
RESULTS: Mean age was 55.9 years (SD, 9.5) with 9.3% non-Hispanic Black and 36% Hispanic. Our hybrid model did not significantly improve risk prediction compared to the BCSC model (AUC of 0.654 vs 0.624, respectively, p = 0.063). In subgroup analyses, the hybrid model outperformed the BCSC model among non-Hispanic Blacks (AUC 0.845 vs. 0.589; p = 0.026) and Hispanics (AUC 0.650 vs 0.595; p = 0.049).
CONCLUSION: We aimed to develop an efficient breast cancer risk assessment method using CNN risk score and clinical factors from the EHR. With future validation in a larger cohort, our CNN model combined with clinical factors may help predict breast cancer risk in a cohort of racially/ethnically diverse women undergoing screening.",True,other,Not specified
37196988,A deep learning approach for medication disposition and corresponding attributes extraction,"OBJECTIVE: This article summarizes our approach to extracting medication and corresponding attributes from clinical notes, which is the focus of track 1 of the 2022 National Natural Language Processing (NLP) Clinical Challenges(n2c2) shared task.
METHODS: The dataset was prepared using Contextualized Medication Event Dataset (CMED), including 500 notes from 296 patients. Our system consisted of three components: medication named entity recognition (NER), event classification (EC), and context classification (CC). These three components were built using transformer models with slightly different architecture and input text engineering. A zero-shot learning solution for CC was also explored.
RESULTS: Our best performance systems achieved micro-average F1 scores of 0.973, 0.911, and 0.909 for the NER, EC, and CC, respectively.
CONCLUSION: In this study, we implemented a deep learning-based NLP system and demonstrated that our approach of (1) utilizing special tokens helps our model to distinguish multiple medications mentions in the same context; (2) aggregating multiple events of a single medication into multiple labels improves our model's performance.",True,text mining,RNN
37189575,Deep Learning Empowers Endoscopic Detection and Polyps Classification: A Multiple-Hospital Study,"The present study aimed to develop an AI-based system for the detection and classification of polyps using colonoscopy images. A total of about 256,220 colonoscopy images from 5000 colorectal cancer patients were collected and processed. We used the CNN model for polyp detection and the EfficientNet-b0 model for polyp classification. Data were partitioned into training, validation and testing sets, with a 70%, 15% and 15% ratio, respectively. After the model was trained/validated/tested, to evaluate its performance rigorously, we conducted a further external validation using both prospective (n = 150) and retrospective (n = 385) approaches for data collection from 3 hospitals. The deep learning model performance with the testing set reached a state-of-the-art sensitivity and specificity of 0.9709 (95% CI: 0.9646-0.9757) and 0.9701 (95% CI: 0.9663-0.9749), respectively, for polyp detection. The polyp classification model attained an AUC of 0.9989 (95% CI: 0.9954-1.00). The external validation from 3 hospital results achieved 0.9516 (95% CI: 0.9295-0.9670) with the lesion-based sensitivity and a frame-based specificity of 0.9720 (95% CI: 0.9713-0.9726) for polyp detection. The model achieved an AUC of 0.9521 (95% CI: 0.9308-0.9734) for polyp classification. The high-performance, deep-learning-based system could be used in clinical practice to facilitate rapid, efficient and reliable decisions by physicians and endoscopists.",True,other,Not specified
37167840,Can deep learning on retinal images augment known risk factors for cardiovascular disease prediction in diabetes? A prospective cohort study from the national screening programme in Scotland,"AIMS: This study's objective was to evaluate whether deep learning (DL) on retinal photographs from a diabetic retinopathy screening programme improve prediction of incident cardiovascular disease (CVD).
METHODS: DL models were trained to jointly predict future CVD risk and CVD risk factors and used to output a DL score. Poisson regression models including clinical risk factors with and without a DL score were fitted to study cohorts with 2,072 and 38,730 incident CVD events in type 1 (T1DM) and type 2 diabetes (T2DM) respectively.
RESULTS: DL scores were independently associated with incident CVD with adjusted standardised incidence rate ratios of 1.14 (P = 3 × 10-04 95 % CI (1.06, 1.23)) and 1.16 (P = 4 × 10-33 95 % CI (1.13, 1.18)) in T1DM and T2DM cohorts respectively. The differences in predictive performance between models with and without a DL score were statistically significant (differences in test log-likelihood 6.7 and 51.1 natural log units) but the increments in C-statistics from 0.820 to 0.822 and from 0.709 to 0.711 for T1DM and T2DM respectively, were small.
CONCLUSIONS: These results show that in people with diabetes, retinal photographs contain information on future CVD risk. However for this to contribute appreciably to clinical prediction of CVD further approaches, including exploitation of serial images, need to be evaluated.",True,other,recurrent neural network
37165971,"Predicting the survival of patients with pancreatic neuroendocrine neoplasms using deep learning: A study based on Surveillance, Epidemiology, and End Results database","BACKGROUND: The study aims to evaluate the performance of three advanced machine learning algorithms and a traditional Cox proportional hazard (CoxPH) model in predicting the overall survival (OS) of patients with pancreatic neuroendocrine neoplasms (PNENs).
METHOD: The clinicopathological dataset obtained from the Surveillance, Epidemiology, and End Results database was randomly assigned to the training set and testing set at a ratio of 7:3. The concordance index (C-index) and integrated Brier score (IBS) were used to compare the predictive performance of the models. The accuracy of the model in predicting the 5-year and 10-year survival rates was compared using the receiver operating characteristic curve, decision curve analysis (DCA) and calibration curve.
RESULTS: This study included 3239 patients with PNENs in total. The DeepSurv model had the highest C-index of 0.7882 in the testing set and training set and the lowest IBS of 0.1278 in the testing set compared with the CoxPH, neural multitask logistic and random survival forest models (C-index = 0.7501, 0.7616, and 0.7612, respectively; IBS = 0.1397, 0.1418, and 0.1432, respectively). Moreover, the DeepSurv model had the highest accuracy in predicting 5- and 10-year OS rates (area under the curve: 0.87 and 0.90). DCA showed that the DeepSurv model had high potential for clinical decisions in 5- and 10-year OS models. Finally, we developed an online application based on the DeepSurv model for clinical use (https://whuh-ml-neuroendocrinetumor-app-predict-oyw5km.streamlit.app/).
CONCLUSIONS: All four models analyzed above can predict the prognosis of PNENs well, among which the DeepSurv model has the best prediction performance.",True,other,recurrent neural network
37163049,Unsupervised representation learning improves genomic discovery and risk prediction for respiratory and circulatory functions and diseases,"High-dimensional clinical data are becoming more accessible in biobank-scale datasets. However, effectively utilizing high-dimensional clinical data for genetic discovery remains challenging. Here we introduce a general deep learning-based framework, REpresentation learning for Genetic discovery on Low-dimensional Embeddings (REGLE), for discovering associations between genetic variants and high-dimensional clinical data. REGLE uses convolutional variational autoencoders to compute a non-linear, low-dimensional, disentangled embedding of the data with highly heritable individual components. REGLE can incorporate expert-defined or clinical features and provides a framework to create accurate disease-specific polygenic risk scores (PRS) in datasets which have minimal expert phenotyping. We apply REGLE to both respiratory and circulatory systems: spirograms which measure lung function and photoplethysmograms (PPG) which measure blood volume changes. Genome-wide association studies on REGLE embeddings identify more genome-wide significant loci than existing methods and replicate known loci for both spirograms and PPG, demonstrating the generality of the framework. Furthermore, these embeddings are associated with overall survival. Finally, we construct a set of PRSs that improve predictive performance of asthma, chronic obstructive pulmonary disease, hypertension, and systolic blood pressure in multiple biobanks. Thus, REGLE embeddings can quantify clinically relevant features that are not currently captured in a standardized or automated way.",True,other,recurrent neural network
37163042,"DeepComBat: A Statistically Motivated, Hyperparameter-Robust, Deep Learning Approach to Harmonization of Neuroimaging Data","Neuroimaging data from multiple batches (i.e. acquisition sites, scanner manufacturer, datasets, etc.) are increasingly necessary to gain new insights into the human brain. However, multi-batch data, as well as extracted radiomic features, exhibit pronounced technical artifacts across batches. These batch effects introduce confounding into the data and can obscure biological effects of interest, decreasing the generalizability and reproducibility of findings. This is especially true when multi-batch data is used alongside complex downstream analysis models, such as machine learning methods. Image harmonization methods seeking to remove these batch effects are important for mitigating these issues; however, significant multivariate batch effects remain in the data following harmonization by current state-of-the-art statistical and deep learning methods. We present DeepCombat, a deep learning harmonization method based on a conditional variational autoencoder architecture and the ComBat harmonization model. DeepCombat learns and removes subject-level batch effects by accounting for the multivariate relationships between features. Additionally, DeepComBat relaxes a number of strong assumptions commonly made by previous deep learning harmonization methods and is empirically robust across a wide range of hyperparameter choices. We apply this method to neuroimaging data from a large cognitive-aging cohort and find that DeepCombat outperforms existing methods, as assessed by a battery of machine learning methods, in removing scanner effects from cortical thickness measurements while preserving biological heterogeneity. Additionally, DeepComBat provides a new perspective for statistically-motivated deep learning harmonization methods.",True,both,recurrent neural network
37161130,Data augmentation based semi-supervised method to improve COVID-19 CT classification,"The Coronavirus (COVID-19) outbreak of December 2019 has become a serious threat to people around the world, creating a health crisis that infected millions of lives, as well as destroying the global economy. Early detection and diagnosis are essential to prevent further transmission. The detection of COVID-19 computed tomography images is one of the important approaches to rapid diagnosis. Many different branches of deep learning methods have played an important role in this area, including transfer learning, contrastive learning, ensemble strategy, etc. However, these works require a large number of samples of expensive manual labels, so in order to save costs, scholars adopted semi-supervised learning that applies only a few labels to classify COVID-19 CT images. Nevertheless, the existing semi-supervised methods focus primarily on class imbalance and pseudo-label filtering rather than on pseudo-label generation. Accordingly, in this paper, we organized a semi-supervised classification framework based on data augmentation to classify the CT images of COVID-19. We revised the classic teacher-student framework and introduced the popular data augmentation method Mixup, which widened the distribution of high confidence to improve the accuracy of selected pseudo-labels and ultimately obtain a model with better performance. For the COVID-CT dataset, our method makes precision, F1 score, accuracy and specificity 21.04%, 12.95%, 17.13% and 38.29% higher than average values for other methods respectively, For the SARS-COV-2 dataset, these increases were 8.40%, 7.59%, 9.35% and 12.80% respectively. For the Harvard Dataverse dataset, growth was 17.64%, 18.89%, 19.81% and 20.20% respectively. The codes are available at https://github.com/YutingBai99/COVID-19-SSL.",True,both,Not specified
37156936,A deep learning algorithm to predict risk of pancreatic cancer from disease trajectories,"Pancreatic cancer is an aggressive disease that typically presents late with poor outcomes, indicating a pronounced need for early detection. In this study, we applied artificial intelligence methods to clinical data from 6 million patients (24,000 pancreatic cancer cases) in Denmark (Danish National Patient Registry (DNPR)) and from 3 million patients (3,900 cases) in the United States (US Veterans Affairs (US-VA)). We trained machine learning models on the sequence of disease codes in clinical histories and tested prediction of cancer occurrence within incremental time windows (CancerRiskNet). For cancer occurrence within 36 months, the performance of the best DNPR model has area under the receiver operating characteristic (AUROC) curve = 0.88 and decreases to AUROC (3m) = 0.83 when disease events within 3 months before cancer diagnosis are excluded from training, with an estimated relative risk of 59 for 1,000 highest-risk patients older than age 50 years. Cross-application of the Danish model to US-VA data had lower performance (AUROC = 0.71), and retraining was needed to improve performance (AUROC = 0.78, AUROC (3m) = 0.76). These results improve the ability to design realistic surveillance programs for patients at elevated risk, potentially benefiting lifespan and quality of life by early detection of this aggressive cancer.",True,other,Not specified
37150781,Deep learning referral suggestion and tumour discrimination using explainable artificial intelligence applied to multiparametric MRI,"OBJECTIVES: An appropriate and fast clinical referral suggestion is important for intra-axial mass-like lesions (IMLLs) in the emergency setting. We aimed to apply an interpretable deep learning (DL) system to multiparametric MRI to obtain clinical referral suggestion for IMLLs, and to validate it in the setting of nontraumatic emergency neuroradiology.
METHODS: A DL system was developed in 747 patients with IMLLs ranging 30 diseases who underwent pre- and post-contrast T1-weighted (T1CE), FLAIR, and diffusion-weighted imaging (DWI). A DL system that segments IMLLs, classifies tumourous conditions, and suggests clinical referral among surgery, systematic work-up, medical treatment, and conservative treatment, was developed. The system was validated in an independent cohort of 130 emergency patients, and performance in referral suggestion and tumour discrimination was compared with that of radiologists using receiver operating characteristics curve, precision-recall curve analysis, and confusion matrices. Multiparametric interpretable visualisation of high-relevance regions from layer-wise relevance propagation overlaid on contrast-enhanced T1WI and DWI was analysed.
RESULTS: The DL system provided correct referral suggestions in 94 of 130 patients (72.3%) and performed comparably to radiologists (accuracy 72.6%, McNemar test; p = .942). For distinguishing tumours from non-tumourous conditions, the DL system (AUC, 0.90 and AUPRC, 0.94) performed similarly to human readers (AUC, 0.81~0.92, and AUPRC, 0.88~0.95). Solid portions of tumours showed a high overlap of relevance, but non-tumours did not (Dice coefficient 0.77 vs. 0.33, p < .001), demonstrating the DL's decision.
CONCLUSIONS: Our DL system could appropriately triage patients using multiparametric MRI and provide interpretability through multiparametric heatmaps, and may thereby aid neuroradiologic diagnoses in emergency settings.
CLINICAL RELEVANCE STATEMENT: Our AI triages patients with raw MRI images to clinical referral pathways in brain intra-axial mass-like lesions. We demonstrate that the decision is based on the relative relevance between contrast-enhanced T1-weighted and diffusion-weighted images, providing explainability across multiparametric MRI data.
KEY POINTS: • A deep learning (DL) system using multiparametric MRI suggested clinical referral to patients with intra-axial mass-like lesions (IMLLs) similar to radiologists (accuracy 72.3% vs. 72.6%). • In the differentiation of tumourous and non-tumourous conditions, the DL system (AUC, 0.90) performed similar with radiologists (AUC, 0.81-0.92). • The DL's decision basis for differentiating tumours from non-tumours can be quantified using multiparametric heatmaps obtained via the layer-wise relevance propagation method.",True,both,LSTM
37144534,The role of artificial intelligence in hepatology research and practice,"PURPOSE OF REVIEW: The use of artificial intelligence (AI) in examining large data sets has recently gained considerable attention to evaluate disease epidemiology, management approaches, and disease outcomes. The purpose of this review is to summarize the current role of AI in contemporary hepatology practice.
RECENT FINDINGS: AI was found to be diagnostically valuable in the evaluation of liver fibrosis, detection of cirrhosis, differentiation between compensated and decompensated cirrhosis, evaluation of portal hypertension, detection and differentiation of particular liver masses, preoperative evaluation of hepatocellular carcinoma as well as response to treatment and estimation of graft survival in patients undergoing liver transplantation. AI additionally holds great promise in examination of structured electronic health records data as well as in examination of clinical text (using various natural language processing approaches). Despite its contributions, AI has several limitations, including the quality of existing data, small cohorts with possible sampling bias and the lack of well validated easily reproducible models.
SUMMARY: AI and deep learning models have extensive applicability in assessing liver disease. However, multicenter randomized controlled trials are indispensable to validate their utility.",True,computer vision,Not specified
37130959,Author Correction: Discovery of drug-omics associations in type 2 diabetes with generative deep-learning models,,True,other,GAN
37128461,Deep Learning vs Traditional Models for Predicting Hospital Readmission among Patients with Diabetes,"A hospital readmission risk prediction tool for patients with diabetes based on electronic health record (EHR) data is needed. The optimal modeling approach, however, is unclear. In 2,836,569 encounters of 36,641 diabetes patients, deep learning (DL) long short-term memory (LSTM) models predicting unplanned, all-cause, 30-day readmission were developed and compared to several traditional models. Models used EHR data defined by a Common Data Model. The LSTM model Area Under the Receiver Operating Characteristic Curve (AUROC) was significantly greater than that of the next best traditional model [LSTM 0.79 vs Random Forest (RF) 0.72, p<0.0001]. Experiments showed that performance of the LSTM models increased as prior encounter number increased up to 30 encounters. An LSTM model with 16 selected laboratory tests yielded equivalent performance to a model with all 981 laboratory tests. This new DL model may provide the basis for a more useful readmission risk prediction tool for diabetes patients.",True,other,LSTM
37094464,Enhancing thoracic disease detection using chest X-rays from PubMed Central Open Access,"Large chest X-rays (CXR) datasets have been collected to train deep learning models to detect thorax pathology on CXR. However, most CXR datasets are from single-center studies and the collected pathologies are often imbalanced. The aim of this study was to automatically construct a public, weakly-labeled CXR database from articles in PubMed Central Open Access (PMC-OA) and to assess model performance on CXR pathology classification by using this database as additional training data. Our framework includes text extraction, CXR pathology verification, subfigure separation, and image modality classification. We have extensively validated the utility of the automatically generated image database on thoracic disease detection tasks, including Hernia, Lung Lesion, Pneumonia, and pneumothorax. We pick these diseases due to their historically poor performance in existing datasets: the NIH-CXR dataset (112,120 CXR) and the MIMIC-CXR dataset (243,324 CXR). We find that classifiers fine-tuned with additional PMC-CXR extracted by the proposed framework consistently and significantly achieved better performance than those without (e.g., Hernia: 0.9335 vs 0.9154; Lung Lesion: 0.7394 vs. 0.7207; Pneumonia: 0.7074 vs. 0.6709; Pneumothorax 0.8185 vs. 0.7517, all in AUC with p< 0.0001) for CXR pathology detection. In contrast to previous approaches that manually submit the medical images to the repository, our framework can automatically collect figures and their accompanied figure legends. Compared to previous studies, the proposed framework improved subfigure segmentation and incorporates our advanced self-developed NLP technique for CXR pathology verification. We hope it complements existing resources and improves our ability to make biomedical image data findable, accessible, interoperable, and reusable.",True,other,LSTM
37088416,"Deep Learning Approaches for Glioblastoma Prognosis in Resource-Limited Settings: A Study Using Basic Patient Demographic, Clinical, and Surgical Inputs","BACKGROUND: Glioblastoma (GBM) is the most common brain tumor in the United States, with an annual incidence rate of 3.21 per 100,000. It is the most aggressive type of diffuse glioma and has a median survival of months after treatment. This study aims to assess the accuracy of different novel deep learning models trained on a set of simple clinical, demographic, and surgical variables to assist in clinical practice, even in areas with constrained health care infrastructure.
METHODS: Our study included 37,095 patients with GBM from the SEER (Surveillance Epidemiology and End Results) database. All predictors were based on demographic, clinicopathologic, and treatment information of the cases. Our outcomes of interest were months of survival and vital status. Concordance index (C-index) and integrated Brier scores (IBS) were used to evaluate the performance of the models.
RESULTS: The patient characteristics and the statistical analyses were consistent with the epidemiologic literature. The models C-index and IBS ranged from 0.6743 to 0.6918 and from 0.0934 to 0.1034, respectively. Probabilistic matrix factorization (0.6918), multitask logistic regression (0.6916), and logistic hazard (0.6916) had the highest C-index scores. The models with the lowest IBS were the probabilistic matrix factorization (0.0934), multitask logistic regression (0.0935), and logistic hazard (0.0936). These models had an accuracy (1-IBS) of 90.66%; 90.65%, and 90.64%, respectively. The deep learning algorithms were deployed on an interactive Web-based tool for practical use available via https://glioblastoma-survanalysis.herokuapp.com/.
CONCLUSIONS: Novel deep learning algorithms can better predict GBM prognosis than do baseline methods and can lead to more personalized patient care regardless of extensive electronic health record availability.",True,other,Not specified
37071168,Reproducibility of a combined artificial intelligence and optimal-surface graph-cut method to automate bronchial parameter extraction,"OBJECTIVES: Computed tomography (CT)-based bronchial parameters correlate with disease status. Segmentation and measurement of the bronchial lumen and walls usually require significant manpower. We evaluate the reproducibility of a deep learning and optimal-surface graph-cut method to automatically segment the airway lumen and wall, and calculate bronchial parameters.
METHODS: A deep-learning airway segmentation model was newly trained on 24 Imaging in Lifelines (ImaLife) low-dose chest CT scans. This model was combined with an optimal-surface graph-cut for airway wall segmentation. These tools were used to calculate bronchial parameters in CT scans of 188 ImaLife participants with two scans an average of 3 months apart. Bronchial parameters were compared for reproducibility assessment, assuming no change between scans.
RESULTS: Of 376 CT scans, 374 (99%) were successfully measured. Segmented airway trees contained a mean of 10 generations and 250 branches. The coefficient of determination (R2) for the luminal area (LA) ranged from 0.93 at the trachea to 0.68 at the 6th generation, decreasing to 0.51 at the 8th generation. Corresponding values for Wall Area Percentage (WAP) were 0.86, 0.67, and 0.42, respectively. Bland-Altman analysis of LA and WAP per generation demonstrated mean differences close to 0; limits of agreement (LoA) were narrow for WAP and Pi10 (± 3.7% of mean) and wider for LA (± 16.4-22.8% for 2-6th generations). From the 7th generation onwards, there was a sharp decrease in reproducibility and a widening LoA.
CONCLUSION: The outlined approach for automatic bronchial parameter measurement on low-dose chest CT scans is a reliable way to assess the airway tree down to the 6th generation.
STATEMENT ON CLINICAL RELEVANCE: This reliable and fully automatic pipeline for bronchial parameter measurement on low-dose CT scans has potential applications in screening for early disease and clinical tasks such as virtual bronchoscopy or surgical planning, while also enabling the exploration of bronchial parameters in large datasets.
KEY POINTS: • Deep learning combined with optimal-surface graph-cut provides accurate airway lumen and wall segmentations on low-dose CT scans. • Analysis of repeat scans showed that the automated tools had moderate-to-good reproducibility of bronchial measurements down to the 6th generation airway. • Automated measurement of bronchial parameters enables the assessment of large datasets with less man-hours.",True,other,Not specified
37063030,Predominant learning approaches of medical students in Saudi Arabia,"PURPOSE OF THE STUDY: This study aims at identifying the predominant learning approaches by Saudi medical students across Saudi Arabia and assess its possible associations with sociodemographic and educational characteristics.
STUDY DESIGN: A cross-sectional study design using the Approaches and Study Skills Inventory for Students questionnaire. The questionnaire gives rise to three possible learning approaches; deep, strategic and surface approaches. Bivariate analyses were performed through independent samples t-test and χ2 tests where appropriate. A multinominal regression analysis was performed to obtain risk estimates and 95% CIs.
RESULTS: A total of 3767 students participated and were included in the analysis. The predominant learning approach was the deep approach, followed by the strategic and surface approaches (40.59%, 37.81% and 21.60%, respectively). Males and students belonging to private medical schools were more likely to adopt a strategic rather than a deep one (relative risk ratio (RRR) 1.22, 95% CI 1.06 to 1.42 and RRR 1.32, 95% CI 1.05 to 1.65, respectively). Students with an A grade point average (GPA) were less likely to adopt a surface approach, whereas those with a C GPA were more likely to adopt it (RRR=0.67, 95% CI 0.54 to 0.83 and RRR=1.29, 95% CI 1.02 to 1.61, respectively).
CONCLUSION: The findings from this study show that medical students predominantly favour the deep learning approach. Results from this study encourage the continuous adaptation of clinical teaching in medical schools to optimise students' learning experiences.",True,text mining,Not specified
37058323,Automated Triage of Screening Breast MRI Examinations in High-Risk Women Using an Ensemble Deep Learning Model,"OBJECTIVES: The aim of the study is to develop and evaluate the performance of a deep learning (DL) model to triage breast magnetic resonance imaging (MRI) findings in high-risk patients without missing any cancers.
MATERIALS AND METHODS: In this retrospective study, 16,535 consecutive contrast-enhanced MRIs performed in 8354 women from January 2013 to January 2019 were collected. From 3 New York imaging sites, 14,768 MRIs were used for the training and validation data set, and 80 randomly selected MRIs were used for a reader study test data set. From 3 New Jersey imaging sites, 1687 MRIs (1441 screening MRIs and 246 MRIs performed in recently diagnosed breast cancer patients) were used for an external validation data set. The DL model was trained to classify maximum intensity projection images as ""extremely low suspicion"" or ""possibly suspicious."" Deep learning model evaluation (workload reduction, sensitivity, specificity) was performed on the external validation data set, using a histopathology reference standard. A reader study was performed to compare DL model performance to fellowship-trained breast imaging radiologists.
RESULTS: In the external validation data set, the DL model triaged 159/1441 of screening MRIs as ""extremely low suspicion"" without missing a single cancer, yielding a workload reduction of 11%, a specificity of 11.5%, and a sensitivity of 100%. The model correctly triaged 246/246 (100% sensitivity) of MRIs in recently diagnosed patients as ""possibly suspicious."" In the reader study, 2 readers classified MRIs with a specificity of 93.62% and 91.49%, respectively, and missed 0 and 1 cancer, respectively. On the other hand, the DL model classified MRIs with a specificity of 19.15% and missed 0 cancers, highlighting its potential use not as an independent reader but as a triage tool.
CONCLUSIONS: Our automated DL model triages a subset of screening breast MRIs as ""extremely low suspicion"" without misclassifying any cancer cases. This tool may be used to reduce workload in standalone mode, to shunt low suspicion cases to designated radiologists or to the end of the workday, or to serve as base model for other downstream AI tools.",True,both,Not specified
37057112,Development and validation of a deep transfer learning-based multivariable survival model to predict overall survival in lung cancer,"BACKGROUND: Numerous deep learning-based survival models are being developed for various diseases, but those that incorporate both deep learning and transfer learning are scarce. Deep learning-based models may not perform optimally in real-world populations due to variations in variables and characteristics. Transfer learning, on the other hand, enables a model developed for one domain to be adapted for a related domain. Our objective was to integrate deep learning and transfer learning to create a multivariable survival model for lung cancer.
METHODS: We collected data from 601,480 lung cancer patients in the Surveillance, Epidemiology, and End Results (SEER) database and 4,512 lung cancer patients in the First Affiliated Hospital of Guangzhou Medical University (GYFY) database. The primary model was trained with the SEER database, internally validated with a dataset from SEER, and externally validated through transfer learning with the GYFY database. The performance of the model was compared with a traditional Cox model by C-indexes. We also explored the model's performance in the setting of missing data and generated the artificial intelligence (AI) certainty of the prediction.
RESULTS: The C-indexes in the training dataset (SEER full sample) with DeepSurv and Cox model were 0.792 (0.791-0.792) and 0.714 (0.713-0.715), respectively. The values were 0.727 (0.704-0.750) and 0.692 (0.666-0.718) after applying the trained model in the test dataset (GYFY). The AI certainty of the DeepSurv model output was from 0.98 to 1. For transfer learning through fine-tuning, the results showed that the test set could achieve a higher C-index (20% vs. 30% fine-tuning data) with more fine-tuning dataset. Besides, the DeepSurv model was more accurate than the traditional Cox model in predicting with missing data, after random data loss of 5%, 10%, 15%, 20%, and median fill-in missing values.
CONCLUSIONS: The model outperformed the traditional Cox model, was robust with missing data and provided the AI certainty of prediction. It can be used for patient self-evaluation and risk stratification in clinical trials. Researchers can fine-tune the pre-trained model and integrate their own database to explore other prognostic factors.",True,other,Not specified
37055729,Development and validation of a deep learning survival model for cervical adenocarcinoma patients,"BACKGROUND: The aim was to develop a personalized survival prediction deep learning model for cervical adenocarcinoma patients and process personalized survival prediction.
METHODS: A total of 2501 cervical adenocarcinoma patients from the surveillance, epidemiology and end results database and 220 patients from Qilu hospital were enrolled in this study. We created our deep learning (DL) model to manipulate the data and evaluated its performance against four other competitive models. We tried to demonstrate a new grouping system oriented by survival outcomes and process personalized survival prediction by using our DL model.
RESULTS: The DL model reached 0.878 c-index and 0.09 Brier score in the test set, which was better than the other four models. In the external test set, our model achieved a 0.80 c-index and 0.13 Brier score. Thus, we developed prognosis-oriented risk grouping for patients according to risk scores computed by our DL model. Notable differences among groupings were observed. In addition, a personalized survival prediction system based on our risk-scoring grouping was developed.
CONCLUSIONS: We developed a deep neural network model for cervical adenocarcinoma patients. The performance of this model proved to be superior to other models. The results of external validation supported the possibility that the model can be used in clinical work. Finally, our survival grouping and personalized prediction system provided more accurate prognostic information for patients than traditional FIGO stages.",True,other,recurrent neural network
37051218,Deep-learning-based survival prediction of patients with cutaneous malignant melanoma,"BACKGROUND: This study obtained data on patients with cutaneous malignant melanoma (CMM) from the Surveillance, Epidemiology, and End Results (SEER) database, and used a deep learning and neural network (DeepSurv) model to predict the survival rate of patients with CMM and evaluate its effectiveness.
METHODS: We collected information on patients with CMM between 2004 and 2015 from the SEER database. We then randomly divided the patients into training and testing cohorts at a 7:3 ratio. The likelihood that patients with CMM will survive was forecasted using the DeepSurv model, and its results were compared with those of the Cox proportional-hazards (CoxPH) model. The calibration curves, time-dependent area under the receiver operating characteristic curve (AUC), and concordance index (C-index) were used to assess the prediction abilities of the model.
RESULTS: This study comprised 37,758 patients with CMM: 26,430 in the training cohort and 11,329 in the testing cohort. The CoxPH model demonstrated that the survival of patients with CMM was significantly influenced by age, sex, marital status, summary stage, surgery, radiotherapy, chemotherapy, postoperative lymph node dissection, tumor size, and tumor extension. The C-index of the CoxPH model was 0.875. We also constructed the DeepSurv model using the data from the training cohort, and its C-index was 0.910. We examined how well the aforementioned two models predicted outcomes. The 1-, 3-, and 5-year AUCs were 0.928, 0.837, and 0.855, respectively, for the CoxPH model, and 0.971, 0.947, and 0.942 for the DeepSurv model. The DeepSurv model presented a greater predictive effect on patients with CMM, and its reliability was better than that of the CoxPH model according to both the AUC value and the calibration curve.
CONCLUSION: The DeepSurv model, which we developed based on the data of patients with CMM in the SEER database, was found to be more effective than the CoxPH model in predicting the survival time of patients with CMM.",True,other,Not specified
37041318,A deep learning nomogram of continuous glucose monitoring data for the risk prediction of diabetic retinopathy in type 2 diabetes,"Continuous glucose monitoring (CGM) data analysis will provide a new perspective to analyze factors related to diabetic retinopathy (DR). However, the problem of visualizing CGM data and automatically predicting the incidence of DR from CGM is still controversial. Here, we explored the feasibility of using CGM profiles to predict DR in type 2 diabetes (T2D) by deep learning approach. This study fused deep learning with a regularized nomogram to construct a novel deep learning nomogram from CGM profiles to identify patients at high risk of DR. Specifically, a deep learning network was employed to mine the nonlinear relationship between CGM profiles and DR. Moreover, a novel nomogram combining CGM deep factors with basic information was established to score the patients' DR risk. This dataset consists of 788 patients belonging to two cohorts: 494 in the training cohort and 294 in the testing cohort. The area under the curve (AUC) values of our deep learning nomogram were 0.82 and 0.80 in the training cohort and testing cohort, respectively. By incorporating basic clinical factors, the deep learning nomogram achieved an AUC of 0.86 in the training cohort and 0.85 in the testing cohort. The calibration plot and decision curve showed that the deep learning nomogram had the potential for clinical application. This analysis method of CGM profiles can be extended to other diabetic complications by further investigation.",True,other,recurrent neural network
37038364,Deep-Learning-Based Detection of Vertebral Fracture and Osteoporosis Using Lateral Spine X-Ray Radiography,"Osteoporosis and vertebral fractures (VFs) remain underdiagnosed. The addition of deep learning methods to lateral spine radiography (a simple, widely available, low-cost test) can potentially solve this problem. In this study, we develop deep learning scores to detect osteoporosis and VF based on lateral spine radiography and investigate whether their use can improve referral of high-risk individuals to bone-density testing. The derivation cohort consisted of patients aged 50 years or older who underwent lateral spine radiography in Severance Hospital, Korea, from January 2007 to December 2018, providing a total of 26,299 lateral spine plain X-rays for 9276 patients (VF prevalence, 18.6%; osteoporosis prevalence, 40.3%). Two individual deep convolutional neural network scores to detect prevalent VF (VERTE-X pVF score) and osteoporosis (VERTE-X osteo score) were tested on an internal test set (20% hold-out set) and external test set (another hospital cohort [Yongin], 395 patients). VERTE-X pVF, osteo scores, and clinical models to detect prevalent VF or osteoporosis were compared in terms of the areas under the receiver-operating-characteristics curves (AUROCs). Net reclassification improvement (NRI) was calculated when using deep-learning scores to supplement clinical indications for classification of high-risk individuals to dual-energy X-ray absorptiometry (DXA) testing. VERTE-X pVF and osteo scores outperformed clinical models in both the internal (AUROC: VF, 0.93 versus 0.78; osteoporosis, 0.85 versus 0.79) and external (VF, 0.92 versus 0.79; osteoporosis, 0.83 versus 0.65; p < 0.01 for all) test sets. VERTE-X pVF and osteo scores improved the reclassification of individuals with osteoporosis to the DXA testing group when applied together with the clinical indications for DXA testing in both the internal (NRI 0.10) and external (NRI 0.14, p < 0.001 for all) test sets. The proposed method could detect prevalent VFs and osteoporosis, and it improved referral of individuals at high risk of fracture to DXA testing more than clinical indications alone. © 2023 The Authors. Journal of Bone and Mineral Research published by Wiley Periodicals LLC on behalf of American Society for Bone and Mineral Research (ASBMR).",True,other,Not specified
37035520,Deep Learning Based Detection of Enlarged Perivascular Spaces on Brain MRI,"Deep learning has been demonstrated effective in many neuroimaging applications. However, in many scenarios, the number of imaging sequences capturing information related to small vessel disease lesions is insufficient to support data-driven techniques. Additionally, cohort-based studies may not always have the optimal or essential imaging sequences for accurate lesion detection. Therefore, it is necessary to determine which imaging sequences are crucial for precise detection. This study introduces a deep learning framework to detect enlarged perivascular spaces (ePVS) and aims to find the optimal combination of MRI sequences for deep learning-based quantification. We implemented an effective lightweight U-Net adapted for ePVS detection and comprehensively investigated different combinations of information from SWI, FLAIR, T1-weighted (T1w), and T2-weighted (T2w) MRI sequences. The experimental results showed that T2w MRI is the most important for accurate ePVS detection, and the incorporation of SWI, FLAIR and T1w MRI in the deep neural network had minor improvements in accuracy and resulted in the highest sensitivity and precision (sensitivity =0.82, precision =0.83). The proposed method achieved comparable accuracy at a minimal time cost compared to manual reading. The proposed automated pipeline enables robust and time-efficient readings of ePVS from MR scans and demonstrates the importance of T2w MRI for ePVS detection and the potential benefits of using multimodal images. Furthermore, the model provides whole-brain maps of ePVS, enabling a better understanding of their clinical correlates compared to the clinical rating methods within only a couple of brain regions.",True,other,recurrent neural network
37027675,RESEAT: Recurrent Self-Attention Network for Multi-Regional Influenza Forecasting,"Early forecasting of influenza is an important task for public health to reduce losses due to influenza. Various deep learning-based models for multi-regional influenza forecasting have been proposed to forecast future influenza occurrences in multiple regions. While they only use historical data for forecasting, temporal and regional patterns need to be jointly considered for better accuracy. Basic deep learning models such as recurrent neural networks and graph neural networks have limited ability to model both patterns together. A more recent approach uses an attention mechanism or its variant, self-attention. Although these mechanisms can model regional interrelationships, in state-of-the-art models, they consider accumulated regional interrelationships based on attention values that are calculated only once for all of the input data. This limitation makes it difficult to effectively model the regional interrelationships that change dynamically during that period. Therefore, in this article, we propose a recurrent self-attention network (RESEAT) for various multi-regional forecasting tasks such as influenza and electrical load forecasting. The model can learn regional interrelationships over the entire period of the input data using self-attention, and it recurrently connects the attention weights using message passing. We demonstrate through extensive experiments that the proposed model outperforms other state-of-the-art forecasting models in terms of the forecasting accuracy for influenza and COVID-19. We also describe how to visualize regional interrelationships and analyze the sensitivity of hyperparameters to forecasting accuracy.",True,other,convolutional neural network
37016684,Smart Artificial Intelligence techniques using embedded band for diagnosis and combating COVID-19,"Recently, COVID-19 virus spread to create a major impact in human body worldwide. The Corona virus, initiated by the SARS-CoV-2 virus, was known in China, December 2019 and affirmed a worldwide epidemic by the World Health Organization on 11 March 2020. The core aim of this research is to detect the spreading of COVID-19 virus and solve the problems in human lungs infection quickly. An Artificial Intelligence (AI) technique is a possibly controlling device in the battle against the corona virus epidemic. Recently, AI with computational techniques are utilized for COVID-19 virus with the building blocks of Deep Learning method using Recurrent Neural Network (RNN) and Convolutional Neural Network (CNN) is used to classify and identify the lung images affected region. These two algorithms used to diagnose COVID-19 infections rapidly. The AI applications against COVID-19 are Medical Imaging for Diagnosis, Lung delineation, Lesion measurement, Non-Invasive Measurements for Disease Tracking, Patient Outcome Prediction, Molecular Scale: from Proteins to Drug Development and Societal Scale: Epidemiology and Infodemiology.",True,other,CNN
37005484,An integrative machine learning framework for classifying SEER breast cancer,"Breast cancer is the commonest type of cancer in women worldwide and the leading cause of mortality for females. The aim of this research is to classify the alive and death status of breast cancer patients using the Surveillance, Epidemiology, and End Results dataset. Due to its capacity to handle enormous data sets systematically, machine learning and deep learning has been widely employed in biomedical research to answer diverse classification difficulties. Pre-processing the data enables its visualization and analysis for use in making important decisions. This research presents a feasible machine learning-based approach for categorizing SEER breast cancer dataset. Moreover, a two-step feature selection method based on Variance Threshold and Principal Component Analysis was employed to select the features from the SEER breast cancer dataset. After selecting the features, the classification of the breast cancer dataset is carried out using Supervised and Ensemble learning techniques such as Ada Boosting, XG Boosting, Gradient Boosting, Naive Bayes and Decision Tree. Utilizing the train-test split and k-fold cross-validation approaches, the performance of various machine learning algorithms is examined. The accuracy of Decision Tree for both train-test split and cross validation achieved as 98%. In this study, it is observed that the Decision Tree algorithm outperforms other supervised and ensemble learning approaches for the SEER Breast Cancer dataset.",True,other,Not specified
37000340,Recent Advances in Melanoma Diagnosis and Prognosis Using Machine Learning Methods,"PURPOSE OF REVIEW: The purpose was to summarize the current role and state of artificial intelligence and machine learning in the diagnosis and management of melanoma.
RECENT FINDINGS: Deep learning algorithms can identify melanoma from clinical, dermoscopic, and whole slide pathology images with increasing accuracy. Efforts to provide more granular annotation to datasets and to identify new predictors are ongoing. There have been many incremental advances in both melanoma diagnostics and prognostic tools using artificial intelligence and machine learning. Higher quality input data will further improve these models' capabilities.",True,other,recurrent neural network
36996662,Epi-DNNs: Epidemiological priors informed deep neural networks for modeling COVID-19 dynamics,"Differential equations-based epidemic compartmental models and deep neural networks-based artificial intelligence (AI) models are powerful tools for analyzing and fighting the transmission of COVID-19. However, the capability of compartmental models is limited by the challenges of parameter estimation, while AI models fail to discover the evolutionary pattern of COVID-19 and lack explainability. This paper aims to provide a novel method (called Epi-DNNs) by integrating compartmental models and deep neural networks (DNNs) to model the complex dynamics of COVID-19. In the proposed Epi-DNNs method, the neural network is designed to express the unknown parameters in the compartmental model and the Runge-Kutta method is implemented to solve the ordinary differential equations (ODEs) so as to give the values of the ODEs at a given time. Specifically, the discrepancy between predictions and observations is incorporated into the loss function, then the defined loss is minimized and applied to identify the best-fitted parameters governing the compartmental model. Furthermore, we verify the performance of Epi-DNNs on the real-world reported COVID-19 data on the Omicron epidemic in Shanghai covering February 25 to May 27, 2022. The experimental findings on the synthesized data have revealed its effectiveness in COVID-19 transmission modeling. Moreover, the inferred parameters from the proposed Epi-DNNs method yield a predictive compartmental model, which can serve to forecast future dynamics.",True,other,convolutional neural network
36994203,Development and validation of machine learning models to predict survival of patients with resected stage-III NSCLC,"OBJECTIVE: To compare the performance of three machine learning algorithms with the tumor, node, and metastasis (TNM) staging system in survival prediction and validate the individual adjuvant treatment recommendations plan based on the optimal model.
METHODS: In this study, we trained three machine learning madel and validated 3 machine learning survival models-deep learning neural network, random forest and cox proportional hazard model- using the data of patients with stage-al3 NSCLC patients who received resection surgery from the National Cancer Institute Surveillance, Epidemiology, and End Results (SEER) database from 2012 to 2017,the performance of survival predication from all machine learning models were assessed using a concordance index (c-index) and the averaged c-index is utilized for cross-validation. The optimal model was externally validated in an independent cohort from Shaanxi Provincial People's Hospital. Then we compare the performance of the optimal model and TNM staging system. Finally, we developed a Cloud-based recommendation system for adjuvant therapy to visualize survival curve of each treatment plan and deployed on the internet.
RESULTS: A total of 4617 patients were included in this study. The deep learning network performed more stably and accurately in predicting stage-iii NSCLC resected patients survival than the random survival forest and Cox proportional hazard model on the internal test dataset (C-index=0.834 vs. 0.678 vs. 0.640) and better than TNM staging system (C-index=0.820 vs. 0.650) in the external validation. The individual patient who follow the reference from recommendation system had superior survival compared to those who did not. The predicted 5-year-survival curve for each adjuvant treatment plan could be accessed in the recommender system via the browser.
CONCLUSION: Deep learning model has several advantages over linear model and random forest model in prognostic predication and treatment recommendations. This novel analytical approach may provide accurate predication on individual survival and treatment recommendations for resected Stage-iii NSCLC patients.",True,other,recurrent neural network
36993761,Predicting metabolite response to dietary intervention using deep learning,"Due to highly personalized biological and lifestyle characteristics, different individuals may have different metabolite responses to specific foods and nutrients. In particular, the gut microbiota, a collection of trillions of microorganisms living in the gastrointestinal tract, is highly personalized and plays a key role in the metabolite responses to foods and nutrients. Accurately predicting metabolite responses to dietary interventions based on individuals' gut microbial compositions holds great promise for precision nutrition. Existing prediction methods are typically limited to traditional machine learning models. Deep learning methods dedicated to such tasks are still lacking. Here we develop a method McMLP (Metabolite response predictor using coupled Multilayer Perceptrons) to fill in this gap. We provide clear evidence that McMLP outperforms existing methods on both synthetic data generated by the microbial consumer-resource model and real data obtained from six dietary intervention studies. Furthermore, we perform sensitivity analysis of McMLP to infer the tripartite food-microbe-metabolite interactions, which are then validated using the ground-truth (or literature evidence) for synthetic (or real) data, respectively. The presented tool has the potential to inform the design of microbiota-based personalized dietary strategies to achieve precision nutrition.",True,other,Not specified
36973312,Author Correction: Development and evaluation of deep learning algorithms for assessment of acute burns and the need for surgery,,True,other,GAN
36966922,Screening for peripartum cardiomyopathies using artificial intelligence in Nigeria (SPEC-AI Nigeria): Clinical trial rationale and design,"BACKGROUND: Artificial intelligence (AI), and more specifically deep learning, models have demonstrated the potential to augment physician diagnostic capabilities and improve cardiovascular health if incorporated into routine clinical practice. However, many of these tools are yet to be evaluated prospectively in the setting of a rigorous clinical trial-a critical step prior to implementing broadly in routine clinical practice.
OBJECTIVES: To describe the rationale and design of a proposed clinical trial aimed at evaluating an AI-enabled electrocardiogram (AI-ECG) for cardiomyopathy detection in an obstetric population in Nigeria.
DESIGN: The protocol will enroll 1,000 pregnant and postpartum women who reside in Nigeria in a prospective randomized clinical trial. Nigeria has the highest reported incidence of peripartum cardiomyopathy worldwide. Women aged 18 and older, seen for routine obstetric care at 6 sites (2 Northern and 4 Southern) in Nigeria will be included. Participants will be randomized to the study intervention or control arm in a 1:1 fashion. This study aims to enroll participants representative of the general obstetric population at each site. The primary outcome is a new diagnosis of cardiomyopathy, defined as left ventricular ejection fraction (LVEF) < 50% during pregnancy or within 12 months postpartum. Secondary outcomes will include the detection of impaired left ventricular function (at different LVEF cut-offs), and exploratory outcomes will include the effectiveness of AI-ECG tools for cardiomyopathy detection, new diagnosis of cardiovascular disease, and the development of composite adverse maternal cardiovascular outcomes.
SUMMARY: This clinical trial focuses on the emerging field of cardio-obstetrics and will serve as foundational data for the use of AI-ECG tools in an obstetric population in Nigeria. This study will gather essential data regarding the utility of the AI-ECG for cardiomyopathy detection in a predominantly Black population of women and pave the way for clinical implementation of these models in routine practice.
TRIAL REGISTRATION: Clinicaltrials.gov: NCT05438576.",True,other,RNN
36959782,Development and validation of survival prediction model for gastric adenocarcinoma patients using deep learning: A SEER-based study,"BACKGROUND: The currently available prediction models, such as the Cox model, were too simplistic to correctly predict the outcome of gastric adenocarcinoma patients. This study aimed to develop and validate survival prediction models for gastric adenocarcinoma patients using the deep learning survival neural network.
METHODS: A total of 14,177 patients with gastric adenocarcinoma from the Surveillance, Epidemiology, and End Results (SEER) database were included in the study and randomly divided into the training and testing group with a 7:3 ratio. Two algorithms were chosen to build the prediction models, and both algorithms include random survival forest (RSF) and a deep learning based-survival prediction algorithm (DeepSurv). Also, a traditional Cox proportional hazard (CoxPH) model was constructed for comparison. The consistency index (C-index), Brier score, and integrated Brier score (IBS) were used to evaluate the model's predictive performance. The accuracy of predicting survival at 1, 3, 5, and 10 years was also assessed using receiver operating characteristic curves (ROC), calibration curves, and area under the ROC curve (AUC).
RESULTS: Gastric adenocarcinoma patients were randomized into a training group (n = 9923) and a testing group (n = 4254). DeepSurv showed the best performance among the three models (c-index: 0.772, IBS: 0.1421), which was superior to that of the traditional CoxPH model (c-index: 0.755, IBS: 0.1506) and the RSF with 3-year survival prediction model (c-index: 0.766, IBS: 0.1502). The DeepSurv model produced superior accuracy and calibrated survival estimates predicting 1-, 3- 5- and 10-year survival (AUC: 0.825-0.871).
CONCLUSIONS: A deep learning algorithm was developed to predict more accurate prognostic information for gastric cancer patients. The DeepSurv model has advantages over the CoxPH and RSF models and performs well in discriminative performance and calibration.",True,other,recurrent neural network
36935112,DeepMiceTL: a deep transfer learning based prediction of mice cardiac conduction diseases using early electrocardiograms,"Cardiac conduction disease is a major cause of morbidity and mortality worldwide. There is considerable clinical significance and an emerging need of early detection of these diseases for preventive treatment success before more severe arrhythmias occur. However, developing such early screening tools is challenging due to the lack of early electrocardiograms (ECGs) before symptoms occur in patients. Mouse models are widely used in cardiac arrhythmia research. The goal of this paper is to develop deep learning models to predict cardiac conduction diseases in mice using their early ECGs. We hypothesize that mutant mice present subtle abnormalities in their early ECGs before severe arrhythmias present. These subtle patterns can be detected by deep learning though they are hard to be identified by human eyes. We propose a deep transfer learning model, DeepMiceTL, which leverages knowledge from human ECGs to learn mouse ECG patterns. We further apply the Bayesian optimization and $k$-fold cross validation methods to tune the hyperparameters of the DeepMiceTL. Our results show that DeepMiceTL achieves a promising performance (F1-score: 83.8%, accuracy: 84.8%) in predicting the occurrence of cardiac conduction diseases using early mouse ECGs. This study is among the first efforts that use state-of-the-art deep transfer learning to identify ECG patterns during the early course of cardiac conduction disease in mice. Our approach not only could help in cardiac conduction disease research in mice, but also suggest a feasibility for early clinical diagnosis of human cardiac conduction diseases and other types of cardiac arrythmias using deep transfer learning in the future.",True,other,Not specified
36929044,Profiling of kidney involvement in systemic lupus erythematosus by deep learning using the National Database of Designated Incurable Diseases of Japan,"BACKGROUND: Kidney involvement frequently occurs in systemic lupus erythematosus (SLE), and its clinical manifestations are complicated. We profiled kidney involvement in SLE patients using deep learning based on data from the National Database of Designated Incurable Diseases of Japan.
METHODS: We analyzed the cross-sectional data of 1655 patients with SLE whose Personal Clinical Records were newly registered between 2015 and 2017. We trained an artificial neural network using clinical data, and the extracted characteristics were evaluated using an autoencoder. We tested the difference of population proportions to analyze the correlation between the presence or absence of kidney involvement and that of other clinical manifestations.
RESULTS: Data of patients with SLE were compressed in a feature space in which the anti-double-stranded deoxyribonucleic acid (anti-dsDNA) antibody titer, antinuclear antibody titer, or white blood cell count contributed significantly to distinguishing patients. Many SLE manifestations were accompanied by kidney involvement, whereas in a subgroup of patients with high anti-dsDNA antibody titers and low antinuclear antibody titers, kidney involvement was positively and negatively correlated with hemolytic anemia and inflammatory manifestations, respectively.
CONCLUSION: Although there are various combinations of SLE manifestations, our study revealed that some of them are specific to kidney involvement. SLE profiles extracted from the objective analysis will be useful for categorizing SLE manifestations.",True,other,Not specified
36927504,DFFNDDS: prediction of synergistic drug combinations with dual feature fusion networks,"Drug combination therapies are promising clinical treatments for curing patients. However, efficiently identifying valid drug combinations remains challenging because the number of available drugs has increased rapidly. In this study, we proposed a deep learning model called the Dual Feature Fusion Network for Drug-Drug Synergy prediction (DFFNDDS) that utilizes a fine-tuned pretrained language model and dual feature fusion mechanism to predict synergistic drug combinations. The dual feature fusion mechanism fuses the drug features and cell line features at the bit-wise level and the vector-wise level. We demonstrated that DFFNDDS outperforms competitive methods and can serve as a reliable tool for identifying synergistic drug combinations.",True,other,recurrent neural network
36913554,Big Data and Infectious Disease Epidemiology: Bibliometric Analysis and Research Agenda,"BACKGROUND: Infectious diseases represent a major challenge for health systems worldwide. With the recent global pandemic of COVID-19, the need to research strategies to treat these health problems has become even more pressing. Although the literature on big data and data science in health has grown rapidly, few studies have synthesized these individual studies, and none has identified the utility of big data in infectious disease surveillance and modeling.
OBJECTIVE: The aim of this study was to synthesize research and identify hotspots of big data in infectious disease epidemiology.
METHODS: Bibliometric data from 3054 documents that satisfied the inclusion criteria retrieved from the Web of Science database over 22 years (2000-2022) were analyzed and reviewed. The search retrieval occurred on October 17, 2022. Bibliometric analysis was performed to illustrate the relationships between research constituents, topics, and key terms in the retrieved documents.
RESULTS: The bibliometric analysis revealed internet searches and social media as the most utilized big data sources for infectious disease surveillance or modeling. The analysis also placed US and Chinese institutions as leaders in this research area. Disease monitoring and surveillance, utility of electronic health (or medical) records, methodology framework for infodemiology tools, and machine/deep learning were identified as the core research themes.
CONCLUSIONS: Proposals for future studies are made based on these findings. This study will provide health care informatics scholars with a comprehensive understanding of big data research in infectious disease epidemiology.",True,other,Not specified
36913401,Deep learning models for hepatitis E incidence prediction leveraging meteorological factors,"BACKGROUND: Infectious diseases are a major threat to public health, causing serious medical consumption and casualties. Accurate prediction of infectious diseases incidence is of great significance for public health organizations to prevent the spread of diseases. However, only using historical incidence data for prediction can not get good results. This study analyzes the influence of meteorological factors on the incidence of hepatitis E, which are used to improve the accuracy of incidence prediction.
METHODS: We extracted the monthly meteorological data, incidence and cases number of hepatitis E from January 2005 to December 2017 in Shandong province, China. We employ GRA method to analyze the correlation between the incidence and meteorological factors. With these meteorological factors, we achieve a variety of methods for incidence of hepatitis E by LSTM and attention-based LSTM. We selected data from July 2015 to December 2017 to validate the models, and the rest was taken as training set. Three metrics were applied to compare the performance of models, including root mean square error(RMSE), mean absolute percentage error(MAPE) and mean absolute error(MAE).
RESULTS: Duration of sunshine and rainfall-related factors(total rainfall, maximum daily rainfall) are more relevant to the incidence of hepatitis E than other factors. Without meteorological factors, we obtained 20.74%, 19.50% for incidence in term of MAPE, by LSTM and A-LSTM, respectively. With meteorological factors, we obtained 14.74%, 12.91%, 13.21%, 16.83% for incidence, in term of MAPE, by LSTM-All, MA-LSTM-All, TA-LSTM-All, BiA-LSTM-All, respectively. The prediction accuracy increased by 7.83%. Without meteorological factors, we achieved 20.41%, 19.39% for cases in term of MAPE, by LSTM and A-LSTM, respectively. With meteorological factors, we achieved 14.20%, 12.49%, 12.72%, 15.73% for cases, in term of MAPE, by LSTM-All, MA-LSTM-All, TA-LSTM-All, BiA-LSTM-All, respectively. The prediction accuracy increased by 7.92%. More detailed results are shown in results section of this paper.
CONCLUSIONS: The experiments show that attention-based LSTM is superior to other comparative models. Multivariate attention and temporal attention can greatly improve the prediction performance of the models. Among them, when all meteorological factors are used, multivariate attention performance is better. This study can provide reference for the prediction of other infectious diseases.",True,computer vision,Not specified
36910327,Artificial intelligence-based HDX (AI-HDX) prediction reveals fundamental characteristics to protein dynamics: Mechanisms on SARS-CoV-2 immune escape,"Three-dimensional structure and dynamics are essential for protein function. Advancements in hydrogen-deuterium exchange (HDX) techniques enable probing protein dynamic information in physiologically relevant conditions. HDX-coupled mass spectrometry (HDX-MS) has been broadly applied in pharmaceutical industries. However, it is challenging to obtain dynamics information at the single amino acid resolution and time consuming to perform the experiments and process the data. Here, we demonstrate the first deep learning model, artificial intelligence-based HDX (AI-HDX), that predicts intrinsic protein dynamics based on the protein sequence. It uncovers the protein structural dynamics by combining deep learning, experimental HDX, sequence alignment, and protein structure prediction. AI-HDX can be broadly applied to drug discovery, protein engineering, and biomedical studies. As a demonstration, we elucidated receptor-binding domain structural dynamics as a potential mechanism of anti-severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) antibody efficacy and immune escape. AI-HDX fundamentally differs from the current AI tools for protein analysis and may transform protein design for various applications.",True,other,Not specified
36892645,Nonalcoholic fatty liver disease (NAFLD) detection and deep learning in a Chinese community-based population,"OBJECTIVES: We aimed to develop and validate a deep learning system (DLS) by using an auxiliary section that extracts and outputs specific ultrasound diagnostic features to improve the explainable, clinical relevant utility of using DLS for detecting NAFLD.
METHODS: In a community-based study of 4144 participants with abdominal ultrasound scan in Hangzhou, China, we sampled 928 (617 [66.5%] females, mean age: 56 years ± 13 [standard deviation]) participants (2 images per participant) to develop and validate DLS, a two-section neural network (2S-NNet). Radiologists' consensus diagnosis classified hepatic steatosis as none steatosis, mild, moderate, and severe. We also explored the NAFLD detection performance of six one-section neural network models and five fatty liver indices on our data set. We further evaluated the influence of participants' characteristics on the correctness of 2S-NNet by logistic regression.
RESULTS: Area under the curve (AUROC) of 2S-NNet for hepatic steatosis was 0.90 for ≥ mild, 0.85 for ≥ moderate, and 0.93 for severe steatosis, and was 0.90 for NAFLD presence, 0.84 for moderate to severe NAFLD, and 0.93 for severe NAFLD. The AUROC of NAFLD severity was 0.88 for 2S-NNet, and 0.79-0.86 for one-section models. The AUROC of NAFLD presence was 0.90 for 2S-NNet, and 0.54-0.82 for fatty liver indices. Age, sex, body mass index, diabetes, fibrosis-4 index, android fat ratio, and skeletal muscle via dual-energy X-ray absorptiometry had no significant impact on the correctness of 2S-NNet (p > 0.05).
CONCLUSIONS: By using two-section design, 2S-NNet had improved the performance for detecting NAFLD with more explainable, clinical relevant utility than using one-section design.
KEY POINTS: • Based on the consensus review derived from radiologists, our DLS (2S-NNet) had an AUROC of 0.88 by using two-section design and yielded better performance for detecting NAFLD than using one-section design with more explainable, clinical relevant utility. • The 2S-NNet outperformed five fatty liver indices with the highest AUROCs (0.84-0.93 vs. 0.54-0.82) for different NAFLD severity screening, indicating screening utility of deep learning-based radiology may perform better than blood biomarker panels in epidemiology. • The correctness of 2S-NNet was not significantly influenced by individual's characteristics, including age, sex, body mass index, diabetes, fibrosis-4 index, android fat ratio, and skeletal muscle via dual-energy X-ray absorptiometry.",True,other,Not specified
36879885,AI-DrugNet: A network-based deep learning model for drug repurposing and combination therapy in neurological disorders,"Discovering effective therapies is difficult for neurological and developmental disorders in that disease progression is often associated with a complex and interactive mechanism. Over the past few decades, few drugs have been identified for treating Alzheimer's disease (AD), especially for impacting the causes of cell death in AD. Although drug repurposing is gaining more success in developing therapeutic efficacy for complex diseases such as common cancer, the complications behind AD require further study. Here, we developed a novel prediction framework based on deep learning to identify potential repurposed drug therapies for AD, and more importantly, our framework is broadly applicable and may generalize to identifying potential drug combinations in other diseases. Our prediction framework is as follows: we first built a drug-target pair (DTP) network based on multiple drug features and target features, as well as the associations between DTP nodes where drug-target pairs are the DTP nodes and the associations between DTP nodes are represented as the edges in the AD disease network; furthermore, we incorporated the drug-target feature from the DTP network and the relationship information between drug-drug, target-target, drug-target within and outside of drug-target pairs, representing each drug-combination as a quartet to generate corresponding integrated features; finally, we developed an AI-based Drug discovery Network (AI-DrugNet), which exhibits robust predictive performance. The implementation of our network model help identify potential repurposed and combination drug options that may serve to treat AD and other diseases.",True,other,Not specified
36873621,A multi-use deep learning method for CITE-seq and single-cell RNA-seq data integration with cell surface protein prediction and imputation,"CITE-seq, a single-cell multi-omics technology that measures RNA and protein expression simultaneously in single cells, has been widely applied in biomedical research, especially in immune related disorders and other diseases such as influenza and COVID-19. Despite the proliferation of CITE-seq, it is still costly to generate such data. Although data integration can increase information content, this raises computational challenges. First, combining multiple datasets is prone to batch effects that need to be addressed. Secondly, it is difficult to combine multiple CITE-seq datasets because the protein panels in different datasets may only partially overlap. Integrating multiple CITE-seq and single-cell RNA-seq (scRNA-seq) datasets is important because this allows the utilization of as many data as possible to uncover cell population heterogeneity. To overcome these challenges, we present sciPENN, a multi-use deep learning approach that supports CITE-seq and scRNA-seq data integration, protein expression prediction for scRNA-seq, protein expression imputation for CITE-seq, quantification of prediction and imputation uncertainty, and cell type label transfer from CITE-seq to scRNA-seq. Comprehensive evaluations spanning multiple datasets demonstrate that sciPENN outperforms other current state-of-the-art methods.",True,both,Not specified
36870459,"Artificial intelligence in cancer immunotherapy: Applications in neoantigen recognition, antibody design and immunotherapy response prediction","Cancer immunotherapy is a method of controlling and eliminating tumors by reactivating the body's cancer-immunity cycle and restoring its antitumor immune response. The increased availability of data, combined with advancements in high-performance computing and innovative artificial intelligence (AI) technology, has resulted in a rise in the use of AI in oncology research. State-of-the-art AI models for functional classification and prediction in immunotherapy research are increasingly used to support laboratory-based experiments. This review offers a glimpse of the current AI applications in immunotherapy, including neoantigen recognition, antibody design, and prediction of immunotherapy response. Advancing in this direction will result in more robust predictive models for developing better targets, drugs, and treatments, and these advancements will eventually make their way into the clinical setting, pushing AI forward in the field of precision oncology.",True,other,Not specified
36862499,Unassisted Clinicians Versus Deep Learning-Assisted Clinicians in Image-Based Cancer Diagnostics: Systematic Review With Meta-analysis,"BACKGROUND: A number of publications have demonstrated that deep learning (DL) algorithms matched or outperformed clinicians in image-based cancer diagnostics, but these algorithms are frequently considered as opponents rather than partners. Despite the clinicians-in-the-loop DL approach having great potential, no study has systematically quantified the diagnostic accuracy of clinicians with and without the assistance of DL in image-based cancer identification.
OBJECTIVE: We systematically quantified the diagnostic accuracy of clinicians with and without the assistance of DL in image-based cancer identification.
METHODS: PubMed, Embase, IEEEXplore, and the Cochrane Library were searched for studies published between January 1, 2012, and December 7, 2021. Any type of study design was permitted that focused on comparing unassisted clinicians and DL-assisted clinicians in cancer identification using medical imaging. Studies using medical waveform-data graphics material and those investigating image segmentation rather than classification were excluded. Studies providing binary diagnostic accuracy data and contingency tables were included for further meta-analysis. Two subgroups were defined and analyzed, including cancer type and imaging modality.
RESULTS: In total, 9796 studies were identified, of which 48 were deemed eligible for systematic review. Twenty-five of these studies made comparisons between unassisted clinicians and DL-assisted clinicians and provided sufficient data for statistical synthesis. We found a pooled sensitivity of 83% (95% CI 80%-86%) for unassisted clinicians and 88% (95% CI 86%-90%) for DL-assisted clinicians. Pooled specificity was 86% (95% CI 83%-88%) for unassisted clinicians and 88% (95% CI 85%-90%) for DL-assisted clinicians. The pooled sensitivity and specificity values for DL-assisted clinicians were higher than for unassisted clinicians, at ratios of 1.07 (95% CI 1.05-1.09) and 1.03 (95% CI 1.02-1.05), respectively. Similar diagnostic performance by DL-assisted clinicians was also observed across the predefined subgroups.
CONCLUSIONS: The diagnostic performance of DL-assisted clinicians appears better than unassisted clinicians in image-based cancer identification. However, caution should be exercised, because the evidence provided in the reviewed studies does not cover all the minutiae involved in real-world clinical practice. Combining qualitative insights from clinical practice with data-science approaches may improve DL-assisted practice, although further research is required.
TRIAL REGISTRATION: PROSPERO CRD42021281372; https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=281372.",True,other,Not specified
36848828,MonkeyNet: A robust deep convolutional neural network for monkeypox disease detection and classification,"The monkeypox virus poses a new pandemic threat while we are still recovering from COVID-19. Despite the fact that monkeypox is not as lethal and contagious as COVID-19, new patient cases are recorded every day. If preparations are not made, a global pandemic is likely. Deep learning (DL) techniques are now showing promise in medical imaging for figuring out what diseases a person has. The monkeypox virus-infected human skin and the region of the skin can be used to diagnose the monkeypox early because an image has been used to learn more about the disease. But there is still no reliable Monkeypox database that is available to the public that can be used to train and test DL models. As a result, it is essential to collect images of monkeypox patients. The ""MSID"" dataset, short form of ""Monkeypox Skin Images Dataset"", which was developed for this research, is free to use and can be downloaded from the Mendeley Data database by anyone who wants to use it. DL models can be built and used with more confidence using the images in this dataset. These images come from a variety of open-source and online sources and can be used for research purposes without any restrictions. Furthermore, we proposed and evaluated a modified DenseNet-201 deep learning-based CNN model named MonkeyNet. Using the original and augmented datasets, this study suggested a deep convolutional neural network that was able to correctly identify monkeypox disease with an accuracy of 93.19% and 98.91% respectively. This implementation also shows the Grad-CAM which indicates the level of the model's effectiveness and identifies the infected regions in each class image, which will help the clinicians. The proposed model will also help doctors make accurate early diagnoses of monkeypox disease and protect against the spread of the disease.",True,other,Not specified
36821889,Incorporating variant frequencies data into short-term forecasting for COVID-19 cases and deaths in the USA: a deep learning approach,"BACKGROUND: Since the US reported its first COVID-19 case on January 21, 2020, the science community has been applying various techniques to forecast incident cases and deaths. To date, providing an accurate and robust forecast at a high spatial resolution has proved challenging, even in the short term.
METHOD: Here we present a novel multi-stage deep learning model to forecast the number of COVID-19 cases and deaths for each US state at a weekly level for a forecast horizon of 1-4 weeks. The model is heavily data driven, and relies on epidemiological, mobility, survey, climate, demographic, and SARS-CoV-2 variant frequencies data. We implement a rigorous and robust evaluation of our model-specifically we report on weekly performance over a one-year period based on multiple error metrics, and explicitly assess how our model performance varies over space, chronological time, and different outbreak phases.
FINDINGS: The proposed model is shown to consistently outperform the CDC ensemble model for all evaluation metrics in multiple spatiotemporal settings, especially for the longer-term (3 and 4 weeks ahead) forecast horizon. Our case study also highlights the potential value of variant frequencies data for use in short-term forecasting to identify forthcoming surges driven by new variants.
INTERPRETATION: Based on our findings, the proposed forecasting framework improves upon the available state-of-the-art forecasting tools currently used to support public health decision making with respect to COVID-19 risk.
FUNDING: This work was funded the NSF Rapid Response Research (RAPID) grant Award ID 2108526 and the CDC Contract #75D30120C09570.",True,other,recurrent neural network
36816916,Deep learning of bone metastasis in small cell lung cancer: A large sample-based study,"INTRODUCTION: Bone is a common metastatic site for small cell lung cancer (SCLC). Bone metastasis (BM) in patients have are known to show poor prognostic outcomes. We explored the epidemiological characteristics of BM in SCLC patients and create a new deep learning model to predict outcomes for cancer-specific survival (CSS) and overall survival (OS).
MATERIALS AND METHODS: Data for SCLC patients diagnosed with or without BM from 2010 to 2016 were retrieved from the Surveillance, Epidemiology, and End Results (SEER) database. Univariate and multivariate Cox proportional hazards regression models were used to evaluate the effects of prognostic variables on OS and CSS. Through integration of these variables, nomograms were created for the prediction of CSS and OS rates at 3-month,6- month,and 12-month. Harrell's coordination index, calibration curves,and time- dependent ROC curves were used to assess the nomograms' accuracy. Decision tree analysis was used to evaluate the clinical application value of the established nomogram.
RESULTS: In this study, 4201 patients were enrolled. Male sex, tumor size 25 but <10, brain and liver metastases, as well as chemotherapy were associated with a high risk for BM. Tumor size, Age, N stage, gender, liver metastasis, radiotherapy as well as chemotherapy were shown to be prognostic variables for OS, and the prognostic variables for CSS were added to the tumor number in addition. Based on these results, nomograms for CSS and OS were established separately. Internal as well as external validation showed that the C-index, calibration cuurve and DCA had good constructive correction effect and clinical application value. Decision tree analysis further confirmed the prognostic factors of OS and CSS.
DISCUSSION: The nomogram and decision tree models developed in this study effectively guided treatment decisions for SCLC patients with BM. The creation of prediction models for BM SCLC patients may be facilitated by deep learning models.",True,other,Not specified
36813827,Author Correction: Prostate cancer therapy personalization via multi-modal deep learning on randomized phase III clinical trials,,True,other,GAN
36807383,Gene-environment interaction analysis via deep learning,"Gene-environment (G-E) interaction analysis plays an important role in studying complex diseases. Extensive methodological research has been conducted on G-E interaction analysis, and the existing methods are mostly based on regression techniques. In many fields including biomedicine and omics, it has been increasingly recognized that deep learning may outperform regression with its unique flexibility (e.g., in accommodating unspecified nonlinear effects) and superior prediction performance. However, there has been a lack of development in deep learning for G-E interaction analysis. In this article, we fill this important knowledge gap and develop a new analysis approach based on deep neural network in conjunction with penalization. The proposed approach can simultaneously conduct model estimation and selection (of important main G effects and G-E interactions), while uniquely respecting the ""main effects, interactions"" variable selection hierarchy. Simulation shows that it has superior prediction and feature selection performance. The analysis of data on lung adenocarcinoma and skin cutaneous melanoma overall survival further establishes its practical utility. Overall, this study can advance G-E interaction analysis by delivering a powerful new analysis approach based on modern deep learning.",True,other,recurrent neural network
36805232,Stroke mortality prediction based on ensemble learning and the combination of structured and textual data,"For severe cerebrovascular diseases such as stroke, the prediction of short-term mortality of patients has tremendous medical significance. In this study, we combined machine learning models Random Forest classifier (RF), Adaptive Boosting (AdaBoost), Extremely Randomised Trees (ExtraTree) classifier, XGBoost classifier, TabNet, and DistilBERT to construct a multi-level prediction model that used bioassay data and radiology text reports from haemorrhagic and ischaemic stroke patients to predict six-month mortality. The performances of the prediction models were measured using the area under the receiver operating characteristic curve (AUROC), the area under the precision-recall curve (AUPRC), precision, recall, and F1-score. The prediction models were built with the use of data from 19,616 haemorrhagic stroke patients and 50,178 ischaemic stroke patients. Novel six-month mortality prediction models for these patients were developed, which enhanced the performance of the prediction models by combining laboratory test data, structured data, and textual radiology report data. The achieved performances were as follows: AUROC = 0.89, AUPRC = 0.70, precision = 0.52, recall = 0.78, and F1 score = 0.63 for haemorrhagic patients, and AUROC = 0.88, AUPRC = 0.54, precision = 0.34, recall = 0.80, and F1 score = 0.48 for ischaemic patients. Such models could be used for mortality risk assessment and early identification of high-risk stroke patients. This could contribute to more efficient utilisation of healthcare resources for stroke survivors.",True,other,Not specified
36789031,HyperVR: a hybrid deep ensemble learning approach for simultaneously predicting virulence factors and antibiotic resistance genes,"Infectious diseases emerge unprecedentedly, posing serious challenges to public health and the global economy. Virulence factors (VFs) enable pathogens to adhere, reproduce and cause damage to host cells, and antibiotic resistance genes (ARGs) allow pathogens to evade otherwise curable treatments. Simultaneous identification of VFs and ARGs can save pathogen surveillance time, especially in situ epidemic pathogen detection. However, most tools can only predict either VFs or ARGs. Few tools that predict VFs and ARGs simultaneously usually have high false-negative rates, are sensitive to the cutoff thresholds and can only identify conserved genes. For better simultaneous prediction of VFs and ARGs, we propose a hybrid deep ensemble learning approach called HyperVR. By considering both best hit scores and statistical gene sequence patterns, HyperVR combines classical machine learning and deep learning to simultaneously and accurately predict VFs, ARGs and negative genes (neither VFs nor ARGs). For the prediction of individual VFs and ARGs, in silico spike-in experiment (the VFs and ARGs in real metagenomic data), and pseudo-VFs and -ARGs (gene fragments), HyperVR outperforms the current state-of-the-art prediction tools. HyperVR uses only gene sequence information without strict cutoff thresholds, hence making prediction straightforward and reliable.",True,other,Not specified
36780207,Deep-Learning Model for Influenza Prediction From Multisource Heterogeneous Data in a Megacity: Model Development and Evaluation,"BACKGROUND: In megacities, there is an urgent need to establish more sensitive forecasting and early warning methods for acute respiratory infectious diseases. Existing prediction and early warning models for influenza and other acute respiratory infectious diseases have limitations and therefore there is room for improvement.
OBJECTIVE: The aim of this study was to explore a new and better-performing deep-learning model to predict influenza trends from multisource heterogeneous data in a megacity.
METHODS: We collected multisource heterogeneous data from the 26th week of 2012 to the 25th week of 2019, including influenza-like illness (ILI) cases and virological surveillance, data of climate and demography, and search engines data. To avoid collinearity, we selected the best predictor according to the weight and correlation of each factor. We established a new multiattention-long short-term memory (LSTM) deep-learning model (MAL model), which was used to predict the percentage of ILI (ILI%) cases and the product of ILI% and the influenza-positive rate (ILI%×positive%), respectively. We also combined the data in different forms and added several machine-learning and deep-learning models commonly used in the past to predict influenza trends for comparison. The R2 value, explained variance scores, mean absolute error, and mean square error were used to evaluate the quality of the models.
RESULTS: The highest correlation coefficients were found for the Baidu search data for ILI% and for air quality for ILI%×positive%. We first used the MAL model to calculate the ILI%, and then combined ILI% with climate, demographic, and Baidu data in different forms. The ILI%+climate+demography+Baidu model had the best prediction effect, with the explained variance score reaching 0.78, R2 reaching 0.76, mean absolute error of 0.08, and mean squared error of 0.01. Similarly, we used the MAL model to calculate the ILI%×positive% and combined this prediction with different data forms. The ILI%×positive%+climate+demography+Baidu model had the best prediction effect, with an explained variance score reaching 0.74, R2 reaching 0.70, mean absolute error of 0.02, and mean squared error of 0.02. Comparisons with random forest, extreme gradient boosting, LSTM, and gated current unit models showed that the MAL model had the best prediction effect.
CONCLUSIONS: The newly established MAL model outperformed existing models. Natural factors and search engine query data were more helpful in forecasting ILI patterns in megacities. With more timely and effective prediction of influenza and other respiratory infectious diseases and the epidemic intensity, early and better preparedness can be achieved to reduce the health damage to the population.",True,other,Not specified
36752347,AD-Syn-Net: systematic identification of Alzheimer's disease-associated mutation and co-mutation vulnerabilities via deep learning,"Alzheimer's disease (AD) is one of the most challenging neurodegenerative diseases because of its complicated and progressive mechanisms, and multiple risk factors. Increasing research evidence demonstrates that genetics may be a key factor responsible for the occurrence of the disease. Although previous reports identified quite a few AD-associated genes, they were mostly limited owing to patient sample size and selection bias. There is a lack of comprehensive research aimed to identify AD-associated risk mutations systematically. To address this challenge, we hereby construct a large-scale AD mutation and co-mutation framework ('AD-Syn-Net'), and propose deep learning models named Deep-SMCI and Deep-CMCI configured with fully connected layers that are capable of predicting cognitive impairment of subjects effectively based on genetic mutation and co-mutation profiles. Next, we apply the customized frameworks to data sets to evaluate the importance scores of the mutations and identified mutation effectors and co-mutation combination vulnerabilities contributing to cognitive impairment. Furthermore, we evaluate the influence of mutation pairs on the network architecture to dissect the genetic organization of AD and identify novel co-mutations that could be responsible for dementia, laying a solid foundation for proposing future targeted therapy for AD precision medicine. Our deep learning model codes are available open access here: https://github.com/Pan-Bio/AD-mutation-effectors.",True,other,Not specified
36747873,An intrinsically interpretable neural network architecture for sequence to function learning,"MOTIVATION: Sequence-based deep learning approaches have been shown to predict a multitude of functional genomic readouts, including regions of open chromatin and RNA expression of genes. However, a major limitation of current methods is that model interpretation relies on computationally demanding post hoc analyses, and even then, one can often not explain the internal mechanics of highly parameterized models. Here, we introduce a deep learning architecture called tiSFM (totally interpretable sequence to function model). tiSFM improves upon the performance of standard multi-layer convolutional models while using fewer parameters. Additionally, while tiSFM is itself technically a multi-layer neural network, internal model parameters are intrinsically interpretable in terms of relevant sequence motifs.
RESULTS: We analyze published open chromatin measurements across hematopoietic lineage cell-types and demonstrate that tiSFM outperforms a state-of-the-art convolutional neural network model custom-tailored to this dataset. We also show that it correctly identifies context specific activities of transcription factors with known roles in hematopoietic differentiation, including Pax5 and Ebf1 for B-cells, and Rorc for innate lymphoid cells. tiSFM's model parameters have biologically meaningful interpretations, and we show the utility of our approach on a complex task of predicting the change in epigenetic state as a function of developmental transition.
AVAILABILITY AND IMPLEMENTATION: The source code, including scripts for the analysis of key findings, can be found at https://github.com/boooooogey/ATAConv, implemented in Python.",True,other,recurrent neural network
36746615,Validation of a deep learning system for the detection of diabetic retinopathy in Indigenous Australians,"BACKGROUND/AIMS: Deep learning systems (DLSs) for diabetic retinopathy (DR) detection show promising results but can underperform in racial and ethnic minority groups, therefore external validation within these populations is critical for health equity. This study evaluates the performance of a DLS for DR detection among Indigenous Australians, an understudied ethnic group who suffer disproportionately from DR-related blindness.
METHODS: We performed a retrospective external validation study comparing the performance of a DLS against a retinal specialist for the detection of more-than-mild DR (mtmDR), vision-threatening DR (vtDR) and all-cause referable DR. The validation set consisted of 1682 consecutive, single-field, macula-centred retinal photographs from 864 patients with diabetes (mean age 54.9 years, 52.4% women) at an Indigenous primary care service in Perth, Australia. Three-person adjudication by a panel of specialists served as the reference standard.
RESULTS: For mtmDR detection, sensitivity of the DLS was superior to the retina specialist (98.0% (95% CI, 96.5 to 99.4) vs 87.1% (95% CI, 83.6 to 90.6), McNemar's test p<0.001) with a small reduction in specificity (95.1% (95% CI, 93.6 to 96.4) vs 97.0% (95% CI, 95.9 to 98.0), p=0.006). For vtDR, the DLS's sensitivity was again superior to the human grader (96.2% (95% CI, 93.4 to 98.6) vs 84.4% (95% CI, 79.7 to 89.2), p<0.001) with a slight drop in specificity (95.8% (95% CI, 94.6 to 96.9) vs 97.8% (95% CI, 96.9 to 98.6), p=0.002). For all-cause referable DR, there was a substantial increase in sensitivity (93.7% (95% CI, 91.8 to 95.5) vs 74.4% (95% CI, 71.1 to 77.5), p<0.001) and a smaller reduction in specificity (91.7% (95% CI, 90.0 to 93.3) vs 96.3% (95% CI, 95.2 to 97.4), p<0.001).
CONCLUSION: The DLS showed improved sensitivity and similar specificity compared with a retina specialist for DR detection. This demonstrates its potential to support DR screening among Indigenous Australians, an underserved population with a high burden of diabetic eye disease.",True,other,Not specified
36745490,"Long Short-term Memory-Based Prediction of the Spread of Influenza-Like Illness Leveraging Surveillance, Weather, and Twitter Data: Model Development and Validation","BACKGROUND: The potential to harness the plurality of available data in real time along with advanced data analytics for the accurate prediction of influenza-like illness (ILI) outbreaks has gained significant scientific interest. Different methodologies based on the use of machine learning techniques and traditional and alternative data sources, such as ILI surveillance reports, weather reports, search engine queries, and social media, have been explored with the ultimate goal of being used in the development of electronic surveillance systems that could complement existing monitoring resources.
OBJECTIVE: The scope of this study was to investigate for the first time the combined use of ILI surveillance data, weather data, and Twitter data along with deep learning techniques toward the development of prediction models able to nowcast and forecast weekly ILI cases. By assessing the predictive power of both traditional and alternative data sources on the use case of ILI, this study aimed to provide a novel approach for corroborating evidence and enhancing accuracy and reliability in the surveillance of infectious diseases.
METHODS: The model's input space consisted of information related to weekly ILI surveillance, web-based social (eg, Twitter) behavior, and weather conditions. For the design and development of the model, relevant data corresponding to the period of 2010 to 2019 and focusing on the Greek population and weather were collected. Long short-term memory (LSTM) neural networks were leveraged to efficiently handle the sequential and nonlinear nature of the multitude of collected data. The 3 data categories were first used separately for training 3 LSTM-based primary models. Subsequently, different transfer learning (TL) approaches were explored with the aim of creating various feature spaces combining the features extracted from the corresponding primary models' LSTM layers for the latter to feed a dense layer.
RESULTS: The primary model that learned from weather data yielded better forecast accuracy (root mean square error [RMSE]=0.144; Pearson correlation coefficient [PCC]=0.801) than the model trained with ILI historical data (RMSE=0.159; PCC=0.794). The best performance was achieved by the TL-based model leveraging the combination of the 3 data categories (RMSE=0.128; PCC=0.822).
CONCLUSIONS: The superiority of the TL-based model, which considers Twitter data, weather data, and ILI surveillance data, reflects the potential of alternative public sources to enhance accurate and reliable prediction of ILI spread. Despite its focus on the use case of Greece, the proposed approach can be generalized to other locations, populations, and social media platforms to support the surveillance of infectious diseases with the ultimate goal of reinforcing preparedness for future epidemics.",True,other,CNN
36740608,Deep learning-based prediction model for postoperative complications of cervical posterior longitudinal ligament ossification,"PURPOSE: Postoperative complication prediction helps surgeons to inform and manage patient expectations. Deep learning, a model that finds patterns in large samples of data, outperform traditional statistical methods in making predictions. This study aimed to create a deep learning-based model (DLM) to predict postoperative complications in patients with cervical ossification of the posterior longitudinal ligament (OPLL).
METHODS: This prospective multicenter study was conducted by the 28 institutions, and 478 patients were included in the analysis. Deep learning was used to create two predictive models of the overall postoperative complications and neurological complications, one of the major complications. These models were constructed by learning the patient's preoperative background, clinical symptoms, surgical procedures, and imaging findings. These logistic regression models were also created, and these accuracies were compared with those of the DLM.
RESULTS: Overall complications were observed in 127 cases (26.6%). The accuracy of the DLM was 74.6 ± 3.7% for predicting the overall occurrence of complications, which was comparable to that of the logistic regression (74.1%). Neurological complications were observed in 48 cases (10.0%), and the accuracy of the DLM was 91.7 ± 3.5%, which was higher than that of the logistic regression (90.1%).
CONCLUSION: A new algorithm using deep learning was able to predict complications after cervical OPLL surgery. This model was well calibrated, with prediction accuracy comparable to that of regression models. The accuracy remained high even for predicting only neurological complications, for which the case number is limited compared to conventional statistical methods.",True,other,recurrent neural network
36703783,Efficient feature extraction from highly sparse binary genotype data for cancer prognosis prediction using an auto-encoder,"Genomics involving tens of thousands of genes is a complex system determining phenotype. An interesting and vital issue is how to integrate highly sparse genetic genomics data with a mass of minor effects into a prediction model for improving prediction power. We find that the deep learning method can work well to extract features by transforming highly sparse dichotomous data to lower-dimensional continuous data in a non-linear way. This may provide benefits in risk prediction-associated genotype data. We developed a multi-stage strategy to extract information from highly sparse binary genotype data and applied it for cancer prognosis. Specifically, we first reduced the size of binary biomarkers via a univariable regression model to a moderate size. Then, a trainable auto-encoder was used to learn compact features from the reduced data. Next, we performed a LASSO problem process to select the optimal combination of extracted features. Lastly, we applied such feature combination to real cancer prognostic models and evaluated the raw predictive effect of the models. The results indicated that these compressed transformation features could better improve the model's original predictive performance and might avoid an overfitting problem. This idea may be enlightening for everyone involved in cancer research, risk reduction, treatment, and patient care via integrating genomics data.",True,other,recurrent neural network
36694118,Comparison of State-of-the-Art Neural Network Survival Models with the Pooled Cohort Equations for Cardiovascular Disease Risk Prediction,"BACKGROUND: The Pooled Cohort Equations (PCEs) are race- and sex-specific Cox proportional hazards (PH)-based models used for 10-year atherosclerotic cardiovascular disease (ASCVD) risk prediction with acceptable discrimination. In recent years, neural network models have gained increasing popularity with their success in image recognition and text classification. Various survival neural network models have been proposed by combining survival analysis and neural network architecture to take advantage of the strengths from both. However, the performance of these survival neural network models compared to each other and to PCEs in ASCVD prediction is unknown.
METHODS: In this study, we used 6 cohorts from the Lifetime Risk Pooling Project (with 5 cohorts as training/internal validation and one cohort as external validation) and compared the performance of the PCEs in 10-year ASCVD risk prediction with an all two-way interactions Cox PH model (Cox PH-TWI) and three state-of-the-art neural network survival models including Nnet-survival, Deepsurv, and Cox-nnet. For all the models, we used the same 7 covariates as used in the PCEs. We fitted each of the aforementioned models in white females, white males, black females, and black males, respectively. We evaluated models' internal and external discrimination power and calibration.
RESULTS: The training/internal validation sample comprised 23216 individuals. The average age at baseline was 57.8 years old (SD = 9.6); 16% developed ASCVD during average follow-up of 10.50 (SD = 3.02) years. Based on 10 × 10 cross-validation, the method that had the highest C-statistics was Deepsurv (0.7371) for white males, Deepsurv and Cox PH-TWI (0.7972) for white females, PCE (0.6981) for black males, and Deepsurv (0.7886) for black females. In the external validation dataset, Deepsurv (0.7032), Cox-nnet (0.7282), PCE (0.6811), and Deepsurv (0.7316) had the highest C-statistics for white male, white female, black male, and black female population, respectively. Calibration plots showed that in 10 × 10 validation, all models had good calibration in all race and sex groups. In external validation, all models overestimated the risk for 10-year ASCVD.
CONCLUSIONS: We demonstrated the use of the state-of-the-art neural network survival models in ASCVD risk prediction. Neural network survival models had similar if not superior discrimination and calibration compared to PCEs.",True,other,recurrent neural network
36691041,Validation of a deep-learning-based retinal biomarker (Reti-CVD) in the prediction of cardiovascular disease: data from UK Biobank,"BACKGROUND: Currently in the United Kingdom, cardiovascular disease (CVD) risk assessment is based on the QRISK3 score, in which 10% 10-year CVD risk indicates clinical intervention. However, this benchmark has limited efficacy in clinical practice and the need for a more simple, non-invasive risk stratification tool is necessary. Retinal photography is becoming increasingly acceptable as a non-invasive imaging tool for CVD. Previously, we developed a novel CVD risk stratification system based on retinal photographs predicting future CVD risk. This study aims to further validate our biomarker, Reti-CVD, (1) to detect risk group of ≥ 10% in 10-year CVD risk and (2) enhance risk assessment in individuals with QRISK3 of 7.5-10% (termed as borderline-QRISK3 group) using the UK Biobank.
METHODS: Reti-CVD scores were calculated and stratified into three risk groups based on optimized cut-off values from the UK Biobank. We used Cox proportional-hazards models to evaluate the ability of Reti-CVD to predict CVD events in the general population. C-statistics was used to assess the prognostic value of adding Reti-CVD to QRISK3 in borderline-QRISK3 group and three vulnerable subgroups.
RESULTS: Among 48,260 participants with no history of CVD, 6.3% had CVD events during the 11-year follow-up. Reti-CVD was associated with an increased risk of CVD (adjusted hazard ratio [HR] 1.41; 95% confidence interval [CI], 1.30-1.52) with a 13.1% (95% CI, 11.7-14.6%) 10-year CVD risk in Reti-CVD-high-risk group. The 10-year CVD risk of the borderline-QRISK3 group was greater than 10% in Reti-CVD-high-risk group (11.5% in non-statin cohort [n = 45,473], 11.5% in stage 1 hypertension cohort [n = 11,966], and 14.2% in middle-aged cohort [n = 38,941]). C statistics increased by 0.014 (0.010-0.017) in non-statin cohort, 0.013 (0.007-0.019) in stage 1 hypertension cohort, and 0.023 (0.018-0.029) in middle-aged cohort for CVD event prediction after adding Reti-CVD to QRISK3.
CONCLUSIONS: Reti-CVD has the potential to identify individuals with ≥ 10% 10-year CVD risk who are likely to benefit from earlier preventative CVD interventions. For borderline-QRISK3 individuals with 10-year CVD risk between 7.5 and 10%, Reti-CVD could be used as a risk enhancer tool to help improve discernment accuracy, especially in adult groups that may be pre-disposed to CVD.",True,other,Not specified
36689543,Influenza surveillance with Baidu index and attention-based long short-term memory model,"BACKGROUND: The prediction and prevention of influenza is a public health issue of great concern, and the study of timely acquisition of influenza transmission trend has become an important research topic. For achieving more quicker and accurate detection and prediction, the data recorded on the Internet, especially on the search engine from Google or Baidu are widely introduced into this field. Moreover, with the development of intelligent technology and machine learning algorithm, many updated and advanced trend tracking and forecasting methods are also being used in this research problem.
METHODS: In this paper, a new recurrent neural network architecture, attention-based long short-term memory model is proposed for influenza surveillance. This is a kind of deep learning model which is trained by processing from Baidu Index series so as to fit the real influenza survey time series. Previous studies on influenza surveillance by Baidu Index mostly used traditional autoregressive moving average model or classical machine learning models such as logarithmic linear regression, support vector regression or multi-layer perception model to fit influenza like illness data, which less considered the deep learning structure. Meanwhile, some new model that considered the deep learning structure did not take into account the application of Baidu index data. This study considers introducing the recurrent neural network with long short-term memory combined with attention mechanism into the influenza surveillance research model, which not only fits the research problems well in model structure, but also provides research methods based on Baidu index.
RESULTS: The actual survey data and Baidu Index data are used to train and test the proposed attention-based long short-term memory model and the other comparison models, so as to iterate the value of the model parameters, and to describe and predict the influenza epidemic situation. The experimental results show that our proposed model has better performance in the mean absolute error, mean absolute percentage error, index of agreement and other indicators than the other comparison models.
CONCLUSION: Our proposed attention-based long short-term memory model vividly verifies the ability of this attention-based long short-term memory structure for better surveillance and prediction the trend of influenza. In comparison with some of the latest models and methods in this research field, the model we proposed is also excellent in effect, even more lightweight and robust. Future research direction can consider fusing multimodal data based on this model and developing more application scenarios.",True,other,recurrent neural network
36688019,Artificial intelligence and inflammatory bowel disease: Where are we going?,"Inflammatory bowel diseases, namely ulcerative colitis and Crohn's disease, are chronic and relapsing conditions that pose a growing burden on healthcare systems worldwide. Because of their complex and partly unknown etiology and pathogenesis, the management of ulcerative colitis and Crohn's disease can prove challenging not only from a clinical point of view but also for resource optimization. Artificial intelligence, an umbrella term that encompasses any cognitive function developed by machines for learning or problem solving, and its subsets machine learning and deep learning are becoming ever more essential tools with a plethora of applications in most medical specialties. In this regard gastroenterology is no exception, and due to the importance of endoscopy and imaging numerous clinical studies have been gradually highlighting the relevant role that artificial intelligence has in inflammatory bowel diseases as well. The aim of this review was to summarize the most recent evidence on the use of artificial intelligence in inflammatory bowel diseases in various contexts such as diagnosis, follow-up, treatment, prognosis, cancer surveillance, data collection, and analysis. Moreover, insights into the potential further developments in this field and their effects on future clinical practice were discussed.",True,other,recurrent neural network
36650803,Pandemic disease detection through wireless communication using infrared image based on deep learning,"Rapid diagnosis to test diseases, such as COVID-19, is a significant issue. It is a routine virus test in a reverse transcriptase-polymerase chain reaction. However, a test like this takes longer to complete because it follows the serial testing method, and there is a high chance of a false-negative ratio (FNR). Moreover, there arises a deficiency of R.T.-PCR test kits. Therefore, alternative procedures for a quick and accurate diagnosis of patients are urgently needed to deal with these pandemics. The infrared image is self-sufficient for detecting these diseases by measuring the temperature at the initial stage. C.T. scans and other pathological tests are valuable aspects of evaluating a patient with a suspected pandemic infection. However, a patient's radiological findings may not be identified initially. Therefore, we have included an Artificial Intelligence (A.I.) algorithm-based Machine Intelligence (MI) system in this proposal to combine C.T. scan findings with all other tests, symptoms, and history to quickly diagnose a patient with a positive symptom of current and future pandemic diseases. Initially, the system will collect information by an infrared camera of the patient's facial regions to measure temperature, keep it as a record, and complete further actions. We divided the face into eight classes and twelve regions for temperature measurement. A database named patient-info-mask is maintained. While collecting sample data, we incorporate a wireless network using a cloudlets server to make processing more accessible with minimal infrastructure. The system will use deep learning approaches. We propose convolution neural networks (CNN) to cross-verify the collected data. For better results, we incorporated tenfold cross-verification into the synthesis method. As a result, our new way of estimating became more accurate and efficient. We achieved 3.29% greater accuracy by incorporating the ""decision tree level synthesis method"" and ""ten-folded-validation method"". It proves the robustness of our proposed method.",True,other,RNN
36650299,"Use of Deep Neural Networks in the Detection and Automated Classification of Lesions Using Clinical Images in Ophthalmology, Dermatology, and Oral Medicine-A Systematic Review","Artificial neural networks (ANN) are artificial intelligence (AI) techniques used in the automated recognition and classification of pathological changes from clinical images in areas such as ophthalmology, dermatology, and oral medicine. The combination of enterprise imaging and AI is gaining notoriety for its potential benefits in healthcare areas such as cardiology, dermatology, ophthalmology, pathology, physiatry, radiation oncology, radiology, and endoscopic. The present study aimed to analyze, through a systematic literature review, the application of performance of ANN and deep learning in the recognition and automated classification of lesions from clinical images, when comparing to the human performance. The PRISMA 2020 approach (Preferred Reporting Items for Systematic Reviews and Meta-analyses) was used by searching four databases of studies that reference the use of IA to define the diagnosis of lesions in ophthalmology, dermatology, and oral medicine areas. A quantitative and qualitative analyses of the articles that met the inclusion criteria were performed. The search yielded the inclusion of 60 studies. It was found that the interest in the topic has increased, especially in the last 3 years. We observed that the performance of IA models is promising, with high accuracy, sensitivity, and specificity, most of them had outcomes equivalent to human comparators. The reproducibility of the performance of models in real-life practice has been reported as a critical point. Study designs and results have been progressively improved. IA resources have the potential to contribute to several areas of health. In the coming years, it is likely to be incorporated into everyday life, contributing to the precision and reducing the time required by the diagnostic process.",True,other,recurrent neural network
36631766,Machine learning for predicting neurodegenerative diseases in the general older population: a cohort study,"BACKGROUND: In the older general population, neurodegenerative diseases (NDs) are associated with increased disability, decreased physical and cognitive function. Detecting risk factors can help implement prevention measures. Using deep neural networks (DNNs), a machine-learning algorithm could be an alternative to Cox regression in tabular datasets with many predictive features. We aimed to compare the performance of different types of DNNs with regularized Cox proportional hazards models to predict NDs in the older general population.
METHODS: We performed a longitudinal analysis with participants of the English Longitudinal Study of Ageing. We included men and women with no NDs at baseline, aged 60 years and older, assessed every 2 years from 2004 to 2005 (wave2) to 2016-2017 (wave 8). The features were a set of 91 epidemiological and clinical baseline variables. The outcome was new events of Parkinson's, Alzheimer or dementia. After applying multiple imputations, we trained three DNN algorithms: Feedforward, TabTransformer, and Dense Convolutional (Densenet). In addition, we trained two algorithms based on Cox models: Elastic Net regularization (CoxEn) and selected features (CoxSf).
RESULTS: 5433 participants were included in wave 2. During follow-up, 12.7% participants developed NDs. Although the five models predicted NDs events, the discriminative ability was superior using TabTransformer (Uno's C-statistic (coefficient (95% confidence intervals)) 0.757 (0.702, 0.805). TabTransformer showed superior time-dependent balanced accuracy (0.834 (0.779, 0.889)) and specificity (0.855 (0.0.773, 0.909)) than the other models. With the CoxSf (hazard ratio (95% confidence intervals)), age (10.0 (6.9, 14.7)), poor hearing (1.3 (1.1, 1.5)) and weight loss 1.3 (1.1, 1.6)) were associated with a higher DNN risk. In contrast, executive function (0.3 (0.2, 0.6)), memory (0, 0, 0.1)), increased gait speed (0.2, (0.1, 0.4)), vigorous physical activity (0.7, 0.6, 0.9)) and higher BMI (0.4 (0.2, 0.8)) were associated with a lower DNN risk.
CONCLUSION: TabTransformer is promising for prediction of NDs with heterogeneous tabular datasets with numerous features. Moreover, it can handle censored data. However, Cox models perform well and are easier to interpret than DNNs. Therefore, they are still a good choice for NDs.",True,other,recurrent neural network
36628797,An integrated LSTM-HeteroRGNN model for interpretable opioid overdose risk prediction,"Opioid overdose (OD) has become a leading cause of accidental death in the United States, and overdose deaths reached a record high during the COVID-19 pandemic. Combating the opioid crisis requires targeting high-need populations by identifying individuals at risk of OD. While deep learning emerges as a powerful method for building predictive models using large scale electronic health records (EHR), it is challenged by the complex intrinsic relationships among EHR data. Further, its utility is limited by the lack of clinically meaningful explainability, which is necessary for making informed clinical or policy decisions using such models. In this paper, we present LIGHTED, an integrated deep learning model combining long short term memory (LSTM) and graph neural networks (GNN) to predict patients' OD risk. The LIGHTED model can incorporate the temporal effects of disease progression and the knowledge learned from interactions among clinical features. We evaluated the model using Cerner's Health Facts database with over 5 million patients. Our experiments demonstrated that the model outperforms traditional machine learning methods and other deep learning models. We also proposed a novel interpretability method by exploiting embeddings provided by GNNs to cluster patients and EHR features respectively, and conducted qualitative feature cluster analysis for clinical interpretations. Our study shows that LIGHTED can take advantage of longitudinal EHR data and the intrinsic graph structure of EHRs among patients to provide effective and interpretable OD risk predictions that may potentially improve clinical decision support.",True,other,Not specified
36625026,Using deep learning and explainable artificial intelligence to assess the severity of gastroesophageal reflux disease according to the Los Angeles Classification System,"OBJECTIVES: Gastroesophageal reflux disease (GERD) is a complex disease with a high worldwide prevalence. The Los Angeles classification (LA-grade) system is meaningful for assessing the endoscopic severity of GERD. Deep learning (DL) methods have been widely used in the field of endoscopy. However, few DL-assisted researches have concentrated on the diagnosis of GERD. This study is the first to develop a five-category classification DL model based on the LA-grade using explainable artificial intelligence (XAI).
MATERIALS AND METHODS: A total of 2081 endoscopic images were used for the development of a DL model, and the classification accuracy of the models and endoscopists with different levels of experience was compared.
RESULTS: Some mainstream DL models were utilized, of which DenseNet-121 outperformed. The area under the curve (AUC) of the DenseNet-121 was 0.968, and its classification accuracy (86.7%) was significantly higher than that of junior (71.5%) and experienced (77.4%) endoscopists. An XAI evaluation was also performed to explore the perception consistency between the DL model and endoscopists, which showed meaningful results for real-world applications.
CONCLUSIONS: The DL model showed a potential in improving the accuracy of endoscopists in LA-grading of GERD, and it has noticeable clinical application prospects and is worthy of further promotion.",True,other,Not specified
36621078,A deep learning method to detect opioid prescription and opioid use disorder from electronic health records,"OBJECTIVE: As the opioid epidemic continues across the United States, methods are needed to accurately and quickly identify patients at risk for opioid use disorder (OUD). The purpose of this study is to develop two predictive algorithms: one to predict opioid prescription and one to predict OUD.
MATERIALS AND METHODS: We developed an informatics algorithm that trains two deep learning models over patient Electronic Health Records (EHRs) using the MIMIC-III database. We utilize both the structured and unstructured parts of the EHR and show that it is possible to predict both challenging outcomes.
RESULTS: Our deep learning models incorporate elements from EHRs to predict opioid prescription with an F1-score of 0.88 ± 0.003 and an AUC-ROC of 0.93 ± 0.002. We also constructed a model to predict OUD diagnosis achieving an F1-score of 0.82 ± 0.05 and AUC-ROC of 0.94 ± 0.008.
DISCUSSION: Our model for OUD prediction outperformed prior algorithms for specificity, F1 score and AUC-ROC while achieving equivalent sensitivity. This demonstrates the importance of a) deep learning approaches in predicting OUD and b) incorporating both structured and unstructured data for this prediction task. No prediction models for opioid prescription as an outcome were found in the literature and therefore our model is the first to predict opioid prescribing behavior.
CONCLUSION: Algorithms such as those described in this paper will become increasingly important to understand the drivers underlying this national epidemic.",True,other,Not specified
36601453,Airway Detection in COPD at Low-Dose CT Using Deep Learning and Multiparametric Freeze and Grow,"PURPOSE: To present and validate a fully automated airway detection method at low-dose CT in patients with chronic obstructive pulmonary disease (COPD).
MATERIALS AND METHODS: In this retrospective study, deep learning (DL) and freeze-and-grow (FG) methods were optimized and applied to automatically detect airways at low-dose CT. Four data sets were used: two data sets consisting of matching standard- and low-dose CT scans from the Genetic Epidemiology of COPD (COPDGene) phase II (2014-2017) cohort (n = 2 × 236; mean age ± SD, 70 years ± 9; 123 women); one data set consisting of low-dose CT scans from the COPDGene phase III (2018-2020) cohort (n = 335; mean age ± SD, 73 years ± 8; 173 women); and one data set consisting of low-dose, anonymized CT scans from the 2003 Dutch-Belgian Randomized Lung Cancer Screening trial (n = 55) acquired by using different CT scanners. Performance measures for different methods were computed and compared by using the Wilcoxon signed rank test.
RESULTS: At low-dose CT, 56 294 of 62 480 (90.1%) airways of the reference total airway count (TAC) and 32 109 of 37 864 (84.8%) airways of the peripheral TAC (TAC<sub>p</sub>), detected at standard-dose CT, were detected. Significant losses (P &lt; .001) of 14 526 of 76 453 (19.0%) airways and 884 of 6908 (12.8%) airways in the TAC and 12 256 of 43 462 (28.2%) airways and 699 of 3882 (18.0%) airways in the TAC<sub>p</sub> were observed, respectively, for the multiprotocol and multiscanner data without retraining. When using the automated low-dose CT method, TAC values of 347, 342, 323, and 266 and TAC<sub>p</sub> values of 205, 202, 289, and 141 were observed for those who have never smoked and participants at Global Initiative for Chronic Obstructive Lung Disease stages 0, 1, and 2, respectively, which were superior to the respective values previously reported for matching groups when using a semiautomated method at standard-dose CT.
CONCLUSION: A low-cost, automated CT-based airway detection method was suitable for investigation of airway phenotypes at low-dose CT.Keywords: Airway, Airway Count, Airway Detection, Chronic Obstructive Pulmonary Disease, CT, Deep Learning, Generalizability, Low-Dose CT, Segmentation, Thorax, LungClinical trial registration no. NCT00608764 Supplemental material is available for this article. © RSNA, 2022.",True,other,Not specified
36598653,Prediction of postoperative infection in elderly using deep learning-based analysis: an observational cohort study,"Elderly patients are susceptible to postoperative infections with increased mortality. Analyzing with a deep learning model, the perioperative factors that could predict and/or contribute to postoperative infections may improve the outcome in elderly. This was an observational cohort study with 2014 elderly patients who had elective surgery from 28 hospitals in China from April to June 2014. We aimed to develop and validate deep learning-based predictive models for postoperative infections in the elderly. 1510 patients were randomly assigned to be training dataset for establishing deep learning-based models, and 504 patients were used to validate the effectiveness of these models. The conventional model predicted postoperative infections was 0.728 (95% CI 0.688-0.768) with the sensitivity of 66.2% (95% CI 58.2-73.6) and specificity of 66.8% (95% CI 64.6-68.9). The deep learning model including risk factors relevant to baseline clinical characteristics predicted postoperative infections was 0.641 (95% CI 0.545-0.737), and sensitivity and specificity were 34.2% (95% CI 19.6-51.4) and 88.8% (95% CI 85.6-91.6), respectively. Including risk factors relevant to baseline variables and surgery, the deep learning model predicted postoperative infections was 0.763 (95% CI 0.681-0.844) with the sensitivity of 63.2% (95% CI 46-78.2) and specificity of 80.5% (95% CI 76.6-84). Our feasibility study indicated that a deep learning model including risk factors for the prediction of postoperative infections can be achieved in elderly. Further study is needed to assess whether this model can be used to guide clinical practice to improve surgical outcomes in elderly.",True,other,Not specified
36593394,Discovery of drug-omics associations in type 2 diabetes with generative deep-learning models,"The application of multiple omics technologies in biomedical cohorts has the potential to reveal patient-level disease characteristics and individualized response to treatment. However, the scale and heterogeneous nature of multi-modal data makes integration and inference a non-trivial task. We developed a deep-learning-based framework, multi-omics variational autoencoders (MOVE), to integrate such data and applied it to a cohort of 789 people with newly diagnosed type 2 diabetes with deep multi-omics phenotyping from the DIRECT consortium. Using in silico perturbations, we identified drug-omics associations across the multi-modal datasets for the 20 most prevalent drugs given to people with type 2 diabetes with substantially higher sensitivity than univariate statistical tests. From these, we among others, identified novel associations between metformin and the gut microbiota as well as opposite molecular responses for the two statins, simvastatin and atorvastatin. We used the associations to quantify drug-drug similarities, assess the degree of polypharmacy and conclude that drug effects are distributed across the multi-omics modalities.",True,other,convolutional neural network
36589855,Overview of global publications on machine learning in diabetic retinopathy from 2011 to 2021: Bibliometric analysis,"PURPOSE: To comprehensively analyze and discuss the publications on machine learning (ML) in diabetic retinopathy (DR) following a bibliometric approach.
METHODS: The global publications on ML in DR from 2011 to 2021 were retrieved from the Web of Science Core Collection (WoSCC) database. We analyzed the publication and citation trend over time and identified highly-cited articles, prolific countries, institutions, journals and the most relevant research domains. VOSviewer and Wordcloud are used to visualize the mainstream research topics and evolution of subtopics in the form of co-occurrence maps of keywords.
RESULTS: By analyzing a total of 1147 relevant publications, this study found a rapid increase in the number of annual publications, with an average growth rate of 42.68%. India and China were the most productive countries. IEEE Access was the most productive journal in this field. In addition, some notable common points were found in the highly-cited articles. The keywords analysis showed that ""diabetic retinopathy"", ""classification"", and ""fundus images"" were the most frequent keywords for the entire period, as automatic diagnosis of DR was always the mainstream topic in the relevant field. The evolution of keywords highlighted some breakthroughs, including ""deep learning"" and ""optical coherence tomography"", indicating the advance in technologies and changes in the research attention.
CONCLUSIONS: As new research topics have emerged and evolved, studies are becoming increasingly diverse and extensive. Multiple modalities of medical data, new ML techniques and constantly optimized algorithms are the future trends in this multidisciplinary field.",True,both,recurrent neural network
38464947,Application of Artificial Intelligence to the Monitoring of Medication Adherence for Tuberculosis Treatment in Africa: Algorithm Development and Validation,"BACKGROUND: Artificial intelligence (AI) applications based on advanced deep learning methods in image recognition tasks can increase efficiency in the monitoring of medication adherence through automation. AI has sparsely been evaluated for the monitoring of medication adherence in clinical settings. However, AI has the potential to transform the way health care is delivered even in limited-resource settings such as Africa.
OBJECTIVE: We aimed to pilot the development of a deep learning model for simple binary classification and confirmation of proper medication adherence to enhance efficiency in the use of video monitoring of patients in tuberculosis treatment.
METHODS: We used a secondary data set of 861 video images of medication intake that were collected from consenting adult patients with tuberculosis in an institutional review board-approved study evaluating video-observed therapy in Uganda. The video images were processed through a series of steps to prepare them for use in a training model. First, we annotated videos using a specific protocol to eliminate those with poor quality. After the initial annotation step, 497 videos had sufficient quality for training the models. Among them, 405 were positive samples, whereas 92 were negative samples. With some preprocessing techniques, we obtained 160 frames with a size of 224 × 224 in each video. We used a deep learning framework that leveraged 4 convolutional neural networks models to extract visual features from the video frames and automatically perform binary classification of adherence or nonadherence. We evaluated the diagnostic properties of the different models using sensitivity, specificity, F<sub>1</sub>-score, and precision. The area under the curve (AUC) was used to assess the discriminative performance and the speed per video review as a metric for model efficiency. We conducted a 5-fold internal cross-validation to determine the diagnostic and discriminative performance of the models. We did not conduct external validation due to a lack of publicly available data sets with specific medication intake video frames.
RESULTS: Diagnostic properties and discriminative performance from internal cross-validation were moderate to high in the binary classification tasks with 4 selected automated deep learning models. The sensitivity ranged from 92.8 to 95.8%, specificity from 43.5 to 55.4%, F<sub>1</sub>-score from 0.91 to 0.92, precision from 88% to 90.1%, and AUC from 0.78 to 0.85. The 3D ResNet model had the highest precision, AUC, and speed.
CONCLUSIONS: All 4 deep learning models showed comparable diagnostic properties and discriminative performance. The findings serve as a reasonable proof of concept to support the potential application of AI in the binary classification of video frames to predict medication adherence.",True,other,Not specified
36586769,The potential role of machine learning in modelling advanced chronic liver disease,"The use of artificial intelligence is rapidly increasing in medicine to support clinical decision making mostly through diagnostic and prediction models. Such models derive from huge databases (big data) including a large variety of health-related individual patient data (input) and the corresponding diagnosis and/or outcome (labels). Various types of algorithms (e.g. neural networks) based on powerful computational ability (machine), allow to detect the relationship between input and labels (learning). More complex algorithms, like recurrent neural network can learn from previous as well as actual input (deep learning) and are used for more complex tasks like imaging analysis and personalized (bespoke) medicine. The prompt availability of big data makes that artificial intelligence can provide rapid answers to questions that would require years of traditional clinical research. It may therefore be a key tool to overcome several major gaps in the model of advanced chronic liver disease, mostly transition from mild to clinically significant portal hypertension, the impact of acute decompensation and the role of further decompensation and treatment efficiency. However, several limitations of artificial intelligence should be overcome before its application in clinical practice. Assessment of the risk of bias, understandability of the black boxes developing the models and models' validation are the most important areas deserving clarification for artificial intelligence to be widely accepted from physicians and patients.",True,other,recurrent neural network
36580391,Development and validation of a deep learning algorithm based on fundus photographs for estimating the CAIDE dementia risk score,"BACKGROUND: the Cardiovascular Risk Factors, Aging, and Incidence of Dementia (CAIDE) dementia risk score is a recognised tool for dementia risk stratification. However, its application is limited due to the requirements for multidimensional information and fasting blood draw. Consequently, an effective and non-invasive tool for screening individuals with high dementia risk in large population-based settings is urgently needed.
METHODS: a deep learning algorithm based on fundus photographs for estimating the CAIDE dementia risk score was developed and internally validated by a medical check-up dataset included 271,864 participants in 19 province-level administrative regions of China, and externally validated based on an independent dataset included 20,690 check-up participants in Beijing. The performance for identifying individuals with high dementia risk (CAIDE dementia risk score ≥ 10 points) was evaluated by area under the receiver operating curve (AUC) with 95% confidence interval (CI).
RESULTS: the algorithm achieved an AUC of 0.944 (95% CI: 0.939-0.950) in the internal validation group and 0.926 (95% CI: 0.913-0.939) in the external group, respectively. Besides, the estimated CAIDE dementia risk score derived from the algorithm was significantly associated with both comprehensive cognitive function and specific cognitive domains.
CONCLUSIONS: this algorithm trained via fundus photographs could well identify individuals with high dementia risk in a population setting. Therefore, it has the potential to be utilised as a non-invasive and more expedient method for dementia risk stratification. It might also be adopted in dementia clinical trials, incorporated as inclusion criteria to efficiently select eligible participants.",True,other,Not specified
36576736,Validation of a Deep Learning-Based Model to Predict Lung Cancer Risk Using Chest Radiographs and Electronic Medical Record Data,"IMPORTANCE: Lung cancer screening with chest computed tomography (CT) prevents lung cancer death; however, fewer than 5% of eligible Americans are screened. CXR-LC, an open-source deep learning tool that estimates lung cancer risk from existing chest radiograph images and commonly available electronic medical record (EMR) data, may enable automated identification of high-risk patients as a step toward improving lung cancer screening participation.
OBJECTIVE: To validate CXR-LC using EMR data to identify individuals at high-risk for lung cancer to complement 2022 US Centers for Medicare & Medicaid Services (CMS) lung cancer screening eligibility guidelines.
DESIGN, SETTING, AND PARTICIPANTS: This prognostic study compared CXR-LC estimates with CMS screening guidelines using patient data from a large US hospital system. Included participants were persons who currently or formerly smoked cigarettes with an outpatient posterior-anterior chest radiograph between January 1, 2013, and December 31, 2014, with no history of lung cancer or screening CT. Data analysis was performed between May 2021 and June 2022.
EXPOSURES: CXR-LC lung cancer screening eligibility (previously defined as having a 3.297% or greater 12-year risk) based on inputs (chest radiograph image, age, sex, and whether currently smoking) extracted from the EMR.
MAIN OUTCOMES AND MEASURES: 6-year incident lung cancer.
RESULTS: A total of 14 737 persons were included in the study population (mean [SD] age, 62.6 [6.8] years; 7154 [48.5%] male; 204 [1.4%] Asian, 1051 [7.3%] Black, 432 [2.9%] Hispanic, 12 330 [85.2%] White) with a 2.4% rate of incident lung cancer over 6 years (361 patients with cancer). CMS eligibility could be determined in 6277 patients (42.6%) using smoking pack-year and quit-date from the EMR. Patients eligible by both CXR-LC and 2022 CMS criteria had a high rate of lung cancer (83 of 974 patients [8.5%]), higher than those eligible by 2022 CMS criteria alone (5 of 177 patients [2.8%]; P < .001). Patients eligible by CXR-LC but not 2022 CMS criteria also had a high 6-year incidence of lung cancer (121 of 3703 [3.3%]). In the 8460 cases (57.4%) where CMS eligibility was unknown, CXR-LC eligible patients had a 5-fold higher rate of lung cancer than ineligible (127 of 5177 [2.5%] vs 18 of 2283 [0.5%]; P < .001). Similar results were found in subgroups, including female patients and Black persons.
CONCLUSIONS AND RELEVANCE: Using routine chest radiographs and other data automatically extracted from the EMR, CXR-LC identified high-risk individuals who may benefit from lung cancer screening CT.",True,other,Not specified
36568200,A novel risk classification system based on the eighth edition of TNM frameworks for esophageal adenocarcinoma patients: A deep learning approach,"OBJECTIVE: To develop and validate a deep learning predictive model with better performance in survival estimation of esophageal adenocarcinoma (EAC).
METHOD: Cases diagnosed between January 2010 and December 2018 were extracted from the Surveillance, Epidemiology, and End Results (SEER) database. A deep learning survival neural network was developed and validated based on 17 variables, including demographic information, clinicopathological characteristics, and treatment details. Based on the total risk score derived from this algorithm, a novel risk classification system was constructed and compared with the 8th edition of the tumor, node, and metastasis (TNM) staging system.
RESULTS: Of 7,764 EAC patients eligible for the study, 6,818 (87.8%) were men and the median (interquartile range, IQR) age was 65 (58-72) years. The deep learning model generated significantly superior predictions to the 8th edition staging system on the test data set (C-index: 0.773 [95% CI, 0.757-0.789] vs. 0.683 [95% CI, 0.667-0.699]; P &lt; 0.001). Calibration curves revealed that the deep learning model was well calibrated for 1- and 3-year OS, most points almost directly distributing on the 45° line. Decision curve analyses (DCAs) showed that the novel risk classification system exhibited a more significant positive net benefit than the TNM staging system. A user-friendly and precise web-based calculator with a portably executable file was implemented to visualize the deep learning predictive model.
CONCLUSION: A deep learning predictive model was developed and validated, which possesses more excellent calibration and discrimination abilities in survival prediction of EAC. The novel risk classification system based on the deep learning algorithm may serve as a useful tool in clinical decision making given its easy-to-use and better clinical applicability.",True,other,recurrent neural network
36562928,Using Artificial Intelligence to Analyse the Retinal Vascular Network: The Future of Cardiovascular Risk Assessment Based on Oculomics? A Narrative Review,"The healthcare burden of cardiovascular diseases remains a major issue worldwide. Understanding the underlying mechanisms and improving identification of people with a higher risk profile of systemic vascular disease through noninvasive examinations is crucial. In ophthalmology, retinal vascular network imaging is simple and noninvasive and can provide in vivo information of the microstructure and vascular health. For more than 10 years, different research teams have been working on developing software to enable automatic analysis of the retinal vascular network from different imaging techniques (retinal fundus photographs, OCT angiography, adaptive optics, etc.) and to provide a description of the geometric characteristics of its arterial and venous components. Thus, the structure of retinal vessels could be considered a witness of the systemic vascular status. A new approach called ""oculomics"" using retinal image datasets and artificial intelligence algorithms recently increased the interest in retinal microvascular biomarkers. Despite the large volume of associated research, the role of retinal biomarkers in the screening, monitoring, or prediction of systemic vascular disease remains uncertain. A PubMed search was conducted until August 2022 and yielded relevant peer-reviewed articles based on a set of inclusion criteria. This literature review is intended to summarize the state of the art in oculomics and cardiovascular disease research.",True,both,Not specified
36550485,LiSA: an assisted literature search pipeline for detecting serious adverse drug events with deep learning,"INTRODUCTION: Detecting safety signals attributed to a drug in scientific literature is a fundamental issue in pharmacovigilance. The constant increase in the volume of publications requires the automation of this tedious task, in order to find and extract relevant articles from the pack. This task is critical, as serious Adverse Drug Reactions (ADRs) still account for a large number of hospital admissions each year.
OBJECTIVES: The aim of this study is to develop an augmented intelligence methodology for automatically identifying relevant publications mentioning an established link between a Drug and a Serious Adverse Event, according to the European Medicines Agency (EMA) definition of seriousness.
METHODS: The proposed pipeline, called LiSA (for Literature Search Application), is based on three independent deep learning models supporting a precise detection of safety signals in the biomedical literature. By combining a Bidirectional Encoder Representations from Transformers (BERT) algorithms and a modular architecture, the pipeline achieves a precision of 0.81 and a recall of 0.89 at sentences level in articles extracted from PubMed (either abstract or full-text). We also measured that by using LiSA, a medical reviewer increases by a factor of 2.5 the number of relevant documents it can collect and evaluate compared to a simple keyword search. In the interest of re-usability, emphasis was placed on building a modular pipeline allowing the insertion of other NLP modules to enrich the results provided by the system, and extend it to other use cases. In addition, a lightweight visualization tool was developed to analyze and monitor safety signal results.
CONCLUSIONS: Overall, the generic pipeline and the visualization tool proposed in this article allows for efficient and accurate monitoring of serious adverse drug reactions from the literature and can easily be adapted to similar pharmacovigilance use cases. To facilitate reproducibility and benefit other research studies, we also shared a first benchmark dataset for Serious Adverse Drug Events detection.",True,both,Not specified
36538072,The uncovered biases and errors in clinical determination of bone age by using deep learning models,"OBJECTIVES: To evaluate AI biases and errors in estimating bone age (BA) by comparing AI and radiologists' clinical determinations of BA.
METHODS: We established three deep learning models from a Chinese private dataset (CHNm), an American public dataset (USAm), and a joint dataset combining the above two datasets (JOIm). The test data CHNt (n = 1246) were labeled by ten senior pediatric radiologists. The effects of data site differences, interpretation bias, and interobserver variability on BA assessment were evaluated. The differences between the AI models' and radiologists' clinical determinations of BA (normal, advanced, and delayed BA groups by using the Brush data) were evaluated by the chi-square test and Kappa values. The heatmaps of CHNm-CHNt were generated by using Grad-CAM.
RESULTS: We obtained an MAD value of 0.42 years on CHNm-CHNt; this result indicated an appropriate accuracy for the whole group but did not indicate an accurate estimation of individual BA because with a kappa value of 0.714, the agreement between AI and human clinical determinations of BA was significantly different. The features of the heatmaps were not fully consistent with the human vision on the X-ray films. Variable performance in BA estimation by different AI models and the disagreement between AI and radiologists' clinical determinations of BA may be caused by data biases, including patients' sex and age, institutions, and radiologists.
CONCLUSIONS: The deep learning models outperform external validation in predicting BA on both internal and joint datasets. However, the biases and errors in the models' clinical determinations of child development should be carefully considered.
KEY POINTS: • With a kappa value of 0.714, clinical determinations of bone age by using AI did not accord well with clinical determinations by radiologists. • Several biases, including patients' sex and age, institutions, and radiologists, may cause variable performance by AI bone age models and disagreement between AI and radiologists' clinical determinations of bone age. • AI heatmaps of bone age were not fully consistent with human vision on X-ray films.",True,text mining,Not specified
36494479,Deep learning-based age estimation from chest X-rays indicates cardiovascular prognosis,"BACKGROUND: In recent years, there has been considerable research on the use of artificial intelligence to estimate age and disease status from medical images. However, age estimation from chest X-ray (CXR) images has not been well studied and the clinical significance of estimated age has not been fully determined.
METHODS: To address this, we trained a deep neural network (DNN) model using more than 100,000 CXRs to estimate the patients' age solely from CXRs. We applied our DNN to CXRs of 1562 consecutive hospitalized heart failure patients, and 3586 patients admitted to the intensive care unit with cardiovascular disease.
RESULTS: The DNN's estimated age (X-ray age) showed a strong significant correlation with chronological age on the hold-out test data and independent test data. Elevated X-ray age is associated with worse clinical outcomes (heart failure readmission and all-cause death) for heart failure. Additionally, elevated X-ray age was associated with a worse prognosis in 3586 patients admitted to the intensive care unit with cardiovascular disease.
CONCLUSIONS: Our results suggest that X-ray age can serve as a useful indicator of cardiovascular abnormalities, which will help clinicians to predict, prevent and manage cardiovascular diseases.",True,other,Not specified
36494091,Deep transformation models for functional outcome prediction after acute ischemic stroke,"In many medical applications, interpretable models with high prediction performance are sought. Often, those models are required to handle semistructured data like tabular and image data. We show how to apply deep transformation models (DTMs) for distributional regression that fulfill these requirements. DTMs allow the data analyst to specify (deep) neural networks for different input modalities making them applicable to various research questions. Like statistical models, DTMs can provide interpretable effect estimates while achieving the state-of-the-art prediction performance of deep neural networks. In addition, the construction of ensembles of DTMs that retain model structure and interpretability allows quantifying epistemic and aleatoric uncertainty. In this study, we compare several DTMs, including baseline-adjusted models, trained on a semistructured data set of 407 stroke patients with the aim to predict ordinal functional outcome three months after stroke. We follow statistical principles of model-building to achieve an adequate trade-off between interpretability and flexibility while assessing the relative importance of the involved data modalities. We evaluate the models for an ordinal and dichotomized version of the outcome as used in clinical practice. We show that both tabular clinical and brain imaging data are useful for functional outcome prediction, whereas models based on tabular data only outperform those based on imaging data only. There is no substantial evidence for improved prediction when combining both data modalities. Overall, we highlight that DTMs provide a powerful, interpretable approach to analyzing semistructured data and that they have the potential to support clinical decision-making.",True,other,LSTM
36478240,Learning from undercoded clinical records for automated International Classification of Diseases (ICD) coding,"OBJECTIVES: To develop an unbiased objective for learning automatic coding algorithms from clinical records annotated with only partial relevant International Classification of Diseases codes, as annotation noise in undercoded clinical records used as training data can mislead the learning process of deep neural networks.
MATERIALS AND METHODS: We use Medical Information Mart for Intensive Care III as our dataset. We employ positive-unlabeled learning to achieve unbiased loss estimation, which is free of misleading training signal. We then utilize reweighting mechanism to compensate for the imbalance between positive and negative samples. To further close the performance gap caused by poor quality annotation, we integrate the supervision provided by the automatic annotation tool Medical Concept Annotation Toolkit which can ease the heavy burden of manual validation.
RESULTS: Our benchmarking results show that positive-unlabeled learning with reweighting outperforms competitive baseline methods over a range of missing label ratios. Integrating supervision provided by annotation tool further boosted the performance.
DISCUSSION: Considering the annotation noise and severe imbalance, unbiased loss estimation and reweighting mechanism are both important for learning from undercoded clinical records. Unbiased loss requires the estimation of false negative ratios and estimation through trained models is practical and competitive.
CONCLUSIONS: The combination of positive-unlabeled learning with reweighting and supervision provided by the annotation tool is a promising solution to learn from undercoded clinical records.",True,other,convolutional neural network
36477816,Deep Learning for Cross-Diagnostic Prediction of Mental Disorder Diagnosis and Prognosis Using Danish Nationwide Register and Genetic Data,"IMPORTANCE: Diagnoses and treatment of mental disorders are hampered by the current lack of objective markers needed to provide a more precise diagnosis and treatment strategy.
OBJECTIVE: To develop deep learning models to predict mental disorder diagnosis and severity spanning multiple diagnoses using nationwide register data, family and patient-specific diagnostic history, birth-related measurement, and genetics.
DESIGN, SETTING, AND PARTICIPANTS: This study was conducted from May 1, 1981, to December 31, 2016. For the analysis, which used a Danish population-based case-cohort sample of individuals born between 1981 and 2005, genotype data and matched longitudinal health register data were taken from the longitudinal Danish population-based Integrative Psychiatric Research Consortium 2012 case-cohort study. Included were individuals with mental disorders (attention-deficit/hyperactivity disorder [ADHD]), autism spectrum disorder (ASD), major depressive disorder (MDD), bipolar disorder (BD), schizophrenia spectrum disorders (SCZ), and population controls. Data were analyzed from February 1, 2021, to January 24, 2022.
EXPOSURE: At least 1 hospital contact with diagnosis of ADHD, ASD, MDD, BD, or SCZ.
MAIN OUTCOMES AND MEASURES: The predictability of (1) mental disorder diagnosis and (2) severity trajectories (measured by future outpatient hospital contacts, admissions, and suicide attempts) were investigated using both a cross-diagnostic and single-disorder setup. Predictive power was measured by AUC, accuracy, and Matthews correlation coefficient (MCC), including an estimate of feature importance.
RESULTS: A total of 63 535 individuals (mean [SD] age, 23 [7] years; 34 944 male [55%]; 28 591 female [45%]) were included in the model. Based on data prior to diagnosis, the specific diagnosis was predicted in a multidiagnostic prediction model including the background population with an overall area under the curve (AUC) of 0.81 and MCC of 0.28, whereas the single-disorder models gave AUCs/MCCs of 0.84/0.54 for SCZ, 0.79/0.41 for BD, 0.77/0.39 for ASD, 0.74/0.38, for ADHD, and 0.74/0.38 for MDD. The most important data sets for multidiagnostic prediction were previous mental disorders and age (11%-23% reduction in prediction accuracy when removed) followed by family diagnoses, birth-related measurements, and genetic data (3%-5% reduction in prediction accuracy when removed). Furthermore, when predicting subsequent disease trajectories of the disorder, the most severe cases were the most easily predictable, with an AUC of 0.72.
CONCLUSIONS AND RELEVANCE: Results of this diagnostic study suggest the possibility of combining genetics and registry data to predict both mental disorder diagnosis and disorder progression in a clinically relevant, cross-diagnostic setting prior to clinical assessment.",True,other,Not specified
36461616,A Deep Learning LSTM Approach to Predict COVD-19 Deaths in North Africa,,True,other,GAN
36447415,Prediction of Decompensation and Death in Advanced Chronic Liver Disease Using Deep Learning Analysis of Gadoxetic Acid-Enhanced MRI,"OBJECTIVE: This study aimed to evaluate the usefulness of quantitative indices obtained from deep learning analysis of gadoxetic acid-enhanced hepatobiliary phase (HBP) MRI and their longitudinal changes in predicting decompensation and death in patients with advanced chronic liver disease (ACLD).
MATERIALS AND METHODS: We included patients who underwent baseline and 1-year follow-up MRI from a prospective cohort that underwent gadoxetic acid-enhanced MRI for hepatocellular carcinoma surveillance between November 2011 and August 2012 at a tertiary medical center. Baseline liver condition was categorized as non-ACLD, compensated ACLD, and decompensated ACLD. The liver-to-spleen signal intensity ratio (LS-SIR) and liver-to-spleen volume ratio (LS-VR) were automatically measured on the HBP images using a deep learning algorithm, and their percentage changes at the 1-year follow-up (ΔLS-SIR and ΔLS-VR) were calculated. The associations of the MRI indices with hepatic decompensation and a composite endpoint of liver-related death or transplantation were evaluated using a competing risk analysis with multivariable Fine and Gray regression models, including baseline parameters alone and both baseline and follow-up parameters.
RESULTS: Our study included 280 patients (153 male; mean age ± standard deviation, 57 ± 7.95 years) with non-ACLD, compensated ACLD, and decompensated ACLD in 32, 186, and 62 patients, respectively. Patients were followed for 11-117 months (median, 104 months). In patients with compensated ACLD, baseline LS-SIR (sub-distribution hazard ratio [sHR], 0.81; p = 0.034) and LS-VR (sHR, 0.71; p = 0.01) were independently associated with hepatic decompensation. The ΔLS-VR (sHR, 0.54; p = 0.002) was predictive of hepatic decompensation after adjusting for baseline variables. ΔLS-VR was an independent predictor of liver-related death or transplantation in patients with compensated ACLD (sHR, 0.46; p = 0.026) and decompensated ACLD (sHR, 0.61; p = 0.023).
CONCLUSION: MRI indices automatically derived from the deep learning analysis of gadoxetic acid-enhanced HBP MRI can be used as prognostic markers in patients with ACLD.",True,other,Not specified
36438691,Space-Distributed Traffic-Enhanced LSTM-Based Machine Learning Model for COVID-19 Incidence Forecasting,"The COVID-19 virus continues to generate waves of infections around the world. With major areas in developing countries still lagging behind in vaccination campaigns, the risk of new variants that can cause re-infections worldwide makes the monitoring and forecasting of the evolution of the virus a high priority. Having accurate models able to forecast the incidence of the spread of the virus provides help to policymakers and health professionals in managing the scarce resources in an optimal way. In this paper, a new machine learning model is proposed to forecast the spread of the virus one-week ahead in a geographic area which combines mobility and COVID-19 incidence data. The area is divided into zones or districts according to the location of the COVID-19 measuring points. A traffic-driven mobility estimate among adjacent districts is proposed to capture the spatial spread of the virus. Traffic-driven mobility in adjacent districts will be used together with COVID-19 incidence data to feed a new deep learning LSTM-based model which will extract patterns from mobility-modulated COVID-19 incidence spatiotemporal data in order to optimize one-week ahead estimations. The model is trained and validated with open data available for the city of Madrid (Spain) for 3 different validation scenarios. A baseline model based on previous literature able to extract temporal patterns in COVID-19 incidence time series is also trained with the same dataset. The results show that the proposed model, based on the combination of traffic and COVID-19 incidence data, is able to outperform the baseline model in all the validation scenarios.",True,other,recurrent neural network
36431321,Cardiovascular/Stroke Risk Stratification in Diabetic Foot Infection Patients Using Deep Learning-Based Artificial Intelligence: An Investigative Study,"A diabetic foot infection (DFI) is among the most serious, incurable, and costly to treat conditions. The presence of a DFI renders machine learning (ML) systems extremely nonlinear, posing difficulties in CVD/stroke risk stratification. In addition, there is a limited number of well-explained ML paradigms due to comorbidity, sample size limits, and weak scientific and clinical validation methodologies. Deep neural networks (DNN) are potent machines for learning that generalize nonlinear situations. The objective of this article is to propose a novel investigation of deep learning (DL) solutions for predicting CVD/stroke risk in DFI patients. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) search strategy was used for the selection of 207 studies. We hypothesize that a DFI is responsible for increased morbidity and mortality due to the worsening of atherosclerotic disease and affecting coronary artery disease (CAD). Since surrogate biomarkers for CAD, such as carotid artery disease, can be used for monitoring CVD, we can thus use a DL-based model, namely, Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) for CVD/stroke risk prediction in DFI patients, which combines covariates such as office and laboratory-based biomarkers, carotid ultrasound image phenotype (CUSIP) lesions, along with the DFI severity. We confirmed the viability of CVD/stroke risk stratification in the DFI patients. Strong designs were found in the research of the DL architectures for CVD/stroke risk stratification. Finally, we analyzed the AI bias and proposed strategies for the early diagnosis of CVD/stroke in DFI patients. Since DFI patients have an aggressive atherosclerotic disease, leading to prominent CVD/stroke risk, we, therefore, conclude that the DL paradigm is very effective for predicting the risk of CVD/stroke in DFI patients.",True,other,recurrent neural network
36430024,Classification and Prediction on Hypertension with Blood Pressure Determinants in a Deep Learning Algorithm,"Few studies classified and predicted hypertension using blood pressure (BP)-related determinants in a deep learning algorithm. The objective of this study is to develop a deep learning algorithm for the classification and prediction of hypertension with BP-related factors based on the Korean Genome and Epidemiology Study-Ansan and Ansung baseline survey. We also investigated whether energy intake adjustment is adequate for deep learning algorithms. We constructed a deep neural network (DNN) in which the number of hidden layers and the number of nodes in each hidden layer are experimentally selected, and we trained the DNN to diagnose hypertension using the dataset while varying the energy intake adjustment method in four ways. For comparison, we trained a decision tree in the same way. Experimental results showed that the DNN performs better than the decision tree in all aspects, such as having higher sensitivity, specificity, F1-score, and accuracy. In addition, we found that unlike general machine learning algorithms, including the decision tree, the DNNs perform best when energy intake is not adjusted. The result indicates that energy intake adjustment is not required when using a deep learning algorithm to classify and predict hypertension with BP-related factors.",True,other,convolutional neural network
36380048,Development and validation of deep learning ECG-based prediction of myocardial infarction in emergency department patients,"Myocardial infarction diagnosis is a common challenge in the emergency department. In managed settings, deep learning-based models and especially convolutional deep models have shown promise in electrocardiogram (ECG) classification, but there is a lack of high-performing models for the diagnosis of myocardial infarction in real-world scenarios. We aimed to train and validate a deep learning model using ECGs to predict myocardial infarction in real-world emergency department patients. We studied emergency department patients in the Stockholm region between 2007 and 2016 that had an ECG obtained because of their presenting complaint. We developed a deep neural network based on convolutional layers similar to a residual network. Inputs to the model were ECG tracing, age, and sex; and outputs were the probabilities of three mutually exclusive classes: non-ST-elevation myocardial infarction (NSTEMI), ST-elevation myocardial infarction (STEMI), and control status, as registered in the SWEDEHEART and other registries. We used an ensemble of five models. Among 492,226 ECGs in 214,250 patients, 5,416 were recorded with an NSTEMI, 1,818 a STEMI, and 485,207 without a myocardial infarction. In a random test set, our model could discriminate STEMIs/NSTEMIs from controls with a C-statistic of 0.991/0.832 and had a Brier score of 0.001/0.008. The model obtained a similar performance in a temporally separated test set of the study sample, and achieved a C-statistic of 0.985 and a Brier score of 0.002 in discriminating STEMIs from controls in an external test set. We developed and validated a deep learning model with excellent performance in discriminating between control, STEMI, and NSTEMI on the presenting ECG of a real-world sample of the important population of all-comers to the emergency department. Hence, deep learning models for ECG decision support could be valuable in the emergency department.",True,other,Not specified
36374004,Examining the Use of an Artificial Intelligence Model to Diagnose Influenza: Development and Validation Study,"BACKGROUND: The global burden of influenza is substantial. It is a major disease that causes annual epidemics and occasionally, pandemics. Given that influenza primarily infects the upper respiratory system, it may be possible to diagnose influenza infection by applying deep learning to pharyngeal images.
OBJECTIVE: We aimed to develop a deep learning model to diagnose influenza infection using pharyngeal images and clinical information.
METHODS: We recruited patients who visited clinics and hospitals because of influenza-like symptoms. In the training stage, we developed a diagnostic prediction artificial intelligence (AI) model based on deep learning to predict polymerase chain reaction (PCR)-confirmed influenza from pharyngeal images and clinical information. In the validation stage, we assessed the diagnostic performance of the AI model. In additional analysis, we compared the diagnostic performance of the AI model with that of 3 physicians and interpreted the AI model using importance heat maps.
RESULTS: We enrolled a total of 7831 patients at 64 hospitals between November 1, 2019, and January 21, 2020, in the training stage and 659 patients (including 196 patients with PCR-confirmed influenza) at 11 hospitals between January 25, 2020, and March 13, 2020, in the validation stage. The area under the receiver operating characteristic curve for the AI model was 0.90 (95% CI 0.87-0.93), and its sensitivity and specificity were 76% (70%-82%) and 88% (85%-91%), respectively, outperforming 3 physicians. In the importance heat maps, the AI model often focused on follicles on the posterior pharyngeal wall.
CONCLUSIONS: We developed the first AI model that can accurately diagnose influenza from pharyngeal images, which has the potential to help physicians to make a timely diagnosis.",True,other,convolutional neural network
36351358,Deep learning-based diagnostic model for predicting complications after gastrectomy,"BACKGROUND: Gastric cancer is one of the leading causes of cancer deaths, and gastrectomy with lymph node dissection is the mainstay of treatment. Despite clinician efforts and advances in surgical methods, the incidence of complications after gastrectomy remains 10%-20% including fatalities. To the best of our knowledge, this is the first report on utilization of a deep learning method to build a new artificial intelligence model that could help surgeons diagnose these complications.
METHODS: A neural network was constructed with a total of 4000 variables. Clinical, surgical, and pathological data of patients who underwent radical gastrectomy at our institute were collected to maintain a deep learning model. We optimized the parameters of the neural network to diagnose whether these patients would develop complications after gastrectomy or not.
RESULTS: Seventy percent of the data was used to optimize the neural network parameters, and the rest was used to validate the model. A model that maximized the receiver operating characteristics (ROC) area under the curve (AUC) for validation of the data was extracted. The ROC-AUC, sensitivity, and specificity of the model to diagnose all complications were 0.8 vs 0.7, 81% vs 50%, and 69% vs 75%, for the teaching and validation data, respectively.
CONCLUSIONS: A predictive model for postoperative complications after radical gastrectomy was successfully constructed using the deep learning method. This model can help surgeons accurately predict the incidence of complications on postoperative day 3.",True,other,Not specified
36339684,An Unsupervised Deep Learning-Based Model Using Multiomics Data to Predict Prognosis of Patients with Stomach Adenocarcinoma,"METHODS: Patients (363 in total) with stomach adenocarcinoma from The Cancer Genome Atlas (TCGA) cohort were included. An autoencoder was constructed to integrate the RNA sequencing, miRNA sequencing, and methylation data. The features of the bottleneck layer were used to perform the k-means clustering algorithm to obtain different subgroups for evaluating the prognosis-related risk of stomach adenocarcinoma. The model's robustness was verified using a 10-fold cross-validation (CV). Survival was analyzed by the Kaplan-Meier method. Univariate and multivariate Cox regression was used to estimate hazard risk. The model was validated in three independent cohorts with different endpoints.
RESULTS: The patients were divided into low-risk and high-risk groups according to the k-means clustering algorithm. The high-risk group had a significantly higher risk of poor survival (log-rank P value = 2.80e - 06; adjusted hazard ratio = 2.386, 95% confidence interval: 1.607~3.543), a concordance index (C-index) of 0.714, and a Brier score of 0.184. The model performed well both in the 10-fold CV procedure and three independent cohorts from the Gene Expression Omnibus (GEO) repository.
CONCLUSIONS: A robust and generalizable model based on the autoencoder was proposed to integrate multiomics data and predict the prognosis of patients with stomach adenocarcinoma. The model demonstrates better performance than two alternative approaches on prognosis prediction. The results might provide the grounds for further exploring the potential biomarkers to predict the prognosis of patients with stomach adenocarcinoma.",True,text mining,autoencoder
36315120,Deep Learning-Based Modeling of the Dark Adaptation Curve for Robust Parameter Estimation,"PURPOSE: This study investigates deep-learning (DL) sequence modeling techniques to reliably fit dark adaptation (DA) curves and estimate their key parameters in patients with age-related macular degeneration (AMD) to improve robustness and curve predictions.
METHODS: A long-short-term memory autoencoder was used as the DL method to model the DA curve. The performance was compared against the classical nonlinear regression method using goodness-of-fit and repeatability metrics. Experiments were performed to predict the latter portion of the curve using data from early measurements. The prediction accuracy was quantified as the rod intercept time (RIT) prediction error between predicted and actual curves.
RESULTS: The two models had comparable goodness-of-fit measures, with root mean squared error (RMSE; SD) = 0.11 (0.04) log-units (LU) for the classical model and RMSE = 0.13 (0.06) LU for the DL model. Repeatability of the curve fits evaluated after introduction of random perturbations, and after performing repeated testing, demonstrated superiority of the DL method, especially among parameters related to cone decay. The DL method exhibited superior ability to predict the curve and RIT using points prior to -2 LU, with 3.1 ± 3.1 minutes RIT prediction error, compared to 19.1 ± 18.6 minutes RIT error for the classical method.
CONCLUSIONS: The parameters obtained from the DL method demonstrated superior robustness as well as predictability of the curve. These could provide important advances in using multiple DA curve parameters to characterize AMD severity.
TRANSLATIONAL RELEVANCE: Dark adaptation is an important functional measure in studies of AMD and curve modeling using DL methods can lead to improved clinical trial end points.",True,other,recurrent neural network
36307509,DeepLPI: a novel deep learning-based model for protein-ligand interaction prediction for drug repurposing,"The substantial cost of new drug research and development has consistently posed a huge burden for both pharmaceutical companies and patients. In order to lower the expenditure and development failure rate, repurposing existing and approved drugs by identifying interactions between drug molecules and target proteins based on computational methods have gained growing attention. Here, we propose the DeepLPI, a novel deep learning-based model that mainly consists of ResNet-based 1-dimensional convolutional neural network (1D CNN) and bi-directional long short term memory network (biLSTM), to establish an end-to-end framework for protein-ligand interaction prediction. We first encode the raw drug molecular sequences and target protein sequences into dense vector representations, which go through two ResNet-based 1D CNN modules to derive features, respectively. The extracted feature vectors are concatenated and further fed into the biLSTM network, followed by the MLP module to finally predict protein-ligand interaction. We downloaded the well-known BindingDB and Davis dataset for training and testing our DeepLPI model. We also applied DeepLPI on a COVID-19 dataset for externally evaluating the prediction ability of DeepLPI. To benchmark our model, we compared our DeepLPI with the baseline methods of DeepCDA and DeepDTA, and observed that our DeepLPI outperformed these methods, suggesting the high accuracy of the DeepLPI towards protein-ligand interaction prediction. The high prediction performance of DeepLPI on the different datasets displayed its high capability of protein-ligand interaction in generalization, demonstrating that the DeepLPI has the potential to pinpoint new drug-target interactions and to find better destinations for proven drugs.",True,other,convolutional neural network
36280773,Survival analysis of localized prostate cancer with deep learning,"In recent years, data-driven, deep-learning-based models have shown great promise in medical risk prediction. By utilizing the large-scale Electronic Health Record data found in the U.S. Department of Veterans Affairs, the largest integrated healthcare system in the United States, we have developed an automated, personalized risk prediction model to support the clinical decision-making process for localized prostate cancer patients. This method combines the representative power of deep learning and the analytical interpretability of parametric regression models and can implement both time-dependent and static input data. To collect a comprehensive evaluation of model performances, we calculate time-dependent C-statistics [Formula: see text] over 2-, 5-, and 10-year time horizons using either a composite outcome or prostate cancer mortality as the target event. The composite outcome combines the Prostate-Specific Antigen (PSA) test, metastasis, and prostate cancer mortality. Our longitudinal model Recurrent Deep Survival Machine (RDSM) achieved [Formula: see text] 0.85 (0.83), 0.80 (0.83), and 0.76 (0.81), while the cross-sectional model Deep Survival Machine (DSM) attained [Formula: see text] 0.85 (0.82), 0.80 (0.82), and 0.76 (0.79) for the 2-, 5-, and 10-year composite (mortality) outcomes, respectively. In addition to estimating the survival probability, our method can quantify the uncertainty associated with the prediction. The uncertainty scores show a consistent correlation with the prediction accuracy. We find PSA and prostate cancer stage information are the most important indicators in risk prediction. Our work demonstrates the utility of the data-driven machine learning model in prostate cancer risk prediction, which can play a critical role in the clinical decision system.",True,other,Not specified
36276409,π VAE: a stochastic process prior for Bayesian deep learning with MCMC,"Stochastic processes provide a mathematically elegant way to model complex data. In theory, they provide flexible priors over function classes that can encode a wide range of interesting assumptions. However, in practice efficient inference by optimisation or marginalisation is difficult, a problem further exacerbated with big data and high dimensional input spaces. We propose a novel variational autoencoder (VAE) called the prior encoding variational autoencoder ( π VAE). π VAE is a new continuous stochastic process. We use π VAE to learn low dimensional embeddings of function classes by combining a trainable feature mapping with generative model using a VAE. We show that our framework can accurately learn expressive function classes such as Gaussian processes, but also properties of functions such as their integrals. For popular tasks, such as spatial interpolation, π VAE achieves state-of-the-art performance both in terms of accuracy and computational efficiency. Perhaps most usefully, we demonstrate an elegant and scalable means of performing fully Bayesian inference for stochastic processes within probabilistic programming languages such as Stan.",True,text mining,recurrent neural network
36263000,Deconstruction of Risk Prediction of Ischemic Cardiovascular and Cerebrovascular Diseases Based on Deep Learning,"Over the years, with the widespread use of computer technology and the dramatic increase in electronic medical data, data-driven approaches to medical data analysis have emerged. However, the analysis of medical data remains challenging due to the mixed nature of the data, the incompleteness of many records, and the high level of noise. This paper proposes an improved neural network DBN-LSTM that combines a deep belief network (DBN) with a long short-term memory (LSTM) network. The subset of feature attributes processed by CFS-EGA is used for training, and the optimal selection test of the number of hidden layers is performed on the upper DBN in the process of training DBN-LSTM. At the same time, the validation set is combined to determine the hyperparameters of the LSTM. Construct the DNN, CNN, and long short-term memory (LSTM) network for comparative analysis with DBN-LSTM. Use the classification method to compare the average of the final results of the two experiments. The results show that the prediction accuracy of DBN-LSTM for cardiovascular and cerebrovascular diseases reaches 95.61%, which is higher than the three traditional neural networks.",True,other,LSTM
36260674,Deep learning and social network analysis elucidate drivers of HIV transmission in a high-incidence cohort of people who inject drugs,"Globally, people who inject drugs (PWID) experience some of the fastest-growing HIV epidemics. Network-based approaches represent a powerful tool for understanding and combating these epidemics; however, detailed social network studies are limited and pose analytical challenges. We collected longitudinal social (injection partners) and spatial (injection venues) network information from 2512 PWID in New Delhi, India. We leveraged network analysis and graph neural networks (GNNs) to uncover factors associated with HIV transmission and identify optimal intervention delivery points. Longitudinal HIV incidence was 21.3 per 100 person-years. Overlapping community detection using GNNs revealed seven communities, with HIV incidence concentrated within one community. The injection venue most strongly associated with incidence was found to overlap six of the seven communities, suggesting that an intervention deployed at this one location could reach the majority of the sample. These findings highlight the utility of network analysis and deep learning in HIV program design.",True,text mining,Not specified
36240224,A deep learning approach to real-time HIV outbreak detection using genetic data,"Pathogen genomic sequence data are increasingly made available for epidemiological monitoring. A main interest is to identify and assess the potential of infectious disease outbreaks. While popular methods to analyze sequence data often involve phylogenetic tree inference, they are vulnerable to errors from recombination and impose a high computational cost, making it difficult to obtain real-time results when the number of sequences is in or above the thousands. Here, we propose an alternative strategy to outbreak detection using genomic data based on deep learning methods developed for image classification. The key idea is to use a pairwise genetic distance matrix calculated from viral sequences as an image, and develop convolutional neutral network (CNN) models to classify areas of the images that show signatures of active outbreak, leading to identification of subsets of sequences taken from an active outbreak. We showed that our method is efficient in finding HIV-1 outbreaks with R0 ≥ 2.5, and overall a specificity exceeding 98% and sensitivity better than 92%. We validated our approach using data from HIV-1 CRF01 in Europe, containing both endemic sequences and a well-known dual outbreak in intravenous drug users. Our model accurately identified known outbreak sequences in the background of slower spreading HIV. Importantly, we detected both outbreaks early on, before they were over, implying that had this method been applied in real-time as data became available, one would have been able to intervene and possibly prevent the extent of these outbreaks. This approach is scalable to processing hundreds of thousands of sequences, making it useful for current and future real-time epidemiological investigations, including public health monitoring using large databases and especially for rapid outbreak identification.",True,other,recurrent neural network
36238252,Performance evaluation of machine learning and Computer Coded Verbal Autopsy (CCVA) algorithms for cause of death determination: A comparative analysis of data from rural South Africa,"Computer Coded Verbal Autopsy (CCVA) algorithms are commonly used to determine the cause of death (CoD) from questionnaire responses extracted from verbal autopsies (VAs). However, they can only operate on structured data and cannot effectively harness information from unstructured VA narratives. Machine Learning (ML) algorithms have also been applied successfully in determining the CoD from VA narratives, allowing the use of auxiliary information that CCVA algorithms cannot directly utilize. However, most ML-based studies only use responses from the structured questionnaire, and the results lack generalisability and comparability across studies. We present a comparative performance evaluation of ML methods and CCVA algorithms on South African VA narratives data, using data from Agincourt Health and Demographic Surveillance Site (HDSS) with physicians' classifications as the gold standard. The data were collected from 1993 to 2015 and have 16,338 cases. The random forest and extreme gradient boosting classifiers outperformed the other classifiers on the combined dataset, attaining accuracy of 96% respectively, with significant statistical differences in algorithmic performance (p &lt; 0.0001). All our models attained Area Under Receiver Operating Characteristics (AUROC) of greater than 0.884. The InterVA CCVA attained 83% Cause Specific Mortality Fraction accuracy and an Overall Chance-Corrected Concordance of 0.36. We demonstrate that ML models could accurately determine the cause of death from VA narratives. Additionally, through mortality trends and pattern analysis, we discovered that in the first decade of the civil registration system in South Africa, the average life expectancy was approximately 50 years. However, in the second decade, life expectancy significantly dropped, and the population was dying at a much younger average age of 40 years, mostly from the leading HIV related causes. Interestingly, in the third decade, we see a gradual improvement in life expectancy, possibly attributed to effective health intervention programmes. Through a structure and semantic analysis of narratives where experts disagree, we also demonstrate the most frequent terms of traditional healer consultations and visits. The comparative approach also makes this study a baseline that can be used for future research enforcing generalization and comparability. Future study will entail exploring deep learning models for CoD classification.",True,other,Not specified
36231500,Validation and Improvement of a Convolutional Neural Network to Predict the Involved Pathology in a Head and Neck Surgery Cohort,"The selection of patients for the constitution of a cohort is a major issue for clinical research (prospective studies and retrospective studies in real life). Our objective was to validate in real life conditions the use of a Deep Learning process based on a neural network, for the classification of patients according to the pathology involved in a head and neck surgery department. 24,434 Electronic Health Records (EHR) from the first visit between 2000 and 2020 were extracted. More than 6000 EHR were manually classified in ten groups of interest according to the reason for consultation with a clinical relevance. A convolutional neural network (TensorFlow, previously reported by Hsu et al.) was then used to predict the group of patients based on their pathology, using two levels of classification based on clinically relevant criteria. On the first and second level of classification, macro-average performances were: 0.95, 0.83, 0.85, 0.97, 0.84 and 0.93, 0.76, 0.83, 0.96, 0.79 for accuracy, recall, precision, specificity and F1-score versus accuracy, recall and precision of 0.580, 580 and 0.582 for Hsu et al., respectively. We validated this model to predict the pathology involved and to constitute clinically relevant cohorts in a tertiary hospital. This model did not require a preprocessing stage, was used in French and showed equivalent or better performances than other already published techniques.",True,other,convolutional neural network
36220099,Challenges for machine learning in clinical translation of big data imaging studies,"Combining deep learning image analysis methods and large-scale imaging datasets offers many opportunities to neuroscience imaging and epidemiology. However, despite these opportunities and the success of deep learning when applied to a range of neuroimaging tasks and domains, significant barriers continue to limit the impact of large-scale datasets and analysis tools. Here, we examine the main challenges and the approaches that have been explored to overcome them. We focus on issues relating to data availability, interpretability, evaluation, and logistical challenges and discuss the problems that still need to be tackled to enable the success of ""big data"" deep learning approaches beyond research.",True,other,convolutional neural network
36216232,Longitudinal deep learning clustering of Type 2 Diabetes Mellitus trajectories using routinely collected health records,"Type 2 diabetes mellitus (T2DM) is a highly heterogeneous chronic disease with different pathophysiological and genetic characteristics affecting its progression, associated complications and response to therapies. The advances in deep learning (DL) techniques and the availability of a large amount of healthcare data allow us to investigate T2DM characteristics and evolution with a completely new approach, studying common disease trajectories rather than cross sectional values. We used an Kernelized-AutoEncoder algorithm to map 5 years of data of 11,028 subjects diagnosed with T2DM in a latent space that embedded similarities and differences between patients in terms of the evolution of the disease. Once we obtained the latent space, we used classical clustering algorithms to create longitudinal clusters representing different evolutions of the diabetic disease. Our unsupervised DL clustering algorithm suggested seven different longitudinal clusters. Different mean ages were observed among the clusters (ranging from 65.3±11.6 to 72.8±9.4). Subjects in clusters B (Hypercholesteraemic) and E (Hypertensive) had shorter diabetes duration (9.2±3.9 and 9.5±3.9 years respectively). Subjects in Cluster G (Metabolic) had the poorest glycaemic control (mean glycated hemoglobin 7.99±1.42%), while cluster E had the best one (mean glycated hemoglobin 7.04±1.11%). Obesity was observed mainly in clusters A (Neuropathic), C (Multiple Complications), F (Retinopathy) and G. A dashboard is available at dm2.b2slab.upc.edu to visualize the different trajectories corresponding to the 7 clusters.",True,text mining,Not specified
36201237,Machine learning in sudden cardiac death risk prediction: a systematic review,"AIMS: Most patients who receive implantable cardioverter defibrillators (ICDs) for primary prevention do not receive therapy during the lifespan of the ICD, whilst up to 50% of sudden cardiac death (SCD) occur in individuals who are considered low risk by conventional criteria. Machine learning offers a novel approach to risk stratification for ICD assignment.
METHODS AND RESULTS: Systematic search was performed in MEDLINE, Embase, Emcare, CINAHL, Cochrane Library, OpenGrey, MedrXiv, arXiv, Scopus, and Web of Science. Studies modelling SCD risk prediction within days to years using machine learning were eligible for inclusion. Transparency and quality of reporting (TRIPOD) and risk of bias (PROBAST) were assessed. A total of 4356 studies were screened with 11 meeting the inclusion criteria with heterogeneous populations, methods, and outcome measures preventing meta-analysis. The study size ranged from 122 to 124 097 participants. Input data sources included demographic, clinical, electrocardiogram, electrophysiological, imaging, and genetic data ranging from 4 to 72 variables per model. The most common outcome metric reported was the area under the receiver operator characteristic (n = 7) ranging between 0.71 and 0.96. In six studies comparing machine learning models and regression, machine learning improved performance in five. No studies adhered to a reporting standard. Five of the papers were at high risk of bias.
CONCLUSION: Machine learning for SCD prediction has been under-applied and incorrectly implemented but is ripe for future investigation. It may have some incremental utility in predicting SCD over traditional models. The development of reporting standards for machine learning is required to improve the quality of evidence reporting in the field.",True,other,Not specified
36189325,SEMA: Antigen B-cell conformational epitope prediction using deep transfer learning,"One of the primary tasks in vaccine design and development of immunotherapeutic drugs is to predict conformational B-cell epitopes corresponding to primary antibody binding sites within the antigen tertiary structure. To date, multiple approaches have been developed to address this issue. However, for a wide range of antigens their accuracy is limited. In this paper, we applied the transfer learning approach using pretrained deep learning models to develop a model that predicts conformational B-cell epitopes based on the primary antigen sequence and tertiary structure. A pretrained protein language model, ESM-1v, and an inverse folding model, ESM-IF1, were fine-tuned to quantitatively predict antibody-antigen interaction features and distinguish between epitope and non-epitope residues. The resulting model called SEMA demonstrated the best performance on an independent test set with ROC AUC of 0.76 compared to peer-reviewed tools. We show that SEMA can quantitatively rank the immunodominant regions within the SARS-CoV-2 RBD domain. SEMA is available at https://github.com/AIRI-Institute/SEMAi and the web-interface http://sema.airi.net.",True,other,Not specified
36176468,Deep learning for screening primary osteopenia and osteoporosis using spine radiographs and patient clinical covariates in a Chinese population,"PURPOSE: Many high-risk osteopenia and osteoporosis patients remain undiagnosed. We proposed to construct a convolutional neural network model for screening primary osteopenia and osteoporosis based on the lumbar radiographs, and to compare the diagnostic performance of the CNN model adding the clinical covariates with the image model alone.
METHODS: A total of 6,908 participants were collected for analysis, including postmenopausal women and men aged 50-95 years, who performed conventional lumbar x-ray examinations and dual-energy x-ray absorptiometry (DXA) examinations within 3 months. All participants were divided into a training set, a validation set, test set 1, and test set 2 at a ratio of 8:1:1:1. The bone mineral density (BMD) values derived from DXA were applied as the reference standard. A three-class CNN model was developed to classify the patients into normal BMD, osteopenia, and osteoporosis. Moreover, we developed the models integrating the images with clinical covariates (age, gender, and BMI), and explored whether adding clinical data improves diagnostic performance over the image mode alone. The receiver operating characteristic curve analysis was performed for assessing the model performance.
RESULTS: As for classifying osteoporosis, the model based on the anteroposterior+lateral channel performed best, with the area under the curve (AUC) range from 0.909 to 0.937 in three test cohorts. The models with images alone achieved moderate sensitivity in classifying osteopenia, in which the highest AUC achieved 0.785. The performance of models integrating images with clinical data shows a slight improvement over models with anteroposterior or lateral images input alone for diagnosing osteoporosis, in which the AUC increased about 2%-4%. Regarding categorizing osteopenia and the normal BMD, the proposed models integrating images with clinical data also outperformed the models with images solely.
CONCLUSION: The deep learning-based approach could screen osteoporosis and osteopenia based on lumbar radiographs.",True,both,RNN
36162197,MCluster-VAEs: An end-to-end variational deep learning-based clustering method for subtype discovery using multi-omics data,"The discovery of cancer subtypes based on unsupervised clustering helps in providing a precise diagnosis, guide treatment, and improve patients' prognoses. Instead of single-omics data, multi-omics data can improve the clustering performance because it obtains a comprehensive landscape for understanding biological systems and mechanisms. However, heterogeneous data from multiple sources raises high complexity and different kinds of noise, which are detrimental to the extraction of clustering information. We propose an end-to-end deep learning based method, called Multi-omics Clustering Variational Autoencoders (MCluster-VAEs), that can extract cluster-friendly representations on multi-omics data. First, a unified network architecture with an attention mechanism was developed for accurately modeling multi-omics data. Then, using a novel objective function built from the Variational Bayes technique, the model was trained to effectively obtain the posterior estimation of the clustering assignments. Compared with 12 other state-of-the-art multi-omics clustering methods, MCluster-VAEs achieved an outstanding performance on benchmark datasets from the TCGA database. On the Pan Cancer dataset, MCluster-VAEs achieved an adjusted Rand index of approximately 0.78 for cancer category recognition, an increase of more than 18% compared with other methods. Furthermore, a survival analysis and clinical parameter enrichment tests conducted on 10 cancer datasets demonstrated that MCluster-VAEs provides comparable and even better results than many common integrative approaches. These results demonstrate that MCluster-VAEs are a powerful new tool for dissecting complex multi-omics relationships and providing new insights for cancer subtype discovery.",True,other,convolutional neural network
36130464,"Erratum to 'Benchmarking weakly-supervised deep learning pipelines for whole slide classification in computational pathology' Medical Image Analysis, Volume 79, July 2022, 102474",,True,other,GAN
36110150,Using ensembles and distillation to optimize the deployment of deep learning models for the classification of electronic cancer pathology reports,"OBJECTIVE: We aim to reduce overfitting and model overconfidence by distilling the knowledge of an ensemble of deep learning models into a single model for the classification of cancer pathology reports.
MATERIALS AND METHODS: We consider the text classification problem that involves 5 individual tasks. The baseline model consists of a multitask convolutional neural network (MtCNN), and the implemented ensemble (teacher) consists of 1000 MtCNNs. We performed knowledge transfer by training a single model (student) with soft labels derived through the aggregation of ensemble predictions. We evaluate performance based on accuracy and abstention rates by using softmax thresholding.
RESULTS: The student model outperforms the baseline MtCNN in terms of abstention rates and accuracy, thereby allowing the model to be used with a larger volume of documents when deployed. The highest boost was observed for subsite and histology, for which the student model classified an additional 1.81% reports for subsite and 3.33% reports for histology.
DISCUSSION: Ensemble predictions provide a useful strategy for quantifying the uncertainty inherent in labeled data and thereby enable the construction of soft labels with estimated probabilities for multiple classes for a given document. Training models with the derived soft labels reduce model confidence in difficult-to-classify documents, thereby leading to a reduction in the number of highly confident wrong predictions.
CONCLUSIONS: Ensemble model distillation is a simple tool to reduce model overconfidence in problems with extreme class imbalance and noisy datasets. These methods can facilitate the deployment of deep learning models in high-risk domains with low computational resources where minimizing inference time is required.",True,other,convolutional neural network
36072795,"Deep learning models for predicting the survival of patients with chondrosarcoma based on a surveillance, epidemiology, and end results analysis","BACKGROUND: Accurate prediction of prognosis is critical for therapeutic decisions in chondrosarcoma patients. Several prognostic models have been created utilizing multivariate Cox regression or binary classification-based machine learning approaches to predict the 3- and 5-year survival of patients with chondrosarcoma, but few studies have investigated the results of combining deep learning with time-to-event prediction. Compared with simplifying the prediction as a binary classification problem, modeling the probability of an event as a function of time by combining it with deep learning can provide better accuracy and flexibility.
MATERIALS AND METHODS: Patients with the diagnosis of chondrosarcoma between 2000 and 2018 were extracted from the Surveillance, Epidemiology, and End Results (SEER) registry. Three algorithms-two based on neural networks (DeepSurv, neural multi-task logistic regression [NMTLR]) and one on ensemble learning (random survival forest [RSF])-were selected for training. Meanwhile, a multivariate Cox proportional hazards (CoxPH) model was also constructed for comparison. The dataset was randomly divided into training and testing datasets at a ratio of 7:3. Hyperparameter tuning was conducted through a 1000-repeated random search with 5-fold cross-validation on the training dataset. The model performance was assessed using the concordance index (C-index), Brier score, and Integrated Brier Score (IBS). The accuracy of predicting 1-, 3-, 5- and 10-year survival was evaluated using receiver operating characteristic curves (ROC), calibration curves, and the area under the ROC curves (AUC).
RESULTS: A total of 3145 patients were finally enrolled in our study. The mean age at diagnosis was 52 ± 18 years, 1662 of the 3145 patients were male (53%), and mean survival time was 83 ± 67 months. Two deep learning models outperformed the RSF and classical CoxPH models, with the C-index on test datasets achieving values of 0.832 (DeepSurv) and 0.821 (NMTLR). The DeepSurv model produced better accuracy and calibrated survival estimates in predicting 1-, 3- 5- and 10-year survival (AUC:0.895-0.937). We deployed the DeepSurv model as a web application for use in clinical practice; it can be accessed through https://share.streamlit.io/whuh-ml/chondrosarcoma/Predict/app.py.
CONCLUSIONS: Time-to-event prediction models based on deep learning algorithms are successful in predicting chondrosarcoma prognosis, with DeepSurv producing the best discriminative performance and calibration.",True,other,Not specified
36056746,Deciphering signatures of natural selection via deep learning,"Identifying genomic regions influenced by natural selection provides fundamental insights into the genetic basis of local adaptation. However, it remains challenging to detect loci under complex spatially varying selection. We propose a deep learning-based framework, DeepGenomeScan, which can detect signatures of spatially varying selection. We demonstrate that DeepGenomeScan outperformed principal component analysis- and redundancy analysis-based genome scans in identifying loci underlying quantitative traits subject to complex spatial patterns of selection. Noticeably, DeepGenomeScan increases statistical power by up to 47.25% under nonlinear environmental selection patterns. We applied DeepGenomeScan to a European human genetic dataset and identified some well-known genes under selection and a substantial number of clinically important genes that were not identified by SPA, iHS, Fst and Bayenv when applied to the same dataset.",True,other,Not specified
36051929,Deep Learning-Based Computed Tomography Features in Evaluating Early Screening and Risk Factors for Chronic Obstructive Pulmonary Disease,"This research aimed to investigate the diagnostic effect of computed tomography (CT) images based on a deep learning double residual convolution neural network (DRCNN) model on chronic obstructive pulmonary disease (COPD) and the related risk factors for COPD. The questionnaire survey was conducted among 980 permanent residents aged ≥ 40 years old. Among them, 84 patients who were diagnosed with COPD and volunteered to participate in the experiment and 25 healthy people were selected as the research subjects, and all of them underwent CT imaging scans. At the same time, an image noise reduction model based on the DRCNN was proposed to process CT images. The results showed that 84 of 980 subjects were diagnosed with COPD, and the overall prevalence of COPD in this epidemiological survey was 8.57%. Multivariate logistic regression model analysis showed that the regression coefficients of COPD with age, family history of COPD, and smoking were 0.557, 0.513, and 0.717, respectively (P &lt; 0.05). The diagnostic sensitivity, specificity, and accuracy of DRCNN-based CT for COPD were greatly superior to those of single CT and the difference was considerable (P &lt; 0.05). In summary, advanced age, family history of COPD, and smoking were independent risk factors for COPD. CT based on the DRCNN model can improve the diagnostic accuracy of simple CT images for COPD and has good performance in the early screening of COPD.",True,other,Not specified
36033454,Development and validation of a deep learning model to predict survival of patients with esophageal cancer,"OBJECTIVE: To compare the performance of a deep learning survival network with the tumor, node, and metastasis (TNM) staging system in survival prediction and test the reliability of individual treatment recommendations provided by the network.
METHODS: In this population-based cohort study, we developed and validated a deep learning survival model using consecutive cases of newly diagnosed stage I to IV esophageal cancer between January 2004 and December 2015 in a Surveillance, Epidemiology, and End Results (SEER) database. The model was externally validated in an independent cohort from Fujian Provincial Hospital. The C statistic was used to compare the performance of the deep learning survival model and TNM staging system. Two other deep learning risk prediction models were trained for treatment recommendations. A Kaplan-Meier survival curve was used to compare survival between the population that followed the recommended therapy and those who did not.
RESULTS: A total of 9069 patients were included in this study. The deep learning network showed more promising results in predicting esophageal cancer-specific survival than the TNM stage in the internal test dataset (C-index=0.753 vs. 0.638) and external validation dataset (C-index=0.687 vs. 0.643). The population who received the recommended treatments had superior survival compared to those who did not, based on the internal test dataset (hazard ratio, 0.753; 95% CI, 0.556-0.987; P=0.042) and the external validation dataset (hazard ratio, 0.633; 95% CI, 0.459-0.834; P=0.0003).
CONCLUSION: Deep learning neural networks have potential advantages over traditional linear models in prognostic assessment and treatment recommendations. This novel analytical approach may provide reliable information on individual survival and treatment recommendations for patients with esophageal cancer.",True,other,Not specified
36030722,COVID-19 forecasting using new viral variants and vaccination effectiveness models,"Recently, a high number of daily positive COVID-19 cases have been reported in regions with relatively high vaccination rates; hence, booster vaccination has become necessary. In addition, infections caused by the different variants and correlated factors have not been discussed in depth. With large variabilities and different co-factors, it is difficult to use conventional mathematical models to forecast the incidence of COVID-19. Machine learning based on long short-term memory was applied to forecasting the time series of new daily positive cases (DPC), serious cases, hospitalized cases, and deaths. Data acquired from regions with high rates of vaccination, such as Israel, were blended with the current data of other regions in Japan such that the effect of vaccination was considered in efficient manner. The protection provided by symptomatic infection was also considered in terms of the population effectiveness of vaccination as well as the vaccination protection waning effect and ratio and infectivity of different viral variants. To represent changes in public behavior, public mobility and interactions through social media were also included in the analysis. Comparing the observed and estimated new DPC in Tel Aviv, Israel, the parameters characterizing vaccination effectiveness and the waning protection from infection were well estimated; the vaccination effectiveness of the second dose after 5 months and the third dose after two weeks from infection by the delta variant were 0.24 and 0.95, respectively. Using the extracted parameters regarding vaccination effectiveness, DPC in three major prefectures of Japan were replicated. The key factor influencing the prevention of COVID-19 transmission is the vaccination effectiveness at the population level, which considers the waning protection from vaccination rather than the percentage of fully vaccinated people. The threshold of the efficiency at the population level was estimated as 0.3 in Tel Aviv and 0.4 in Tokyo, Osaka, and Aichi. Moreover, a weighting scheme associated with infectivity results in more accurate forecasting by the infectivity model of viral variants. Results indicate that vaccination effectiveness and infectivity of viral variants are important factors in future forecasting of DPC. Moreover, this study demonstrate a feasible way to project the effect of vaccination using data obtained from other country.",True,other,recurrent neural network
36030468,A deep learning-based model predicts survival for patients with laryngeal squamous cell carcinoma: a large population-based study,"OBJECTIVES: To assess the performance of DeepSurv, a deep learning-based model in the survival prediction of laryngeal squamous cell carcinoma (LSCC) using the Surveillance, Epidemiology, and End Results (SEER) database.
METHODS: In this large population-based study, we developed and validated a deep learning survival neural network using pathologically diagnosed patients with LSCC from the SEER database between January 2010 and December 2018. Totally 13 variables were included in this network, including patients baseline characteristics, stage, grade, site, tumor extension and treatment details. Based on the total risk score derived from this algorithm, a three-knot restricted cubic spline was plotted to exhibit the difference of survival benefits from two treatment modalities.
RESULTS: Totally 6316 patients with LSCC were included in the study, of which 4237 cases diagnosed between 2010 and 2015 were selected as the development cohort, and the rest (2079 cases diagnosed from 2016 to 2018) were the validation cohort. A state-of-the-art deep learning-based model based on 23 features (i.e., 13 variables) was generated, which showed more superior performance in the prediction of overall survival (OS) than the tumor, node, and metastasis (TNM) staging system (C-index for DeepSurv vs TNM staging = 0.71; 95% CI 0.69-0.74 vs 0.61; 95% CI 0.60-0.63). Interestingly, a significantly nonlinear association between total risk score and treatment effectiveness was observed. When the total risk score ranges 0.1-1.5, surgical treatment brought more survival benefits than nonsurgical one for LSCC patients, especially in 70.5% of patients staged III-IV.
CONCLUSIONS: The deep learning-based model shows more potential benefits in survival estimation for patients with LSCC, which may potentially serve as an auxiliary approach to provide reliable treatment recommendations.",True,other,Not specified
36028138,Deep learning research should be encouraged for diagnosis and treatment of antibiotic resistance of microbial infections in treatment associated emergencies in hospitals,,True,other,GAN
35976491,Quality assurance for automatically generated contours with additional deep learning,"OBJECTIVE: Deploying an automatic segmentation model in practice should require rigorous quality assurance (QA) and continuous monitoring of the model's use and performance, particularly in high-stakes scenarios such as healthcare. Currently, however, tools to assist with QA for such models are not available to AI researchers. In this work, we build a deep learning model that estimates the quality of automatically generated contours.
METHODS: The model was trained to predict the segmentation quality by outputting an estimate of the Dice similarity coefficient given an image contour pair as input. Our dataset contained 60 axial T2-weighted MRI images of prostates with ground truth segmentations along with 80 automatically generated segmentation masks. The model we used was a 3D version of the EfficientDet architecture with a custom regression head. For validation, we used a fivefold cross-validation. To counteract the limitation of the small dataset, we used an extensive data augmentation scheme capable of producing virtually infinite training samples from a single ground truth label mask. In addition, we compared the results against a baseline model that only uses clinical variables for its predictions.
RESULTS: Our model achieved a mean absolute error of 0.020 ± 0.026 (2.2% mean percentage error) in estimating the Dice score, with a rank correlation of 0.42. Furthermore, the model managed to correctly identify incorrect segmentations (defined in terms of acceptable/unacceptable) 99.6% of the time.
CONCLUSION: We believe that the trained model can be used alongside automatic segmentation tools to ensure quality and thus allow intervention to prevent undesired segmentation behavior.",True,computer vision,convolutional neural network
35959675,Artificial Intelligence-Enabled Model for Early Detection of Left Ventricular Hypertrophy and Mortality Prediction in Young to Middle-Aged Adults,"BACKGROUND: Concealed left ventricular hypertrophy (LVH) is a prevalent condition that is correlated with a substantial risk of cardiovascular events and mortality, especially in young to middle-aged adults. Early identification of LVH is warranted. In this work, we aimed to develop an artificial intelligence (AI)-enabled model for early detection and risk stratification of LVH using 12-lead ECGs.
METHODS: By deep learning techniques on the ECG recordings from 28 745 patients (20-60 years old), the AI model was developed to detect verified LVH from transthoracic echocardiography and evaluated on an independent cohort. Two hundred twenty-five patients from Japan were externally validated. Cardiologists' diagnosis of LVH was based on conventional ECG criteria. The area under the curve (AUC), sensitivity, and specificity were applied to evaluate the model performance. A Cox regression model estimated the independent effects of AI-predicted LVH on cardiovascular or all-cause death.
RESULTS: The AUC of the AI model in diagnosing LVH was 0.89 (sensitivity: 90.3%, specificity: 69.3%), which was significantly better than that of the cardiologists' diagnosis (AUC, 0.64). In the second independent cohort, the diagnostic performance of the AI model was consistent (AUC, 0.86; sensitivity: 85.4%, specificity: 67.0%). After a follow-up of 6 years, AI-predicted LVH was independently associated with higher cardiovascular or all-cause mortality (hazard ratio, 1.91 [1.04-3.49] and 1.54 [1.20-1.97], respectively). The predictive power of the AI model for mortality was consistently valid among patients of different ages, sexes, and comorbidities, including hypertension, diabetes, stroke, heart failure, and myocardial infarction. Last, we also validated the model in the international independent cohort from Japan (AUC, 0.83).
CONCLUSIONS: The AI model improved the detection of LVH and mortality prediction in the young to middle-aged population and represented an attractive tool for risk stratification. Early identification by the AI model gives every chance for timely treatment to reverse adverse outcomes.",True,other,LSTM
35943339,Deep Learning Detects Changes Indicative of Axial Spondyloarthritis at MRI of Sacroiliac Joints,"Background MRI is frequently used for early diagnosis of axial spondyloarthritis (axSpA). However, evaluation is time-consuming and requires profound expertise because noninflammatory degenerative changes can mimic axSpA, and early signs may therefore be missed. Deep neural networks could function as assistance for axSpA detection. Purpose To create a deep neural network to detect MRI changes in sacroiliac joints indicative of axSpA. Materials and Methods This retrospective multicenter study included MRI examinations of five cohorts of patients with clinical suspicion of axSpA collected at university and community hospitals between January 2006 and September 2020. Data from four cohorts were used as the training set, and data from one cohort as the external test set. Each MRI examination in the training and test sets was scored by six and seven raters, respectively, for inflammatory changes (bone marrow edema, enthesitis) and structural changes (erosions, sclerosis). A deep learning tool to detect changes indicative of axSpA was developed. First, a neural network to homogenize the images, then a classification network were trained. Performance was evaluated with use of area under the receiver operating characteristic curve (AUC), sensitivity, and specificity. P &lt; .05 was considered indicative of statistically significant difference. Results Overall, 593 patients (mean age, 37 years ± 11 [SD]; 302 women) were studied. Inflammatory and structural changes were found in 197 of 477 patients (41%) and 244 of 477 (51%), respectively, in the training set and 25 of 116 patients (22%) and 26 of 116 (22%) in the test set. The AUCs were 0.94 (95% CI: 0.84, 0.97) for all inflammatory changes, 0.88 (95% CI: 0.80, 0.95) for inflammatory changes fulfilling the Assessment of SpondyloArthritis international Society definition, and 0.89 (95% CI: 0.81, 0.96) for structural changes indicative of axSpA. Sensitivity and specificity on the external test set were 22 of 25 patients (88%) and 65 of 91 patients (71%), respectively, for inflammatory changes and 22 of 26 patients (85%) and 70 of 90 patients (78%) for structural changes. Conclusion Deep neural networks can detect inflammatory or structural changes to the sacroiliac joint indicative of axial spondyloarthritis at MRI. © RSNA, 2022 Online supplemental material is available for this article.",True,other,recurrent neural network
35926935,Deep Learning Electrocardiographic Analysis for Detection of Left-Sided Valvular Heart Disease,"BACKGROUND: Valvular heart disease is an important contributor to cardiovascular morbidity and mortality and remains underdiagnosed. Deep learning analysis of electrocardiography (ECG) may be useful in detecting aortic stenosis (AS), aortic regurgitation (AR), and mitral regurgitation (MR).
OBJECTIVES: This study aimed to develop ECG deep learning algorithms to identify moderate or severe AS, AR, and MR alone and in combination.
METHODS: A total of 77,163 patients undergoing ECG within 1 year before echocardiography from 2005-2021 were identified and split into train (n = 43,165), validation (n = 12,950), and test sets (n = 21,048; 7.8% with any of AS, AR, or MR). Model performance was assessed using area under the receiver-operating characteristic (AU-ROC) and precision-recall curves. Outside validation was conducted on an independent data set. Test accuracy was modeled using different disease prevalence levels to simulate screening efficacy using the deep learning model.
RESULTS: The deep learning algorithm model accuracy was as follows: AS (AU-ROC: 0.88), AR (AU-ROC: 0.77), MR (AU-ROC: 0.83), and any of AS, AR, or MR (AU-ROC: 0.84; sensitivity 78%, specificity 73%) with similar accuracy in external validation. In screening program modeling, test characteristics were dependent on underlying prevalence and selected sensitivity levels. At a prevalence of 7.8%, the positive and negative predictive values were 20% and 97.6%, respectively.
CONCLUSIONS: Deep learning analysis of the ECG can accurately detect AS, AR, and MR in this multicenter cohort and may serve as the basis for the development of a valvular heart disease screening program.",True,other,Not specified
35915642,Deep learning and machine learning-based voice analysis for the detection of COVID-19: A proposal and comparison of architectures,"Alongside the currently used nasal swab testing, the COVID-19 pandemic situation would gain noticeable advantages from low-cost tests that are available at any-time, anywhere, at a large-scale, and with real time answers. A novel approach for COVID-19 assessment is adopted here, discriminating negative subjects versus positive or recovered subjects. The scope is to identify potential discriminating features, highlight mid and short-term effects of COVID on the voice and compare two custom algorithms. A pool of 310 subjects took part in the study; recordings were collected in a low-noise, controlled setting employing three different vocal tasks. Binary classifications followed, using two different custom algorithms. The first was based on the coupling of boosting and bagging, with an AdaBoost classifier using Random Forest learners. A feature selection process was employed for the training, identifying a subset of features acting as clinically relevant biomarkers. The other approach was centered on two custom CNN architectures applied to mel-Spectrograms, with a custom knowledge-based data augmentation. Performances, evaluated on an independent test set, were comparable: Adaboost and CNN differentiated COVID-19 positive from negative with accuracies of 100% and 95% respectively, and recovered from negative individuals with accuracies of 86.1% and 75% respectively. This study highlights the possibility to identify COVID-19 positive subjects, foreseeing a tool for on-site screening, while also considering recovered subjects and the effects of COVID-19 on the voice. The two proposed novel architectures allow for the identification of biomarkers and demonstrate the ongoing relevance of traditional ML versus deep learning in speech analysis.",True,other,Not specified
35901181,An evolutionary machine learning algorithm for cardiovascular disease risk prediction,"INTRODUCTION: This study developed a novel risk assessment model to predict the occurrence of cardiovascular disease (CVD) events. It uses a Genetic Algorithm (GA) to develop an easy-to-use model with high accuracy, calibrated based on the Isfahan Cohort Study (ICS) database.
METHODS: The ICS was a population-based prospective cohort study of 6,504 healthy Iranian adults aged ≥ 35 years followed for incident CVD over ten years, from 2001 to 2010. To develop a risk score, the problem of predicting CVD was solved using a well-designed GA, and finally, the results were compared with classic machine learning (ML) and statistical methods.
RESULTS: A number of risk scores such as the WHO, and PARS models were utilized as the baseline for comparison due to their similar chart-based models. The Framingham and PROCAM models were also applied to the dataset, with the area under a Receiver Operating Characteristic curve (AUROC) equal to 0.633 and 0.683, respectively. However, the more complex Deep Learning model using a three-layered Convolutional Neural Network (CNN) performed best among the ML models, with an AUROC of 0.74, and the GA-based eXplanaible Persian Atherosclerotic CVD Risk Stratification (XPARS) showed higher performance compared to the statistical methods. XPARS with eight features showed an AUROC of 0.76, and the XPARS with four features, showed an AUROC of 0.72.
CONCLUSION: A risk model that is extracted using GA substantially improves the prediction of CVD compared to conventional methods. It is clear, interpretable and can be a suitable replacement for conventional statistical methods.",True,other,Not specified
35901027,Predicting malnutrition from longitudinal patient trajectories with deep learning,"Malnutrition is common, morbid, and often correctable, but subject to missed and delayed diagnosis. Better screening and prediction could improve clinical, functional, and economic outcomes. This study aimed to assess the predictability of malnutrition from longitudinal patient records, and the external generalizability of a predictive model. Predictive models were developed and validated on statewide emergency department (ED) and hospital admission databases for California, Florida and New York, including visits from October 1, 2015 to December 31, 2018. Visit features included patient demographics, diagnosis codes, and procedure categories. Models included long short-term memory (LSTM) recurrent neural networks trained on longitudinal trajectories, and gradient-boosted tree and logistic regression models trained on cross-sectional patient data. The dataset used for model training and internal validation (California and Florida) included 62,811 patient trajectories (266,951 visits). Test sets included 63,997 (California), 63,112 (Florida), and 62,472 (New York) trajectories, such that each cohort's composition was proportional to the prevalence of malnutrition in that state. Trajectories contained seven patient characteristics and up to 2,008 diagnosis categories. Area under the receiver-operating characteristic (AUROC) and precision-recall curves (AUPRC) were used to characterize prediction of first malnutrition diagnoses in the test sets. Data analysis was performed from September 2020 to May 2021. Between 4.0% (New York) and 6.2% (California) of patients received malnutrition diagnoses. The longitudinal LSTM model produced the most accurate predictions of malnutrition, with comparable predictive performance in California (AUROC 0.854, AUPRC 0.258), Florida (AUROC 0.869, AUPRC 0.234), and New York (AUROC 0.869, AUPRC 0.190). Deep learning models can reliably predict malnutrition from existing longitudinal patient records, with better predictive performance and lower data-collection requirements than existing instruments. This approach may facilitate early nutritional intervention via automated screening at the point of care.",True,text mining,Not specified
35885865,Enhanced Gravitational Search Optimization with Hybrid Deep Learning Model for COVID-19 Diagnosis on Epidemiology Data,"Effective screening provides efficient and quick diagnoses of COVID-19 and could alleviate related problems in the health care system. A prediction model that combines multiple features to assess contamination risks was established in the hope of supporting healthcare workers worldwide in triaging patients, particularly in situations with limited health care resources. Furthermore, a lack of diagnosis kits and asymptomatic cases can lead to missed or delayed diagnoses, exposing visitors, medical staff, and patients to 2019-nCoV contamination. Non-clinical techniques including data mining, expert systems, machine learning, and other artificial intelligence technologies have a crucial role to play in containment and diagnosis in the COVID-19 outbreak. This study developed Enhanced Gravitational Search Optimization with a Hybrid Deep Learning Model (EGSO-HDLM) for COVID-19 diagnoses using epidemiology data. The major aim of designing the EGSO-HDLM model was the identification and classification of COVID-19 using epidemiology data. In order to examine the epidemiology data, the EGSO-HDLM model employed a hybrid convolutional neural network with a gated recurrent unit based fusion (HCNN-GRUF) model. In addition, the hyperparameter optimization of the HCNN-GRUF model was improved by the use of the EGSO algorithm, which was derived by including the concepts of cat map and the traditional GSO algorithm. The design of the EGSO algorithm helps in reducing the ergodic problem, avoiding premature convergence, and enhancing algorithm efficiency. To demonstrate the better performance of the EGSO-HDLM model, experimental validation on a benchmark dataset was performed. The simulation results ensured the enhanced performance of the EGSO-HDLM model over recent approaches.",True,both,Not specified
35885449,Deep Learning Paradigm for Cardiovascular Disease/Stroke Risk Stratification in Parkinson's Disease Affected by COVID-19: A Narrative Review,"Background and Motivation: Parkinson's disease (PD) is one of the most serious, non-curable, and expensive to treat. Recently, machine learning (ML) has shown to be able to predict cardiovascular/stroke risk in PD patients. The presence of COVID-19 causes the ML systems to become severely non-linear and poses challenges in cardiovascular/stroke risk stratification. Further, due to comorbidity, sample size constraints, and poor scientific and clinical validation techniques, there have been no well-explained ML paradigms. Deep neural networks are powerful learning machines that generalize non-linear conditions. This study presents a novel investigation of deep learning (DL) solutions for CVD/stroke risk prediction in PD patients affected by the COVID-19 framework. Method: The PRISMA search strategy was used for the selection of 292 studies closely associated with the effect of PD on CVD risk in the COVID-19 framework. We study the hypothesis that PD in the presence of COVID-19 can cause more harm to the heart and brain than in non-COVID-19 conditions. COVID-19 lung damage severity can be used as a covariate during DL training model designs. We, therefore, propose a DL model for the estimation of, (i) COVID-19 lesions in computed tomography (CT) scans and (ii) combining the covariates of PD, COVID-19 lesions, office and laboratory arterial atherosclerotic image-based biomarkers, and medicine usage for the PD patients for the design of DL point-based models for CVD/stroke risk stratification. Results: We validated the feasibility of CVD/stroke risk stratification in PD patients in the presence of a COVID-19 environment and this was also verified. DL architectures like long short-term memory (LSTM), and recurrent neural network (RNN) were studied for CVD/stroke risk stratification showing powerful designs. Lastly, we examined the artificial intelligence bias and provided recommendations for early detection of CVD/stroke in PD patients in the presence of COVID-19. Conclusion: The DL is a very powerful tool for predicting CVD/stroke risk in PD patients affected by COVID-19.",True,other,recurrent neural network
35876790,Deep Learning vs Traditional Breast Cancer Risk Models to Support Risk-Based Mammography Screening,"BACKGROUND: Deep learning breast cancer risk models demonstrate improved accuracy compared with traditional risk models but have not been prospectively tested. We compared the accuracy of a deep learning risk score derived from the patient's prior mammogram to traditional risk scores to prospectively identify patients with cancer in a cohort due for screening.
METHODS: We collected data on 119 139 bilateral screening mammograms in 57 617 consecutive patients screened at 5 facilities between September 18, 2017, and February 1, 2021. Patient demographics were retrieved from electronic medical records, cancer outcomes determined through regional tumor registry linkage, and comparisons made across risk models using Wilcoxon and Pearson χ2 2-sided tests. Deep learning, Tyrer-Cuzick, and National Cancer Institute Breast Cancer Risk Assessment Tool (NCI BCRAT) risk models were compared with respect to performance metrics and area under the receiver operating characteristic curves.
RESULTS: Cancers detected per thousand patients screened were higher in patients at increased risk by the deep learning model (8.6, 95% confidence interval [CI] = 7.9 to 9.4) compared with Tyrer-Cuzick (4.4, 95% CI = 3.9 to 4.9) and NCI BCRAT (3.8, 95% CI = 3.3 to 4.3) models (P &lt; .001). Area under the receiver operating characteristic curves of the deep learning model (0.68, 95% CI = 0.66 to 0.70) was higher compared with Tyrer-Cuzick (0.57, 95% CI = 0.54 to 0.60) and NCI BCRAT (0.57, 95% CI = 0.54 to 0.60) models. Simulated screening of the top 50th percentile risk by the deep learning model captured statistically significantly more patients with cancer compared with Tyrer-Cuzick and NCI BCRAT models (P &lt; .001).
CONCLUSIONS: A deep learning model to assess breast cancer risk can support feasible and effective risk-based screening and is superior to traditional models to identify patients destined to develop cancer in large screening cohorts.",True,other,Not specified
35867160,Deep learning imaging features derived from kidney ultrasounds predict chronic kidney disease progression in children with posterior urethral valves,"BACKGROUND: We sought to use deep learning to extract anatomic features from postnatal kidney ultrasounds and evaluate their performance in predicting the risk and timing of chronic kidney disease (CKD) progression for boys with posterior urethral valves (PUV). We hypothesized that these features would predict CKD progression better than clinical characteristics such as nadir creatinine alone.
METHODS: We performed a retrospective cohort study of boys with PUV treated at two pediatric health systems from 1990 to 2021. Features of kidneys were extracted from initial postnatal kidney ultrasound images using a deep learning model. Three time-to-event prediction models were built using random survival forests. The Imaging Model included deep learning imaging features, the Clinical Model included clinical data, and the Ensemble Model combined imaging features and clinical data. Separate models were built to include time-dependent clinical data that were available at 6 months, 1 year, 3 years, and 5 years.
RESULTS: Two-hundred and twenty-five patients were included in the analysis. All models performed well with C-indices of 0.7 or greater. The Clinical Model outperformed the Imaging Model at all time points with nadir creatinine driving the performance of the Clinical Model. Combining the 6-month Imaging Model (C-index 0.7; 95% confidence interval [CI] 0.6, 0.79) with the 6-month Clinical Model (C-index 0.79; 95% CI 0.71, 0.86) resulted in a 6-month Ensemble Model that performed better (C-index 0.82; 95% CI 0.77, 0.88) than either model alone.
CONCLUSIONS: Deep learning imaging features extracted from initial postnatal kidney ultrasounds may improve early prediction of CKD progression among children with PUV. A higher resolution version of the Graphical abstract is available as Supplementary information.",True,other,Not specified
35844896,Individual Factors Associated With COVID-19 Infection: A Machine Learning Study,"The fast, exponential increase of COVID-19 infections and their catastrophic effects on patients' health have required the development of tools that support health systems in the quick and efficient diagnosis and prognosis of this disease. In this context, the present study aims to identify the potential factors associated with COVID-19 infections, applying machine learning techniques, particularly random forest, chi-squared, xgboost, and rpart for feature selection; ROSE and SMOTE were used as resampling methods due to the existence of class imbalance. Similarly, machine and deep learning algorithms such as support vector machines, C4.5, random forest, rpart, and deep neural networks were explored during the train/test phase to select the best prediction model. The dataset used in this study contains clinical data, anthropometric measurements, and other health parameters related to smoking habits, alcohol consumption, quality of sleep, physical activity, and health status during confinement due to the pandemic associated with COVID-19. The results showed that the XGBoost model got the best features associated with COVID-19 infection, and random forest approximated the best predictive model with a balanced accuracy of 90.41% using SMOTE as a resampling technique. The model with the best performance provides a tool to help prevent contracting SARS-CoV-2 since the variables with the highest risk factor are detected, and some of them are, to a certain extent controllable.",True,other,recurrent neural network
35834249,Development and Validation of an Artificial Intelligence Model for Small Bowel Capsule Endoscopy Video Review,"IMPORTANCE: Reading small bowel capsule endoscopy (SBCE) videos is a tedious task for clinicians, and a new method should be applied to solve the situation.
OBJECTIVES: To develop and evaluate the performance of a convolutional neural network algorithm for SBCE video review in real-life clinical care.
DESIGN, SETTING, AND PARTICIPANTS: In this multicenter, retrospective diagnostic study, a deep learning neural network (SmartScan) was trained and validated for the SBCE video review. A total of 2927 SBCE examinations from 29 medical centers were used to train SmartScan to detect 17 types of CE structured terminology (CEST) findings from January 1, 2019, to June 30, 2020. SmartScan was later validated with conventional reading (CR) and SmartScan-assisted reading (SSAR) in 2898 SBCE examinations collected from 22 medical centers. Data analysis was performed from January 25 to December 31, 2021.
EXPOSURE: An artificial intelligence-based tool for interpreting clinical images of SBCE.
MAIN OUTCOMES AND MEASURES: The detection rate and efficiency of CEST findings detected by SSAR and CR were compared.
RESULTS: A total of 5825 SBCE examinations were retrospectively collected; 2898 examinations (1765 male participants [60.9%]; mean [SD] age, 49.8 [15.5] years) were included in the validation phase. From a total of 6084 CEST-classified SB findings, SSAR detected 5834 findings (95.9%; 95% CI, 95.4%-96.4%), significantly higher than CR, which detected 4630 findings (76.1%; 95% CI, 75.0%-77.2%). SmartScan-assisted reading achieved a higher per-patient detection rate (79.3% [2298 of 2898]) for CEST findings compared with CR (70.7% [2048 of 2298]; 95% CI, 69.0%-72.3%). With SSAR, the mean (SD) number of images (per SBCE video) requiring review was reduced to 779.2 (337.2) compared with 27 910.8 (12 882.9) with CR, for a mean (SD) reduction rate of 96.1% (4.3%). The mean (SD) reading time with SSAR was shortened to 5.4 (1.5) minutes compared with CR (51.4 [11.6] minutes), for a mean (SD) reduction rate of 89.3% (3.1%).
CONCLUSIONS AND RELEVANCE: This study suggests that a convolutional neural network-based algorithm is associated with an increased detection rate of SBCE findings and reduced SBCE video reading time.",True,other,CNN
35832894,Using deep learning to detect patients at risk for prostate cancer despite benign biopsies,"Routine transrectal ultrasound-guided systematic prostate biopsy only samples a small volume of the prostate and tumors between biopsy cores can be missed, leading to low sensitivity to detect clinically relevant prostate cancers (PCa). Deep learning may enable detection of PCa despite benign biopsies. We included 14,354 hematoxylin-eosin stained benign prostate biopsies from 1,508 men in two groups: men without established PCa diagnosis and men with at least one core biopsy diagnosed with PCa. A 10-Convolutional Neural Network ensemble was optimized to distinguish benign biopsies from benign men or patients with PCa. Area under the receiver operating characteristic curve was estimated at 0.739 (bootstrap 95% CI:0.682-0.796) on man level in the held-out test set. At the specificity of 0.90, the model sensitivity was 0.348. The proposed model can detect men with risk of missed PCa and has the potential to reduce false negatives and to indicate men who could benefit from rebiopsies.",True,other,Not specified
35812486,A Survey on Machine Learning and Internet of Medical Things-Based Approaches for Handling COVID-19: Meta-Analysis,"Early diagnosis, prioritization, screening, clustering, and tracking of patients with COVID-19, and production of drugs and vaccines are some of the applications that have made it necessary to use a new style of technology to involve, manage, and deal with this epidemic. Strategies backed by artificial intelligence (A.I.) and the Internet of Things (IoT) have been undeniably effective to understand how the virus works and prevent it from spreading. Accordingly, the main aim of this survey is to critically review the ML, IoT, and the integration of IoT and ML-based techniques in the applications related to COVID-19, from the diagnosis of the disease to the prediction of its outbreak. According to the main findings, IoT provided a prompt and efficient approach to tracking the disease spread. On the other hand, most of the studies developed by ML-based techniques aimed at the detection and handling of challenges associated with the COVID-19 pandemic. Among different approaches, Convolutional Neural Network (CNN), Support Vector Machine, Genetic CNN, and pre-trained CNN, followed by ResNet have demonstrated the best performances compared to other methods.",True,both,CNN
38505255,Development and external validation of a deep learning-based computed tomography classification system for COVID-19,"BACKGROUND: We aimed to develop and externally validate a novel machine learning model that can classify CT image findings as positive or negative for SARS-CoV-2 reverse transcription polymerase chain reaction (RT-PCR).
METHODS: We used 2,928 images from a wide variety of case-control type data sources for the development and internal validation of the machine learning model. A total of 633 COVID-19 cases and 2,295 non-COVID-19 cases were included in the study. We randomly divided cases into training and tuning sets at a ratio of 8:2. For external validation, we used 893 images from 740 consecutive patients at 11 acute care hospitals suspected of having COVID-19 at the time of diagnosis. The dataset included 343 COVID-19 patients. The reference standard was RT-PCR.
RESULTS: In external validation, the sensitivity and specificity of the model were 0.869 and 0.432, at the low-level cutoff, 0.724 and 0.721, at the high-level cutoff. Area under the receiver operating characteristic was 0.76.
CONCLUSIONS: Our machine learning model exhibited a high sensitivity in external validation datasets and may assist physicians to rule out COVID-19 diagnosis in a timely manner at emergency departments. Further studies are warranted to improve model specificity.",True,other,recurrent neural network
35794110,Deep learning from phylogenies to uncover the epidemiological dynamics of outbreaks,"Widely applicable, accurate and fast inference methods in phylodynamics are needed to fully profit from the richness of genetic data in uncovering the dynamics of epidemics. Standard methods, including maximum-likelihood and Bayesian approaches, generally rely on complex mathematical formulae and approximations, and do not scale with dataset size. We develop a likelihood-free, simulation-based approach, which combines deep learning with (1) a large set of summary statistics measured on phylogenies or (2) a complete and compact representation of trees, which avoids potential limitations of summary statistics and applies to any phylodynamics model. Our method enables both model selection and estimation of epidemiological parameters from very large phylogenies. We demonstrate its speed and accuracy on simulated data, where it performs better than the state-of-the-art methods. To illustrate its applicability, we assess the dynamics induced by superspreading individuals in an HIV dataset of men-having-sex-with-men in Zurich. Our tool PhyloDeep is available on github.com/evolbioinfo/phylodeep .",True,text mining,Not specified
38504945,Introduction to supervised machine learning in clinical epidemiology,"Machine learning refers to a series of processes in which a computer finds rules from a vast amount of data. With recent advances in computer technology and the availability of a wide variety of health data, machine learning has rapidly developed and been applied in medical research. Currently, there are three types of machine learning: supervised, unsupervised, and reinforcement learning. In medical research, supervised learning is commonly used for diagnoses and prognoses, while unsupervised learning is used for phenotyping a disease, and reinforcement learning for maximizing favorable results, such as optimization of total patients' waiting time in the emergency department. The present article focuses on the concept and application of supervised learning in medicine, the most commonly used machine learning approach in medicine, and provides a brief explanation of four algorithms widely used for prediction (random forests, gradient-boosted decision tree, support vector machine, and neural network). Among these algorithms, the neural network has further developed into deep learning algorithms to solve more complex tasks. Along with simple classification problems, deep learning is commonly used to process medical imaging, such as retinal fundus photographs for diabetic retinopathy diagnosis. Although machine learning can bring new insights into medicine by processing a vast amount of data that are often beyond human capacity, algorithms can also fail when domain knowledge is neglected. The combination of algorithms and human cognitive ability is a key to the successful application of machine learning in medicine.",True,other,recurrent neural network
35741292,COVLIAS 2.0-cXAI: Cloud-Based Explainable Deep Learning System for COVID-19 Lesion Localization in Computed Tomography Scans,"Background: The previous COVID-19 lung diagnosis system lacks both scientific validation and the role of explainable artificial intelligence (AI) for understanding lesion localization. This study presents a cloud-based explainable AI, the “COVLIAS 2.0-cXAI” system using four kinds of class activation maps (CAM) models. Methodology: Our cohort consisted of ~6000 CT slices from two sources (Croatia, 80 COVID-19 patients and Italy, 15 control patients). COVLIAS 2.0-cXAI design consisted of three stages: (i) automated lung segmentation using hybrid deep learning ResNet-UNet model by automatic adjustment of Hounsfield units, hyperparameter optimization, and parallel and distributed training, (ii) classification using three kinds of DenseNet (DN) models (DN-121, DN-169, DN-201), and (iii) validation using four kinds of CAM visualization techniques: gradient-weighted class activation mapping (Grad-CAM), Grad-CAM++, score-weighted CAM (Score-CAM), and FasterScore-CAM. The COVLIAS 2.0-cXAI was validated by three trained senior radiologists for its stability and reliability. The Friedman test was also performed on the scores of the three radiologists. Results: The ResNet-UNet segmentation model resulted in dice similarity of 0.96, Jaccard index of 0.93, a correlation coefficient of 0.99, with a figure-of-merit of 95.99%, while the classifier accuracies for the three DN nets (DN-121, DN-169, and DN-201) were 98%, 98%, and 99% with a loss of ~0.003, ~0.0025, and ~0.002 using 50 epochs, respectively. The mean AUC for all three DN models was 0.99 (p < 0.0001). The COVLIAS 2.0-cXAI showed 80% scans for mean alignment index (MAI) between heatmaps and gold standard, a score of four out of five, establishing the system for clinical settings. Conclusions: The COVLIAS 2.0-cXAI successfully showed a cloud-based explainable AI system for lesion localization in lung CT scans.",True,other,Not specified
35737602,Targeted-BEHRT: Deep Learning for Observational Causal Inference on Longitudinal Electronic Health Records,"Observational causal inference is useful for decision-making in medicine when randomized clinical trials (RCTs) are infeasible or nongeneralizable. However, traditional approaches do not always deliver unconfounded causal conclusions in practice. The rise of ""doubly robust"" nonparametric tools coupled with the growth of deep learning for capturing rich representations of multimodal data offers a unique opportunity to develop and test such models for causal inference on comprehensive electronic health records (EHRs). In this article, we investigate causal modeling of an RCT-established causal association: the effect of classes of antihypertensive on incident cancer risk. We develop a transformer-based model, targeted bidirectional EHR transformer (T-BEHRT) coupled with doubly robust estimation to estimate average risk ratio (RR). We compare our model to benchmark statistical and deep learning models for causal inference in multiple experiments on semi-synthetic derivations of our dataset with various types and intensities of confounding. In order to further test the reliability of our approach, we test our model on situations of limited data. We find that our model provides more accurate estimates of relative risk [least sum absolute error (SAE) from ground truth] compared with benchmark estimations. Finally, our model provides an estimate of class-wise antihypertensive effect on cancer risk that is consistent with results derived from RCTs.",True,other,Not specified
35713866,"A Hybrid Protocol for Identifying Comorbidity-Based Potential Drugs for COVID-19 Using Biomedical Literature Mining, Network Analysis, and Deep Learning","Coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV2) has spread on an unprecedented scale around the globe. Despite of 141,975 published papers on COVID-19 and several hundreds of new studies carried out every day, this pandemic remains as a global challenge. Biomedical literature mining helps the researchers to understand the etiology of the disease and to gain an in-depth knowledge of the disease, potential drugs, vaccines developed and novel therapies. In addition to the available treatments, there is a huge need to address the comorbidity-based disease mortality in case of COVID-19 patients with type 2 diabetes mellitus (T2D), hypertension and cardiovascular disease (CVD). In this chapter, we provide a hybrid protocol based on biomedical literature mining, network analysis of omics data, and deep learning for the identification of most potential drugs for COVID-19.",True,other,Not specified
35711777,Machine Learning Advances in Microbiology: A Review of Methods and Applications,"Microorganisms play an important role in natural material and elemental cycles. Many common and general biology research techniques rely on microorganisms. Machine learning has been gradually integrated with multiple fields of study. Machine learning, including deep learning, aims to use mathematical insights to optimize variational functions to aid microbiology using various types of available data to help humans organize and apply collective knowledge of various research objects in a systematic and scaled manner. Classification and prediction have become the main achievements in the development of microbial community research in the direction of computational biology. This review summarizes the application and development of machine learning and deep learning in the field of microbiology and shows and compares the advantages and disadvantages of different algorithm tools in four fields: microbiome and taxonomy, microbial ecology, pathogen and epidemiology, and drug discovery.",True,other,Not specified
35688650,Artificial Intelligence and Machine Learning in Cancer Research: A Systematic and Thematic Analysis of the Top 100 Cited Articles Indexed in Scopus Database,"INTRODUCTION: Cancer is a major public health problem and a global leading cause of death where the screening, diagnosis, prediction, survival estimation, and treatment of cancer and control measures are still a major challenge. The rise of Artificial Intelligence (AI) and Machine Learning (ML) techniques and their applications in various fields have brought immense value in providing insights into advancement in support of cancer control.
METHODS: A systematic and thematic analysis was performed on the Scopus database to identify the top 100 cited articles in cancer research. Data were analyzed using RStudio and VOSviewer.Var1.6.6.
RESULTS: The top 100 articles in AI and ML in cancer received a 33 920 citation score with a range of 108 to 5758 times. Doi Kunio from the USA was the most cited author with total number of citations (TNC = 663). Out of 43 contributed countries, 30% of the top 100 cited articles originated from the USA, and 10% originated from China. Among the 57 peer-reviewed journals, the ""Expert Systems with Application"" published 8% of the total articles. The results were presented in highlight technological advancement through AI and ML via the widespread use of Artificial Neural Network (ANNs), Deep Learning or machine learning techniques, Mammography-based Model, Convolutional Neural Networks (SC-CNN), and text mining techniques in the prediction, diagnosis, and prevention of various types of cancers towards cancer control.
CONCLUSIONS: This bibliometric study provides detailed overview of the most cited empirical evidence in AI and ML adoption in cancer research that could efficiently help in designing future research. The innovations guarantee greater speed by using AI and ML in the detection and control of cancer to improve patient experience.",True,other,Not specified
35682349,A Novel Approach on Deep Learning-Based Decision Support System Applying Multiple Output LSTM-Autoencoder: Focusing on Identifying Variations by PHSMs' Effect over COVID-19 Pandemic,"Following the outbreak of the COVID-19 pandemic, the continued emergence of major variant viruses has caused enormous damage worldwide by generating social and economic ripple effects, and the importance of PHSMs (Public Health and Social Measures) is being highlighted to cope with this severe situation. Accordingly, there has also been an increase in research related to a decision support system based on simulation approaches used as a basis for PHSMs. However, previous studies showed limitations impeding utilization as a decision support system for policy establishment and implementation, such as the failure to reflect changes in the effectiveness of PHSMs and the restriction to short-term forecasts. Therefore, this study proposes an LSTM-Autoencoder-based decision support system for establishing and implementing PHSMs. To overcome the limitations of existing studies, the proposed decision support system used a methodology for predicting the number of daily confirmed cases over multiple periods based on multiple output strategies and a methodology for rapidly identifying varies in policy effects based on anomaly detection. It was confirmed that the proposed decision support system demonstrated excellent performance compared to models used for time series analysis such as statistical models and deep learning models. In addition, we endeavored to increase the usability of the proposed decision support system by suggesting a transfer learning-based methodology that can efficiently reflect variations in policy effects. Finally, the decision support system proposed in this study provides a methodology that provides multi-period forecasts, identifying variations in policy effects, and efficiently reflects the effects of variation policies. It was intended to provide reasonable and realistic information for the establishment and implementation of PHSMs and, through this, to yield information expected to be highly useful, which had not been provided in the decision support systems presented in previous studies.",True,text mining,Not specified
35681961,In the Seeking of Association between Air Pollutant and COVID-19 Confirmed Cases Using Deep Learning,"The COVID-19 pandemic raises awareness of how the fatal spreading of infectious disease impacts economic, political, and cultural sectors, which causes social implications. Across the world, strategies aimed at quickly recognizing risk factors have also helped shape public health guidelines and direct resources; however, they are challenging to analyze and predict since those events still happen. This paper intends to invesitgate the association between air pollutants and COVID-19 confirmed cases using Deep Learning. We used Delhi, India, for daily confirmed cases and air pollutant data for the dataset. We used LSTM deep learning for training the combination of COVID-19 Confirmed Case and AQI parameters over the four different lag times of 1, 3, 7, and 14 days. The finding indicates that CO is the most excellent model compared with the others, having on average, 13 RMSE values. This was followed by pressure at 15, PM<sub>2.5</sub> at 20, NO<sub>2</sub> at 20, and O<sub>3</sub> at 22 error rates.",True,other,Not specified
35652114,External Validation of Deep Learning Algorithms for Radiologic Diagnosis: A Systematic Review,"PURPOSE: To assess generalizability of published deep learning (DL) algorithms for radiologic diagnosis.
MATERIALS AND METHODS: In this systematic review, the PubMed database was searched for peer-reviewed studies of DL algorithms for image-based radiologic diagnosis that included external validation, published from January 1, 2015, through April 1, 2021. Studies using nonimaging features or incorporating non-DL methods for feature extraction or classification were excluded. Two reviewers independently evaluated studies for inclusion, and any discrepancies were resolved by consensus. Internal and external performance measures and pertinent study characteristics were extracted, and relationships among these data were examined using nonparametric statistics.
RESULTS: Eighty-three studies reporting 86 algorithms were included. The vast majority (70 of 86, 81%) reported at least some decrease in external performance compared with internal performance, with nearly half (42 of 86, 49%) reporting at least a modest decrease (≥0.05 on the unit scale) and nearly a quarter (21 of 86, 24%) reporting a substantial decrease (≥0.10 on the unit scale). No study characteristics were found to be associated with the difference between internal and external performance.
CONCLUSION: Among published external validation studies of DL algorithms for image-based radiologic diagnosis, the vast majority demonstrated diminished algorithm performance on the external dataset, with some reporting a substantial performance decrease.Keywords: Meta-Analysis, Computer Applications-Detection/Diagnosis, Neural Networks, Computer Applications-General (Informatics), Epidemiology, Technology Assessment, Diagnosis, Informatics Supplemental material is available for this article. © RSNA, 2022.",True,other,Not specified
35642636,A deep-learning system predicts glaucoma incidence and progression using retinal photographs,"BackgroundDeep learning has been widely used for glaucoma diagnosis. However, there is no clinically validated algorithm for glaucoma incidence and progression prediction. This study aims to develop a clinically feasible deep-learning system for predicting and stratifying the risk of glaucoma onset and progression based on color fundus photographs (CFPs), with clinical validation of performance in external population cohorts.MethodsWe established data sets of CFPs and visual fields collected from longitudinal cohorts. The mean follow-up duration was 3 to 5 years across the data sets. Artificial intelligence (AI) models were developed to predict future glaucoma incidence and progression based on the CFPs of 17,497 eyes in 9346 patients. The area under the receiver operating characteristic (AUROC) curve, sensitivity, and specificity of the AI models were calculated with reference to the labels provided by experienced ophthalmologists. Incidence and progression of glaucoma were determined based on longitudinal CFP images or visual fields, respectively.ResultsThe AI model to predict glaucoma incidence achieved an AUROC of 0.90 (0.81-0.99) in the validation set and demonstrated good generalizability, with AUROCs of 0.89 (0.83-0.95) and 0.88 (0.79-0.97) in external test sets 1 and 2, respectively. The AI model to predict glaucoma progression achieved an AUROC of 0.91 (0.88-0.94) in the validation set, and also demonstrated outstanding predictive performance with AUROCs of 0.87 (0.81-0.92) and 0.88 (0.83-0.94) in external test sets 1 and 2, respectively.ConclusionOur study demonstrates the feasibility of deep-learning algorithms in the early detection and prediction of glaucoma progression.FUNDINGNational Natural Science Foundation of China (NSFC); the High-level Hospital Construction Project, Zhongshan Ophthalmic Center, Sun Yat-sen University; the Science and Technology Program of Guangzhou, China (2021), the Science and Technology Development Fund (FDCT) of Macau, and FDCT-NSFC.",True,other,Not specified
35632811,Convolutional Neural Networks Based on Sequential Spike Predict the High Human Adaptation of SARS-CoV-2 Omicron Variants,"The COVID-19 pandemic has frequently produced more highly transmissible SARS-CoV-2 variants, such as Omicron, which has produced sublineages. It is a challenge to tell apart high-risk Omicron sublineages and other lineages of SARS-CoV-2 variants. We aimed to build a fine-grained deep learning (DL) model to assess SARS-CoV-2 transmissibility, updating our former coarse-grained model, with the training/validating data of early-stage SARS-CoV-2 variants and based on sequential Spike samples. Sequential amino acid (AA) frequency was decomposed into serially and slidingly windowed fragments in Spike. Unsupervised machine learning approaches were performed to observe the distribution in sequential AA frequency and then a supervised Convolutional Neural Network (CNN) was built with three adaptation labels to predict the human adaptation of Omicron variants in sublineages. Results indicated clear inter-lineage separation and intra-lineage clustering for SARS-CoV-2 variants in the decomposed sequential AAs. Accurate classification by the predictor was validated for the variants with different adaptations. Higher adaptation for the BA.2 sublineage and middle-level adaptation for the BA.1/BA.1.1 sublineages were predicted for Omicron variants. Summarily, the Omicron BA.2 sublineage is more adaptive than BA.1/BA.1.1 and has spread more rapidly, particularly in Europe. The fine-grained adaptation DL model works well for the timely assessment of the transmissibility of SARS-CoV-2 variants, facilitating the control of emerging SARS-CoV-2 variants.",True,other,recurrent neural network
35632066,COVID-19 Spatio-Temporal Evolution Using Deep Learning at a European Level,"COVID-19 evolution imposes significant challenges for the European healthcare system. The heterogeneous spread of the pandemic within EU regions elicited a wide range of policies, such as school closure, transport restrictions, etc. However, the implementation of these interventions is not accompanied by the implementation of quantitative methods, which would indicate their effectiveness. As a result, the efficacy of such policies on reducing the spread of the virus varies significantly. This paper investigates the effectiveness of using deep learning paradigms to accurately model the spread of COVID-19. The deep learning approaches proposed in this paper are able to effectively map the temporal evolution of a COVID-19 outbreak, while simultaneously taking into account policy interventions directly into the modelling process. Thus, our approach facilitates data-driven decision making by utilizing previous knowledge to train models that predict not only the spread of COVID-19, but also the effect of specific policy measures on minimizing this spread. Global models at the EU level are proposed, which can be successfully applied at the national level. These models use various inputs in order to successfully model the spatio-temporal variability of the phenomenon and obtain generalization abilities. The proposed models are compared against the traditional epidemiological and Autoregressive Integrated Moving Average (ARIMA) models.",True,other,Not specified
35629190,A Novel Patient Similarity Network (PSN) Framework Based on Multi-Model Deep Learning for Precision Medicine,"Precision medicine can be defined as the comparison of a new patient with existing patients that have similar characteristics and can be referred to as patient similarity. Several deep learning models have been used to build and apply patient similarity networks (PSNs). However, the challenges related to data heterogeneity and dimensionality make it difficult to use a single model to reduce data dimensionality and capture the features of diverse data types. In this paper, we propose a multi-model PSN that considers heterogeneous static and dynamic data. The combination of deep learning models and PSN allows ample clinical evidence and information extraction against which similar patients can be compared. We use the bidirectional encoder representations from transformers (BERT) to analyze the contextual data and generate word embedding, where semantic features are captured using a convolutional neural network (CNN). Dynamic data are analyzed using a long-short-term-memory (LSTM)-based autoencoder, which reduces data dimensionality and preserves the temporal features of the data. We propose a data fusion approach combining temporal and clinical narrative data to estimate patient similarity. The experiments we conducted proved that our model provides a higher classification accuracy in determining various patient health outcomes when compared with other traditional classification algorithms.",True,other,RNN
35627495,A Deep Learning Approach to Estimate the Incidence of Infectious Disease Cases for Routinely Collected Ambulatory Records: The Example of Varicella-Zoster,"The burden of infectious diseases is crucial for both epidemiological surveillance and prompt public health response. A variety of data, including textual sources, can be fruitfully exploited. Dealing with unstructured data necessitates the use of methods for automatic data-driven variable construction and machine learning techniques (MLT) show promising results. In this framework, varicella-zoster virus (VZV) infection was chosen to perform an automatic case identification with MLT. Pedianet, an Italian pediatric primary care database, was used to train a series of models to identify whether a child was diagnosed with VZV infection between 2004 and 2014 in the Veneto region, starting from free text fields. Given the nature of the task, a recurrent neural network (RNN) with bidirectional gated recurrent units (GRUs) was chosen; the same models were then used to predict the children's status for the following years. A gold standard produced by manual extraction for the same interval was available for comparison. RNN-GRU improved its performance over time, reaching the maximum value of area under the ROC curve (AUC-ROC) of 95.30% at the end of the period. The absolute bias in estimates of VZV infection was below 1.5% in the last five years analyzed. The findings in this study could assist the large-scale use of EHRs for clinical outcome predictive modeling and help establish high-performance systems in other medical domains.",True,other,LSTM
35626403,Development of a Deep Learning Model for Malignant Small Bowel Tumors Survival: A SEER-Based Study,"Background This study aims to explore a deep learning (DL) algorithm for developing a prognostic model and perform survival analyses in SBT patients. Methods The demographic and clinical features of patients with SBTs were extracted from the Surveillance, Epidemiology and End Results (SEER) database. We randomly split the samples into the training set and the validation set at 7:3. Cox proportional hazards (Cox-PH) analysis and the DeepSurv algorithm were used to develop models. The performance of the Cox-PH and DeepSurv models was evaluated using receiver operating characteristic curves, calibration curves, C-statistics and decision-curve analysis (DCA). A Kaplan−Meier (K−M) survival analysis was performed for further explanation on prognostic effect of the Cox-PH model. Results The multivariate analysis demonstrated that seven variables were associated with cancer-specific survival (CSS) (all p < 0.05). The DeepSurv model showed better performance than the Cox-PH model (C-index: 0.871 vs. 0.866). The calibration curves and DCA revealed that the two models had good discrimination and calibration. Moreover, patients with ileac malignancy and N2 stage disease were not responding to surgery according to the K−M analysis. Conclusions This study reported a DeepSurv model that performed well in CSS in SBT patients. It might offer insights into future research to explore more DL algorithms in cohort studies.",True,other,Not specified
35612154,Influenza Screening Using Patient-Generated Health Data in Post COVID-19 Pandemic,"It is very important to ensure reliable performance of deep learning model for future dataset for healthcare. This is more pronounced in the case of patient generated health data such as patient reported symptoms, which are not collected in a controlled environment. Since there has been a big difference in influenza incidence since the COVID-19 pandemic, we evaluated whether the deep learning model can maintain sufficiently robust performance against these changes. We have collected 226,655 episodes from 110,893 users since June 2020 and tested the influenza screening model, our model showed 87.02% sensitivity and 0.8670 of AUROC. The results of COVID-19 pandemic are comparable to that of before COVID-19 pandemic.",True,other,recurrent neural network
35610333,"Clinical measures, radiomics, and genomics offer synergistic value in AI-based prediction of overall survival in patients with glioblastoma","Multi-omic data, i.e., clinical measures, radiomic, and genetic data, capture multi-faceted tumor characteristics, contributing to a comprehensive patient risk assessment. Here, we investigate the additive value and independent reproducibility of integrated diagnostics in prediction of overall survival (OS) in isocitrate dehydrogenase (IDH)-wildtype GBM patients, by combining conventional and deep learning methods. Conventional radiomics and deep learning features were extracted from pre-operative multi-parametric MRI of 516 GBM patients. Support vector machine (SVM) classifiers were trained on the radiomic features in the discovery cohort (n = 404) to categorize patient groups of high-risk (OS < 6 months) vs all, and low-risk (OS ≥ 18 months) vs all. The trained radiomic model was independently tested in the replication cohort (n = 112) and a patient-wise survival prediction index was produced. Multivariate Cox-PH models were generated for the replication cohort, first based on clinical measures solely, and then by layering on radiomics and molecular information. Evaluation of the high-risk and low-risk classifiers in the discovery/replication cohorts revealed area under the ROC curves (AUCs) of 0.78 (95% CI 0.70-0.85)/0.75 (95% CI 0.64-0.79) and 0.75 (95% CI 0.65-0.84)/0.63 (95% CI 0.52-0.71), respectively. Cox-PH modeling showed a concordance index of 0.65 (95% CI 0.6-0.7) for clinical data improving to 0.75 (95% CI 0.72-0.79) for the combination of all omics. This study signifies the value of integrated diagnostics for improved prediction of OS in GBM.",True,other,Not specified
35600815,The Food Recognition Benchmark: Using Deep Learning to Recognize Food in Images,"The automatic recognition of food on images has numerous interesting applications, including nutritional tracking in medical cohorts. The problem has received significant research attention, but an ongoing public benchmark on non-biased (i.e., not scraped from web) data to develop open and reproducible algorithms has been missing. Here, we report on the setup of such a benchmark using publicly available food images sourced through the mobile MyFoodRepo app used in research cohorts. Through four rounds, the benchmark released the MyFoodRepo-273 dataset constituting 24,119 images and a total of 39,325 segmented polygons categorized in 273 different classes. Models were evaluated on private tests sets from the same platform with 5,000 images and 7,865 annotations in the final round. Top-performing models on the 273 food categories reached a mean average precision of 0.568 (round 4) and a mean average recall of 0.885 (round 3), and were deployed in production use of the MyFoodRepo app. We present experimental validation of round 4 results, and discuss implications of the benchmark setup designed to increase the size and diversity of the dataset for future rounds.",True,both,Not specified
35591208,Deep Spatiotemporal Model for COVID-19 Forecasting,"COVID-19 has caused millions of infections and deaths over the last 2 years. Machine learning models have been proposed as an alternative to conventional epidemiologic models in an effort to optimize short- and medium-term forecasts that will help health authorities to optimize the use of policies and resources to tackle the spread of the SARS-CoV-2 virus. Although previous machine learning models based on time pattern analysis for COVID-19 sensed data have shown promising results, the spread of the virus has both spatial and temporal components. This manuscript proposes a new deep learning model that combines a time pattern extraction based on the use of a Long-Short Term Memory (LSTM) Recurrent Neural Network (RNN) over a preceding spatial analysis based on a Convolutional Neural Network (CNN) applied to a sequence of COVID-19 incidence images. The model has been validated with data from the 286 health primary care centers in the Comunidad de Madrid (Madrid region, Spain). The results show improved scores in terms of both root mean square error (RMSE) and explained variance (EV) when compared with previous models that have mainly focused on the temporal patterns and dependencies.",True,other,recurrent neural network
35589255,Artificial intelligence for the prevention and clinical management of hepatocellular carcinoma,"Hepatocellular carcinoma (HCC) currently represents the fifth most common malignancy and the third-leading cause of cancer-related death worldwide, with incidence and mortality rates that are increasing. Recently, artificial intelligence (AI) has emerged as a unique opportunity to improve the full spectrum of HCC clinical care, by improving HCC risk prediction, diagnosis, and prognostication. AI approaches include computational search algorithms, machine learning (ML) and deep learning (DL) models. ML consists of a computer running repeated iterations of models, in order to progressively improve performance of a specific task, such as classifying an outcome. DL models are a subtype of ML, based on neural network structures that are inspired by the neuroanatomy of the human brain. A growing body of recent data now apply DL models to diverse data sources - including electronic health record data, imaging modalities, histopathology and molecular biomarkers - to improve the accuracy of HCC risk prediction, detection and prediction of treatment response. Despite the promise of these early results, future research is still needed to standardise AI data, and to improve both the generalisability and interpretability of results. If such challenges can be overcome, AI has the potential to profoundly change the way in which care is provided to patients with or at risk of HCC.",True,other,Not specified
35588568,Benchmarking weakly-supervised deep learning pipelines for whole slide classification in computational pathology,"Artificial intelligence (AI) can extract visual information from histopathological slides and yield biological insight and clinical biomarkers. Whole slide images are cut into thousands of tiles and classification problems are often weakly-supervised: the ground truth is only known for the slide, not for every single tile. In classical weakly-supervised analysis pipelines, all tiles inherit the slide label while in multiple-instance learning (MIL), only bags of tiles inherit the label. However, it is still unclear how these widely used but markedly different approaches perform relative to each other. We implemented and systematically compared six methods in six clinically relevant end-to-end prediction tasks using data from N=2980 patients for training with rigorous external validation. We tested three classical weakly-supervised approaches with convolutional neural networks and vision transformers (ViT) and three MIL-based approaches with and without an additional attention module. Our results empirically demonstrate that histological tumor subtyping of renal cell carcinoma is an easy task in which all approaches achieve an area under the receiver operating curve (AUROC) of above 0.9. In contrast, we report significant performance differences for clinically relevant tasks of mutation prediction in colorectal, gastric, and bladder cancer. In these mutation prediction tasks, classical weakly-supervised workflows outperformed MIL-based weakly-supervised methods for mutation prediction, which is surprising given their simplicity. This shows that new end-to-end image analysis pipelines in computational pathology should be compared to classical weakly-supervised methods. Also, these findings motivate the development of new methods which combine the elegant assumptions of MIL with the empirically observed higher performance of classical weakly-supervised approaches. We make all source codes publicly available at https://github.com/KatherLab/HIA, allowing easy application of all methods to any similar task.",True,other,recurrent neural network
35579812,Artificial Intelligence Based on Machine Learning in Pharmacovigilance: A Scoping Review,"INTRODUCTION: Artificial intelligence based on machine learning has made large advancements in many fields of science and medicine but its impact on pharmacovigilance is yet unclear.
OBJECTIVE: The present study conducted a scoping review of the use of artificial intelligence based on machine learning to understand how it is used for pharmacovigilance tasks, characterize differences with other fields, and identify opportunities to improve pharmacovigilance through the use of machine learning.
DESIGN: The PubMed, Embase, Web of Science, and IEEE Xplore databases were searched to identify articles pertaining to the use of machine learning in pharmacovigilance published from the year 2000 to September 2021. After manual screening of 7744 abstracts, a total of 393 papers met the inclusion criteria for further analysis. Extraction of key data on study design, data sources, sample size, and machine learning methodology was performed. Studies with the characteristics of good machine learning practice were defined and manual review focused on identifying studies that fulfilled these criteria and results that showed promise.
RESULTS: The majority of studies (53%) were focused on detecting safety signals using traditional statistical methods. Of the studies that used more recent machine learning methods, 61% used off-the-shelf techniques with minor modifications. Temporal analysis revealed that newer methods such as deep learning have shown increased use in recent years. We found only 42 studies (10%) that reflect current best practices and trends in machine learning. In the subset of 154 papers that focused on data intake and ingestion, 30 (19%) were found to incorporate the same best practices.
CONCLUSION: Advances from artificial intelligence have yet to fully penetrate pharmacovigilance, although recent studies show signs that this may be changing.",True,other,Not specified
35579519,Emphysema Progression at CT by Deep Learning Predicts Functional Impairment and Mortality: Results from the COPDGene Study,"Background Visual assessment remains the standard for evaluating emphysema at CT; however, it is time consuming, is subjective, requires training, and is affected by variability that may limit sensitivity to longitudinal change. Purpose To evaluate the clinical and imaging significance of increasing emphysema severity as graded by a deep learning algorithm on sequential CT scans in cigarette smokers. Materials and Methods A secondary analysis of the prospective Genetic Epidemiology of Chronic Obstructive Pulmonary Disease (COPDGene) study participants was performed and included baseline and 5-year follow-up CT scans from 2007 to 2017. Emphysema was classified automatically according to the Fleischner emphysema grading system at baseline and 5-year follow-up using a deep learning model. Baseline and change in clinical and imaging parameters at 5-year follow-up were compared in participants whose emphysema progressed versus those who did not. Kaplan-Meier analysis and multivariable Cox regression were used to assess the relationship between emphysema score progression and mortality. Results A total of 5056 participants (mean age, 60 years ± 9 [SD]; 2566 men) were evaluated. At 5-year follow-up, 1293 of the 5056 participants (26%) had emphysema progression according to the Fleischner grading system. This group demonstrated progressive airflow obstruction (forced expiratory volume in 1 second [percent predicted]: -3.4 vs -1.8), a greater decline in 6-minute walk distance (-177 m vs -124 m), and greater progression in quantitative emphysema extent (adjusted lung density: -1.4 g/L vs 0.5 g/L; percentage of lung voxels with CT attenuation less than -950 HU: 0.6 vs 0.2) than those with nonprogressive emphysema (P &lt; .001 for each). Multivariable Cox regression analysis showed a higher mortality rate in the group with emphysema progression, with an estimated hazard ratio of 1.5 (95% CI: 1.2, 1.8; P &lt; .001). Conclusion An increase in Fleischner emphysema grade on sequential CT scans using an automated deep learning algorithm was associated with increased functional impairment and increased risk of mortality. ClinicalTrials.gov registration no. NCT00608764 © RSNA, 2022 Online supplemental material is available for this article. See also the editorial by Grenier in this issue.",True,other,Not specified
35564493,"Machine Learning, Deep Learning, and Mathematical Models to Analyze Forecasting and Epidemiology of COVID-19: A Systematic Literature Review","COVID-19 is a disease caused by SARS-CoV-2 and has been declared a worldwide pandemic by the World Health Organization due to its rapid spread. Since the first case was identified in Wuhan, China, the battle against this deadly disease started and has disrupted almost every field of life. Medical staff and laboratories are leading from the front, but researchers from various fields and governmental agencies have also proposed healthy ideas to protect each other. In this article, a Systematic Literature Review (SLR) is presented to highlight the latest developments in analyzing the COVID-19 data using machine learning and deep learning algorithms. The number of studies related to Machine Learning (ML), Deep Learning (DL), and mathematical models discussed in this research has shown a significant impact on forecasting and the spread of COVID-19. The results and discussion presented in this study are based on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Out of 218 articles selected at the first stage, 57 met the criteria and were included in the review process. The findings are therefore associated with those 57 studies, which recorded that CNN (DL) and SVM (ML) are the most used algorithms for forecasting, classification, and automatic detection. The importance of the compartmental models discussed is that the models are useful for measuring the epidemiological features of COVID-19. Current findings suggest that it will take around 1.7 to 140 days for the epidemic to double in size based on the selected studies. The 12 estimates for the basic reproduction range from 0 to 7.1. The main purpose of this research is to illustrate the use of ML, DL, and mathematical models that can be helpful for the researchers to generate valuable solutions for higher authorities and the healthcare industry to reduce the impact of this epidemic.",True,other,Not specified
35554875,External validation of a deep-learning model to predict severe acute kidney injury based on urine output changes in critically ill patients,"OBJECTIVES: The purpose of this study was to externally validate algorithms (previously developed and trained in two United States populations) aimed at early detection of severe oliguric AKI (stage 2/3 KDIGO) in intensive care units patients.
METHODS: The independent cohort was composed of 10'596 patients from the university hospital ICU of Amsterdam (the ""AmsterdamUMC database"") admitted to their intensive care units. In this cohort, we analysed the accuracy of algorithms based on logistic regression and deep learning methods. The accuracy of investigated algorithms had previously been tested with electronic intensive care unit (eICU) and MIMIC-III patients.
RESULTS: The deep learning model had an area under the ROC curve (AUC) of 0,907 (± 0,007SE) with a sensitivity and specificity of 80% and 89%, respectively, for identifying oliguric AKI episodes. Logistic regression models had an AUC of 0,877 (± 0,005SE) with a sensitivity and specificity of 80% and 81%, respectively. These results were comparable to those obtained in the two US populations upon which the algorithms were previously developed and trained.
CONCLUSION: External validation on the European sample confirmed the accuracy of the algorithms, previously investigated in the US population. The models show high accuracy in both the European and the American databases even though the two cohorts differ in a range of demographic and clinical characteristics, further underlining the validity and the generalizability of the two analytical approaches.",True,other,recurrent neural network
35534142,Artificial intelligence for forecasting and diagnosing COVID-19 pandemic: A focused review,"The outbreak of novel corona virus 2019 (COVID-19) has been treated as a public health crisis of global concern by the World Health Organization (WHO). COVID-19 pandemic hugely affected countries worldwide raising the need to exploit novel, alternative and emerging technologies to respond to the emergency created by the weak health-care systems. In this context, Artificial Intelligence (AI) techniques can give a valid support to public health authorities, complementing traditional approaches with advanced tools. This study provides a comprehensive review of methods, algorithms, applications, and emerging AI technologies that can be utilized for forecasting and diagnosing COVID-19. The main objectives of this review are summarized as follows. (i) Understanding the importance of AI approaches such as machine learning and deep learning for COVID-19 pandemic; (ii) discussing the efficiency and impact of these methods for COVID-19 forecasting and diagnosing; (iii) providing an extensive background description of AI techniques to help non-expert to better catch the underlying concepts; (iv) for each work surveyed, give a detailed analysis of the rationale behind the approach, highlighting the method used, the type and size of data analyzed, the validation method, the target application and the results achieved; (v) focusing on some future challenges in COVID-19 forecasting and diagnosing.",True,other,Not specified
35524783,Deep learning-based atherosclerotic coronary plaque segmentation on coronary CT angiography,"OBJECTIVES: Volumetric evaluation of coronary artery disease (CAD) allows better prediction of cardiac events. However, CAD segmentation is labor intensive. Our objective was to create an open-source deep learning (DL) model to segment coronary plaques on coronary CT angiography (CCTA).
METHODS: Three hundred eight individuals' 894 CCTA scans with 3035 manually segmented plaques by an expert reader (considered as ground truth) were used to train (186/308, 60%), validate (tune, 61/308, 20%), and test (61/308, 20%) a 3D U-net model. We also evaluated the model on an external test set of 50 individuals with vulnerable plaques acquired at a different site. Furthermore, we applied transfer learning on 77 individuals' data and re-evaluated the model's performance using intra-class correlation coefficient (ICC).
RESULTS: On the test set, DL outperformed the currently used minimum cost approach method to quantify total: ICC: 0.88 [CI: 0.85-0.91] vs. 0.63 [CI: 0.42-0.76], noncalcified: 0.84 [CI: 0.80-0.88] vs. 0.45 [CI: 0.26-0.59], calcified: 0.99 [CI: 0.98-0.99] vs. 0.96 [CI: 0.94-0.97], and low attenuation noncalcified: 0.25 [CI: 0.13-0.37] vs. -0.01 [CI: -0.13 to 0.11] plaque volumes. On the external dataset, substantial improvement was observed in DL model performance after transfer learning, total: 0.62 [CI: 0.01-0.84] vs. 0.94 [CI: 0.87-0.97], noncalcified: 0.54 [CI: -0.04 to 0.80] vs. 0.93 [CI: 0.86-0.96], calcified: 0.91 [CI:0.85-0.95] vs. 0.95 [CI: 0.91-0.97], and low attenuation noncalcified 0.48 [CI: 0.18-0.69] vs. 0.86 [CI: 0.76-0.92].
CONCLUSIONS: Our open-source DL algorithm achieved excellent agreement with expert CAD segmentations. However, transfer learning may be required to achieve accurate segmentations in the case of different plaque characteristics or machinery.
KEY POINTS: • Deep learning 3D U-net model for coronary segmentation achieves comparable results with expert readers' volumetric plaque quantification. • Transfer learning may be needed to achieve similar results for other scanner and plaque characteristics. • The developed deep learning algorithm is open-source and may be implemented in any CT analysis software.",True,other,Not specified
35491970,A novel deep learning prognostic system improves survival predictions for stage III non-small cell lung cancer,"BACKGROUND: Accurate prognostic prediction plays a crucial role in the clinical setting. However, the TNM staging system fails to provide satisfactory individual survival prediction for stage III non-small cell lung cancer (NSCLC). The performance of the deep learning network for survival prediction in stage III NSCLC has not been explored.
OBJECTIVES: This study aimed to develop a deep learning-based prognostic system that could achieve better predictive performance than the existing staging system for stage III NSCLC.
METHODS: In this study, a deep survival learning model (DSLM) for stage III NSCLC was developed based on the Surveillance, Epidemiology, and End Results (SEER) database and was independently tested with another external cohort from our institute. DSLM was compared with the Cox proportional hazard (CPH) and random survival forest (RSF) models. A new prognostic system for stage III NSCLC was also proposed based on the established deep learning model.
RESULTS: The study included 16,613 patients with stage III NSCLC from the SEER database. DSLM showed the best performance in survival prediction, with a C-index of 0.725 in the validation set, followed by RSF (0.688) and CPH (0.683). DSLM also showed C-indices of 0.719 and 0.665 in the internal and real-world external testing datasets, respectively. In addition, the new prognostic system based on DSLM (AUROC = 0.744) showed better performance than the TNM staging system (AUROC = 0.561).
CONCLUSION: In this study, a new, integrated deep learning-based prognostic model was developed and evaluated for stage III NSCLC. This novel approach may be valuable in improving patient stratification and potentially provide meaningful prognostic information that contributes to personalized therapy.",True,other,Not specified
35489596,A multi-task Gaussian process self-attention neural network for real-time prediction of the need for mechanical ventilators in COVID-19 patients,"OBJECTIVE: The Coronavirus Disease 2019 (COVID-19) pandemic has overwhelmed the capacity of healthcare resources and posed a challenge for worldwide hospitals. The ability to distinguish potentially deteriorating patients from the rest helps facilitate reasonable allocation of medical resources, such as ventilators, hospital beds, and human resources. The real-time accurate prediction of a patient's risk scores could also help physicians to provide earlier respiratory support for the patient and reduce the risk of mortality.
METHODS: We propose a robust real-time prediction model for the in-hospital COVID-19 patients' probability of requiring mechanical ventilation (MV). The end-to-end neural network model incorporates the Multi-task Gaussian Process to handle the irregular sampling rate in observational data together with a self-attention neural network for the prediction task.
RESULTS: We evaluate our model on a large database with 9,532 nationwide in-hospital patients with COVID-19. The model demonstrates significant robustness and consistency improvements compared to conventional machine learning models. The proposed prediction model also shows performance improvements in terms of area under the receiver operating characteristic curve (AUROC) and area under the precision-recall curve (AUPRC) compared to various deep learning models, especially at early times after a patient's hospital admission.
CONCLUSION: The availability of large and real-time clinical data calls for new methods to make the best use of them for real-time patient risk prediction. It is not ideal for simplifying the data for traditional methods or for making unrealistic assumptions that deviate from observation's true dynamics. We demonstrate a pilot effort to harmonize cross-sectional and longitudinal information for mechanical ventilation needing prediction.",True,computer vision,Not specified
35453885,Deep Learning on Histopathological Images for Colorectal Cancer Diagnosis: A Systematic Review,"Colorectal cancer (CRC) is the second most common cancer in women and the third most common in men, with an increasing incidence. Pathology diagnosis complemented with prognostic and predictive biomarker information is the first step for personalized treatment. The increased diagnostic load in the pathology laboratory, combined with the reported intra- and inter-variability in the assessment of biomarkers, has prompted the quest for reliable machine-based methods to be incorporated into the routine practice. Recently, Artificial Intelligence (AI) has made significant progress in the medical field, showing potential for clinical applications. Herein, we aim to systematically review the current research on AI in CRC image analysis. In histopathology, algorithms based on Deep Learning (DL) have the potential to assist in diagnosis, predict clinically relevant molecular phenotypes and microsatellite instability, identify histological features related to prognosis and correlated to metastasis, and assess the specific components of the tumor microenvironment.",True,both,Not specified
35421855,"Towards a safe and efficient clinical implementation of machine learning in radiation oncology by exploring model interpretability, explainability and data-model dependency","The interest in machine learning (ML) has grown tremendously in recent years, partly due to the performance leap that occurred with new techniques of deep learning, convolutional neural networks for images, increased computational power, and wider availability of large datasets. Most fields of medicine follow that popular trend and, notably, radiation oncology is one of those that are at the forefront, with already a long tradition in using digital images and fully computerized workflows. ML models are driven by data, and in contrast with many statistical or physical models, they can be very large and complex, with countless generic parameters. This inevitably raises two questions, namely, the tight dependence between the models and the datasets that feed them, and the interpretability of the models, which scales with its complexity. Any problems in the data used to train the model will be later reflected in their performance. This, together with the low interpretability of ML models, makes their implementation into the clinical workflow particularly difficult. Building tools for risk assessment and quality assurance of ML models must involve then two main points: interpretability and data-model dependency. After a joint introduction of both radiation oncology and ML, this paper reviews the main risks and current solutions when applying the latter to workflows in the former. Risks associated with data and models, as well as their interaction, are detailed. Next, the core concepts of interpretability, explainability, and data-model dependency are formally defined and illustrated with examples. Afterwards, a broad discussion goes through key applications of ML in workflows of radiation oncology as well as vendors' perspectives for the clinical implementation of ML.",True,other,Not specified
35419081,Computational and Mathematical Methods in Medicine Prediction of COVID-19 in BRICS Countries: An Integrated Deep Learning Model of CEEMDAN-R-ILSTM-Elman,"Since the outbreak of COVID-19, BRICS countries have experienced different epidemic spread due to different health conditions, social isolation measures, vaccination rates, and other factors. A descriptive analysis is conducted for the spread of the epidemic in the BRICS countries. Considering the nonlinear and nonstationary characteristics of COVID-19 data, a principle of decomposition-reconstruction(R)-prediction-integration is proposed. Correspondingly, this paper constructs an integrated deep learning prediction model of CEEMDAN-R-ILSTM-Elman. Specifically, the prediction model is integrated by complete ensemble empirical mode decomposition (CEEMDAN), improved long-term and short-term memory network (ILSTM), and Elman neural network. First, the data is decomposed by adopting CEEMDAN. Then, by calculating the permutation entropy and average period, the decomposed eigenmode component IMFs are reconstructed into four sequences of high, medium, low level, and trend term. Thus, ILSTM and Elman algorithms are used for component sequence prediction, whose results are integrated as the final results. The ILSTM is established based on the LSTM model and the improved beetle antennae search algorithm (IBAS). The ILSTM mainly considers that the prediction accuracy of LSTM model is vulnerable to the influence of parameter selection. The IBAS with adaptive step size is used to automatically optimize the super parameters of LSTM model and to improve the modeling efficiency and prediction accuracy. Experimental results indicate that compared with other benchmark models, CEEMDAN-R-ILSTM-Elman integrated model predicts the number of newly confirmed cases of COVID-19 in BRICS countries with higher accuracy and lower error. Strict social policies have a greater impact on the infection rate and mortality rate of the epidemic. During July-August 2021, epidemic spread in BRICS countries will slow down, and the overall situation is still quite severe.",True,text mining,recurrent neural network
35417459,Deep learning time series prediction models in surveillance data of hepatitis incidence in China,"BACKGROUND: Precise incidence prediction of Hepatitis infectious disease is critical for early prevention and better government strategic planning. In this paper, we presented different prediction models using deep learning methods based on the monthly incidence of Hepatitis through a national public health surveillance system in China mainland.
METHODS: We assessed and compared the performance of three deep learning methods, namely, Long Short-Term Memory (LSTM) prediction model, Recurrent Neural Network (RNN) prediction model, and Back Propagation Neural Network (BPNN) prediction model. The data collected from 2005 to 2018 were used for the training and prediction model, while the data are split via 5-Fold cross-validation. The performance was evaluated based on three metrics: mean square error (MSE), mean absolute error (MAE), and mean absolute percentage error (MAPE).
RESULTS: Among the year 2005-2018, 20,924,951 cases and 11,892 deaths were supervised in the system. Hepatitis B (HB) is the most disease-causing incidence and death, and the proportion is greater than 70 percent, while the percentage of the incidence and deaths is decreased much in 2018 compared with 2005. Based on the measured errors and the visualization of the three neural networks, there is no one model predicting the incidence cases that can be completely superior to other models. When predicting the number of incidence cases for HB, the performance ranking of the three models from high to low is LSTM, BPNN, RNN, while it is LSTM, RNN, BPNN for Hepatitis C (HC). while the MAE, MSE and MAPE of the LSTM model for HB, HC are 3.84*10-06, 3.08*10-11, 4.981, 8.84*10-06, 1.98*10-12,5.8519, respectively.
CONCLUSIONS: The deep learning time series predictive models show their significance to forecast the Hepatitis incidence and have the potential to assist the decision-makers in making efficient decisions for the early detection of the disease incidents, which would significantly promote Hepatitis disease control and management.",True,other,convolutional neural network
35413983,Identification of osteoporosis using ensemble deep learning model with panoramic radiographs and clinical covariates,"Osteoporosis is becoming a global health issue due to increased life expectancy. However, it is difficult to detect in its early stages owing to a lack of discernible symptoms. Hence, screening for osteoporosis with widely used dental panoramic radiographs would be very cost-effective and useful. In this study, we investigate the use of deep learning to classify osteoporosis from dental panoramic radiographs. In addition, the effect of adding clinical covariate data to the radiographic images on the identification performance was assessed. For objective labeling, a dataset containing 778 images was collected from patients who underwent both skeletal-bone-mineral density measurement and dental panoramic radiography at a single general hospital between 2014 and 2020. Osteoporosis was assessed from the dental panoramic radiographs using convolutional neural network (CNN) models, including EfficientNet-b0, -b3, and -b7 and ResNet-18, -50, and -152. An ensemble model was also constructed with clinical covariates added to each CNN. The ensemble model exhibited improved performance on all metrics for all CNNs, especially accuracy and AUC. The results show that deep learning using CNN can accurately classify osteoporosis from dental panoramic radiographs. Furthermore, it was shown that the accuracy can be improved using an ensemble model with patient covariates.",True,both,Not specified
35404262,Neural Translation and Automated Recognition of ICD-10 Medical Entities From Natural Language: Model Development and Performance Assessment,"BACKGROUND: The recognition of medical entities from natural language is a ubiquitous problem in the medical field, with applications ranging from medical coding to the analysis of electronic health data for public health. It is, however, a complex task usually requiring human expert intervention, thus making it expansive and time-consuming. Recent advances in artificial intelligence, specifically the rise of deep learning methods, have enabled computers to make efficient decisions on a number of complex problems, with the notable example of neural sequence models and their powerful applications in natural language processing. However, they require a considerable amount of data to learn from, which is typically their main limiting factor. The Centre for Epidemiology on Medical Causes of Death (CépiDc) stores an exhaustive database of death certificates at the French national scale, amounting to several millions of natural language examples provided with their associated human-coded medical entities available to the machine learning practitioner.
OBJECTIVE: The aim of this paper was to investigate the application of deep neural sequence models to the problem of medical entity recognition from natural language.
METHODS: The investigated data set included every French death certificate from 2011 to 2016. These certificates contain information such as the subject's age, the subject's gender, and the chain of events leading to his or her death, both in French and encoded as International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10) medical entities, for a total of around 3 million observations in the data set. The task of automatically recognizing ICD-10 medical entities from the French natural language-based chain of events leading to death was then formulated as a type of predictive modeling problem known as a sequence-to-sequence modeling problem. A deep neural network-based model, known as the Transformer, was then slightly adapted and fit to the data set. Its performance was then assessed on an external data set and compared to the current state-of-the-art approach. CIs for derived measurements were estimated via bootstrapping.
RESULTS: The proposed approach resulted in an F-measure value of 0.952 (95% CI 0.946-0.957), which constitutes a significant improvement over the current state-of-the-art approach and its previously reported F-measure value of 0.825 as assessed on a comparable data set. Such an improvement makes possible a whole field of new applications, from nosologist-level automated coding to temporal harmonization of death statistics.
CONCLUSIONS: This paper shows that a deep artificial neural network can directly learn from voluminous data sets in order to identify complex relationships between natural language and medical entities, without any explicit prior knowledge. Although not entirely free from mistakes, the derived model constitutes a powerful tool for automated coding of medical entities from medical language with promising potential applications.",True,text mining,convolutional neural network
35391847,A Deep Learning System for Fully Automated Retinal Vessel Measurement in High Throughput Image Analysis,"MOTIVATION: Retinal microvasculature is a unique window for predicting and monitoring major cardiovascular diseases, but high throughput tools based on deep learning for in-detail retinal vessel analysis are lacking. As such, we aim to develop and validate an artificial intelligence system (Retina-based Microvascular Health Assessment System, RMHAS) for fully automated vessel segmentation and quantification of the retinal microvasculature.
RESULTS: RMHAS achieved good segmentation accuracy across datasets with diverse eye conditions and image resolutions, having AUCs of 0.91, 0.88, 0.95, 0.93, 0.97, 0.95, 0.94 for artery segmentation and 0.92, 0.90, 0.96, 0.95, 0.97, 0.95, 0.96 for vein segmentation on the AV-WIDE, AVRDB, HRF, IOSTAR, LES-AV, RITE, and our internal datasets. Agreement and repeatability analysis supported the robustness of the algorithm. For vessel analysis in quantity, less than 2 s were needed to complete all required analysis.",True,other,recurrent neural network
35381451,Vaxi-DL: A web-based deep learning server to identify potential vaccine candidates,"The development of a new vaccine is a challenging exercise involving several steps including computational studies, experimental work, and animal studies followed by clinical studies. To accelerate the process, in silico screening is frequently used for antigen identification. Here, we present Vaxi-DL, web-based deep learning (DL) software that evaluates the potential of protein sequences to serve as vaccine target antigens. Four different DL pathogen models were trained to predict target antigens in bacteria, protozoa, fungi, and viruses that cause infectious diseases in humans. Datasets containing antigenic and non-antigenic sequences were derived from known vaccine candidates and the Protegen database. Biological and physicochemical properties were computed for the datasets using publicly available bioinformatics tools. For each of the four pathogen models, the datasets were divided into training, validation, and testing subsets and then scaled and normalised. The models were constructed using Fully Connected Layers (FCLs), hyper-tuned, and trained using the training subset. Accuracy, sensitivity, specificity, precision, recall, and AUC (Area under the Curve) were used as metrics to assess the performance of these models. The models were benchmarked using independent datasets of known target antigens against other prediction tools such as VaxiJen and Vaxign-ML. We also tested Vaxi-DL on 219 known potential vaccine candidates (PVC) from 37 different pathogens. Our tool predicted 175 PVCs correctly out of 219 sequences. We also tested Vaxi-DL on different datasets obtained from multiple resources. Our tool has demonstrated an average sensitivity of 93% and will thus be a useful tool for prioritising PVCs for preclinical studies.",True,other,Not specified
35381190,Deep Neural Networks Predict the Need for CT in Pediatric Mild Traumatic Brain Injury: A Corroboration of the PECARN Rule,"PURPOSE: Only 10% of CT scans unveil positive findings in mild traumatic brain injury, raising concerns of its overuse in this population. A number of clinical rules have been developed to address this issue, but they still suffer limitations in their specificity. Machine learning models have been applied in limited studies to mimic clinical rules; however, further improvement in terms of balanced sensitivity and specificity is still needed. In this work, the authors applied a deep artificial neural networks (DANN) model and an instance hardness threshold algorithm to reproduce the Pediatric Emergency Care Applied Research Network (PECARN) clinical rule in a pediatric population collected as a part of the PECARN study between 2004 and 2006.
METHODS: The DANN model was applied using 14,983 patients younger than 18 years with Glasgow Coma Scale scores ≥ 14 who had head CT reports. The clinical features of the PECARN rules, PECARN-A (group A, age < 2 years) and PECARN-B (group B, age ≤ 2 years), were used to directly evaluate the model. The average accuracy, sensitivity, precision, and specificity were calculated by comparing the model's prediction outcome to that reported by the PECARN investigators. The instance hardness threshold and DANN model were applied to predict the need for CT in pediatric patients using 5-fold cross-validation.
RESULTS: In the first phase, the DANN model resulted in 98.6% sensitivity and 99.7% specificity for predicting the need for CT using the predictors of the two PECARN clinical rules combined to train the model. In the second phase, the DANN model was superior to both the PECARN-A and PECARN-B rules using the predictors for each age group separately to train the model. Compared with the clinical rule, for group A, the model achieved an average sensitivity (93.7% versus 100%) and specificity (97.5% versus 53.6%); for group B, the average sensitivity of the model was 99.2% versus 98.6%, and the specificity was 98.8% versus 58.2%.
CONCLUSIONS: In this study, a DANN model achieved comparable sensitivity and outstanding specificity for replicating the PECARN clinical rule and predicting the need for CT in pediatric patients after mild traumatic brain injury compared with the original statistically derived clinical rule.",True,other,recurrent neural network
35373824,Commentary: Deep learning approaches applied to routinely collected health data: future directions,,True,other,GAN
35353118,Assessment of Artificial Intelligence in Echocardiography Diagnostics in Differentiating Takotsubo Syndrome From Myocardial Infarction,"IMPORTANCE: Machine learning algorithms enable the automatic classification of cardiovascular diseases based on raw cardiac ultrasound imaging data. However, the utility of machine learning in distinguishing between takotsubo syndrome (TTS) and acute myocardial infarction (AMI) has not been studied.
OBJECTIVES: To assess the utility of machine learning systems for automatic discrimination of TTS and AMI.
DESIGN, SETTINGS, AND PARTICIPANTS: This cohort study included clinical data and transthoracic echocardiogram results of patients with AMI from the Zurich Acute Coronary Syndrome Registry and patients with TTS obtained from 7 cardiovascular centers in the International Takotsubo Registry. Data from the validation cohort were obtained from April 2011 to February 2017. Data from the training cohort were obtained from March 2017 to May 2019. Data were analyzed from September 2019 to June 2021.
EXPOSURE: Transthoracic echocardiograms of 224 patients with TTS and 224 patients with AMI were analyzed.
MAIN OUTCOMES AND MEASURES: Area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, and specificity of the machine learning system evaluated on an independent data set and 4 practicing cardiologists for comparison. Echocardiography videos of 228 patients were used in the development and training of a deep learning model. The performance of the automated echocardiogram video analysis method was evaluated on an independent data set consisting of 220 patients. Data were matched according to age, sex, and ST-segment elevation/non-ST-segment elevation (1 patient with AMI for each patient with TTS). Predictions were compared with echocardiographic-based interpretations from 4 practicing cardiologists in terms of sensitivity, specificity, and AUC calculated from confidence scores concerning their binary diagnosis.
RESULTS: In this cohort study, apical 2-chamber and 4-chamber echocardiographic views of 110 patients with TTS (mean [SD] age, 68.4 [12.1] years; 103 [90.4%] were female) and 110 patients with AMI (mean [SD] age, 69.1 [12.2] years; 103 [90.4%] were female) from an independent data set were evaluated. This approach achieved a mean (SD) AUC of 0.79 (0.01) with an overall accuracy of 74.8 (0.7%). In comparison, cardiologists achieved a mean (SD) AUC of 0.71 (0.03) and accuracy of 64.4 (3.5%) on the same data set. In a subanalysis based on 61 patients with apical TTS and 56 patients with AMI due to occlusion of the left anterior descending coronary artery, the model achieved a mean (SD) AUC score of 0.84 (0.01) and an accuracy of 78.6 (1.6%), outperforming the 4 practicing cardiologists (mean [SD] AUC, 0.72 [0.02]) and accuracy of 66.9 (2.8%).
CONCLUSIONS AND RELEVANCE: In this cohort study, a real-time system for fully automated interpretation of echocardiogram videos was established and trained to differentiate TTS from AMI. While this system was more accurate than cardiologists in echocardiography-based disease classification, further studies are warranted for clinical application.",True,other,RNN
35351363,Deep Learning Classification of Spinal Osteoporotic Compression Fractures on Radiographs using an Adaptation of the Genant Semiquantitative Criteria,"RATIONALE AND OBJECTIVES: Osteoporosis affects 9% of individuals over 50 in the United States and 200 million women globally. Spinal osteoporotic compression fractures (OCFs), an osteoporosis biomarker, are often incidental and under-reported. Accurate automated opportunistic OCF screening can increase the diagnosis rate and ensure adequate treatment. We aimed to develop a deep learning classifier for OCFs, a critical component of our future automated opportunistic screening tool.
MATERIALS AND METHODS: The dataset from the Osteoporotic Fractures in Men Study comprised 4461 subjects and 15,524 spine radiographs. This dataset was split by subject: 76.5% training, 8.5% validation, and 15% testing. From the radiographs, 100,409 vertebral bodies were extracted, each assigned one of two labels adapted from the Genant semiquantitative system: moderate to severe fracture vs. normal/trace/mild fracture. GoogLeNet, a deep learning model, was trained to classify the vertebral bodies. The classification threshold on the predicted probability of OCF outputted by GoogLeNet was set to prioritize the positive predictive value (PPV) while balancing it with the sensitivity. Vertebral bodies with the top 0.75% predicted probabilities were classified as moderate to severe fracture.
RESULTS: Our model yielded a sensitivity of 59.8%, a PPV of 91.2%, and an F<sub>1</sub> score of 0.72. The areas under the receiver operating characteristic curve (AUC-ROC) and the precision-recall curve were 0.99 and 0.82, respectively.
CONCLUSION: Our model classified vertebral bodies with an AUC-ROC of 0.99, providing a critical component for our future automated opportunistic screening tool. This could lead to earlier detection and treatment of OCFs.",True,both,Not specified
35348385,Deep Learning Algorithms to Detect Fractures: Systematic Review Shows Promising Results but Many Limitations,,True,other,GAN
35343267,KEDOP: Keratoconus early detection of progression using tomography images,"PURPOSE: To investigate a method to identification of early progression of keratoconus using deep learning neural networks.
METHODS: Retrospective evaluation of medical records of patients with progressive keratoconus and had more than one followup visits. Images extracted from the single scheimplug analyzer for analysis were captured during the patient visits. The baseline progression of keratoconus is detected by a change in flat or steep K of ≥1.0D which is labeled as keratometric progression (KP) and progression detected by image based deep learning convolutional neural network (CNN) models, is labeled as latent progression (LP). Patient data consisted of model data (385 eyes of 351patients) to train and test the learning models and prediction data (1331 eyes of 828 patients) to determine the LP based on the learning models.
RESULTS: The LP prediction model was able to identify progression at a mean of 11.1 months earlier than KP (p < 0.001). LP prediction model was able to identify progression earlier than KP irrespective of age category, gender, the severity of keratoconus, presenting visual acuity, astigmatism, and spherical equivalent (P < 0.001). When compared to the first visit the corrected distance visual acuity was more stable in 71% of the eyes at LP prediction visit compared to 50% at KP visit (p < 0.001).
CONCLUSION: Through this study, we propose a possible solution to address the shortcomings noted in the current approaches of detecting progression relying only on KP. Avoiding bias towards feature selection from tomography images as done in the current study aids in identifying very subtle changes on the images between visits.",True,other,recurrent neural network
35332308,Long COVID and cardiovascular disease: a learning health system approach,"Cardiovascular disease is both a risk factor and potential outcome of the direct, indirect and long-term effects of COVID-19. A recent analysis in >150,000 survivors of COVID-19 demonstrates an increased 1-year risk of numerous cardiovascular diseases. Preventing and managing this new disease burden presents challenges to health systems and requires a learning health system approach.",True,computer vision,Not specified
35326674,The Role of Artificial Intelligence in Early Cancer Diagnosis,"Improving the proportion of patients diagnosed with early-stage cancer is a key priority of the World Health Organisation. In many tumour groups, screening programmes have led to improvements in survival, but patient selection and risk stratification are key challenges. In addition, there are concerns about limited diagnostic workforces, particularly in light of the COVID-19 pandemic, placing a strain on pathology and radiology services. In this review, we discuss how artificial intelligence algorithms could assist clinicians in (1) screening asymptomatic patients at risk of cancer, (2) investigating and triaging symptomatic patients, and (3) more effectively diagnosing cancer recurrence. We provide an overview of the main artificial intelligence approaches, including historical models such as logistic regression, as well as deep learning and neural networks, and highlight their early diagnosis applications. Many data types are suitable for computational analysis, including electronic healthcare records, diagnostic images, pathology slides and peripheral blood, and we provide examples of how these data can be utilised to diagnose cancer. We also discuss the potential clinical implications for artificial intelligence algorithms, including an overview of models currently used in clinical practice. Finally, we discuss the potential limitations and pitfalls, including ethical concerns, resource demands, data security and reporting standards.",True,other,Not specified
35304638,Validation of a deep learning segmentation algorithm to quantify the skeletal muscle index and sarcopenia in metastatic renal carcinoma,"OBJECTIVES: To validate a deep learning (DL) algorithm for measurement of skeletal muscular index (SMI) and prediction of overall survival in oncology populations.
METHODS: A retrospective single-center observational study included patients with metastatic renal cell carcinoma between 2007 and 2019. A set of 37 patients was used for technical validation of the algorithm, comparing manual vs DL-based evaluations. Segmentations were compared using mean Dice similarity coefficient (DSC), SMI using concordance correlation coefficient (CCC) and Bland-Altman plots. Overall survivals (OS) were compared using log-rank (Kaplan-Meier) and Mann-Whitney tests. Generalizability of the prognostic value was tested in an independent validation population (N = 87).
RESULTS: Differences between two manual segmentations (DSC = 0.91, CCC = 0.98 for areas) or manual vs. automated segmentation (DSC = 0.90, CCC = 0.98 for areas, CCC = 0.97 for SMI) had the same order of magnitude. Bland-Altman plots showed a mean difference of -3.33 cm2 [95%CI: -15.98, 9.1] between two manual segmentations, and -3.28 cm2 [95% CI: -14.77, 8.21] for manual vs. automated segmentations. With each method, 20/37 (56%) patients were classified as sarcopenic. Sarcopenic vs. non-sarcopenic groups had statistically different survival curves with median OS of 6.0 vs. 12.5 (p = 0.008) and 6.0 vs. 13.9 (p = 0.014) months respectively for manual and DL methods. In the independent validation population, sarcopenic patients according to DL had a lower OS (10.7 vs. 17.3 months, p = 0.033).
CONCLUSION: A DL algorithm allowed accurate estimation of SMI compared to manual reference standard. The DL-calculated SMI demonstrated a prognostic value in terms of OS.
KEY POINTS: • A deep learning algorithm allows accurate estimation of skeletal muscle index compared to a manual reference standard with a concordance correlation coefficient of 0.97. • Sarcopenic patients according to SMI thresholds after segmentation by the deep learning algorithm had statistically significantly lower overall survival compared to non-sarcopenic patients.",True,other,Not specified
35304305,Federated Learning for Multicenter Collaboration in Ophthalmology: Implications for Clinical Diagnosis and Disease Epidemiology,"OBJECTIVE: To utilize a deep learning (DL) model trained via federated learning (FL), a method of collaborative training without sharing patient data, to delineate institutional differences in clinician diagnostic paradigms and disease epidemiology in retinopathy of prematurity (ROP).
DESIGN: Evaluation of a diagnostic test or technology.
SUBJECTS AND CONTROLS: We included 5245 patients with wide-angle retinal imaging from the neonatal intensive care units of 7 institutions as part of the Imaging and Informatics in ROP study. Images were labeled with the clinical diagnoses of plus disease (plus, preplus, no plus), which were documented in the chart, and a reference standard diagnosis was determined by 3 image-based ROP graders and the clinical diagnosis.
METHODS: Demographics (birth weight, gestational age) and clinical diagnoses for all eye examinations were recorded from each institution. Using an FL approach, a DL model for plus disease classification was trained using only the clinical labels. The 3 class probabilities were then converted into a vascular severity score (VSS) for each eye examination, as well as an ""institutional VSS,"" in which the average of the VSS values assigned to patients' higher severity (""worse"") eyes at each examination was calculated for each institution.
MAIN OUTCOME MEASURES: We compared demographics, clinical diagnoses of plus disease, and institutional VSSs between institutions using the McNemar-Bowker test, 2-proportion Z test, and 1-way analysis of variance with post hoc analysis by the Tukey-Kramer test. Single regression analysis was performed to explore the relationship between demographics and VSSs.
RESULTS: We found that the proportion of patients diagnosed with preplus disease varied significantly between institutions (P &lt; 0.001). Using the DL-derived VSS trained on the data from all institutions using FL, we observed differences in the institutional VSS and the level of vascular severity diagnosed as no plus (P &lt; 0.001) across institutions. A significant, inverse relationship between the institutional VSS and mean gestational age was found (P = 0.049, adjusted R2 = 0.49).
CONCLUSIONS: A DL-derived ROP VSS developed without sharing data between institutions using FL identified differences in the clinical diagnoses of plus disease and overall levels of ROP severity between institutions. Federated learning may represent a method to standardize clinical diagnoses and provide objective measurements of disease for image-based diseases.",True,other,RNN
35296530,Use of machine learning in osteoarthritis research: a systematic literature review,"OBJECTIVE: The aim of this systematic literature review was to provide a comprehensive and exhaustive overview of the use of machine learning (ML) in the clinical care of osteoarthritis (OA).
METHODS: A systematic literature review was performed in July 2021 using MEDLINE PubMed with key words and MeSH terms. For each selected article, the number of patients, ML algorithms used, type of data analysed, validation methods and data availability were collected.
RESULTS: From 1148 screened articles, 46 were selected and analysed; most were published after 2017. Twelve articles were related to diagnosis, 7 to prediction, 4 to phenotyping, 12 to severity and 11 to progression. The number of patients included ranged from 18 to 5749. Overall, 35% of the articles described the use of deep learning And 74% imaging analyses. A total of 85% of the articles involved knee OA and 15% hip OA. No study investigated hand OA. Most of the studies involved the same cohort, with data from the OA initiative described in 46% of the articles and the MOST and Cohort Hip and Cohort Knee cohorts in 11% and 7%. Data and source codes were described as publicly available respectively in 54% and 22% of the articles. External validation was provided in only 7% of the articles.
CONCLUSION: This review proposes an up-to-date overview of ML approaches used in clinical OA research and will help to enhance its application in this field.",True,both,Not specified
35296449,Federated Learning for Multicenter Collaboration in Ophthalmology: Improving Classification Performance in Retinopathy of Prematurity,"OBJECTIVE: To compare the performance of deep learning classifiers for the diagnosis of plus disease in retinopathy of prematurity (ROP) trained using 2 methods for developing models on multi-institutional data sets: centralizing data versus federated learning (FL) in which no data leave each institution.
DESIGN: Evaluation of a diagnostic test or technology.
SUBJECTS: Deep learning models were trained, validated, and tested on 5255 wide-angle retinal images in the neonatal intensive care units of 7 institutions as part of the Imaging and Informatics in ROP study. All images were labeled for the presence of plus, preplus, or no plus disease with a clinical label and a reference standard diagnosis (RSD) determined by 3 image-based ROP graders and the clinical diagnosis.
METHODS: We compared the area under the receiver operating characteristic curve (AUROC) for models developed on multi-institutional data, using a central approach initially, followed by FL, and compared locally trained models with both approaches. We compared the model performance (κ) with the label agreement (between clinical and RSD), data set size, and number of plus disease cases in each training cohort using the Spearman correlation coefficient (CC).
MAIN OUTCOME MEASURES: Model performance using AUROC and linearly weighted κ.
RESULTS: Four settings of experiment were used: FL trained on RSD against central trained on RSD, FL trained on clinical labels against central trained on clinical labels, FL trained on RSD against central trained on clinical labels, and FL trained on clinical labels against central trained on RSD (P = 0.046, P = 0.126, P = 0.224, and P = 0.0173, respectively). Four of the 7 (57%) models trained on local institutional data performed inferiorly to the FL models. The model performance for local models was positively correlated with the label agreement (between clinical and RSD labels, CC = 0.389, P = 0.387), total number of plus cases (CC = 0.759, P = 0.047), and overall training set size (CC = 0.924, P = 0.002).
CONCLUSIONS: We found that a trained FL model performs comparably to a centralized model, confirming that FL may provide an effective, more feasible solution for interinstitutional learning. Smaller institutions benefit more from collaboration than larger institutions, showing the potential of FL for addressing disparities in resource access.",True,other,RNN
35272972,Real-time diabetic retinopathy screening by deep learning in a multisite national screening programme: a prospective interventional cohort study,"BACKGROUND: Diabetic retinopathy is a leading cause of preventable blindness, especially in low-income and middle-income countries (LMICs). Deep-learning systems have the potential to enhance diabetic retinopathy screenings in these settings, yet prospective studies assessing their usability and performance are scarce.
METHODS: We did a prospective interventional cohort study to evaluate the real-world performance and feasibility of deploying a deep-learning system into the health-care system of Thailand. Patients with diabetes and listed on the national diabetes registry, aged 18 years or older, able to have their fundus photograph taken for at least one eye, and due for screening as per the Thai Ministry of Public Health guidelines were eligible for inclusion. Eligible patients were screened with the deep-learning system at nine primary care sites under Thailand's national diabetic retinopathy screening programme. Patients with a previous diagnosis of diabetic macular oedema, severe non-proliferative diabetic retinopathy, or proliferative diabetic retinopathy; previous laser treatment of the retina or retinal surgery; other non-diabetic retinopathy eye disease requiring referral to an ophthalmologist; or inability to have fundus photograph taken of both eyes for any reason were excluded. Deep-learning system-based interpretations of patient fundus images and referral recommendations were provided in real time. As a safety mechanism, regional retina specialists over-read each image. Performance of the deep-learning system (accuracy, sensitivity, specificity, positive predictive value [PPV], and negative predictive value [NPV]) were measured against an adjudicated reference standard, provided by fellowship-trained retina specialists. This study is registered with the Thai national clinical trials registry, TCRT20190902002.
FINDINGS: Between Dec 12, 2018, and March 29, 2020, 7940 patients were screened for inclusion. 7651 (96·3%) patients were eligible for study analysis, and 2412 (31·5%) patients were referred for diabetic retinopathy, diabetic macular oedema, ungradable images, or low visual acuity. For vision-threatening diabetic retinopathy, the deep-learning system had an accuracy of 94·7% (95% CI 93·0-96·2), sensitivity of 91·4% (87·1-95·0), and specificity of 95·4% (94·1-96·7). The retina specialist over-readers had an accuracy of 93·5 (91·7-95·0; p=0·17), a sensitivity of 84·8% (79·4-90·0; p=0·024), and specificity of 95·5% (94·1-96·7; p=0·98). The PPV for the deep-learning system was 79·2 (95% CI 73·8-84·3) compared with 75·6 (69·8-81·1) for the over-readers. The NPV for the deep-learning system was 95·5 (92·8-97·9) compared with 92·4 (89·3-95·5) for the over-readers.
INTERPRETATION: A deep-learning system can deliver real-time diabetic retinopathy detection capability similar to retina specialists in community-based screening settings. Socioenvironmental factors and workflows must be taken into consideration when implementing a deep-learning system within a large-scale screening programme in LMICs.
FUNDING: Google and Rajavithi Hospital, Bangkok, Thailand.
TRANSLATION: For the Thai translation of the abstract see Supplementary Materials section.",True,other,Not specified
35269624,Augmentation of Transcriptomic Data for Improved Classification of Patients with Respiratory Diseases of Viral Origin,"To better understand the molecular basis of respiratory diseases of viral origin, high-throughput gene-expression data are frequently taken by means of DNA microarray or RNA-seq technology. Such data can also be useful to classify infected individuals by molecular signatures in the form of machine-learning models with genes as predictor variables. Early diagnosis of patients by molecular signatures could also contribute to better treatments. An approach that has rarely been considered for machine-learning models in the context of transcriptomics is data augmentation. For other data types it has been shown that augmentation can improve classification accuracy and prevent overfitting. Here, we compare three strategies for data augmentation of DNA microarray and RNA-seq data from two selected studies on respiratory diseases of viral origin. The first study involves samples of patients with either viral or bacterial origin of the respiratory disease, the second study involves patients with either SARS-CoV-2 or another respiratory virus as disease origin. Specifically, we reanalyze these public datasets to study whether patient classification by transcriptomic signatures can be improved when adding artificial data for training of the machine-learning models. Our comparison reveals that augmentation of transcriptomic data can improve the classification accuracy and that fewer genes are necessary as explanatory variables in the final models. We also report genes from our signatures that overlap with signatures presented in the original publications of our example data. Due to strict selection criteria, the molecular role of these genes in the context of respiratory infectious diseases is underlined.",True,other,recurrent neural network
35264189,"Application of machine learning in understanding plant virus pathogenesis: trends and perspectives on emergence, diagnosis, host-virus interplay and management","BACKGROUND: Inclusion of high throughput technologies in the field of biology has generated massive amounts of data in the recent years. Now, transforming these huge volumes of data into knowledge is the primary challenge in computational biology. The traditional methods of data analysis have failed to carry out the task. Hence, researchers are turning to machine learning based approaches for the analysis of high-dimensional big data. In machine learning, once a model is trained with a training dataset, it can be applied on a testing dataset which is independent. In current times, deep learning algorithms further promote the application of machine learning in several field of biology including plant virology.
MAIN BODY: Plant viruses have emerged as one of the principal global threats to food security due to their devastating impact on crops and vegetables. The emergence of new viral strains and species help viruses to evade the concurrent preventive methods. According to a survey conducted in 2014, plant viruses are anticipated to cause a global yield loss of more than thirty billion USD per year. In order to design effective, durable and broad-spectrum management protocols, it is very important to understand the mechanistic details of viral pathogenesis. The application of machine learning enables precise diagnosis of plant viral diseases at an early stage. Furthermore, the development of several machine learning-guided bioinformatics platforms has primed plant virologists to understand the host-virus interplay better. In addition, machine learning has tremendous potential in deciphering the pattern of plant virus evolution and emergence as well as in developing viable control options.
CONCLUSIONS: Considering a significant progress in the application of machine learning in understanding plant virology, this review highlights an introductory note on machine learning and comprehensively discusses the trends and prospects of machine learning in the diagnosis of viral diseases, understanding host-virus interplay and emergence of plant viruses.",True,other,recurrent neural network
35247764,Forecasting COVID-19 new cases using deep learning methods,"After nearly two years since the first identification of SARS-CoV-2 virus, the surge in cases because of virus mutations is a cause of grave public health concern across the globe. As a result of this health crisis, predicting the transmission pattern of the virus is one of the most vital tasks for preparing and controlling the pandemic. In addition to mathematical models, machine learning tools, especially deep learning models have been developed for forecasting the trend of the number of patients affected by SARS-CoV-2 with great success. In this paper, three deep learning models, including CNN, LSTM, and the CNN-LSTM have been developed to predict the number of COVID-19 cases for Brazil, India and Russia. We also compare the performance of our models with the previously developed deep learning models and notice significant improvements in prediction performance. Although our models have been used only for forecasting cases in these three countries, the models can be easily applied to datasets of other countries. Among the models developed in this work, the LSTM model has the highest performance when forecasting and shows an improvement in the forecasting accuracy compared with some existing models. The research will enable accurate forecasting of the COVID-19 cases and support the global fight against the pandemic.",True,other,convolutional neural network
35247613,Deep Learning to Predict Traumatic Brain Injury Outcomes in the Low-Resource Setting,"OBJECTIVE: Traumatic brain injury (TBI) disproportionately affects low- and middle-income countries (LMICs). In these settings, accurate patient prognostication is both difficult and essential for high-quality patient care. With the ultimate goal of enhancing TBI triage in LMICs, we aim to develop the first deep learning model to predict outcomes after TBI and compare its performance with that of less complex algorithms.
METHODS: TBI patients' data were prospectively collected in Kampala, Uganda, from 2016 to 2020. To predict good versus poor outcome at hospital discharge, we created deep neural network, shallow neural network, and elastic-net regularized logistic regression models. Predictors included 13 easily acquirable clinical variables. We assessed model performance with 5-fold cross-validation to calculate areas under both the receiver operating characteristic curve and precision-recall curve (AUPRC), in addition to standardized partial AUPRC to focus on comparisons at clinically relevant operating points.
RESULTS: We included 2164 patients for model training, of which 12% had poor outcomes. The deep neural network performed best as measured by the area under the receiver operating characteristic curve (0.941) and standardized partial AUPRC in region maximizing recall (0.291), whereas the shallow neural network was best by the area under the precision-recall curve (0.770). In several other comparisons, the elastic-net regularized logistic regression was noninferior to the neural networks.
CONCLUSIONS: We present the first use of deep learning for TBI prognostication, with an emphasis on LMICs, where there is great need for decision support to allocate limited resources. Optimal algorithm selection depends on the specific clinical setting; deep learning is not a panacea, though it may have a role in these efforts.",True,other,Not specified
35233612,Deep learning based on biologically interpretable genome representation predicts two types of human adaptation of SARS-CoV-2 variants,"Explosively emerging SARS-CoV-2 variants challenge current nomenclature schemes based on genetic diversity and biological significance. Genomic composition-based machine learning methods have recently performed well in identifying phenotype-genotype relationships. We introduced a framework involving dinucleotide (DNT) composition representation (DCR) to parse the general human adaptation of RNA viruses and applied a three-dimensional convolutional neural network (3D CNN) analysis to learn the human adaptation of other existing coronaviruses (CoVs) and predict the adaptation of SARS-CoV-2 variants of concern (VOCs). A markedly separable, linear DCR distribution was observed in two major genes-receptor-binding glycoprotein and RNA-dependent RNA polymerase (RdRp)-of six families of single-stranded (ssRNA) viruses. Additionally, there was a general host-specific distribution of both the spike proteins and RdRps of CoVs. The 3D CNN based on spike DCR predicted a dominant type II adaptation of most Beta, Delta and Omicron VOCs, with high transmissibility and low pathogenicity. Type I adaptation with opposite transmissibility and pathogenicity was predicted for SARS-CoV-2 Alpha VOCs (77%) and Kappa variants of interest (58%). The identified adaptive determinants included D1118H and A570D mutations and local DNTs. Thus, the 3D CNN model based on DCR features predicts SARS-CoV-2, a major type II human adaptation and is qualified to predict variant adaptation in real time, facilitating the risk-assessment of emerging SARS-CoV-2 variants and COVID-19 control.",True,other,convolutional neural network
35216571,"Deep-learning model for predicting the survival of rectal adenocarcinoma patients based on a surveillance, epidemiology, and end results analysis","BACKGROUND: We collected information on patients with rectal adenocarcinoma in the United States from the Surveillance, Epidemiology, and EndResults (SEER) database. We used this information to establish a model that combined deep learning with a multilayer neural network (the DeepSurv model) for predicting the survival rate of patients with rectal adenocarcinoma.
METHODS: We collected patients with rectal adenocarcinoma in the United States and older than 20 yearswho had been added to the SEER database from 2004 to 2015. We divided these patients into training and test cohortsat a ratio of 7:3. The training cohort was used to develop a seven-layer neural network based on the analysis method established by Katzman and colleagues to construct a DeepSurv prediction model. We then used the C-index and calibration plots to evaluate the prediction performance of the DeepSurv model.
RESULTS: The 49,275 patients with rectal adenocarcinoma included in the study were randomly divided into the training cohort (70%, n = 34,492) and the test cohort (30%, n = 14,783). There were no statistically significant differences in clinical characteristics between the two cohorts (p > 0.05). We applied Cox proportional-hazards regression to the data in the training cohort, which showed that age, sex, marital status, tumor grade, surgery status, and chemotherapy status were significant factors influencing survival (p < 0.05). Using the training cohort to construct the DeepSurv model resulted in a C-index of the model of 0.824, while using the test cohort to verify the DeepSurv model yielded a C-index of 0.821. Thesevalues show that the prediction effect of the DeepSurv model for the test-cohort patients was highly consistent with the prediction resultsfor the training-cohort patients.
CONCLUSION: The DeepSurv prediction model of the seven-layer neural network that we have established can accurately predict the survival rateand time of rectal adenocarcinoma patients.",True,other,recurrent neural network
35213361,Optimal vocabulary selection approaches for privacy-preserving deep NLP model training for information extraction and cancer epidemiology,"BACKGROUND: With the use of artificial intelligence and machine learning techniques for biomedical informatics, security and privacy concerns over the data and subject identities have also become an important issue and essential research topic. Without intentional safeguards, machine learning models may find patterns and features to improve task performance that are associated with private personal information.
OBJECTIVE: The privacy vulnerability of deep learning models for information extraction from medical textural contents needs to be quantified since the models are exposed to private health information and personally identifiable information. The objective of the study is to quantify the privacy vulnerability of the deep learning models for natural language processing and explore a proper way of securing patients' information to mitigate confidentiality breaches.
METHODS: The target model is the multitask convolutional neural network for information extraction from cancer pathology reports, where the data for training the model are from multiple state population-based cancer registries. This study proposes the following schemes to collect vocabularies from the cancer pathology reports; (a) words appearing in multiple registries, and (b) words that have higher mutual information. We performed membership inference attacks on the models in high-performance computing environments.
RESULTS: The comparison outcomes suggest that the proposed vocabulary selection methods resulted in lower privacy vulnerability while maintaining the same level of clinical task performance.",True,other,RNN
35210447,Proposing a novel deep network for detecting COVID-19 based on chest images,"The rapid outbreak of coronavirus threatens humans' life all around the world. Due to the insufficient diagnostic infrastructures, developing an accurate, efficient, inexpensive, and quick diagnostic tool is of great importance. To date, researchers have proposed several detection models based on chest imaging analysis, primarily based on deep neural networks; however, none of which could achieve a reliable and highly sensitive performance yet. Therefore, the nature of this study is primary epidemiological research that aims to overcome the limitations mentioned above by proposing a large-scale publicly available dataset of chest computed tomography scan (CT-scan) images consisting of more than 13k samples. Secondly, we propose a more sensitive deep neural networks model for CT-scan images of the lungs, providing a pixel-wise attention layer on top of the high-level features extracted from the network. Moreover, the proposed model is extended through a transfer learning approach for being applicable in the case of chest X-Ray (CXR) images. The proposed model and its extension have been trained and evaluated through several experiments. The inclusion criteria were patients with suspected PE and positive real-time reverse-transcription polymerase chain reaction (RT-PCR) for SARS-CoV-2. The exclusion criteria were negative or inconclusive RT-PCR and other chest CT indications. Our model achieves an AUC score of 0.886, significantly better than its closest competitor, whose AUC is 0.843. Moreover, the obtained results on another commonly-used benchmark show an AUC of 0.899, outperforming related models. Additionally, the sensitivity of our model is 0.858, while that of its closest competitor is 0.81, explaining the efficiency of pixel-wise attention strategy in detecting coronavirus. Our promising results and the efficiency of the models imply that the proposed models can be considered reliable tools for assisting doctors in detecting coronavirus.",True,other,Not specified
35206201,An Efficient Deep Learning Model to Detect COVID-19 Using Chest X-ray Images,"The tragic pandemic of COVID-19, due to the Severe Acute Respiratory Syndrome coronavirus-2 or SARS-CoV-2, has shaken the entire world, and has significantly disrupted healthcare systems in many countries. Because of the existing challenges and controversies to testing for COVID-19, improved and cost-effective methods are needed to detect the disease. For this purpose, machine learning (ML) has emerged as a strong forecasting method for detecting COVID-19 from chest X-ray images. In this paper, we used a Deep Learning Method (DLM) to detect COVID-19 using chest X-ray (CXR) images. Radiographic images are readily available and can be used effectively for COVID-19 detection compared to other expensive and time-consuming pathological tests. We used a dataset of 10,040 samples, of which 2143 had COVID-19, 3674 had pneumonia (but not COVID-19), and 4223 were normal (not COVID-19 or pneumonia). Our model had a detection accuracy of 96.43% and a sensitivity of 93.68%. The area under the ROC curve was 99% for COVID-19, 97% for pneumonia (but not COVID-19 positive), and 98% for normal cases. In conclusion, ML approaches may be used for rapid analysis of CXR images and thus enable radiologists to filter potential candidates in a time-effective manner to detect COVID-19.",True,other,recurrent neural network
35199063,Breaking away from labels: The promise of self-supervised machine learning in intelligent health,"Medicine is undergoing an unprecedented digital transformation, as massive amounts of health data are being produced, gathered, and curated, ranging from in-hospital (e.g., intensive care unit [ICU]) to person-generated data (wearables). Annotating all these data for training purposes in order to feed to deep learning models for pattern recognition is impractical. Here, we discuss some exciting recent results of self-supervised learning (SSL) applications to high-resolution health signals. These examples leverage unlabeled data to learn meaningful representations that can generalize to situations where the ground truth is inadequate or simply infeasible to collect due to the high burden or associated costs. The most prominent bottleneck of deep learning today is access to labeled, carefully curated datasets, and self-supervision on health signals opens up new possibilities to eliminate data silos through general-purpose models that can transfer to low-resource environments and tasks.",True,other,convolutional neural network
35197214,A deep learning model for screening type 2 diabetes from retinal photographs,"BACKGROUND AND AIMS: We aimed to develop and evaluate a non-invasive deep learning algorithm for screening type 2 diabetes in UK Biobank participants using retinal images.
METHODS AND RESULTS: The deep learning model for prediction of type 2 diabetes was trained on retinal images from 50,077 UK Biobank participants and tested on 12,185 participants. We evaluated its performance in terms of predicting traditional risk factors (TRFs) and genetic risk for diabetes. Next, we compared the performance of three models in predicting type 2 diabetes using 1) an image-only deep learning algorithm, 2) TRFs, 3) the combination of the algorithm and TRFs. Assessing net reclassification improvement (NRI) allowed quantification of the improvement afforded by adding the algorithm to the TRF model. When predicting TRFs with the deep learning algorithm, the areas under the curve (AUCs) obtained with the validation set for age, sex, and HbA1c status were 0.931 (0.928-0.934), 0.933 (0.929-0.936), and 0.734 (0.715-0.752), respectively. When predicting type 2 diabetes, the AUC of the composite logistic model using non-invasive TRFs was 0.810 (0.790-0.830), and that for the deep learning model using only fundus images was 0.731 (0.707-0.756). Upon addition of TRFs to the deep learning algorithm, discriminative performance was improved to 0.844 (0.826-0.861). The addition of the algorithm to the TRFs model improved risk stratification with an overall NRI of 50.8%.
CONCLUSION: Our results demonstrate that this deep learning algorithm can be a useful tool for stratifying individuals at high risk of type 2 diabetes in the general population.",True,other,recurrent neural network
35182291,AI-Driven Model for Automatic Emphysema Detection in Low-Dose Computed Tomography Using Disease-Specific Augmentation,"The objective of this study is to evaluate the feasibility of a disease-specific deep learning (DL) model based on minimum intensity projection (minIP) for automated emphysema detection in low-dose computed tomography (LDCT) scans. LDCT scans of 240 individuals from a population-based cohort in the Netherlands (ImaLife study, mean age ± SD = 57 ± 6 years) were retrospectively chosen for training and internal validation of the DL model. For independent testing, LDCT scans of 125 individuals from a lung cancer screening cohort in the USA (NLST study, mean age ± SD = 64 ± 5 years) were used. Dichotomous emphysema diagnosis based on radiologists' annotation was used to develop the model. The automated model included minIP processing (slab thickness range: 1 mm to 11 mm), classification, and detection maps generation. The data-split for the pipeline evaluation involved class-balanced and imbalanced settings. The proposed DL pipeline showed the highest performance (area under receiver operating characteristics curve) for 11 mm slab thickness in both the balanced (ImaLife = 0.90 ± 0.05) and the imbalanced dataset (NLST = 0.77 ± 0.06). For ImaLife subcohort, the variation in minIP slab thickness from 1 to 11 mm increased the DL model's sensitivity from 75 to 88% and decreased the number of false-negative predictions from 10 to 5. The minIP-based DL model can automatically detect emphysema in LDCTs. The performance of thicker minIP slabs was better than that of thinner slabs. LDCT can be leveraged for emphysema detection by applying disease specific augmentation.",True,other,Not specified
35169217,Deep learning in image-based breast and cervical cancer detection: a systematic review and meta-analysis,"Accurate early detection of breast and cervical cancer is vital for treatment success. Here, we conduct a meta-analysis to assess the diagnostic performance of deep learning (DL) algorithms for early breast and cervical cancer identification. Four subgroups are also investigated: cancer type (breast or cervical), validation type (internal or external), imaging modalities (mammography, ultrasound, cytology, or colposcopy), and DL algorithms versus clinicians. Thirty-five studies are deemed eligible for systematic review, 20 of which are meta-analyzed, with a pooled sensitivity of 88% (95% CI 85-90%), specificity of 84% (79-87%), and AUC of 0.92 (0.90-0.94). Acceptable diagnostic performance with analogous DL algorithms was highlighted across all subgroups. Therefore, DL algorithms could be useful for detecting breast and cervical cancer using medical imaging, having equivalent performance to human clinicians. However, this tentative assertion is based on studies with relatively poor designs and reporting, which likely caused bias and overestimated algorithm performance. Evidence-based, standardized guidelines around study methods and reporting are required to improve the quality of DL research.",True,other,Not specified
35168624,Deep learning model for multi-classification of infectious diseases from unstructured electronic medical records,"PURPOSE: Predictively diagnosing infectious diseases helps in providing better treatment and enhances the prevention and control of such diseases. This study uses actual data from a hospital. A multiple infectious disease diagnostic model (MIDDM) is designed for conducting multi-classification of infectious diseases so as to assist in clinical infectious-disease decision-making.
METHODS: Based on actual hospital medical records of infectious diseases from December 2012 to December 2020, a deep learning model for multi-classification research on infectious diseases is constructed. The data includes 20,620 cases covering seven types of infectious diseases, including outpatients and inpatients, of which training data accounted for 80%, i.e., 16,496 cases, and test data accounted for 20%, i.e., 4124 cases. Through the auto-encoder, data normalization and sparse data densification processing are carried out to improve the model training effect. A residual network and attention mechanism are introduced into the MIDDM model to improve the performance of the model.
RESULT: MIDDM achieved improved prediction results in diagnosing seven kinds of infectious diseases. In the case of similar disease diagnosis characteristics and similar interference factors, the prediction accuracy of disease classification with more sample data is significantly higher than the prediction accuracy of disease classification with fewer sample data. For instance, the training data for viral hepatitis, influenza, and hand foot and mouth disease were 2954, 3924, and 3015 respectively and the corresponding test accuracy rates were 99.86%, 98.47%, and 97.31%. There is less training data for syphilis, infectious diarrhea, and measles, i.e., 1208, 575, and 190 respectively and the corresponding test accuracy rates were noticeably lower, i.e., 83.03%, 87.30%, and42.11%. We also compared the MIDDM model with the models used in other studies. Using the same input data, taking viral hepatitis as an example, the accuracy of MIDDM is 99.44%, which is significantly higher than that of XGBoost (96.19%), Decision tree (90.13%), Bayesian method (85.19%), and logistic regression (91.26%). Other diseases were also significantly better predicted by MIDDM than by these three models.
CONCLUSION: The application of the MIDDM model to multi-class diagnosis and prediction of infectious diseases can improve the accuracy of infectious-disease diagnosis. However, these results need to be further confirmed via clinical randomized controlled trials.",True,computer vision,RNN
35130176,An Explainable Transformer-Based Deep Learning Model for the Prediction of Incident Heart Failure,"Predicting the incidence of complex chronic conditions such as heart failure is challenging. Deep learning models applied to rich electronic health records may improve prediction but remain unexplainable hampering their wider use in medical practice. We aimed to develop a deep-learning framework for accurate and yet explainable prediction of 6-month incident heart failure (HF). Using 100,071 patients from longitudinal linked electronic health records across the U.K., we applied a novel Transformer-based risk model using all community and hospital diagnoses and medications contextualized within the age and calendar year for each patient's clinical encounter. Feature importance was investigated with an ablation analysis to compare model performance when alternatively removing features and by comparing the variability of temporal representations. A post-hoc perturbation technique was conducted to propagate the changes in the input to the outcome for feature contribution analyses. Our model achieved 0.93 area under the receiver operator curve and 0.69 area under the precision-recall curve on internal 5-fold cross validation and outperformed existing deep learning models. Ablation analysis indicated medication is important for predicting HF risk, calendar year is more important than chronological age, which was further reinforced by temporal variability analysis. Contribution analyses identified risk factors that are closely related to HF. Many of them were consistent with existing knowledge from clinical and epidemiological research but several new associations were revealed which had not been considered in expert-driven risk prediction models. In conclusion, the results highlight that our deep learning model, in addition high predictive performance, can inform data-driven risk factor identification.",True,other,Not specified
35127232,Comparison of Machine-Learning Algorithms for the Prediction of Current Procedural Terminology (CPT) Codes from Pathology Reports,"BACKGROUND: Pathology reports serve as an auditable trial of a patient's clinical narrative, containing text pertaining to diagnosis, prognosis, and specimen processing. Recent works have utilized natural language processing (NLP) pipelines, which include rule-based or machine-learning analytics, to uncover textual patterns that inform clinical endpoints and biomarker information. Although deep learning methods have come to the forefront of NLP, there have been limited comparisons with the performance of other machine-learning methods in extracting key insights for the prediction of medical procedure information, which is used to inform reimbursement for pathology departments. In addition, the utility of combining and ranking information from multiple report subfields as compared with exclusively using the diagnostic field for the prediction of Current Procedural Terminology (CPT) codes and signing pathologists remains unclear.
METHODS: After preprocessing pathology reports, we utilized advanced topic modeling to identify topics that characterize a cohort of 93,039 pathology reports at the Dartmouth-Hitchcock Department of Pathology and Laboratory Medicine (DPLM). We separately compared XGBoost, SVM, and BERT (Bidirectional Encoder Representation from Transformers) methodologies for the prediction of primary CPT codes (CPT 88302, 88304, 88305, 88307, 88309) as well as 38 ancillary CPT codes, using both the diagnostic text alone and text from all subfields. We performed similar analyses for characterizing text from a group of the 20 pathologists with the most pathology report sign-outs. Finally, we uncovered important report subcomponents by using model explanation techniques.
RESULTS: We identified 20 topics that pertained to diagnostic and procedural information. Operating on diagnostic text alone, BERT outperformed XGBoost for the prediction of primary CPT codes. When utilizing all report subfields, XGBoost outperformed BERT for the prediction of primary CPT codes. Utilizing additional subfields of the pathology report increased prediction accuracy across ancillary CPT codes, and performance gains for using additional report subfields were high for the XGBoost model for primary CPT codes. Misclassifications of CPT codes were between codes of a similar complexity, and misclassifications between pathologists were subspecialty related.
CONCLUSIONS: Our approach generated CPT code predictions with an accuracy that was higher than previously reported. Although diagnostic text is an important source of information, additional insights may be extracted from other report subfields. Although BERT approaches performed comparably to the XGBoost approaches, they may lend valuable information to pipelines that combine image, text, and -omics information. Future resource-saving opportunities exist to help hospitals detect mis-billing, standardize report text, and estimate productivity metrics that pertain to pathologist compensation (RVUs).",True,other,RNN
35100119,A Deep Learning Approach for the Estimation of Glomerular Filtration Rate,"An accurate estimation of glomerular filtration rate (GFR) is clinically crucial for kidney disease diagnosis and predicting the prognosis of chronic kidney disease (CKD). Machine learning methodologies such as deep neural networks provide a potential avenue for increasing accuracy in GFR estimation. We developed a novel deep learning architecture, a deep and shallow neural network, to estimate GFR (dlGFR for short) and examined its comparative performance with estimated GFR from Modification of Diet in Renal Disease (MDRD) and Chronic Kidney Disease Epidemiology Collaboration (CKD-EPI) equations. The dlGFR model jointly trains a shallow learning model and a deep neural network to enable both linear transformation from input features to a log GFR target, and non-linear feature embedding for stage of kidney function classification. We validate the proposed methods on the data from multiple studies obtained from the NIDDK Central Database Repository. The deep learning model predicted values of GFR within 30% of measured GFR with 88.3% accuracy, compared to the 87.1% and 84.7% of the accuracy achieved by CKD-EPI and MDRD equations (p = 0.051 and p &lt; 0.001, respectively). Our results suggest that deep learning methods are superior to equations resulting from traditional statistical methods in estimating glomerular filtration rate. Based on these results, an end-to-end predication system has been deployed to facilitate use of the proposed dlGFR algorithm.",True,other,convolutional neural network
35089976,Deep learning via LSTM models for COVID-19 infection forecasting in India,"The COVID-19 pandemic continues to have major impact to health and medical infrastructure, economy, and agriculture. Prominent computational and mathematical models have been unreliable due to the complexity of the spread of infections. Moreover, lack of data collection and reporting makes modelling attempts difficult and unreliable. Hence, we need to re-look at the situation with reliable data sources and innovative forecasting models. Deep learning models such as recurrent neural networks are well suited for modelling spatiotemporal sequences. In this paper, we apply recurrent neural networks such as long short term memory (LSTM), bidirectional LSTM, and encoder-decoder LSTM models for multi-step (short-term) COVID-19 infection forecasting. We select Indian states with COVID-19 hotpots and capture the first (2020) and second (2021) wave of infections and provide two months ahead forecast. Our model predicts that the likelihood of another wave of infections in October and November 2021 is low; however, the authorities need to be vigilant given emerging variants of the virus. The accuracy of the predictions motivate the application of the method in other countries and regions. Nevertheless, the challenges in modelling remain due to the reliability of data and difficulties in capturing factors such as population density, logistics, and social aspects such as culture and lifestyle.",True,other,recurrent neural network
35083620,Qualitative Evaluation of Common Quantitative Metrics for Clinical Acceptance of Automatic Segmentation: a Case Study on Heart Contouring from CT Images by Deep Learning Algorithms,"Organs-at-risk contouring is time consuming and labour intensive. Automation by deep learning algorithms would decrease the workload of radiotherapists and technicians considerably. However, the variety of metrics used for the evaluation of deep learning algorithms make the results of many papers difficult to interpret and compare. In this paper, a qualitative evaluation is done on five established metrics to assess whether their values correlate with clinical usability. A total of 377 CT volumes with heart delineations were randomly selected for training and evaluation. A deep learning algorithm was used to predict the contours of the heart. A total of 101 CT slices from the validation set with the predicted contours were shown to three experienced radiologists. They examined each slice independently whether they would accept or adjust the prediction and if there were (small) mistakes. For each slice, the scores of this qualitative evaluation were then compared with the Sørensen-Dice coefficient (DC), the Hausdorff distance (HD), pixel-wise accuracy, sensitivity and precision. The statistical analysis of the qualitative evaluation and metrics showed a significant correlation. Of the slices with a DC over 0.96 (N = 20) or a 95% HD under 5 voxels (N = 25), no slices were rejected by the readers. Contours with lower DC or higher HD were seen in both rejected and accepted contours. Qualitative evaluation shows that it is difficult to use common quantification metrics as indicator for use in clinic. We might need to change the reporting of quantitative metrics to better reflect clinical acceptance.",True,other,convolutional neural network
35071603,Data Homogeneity Effect in Deep Learning-Based Prediction of Type 1 Diabetic Retinopathy,"This study is aimed at evaluating a deep transfer learning-based model for identifying diabetic retinopathy (DR) that was trained using a dataset with high variability and predominant type 2 diabetes (T2D) and comparing model performance with that in patients with type 1 diabetes (T1D). The Kaggle dataset, which is a publicly available dataset, was divided into training and testing Kaggle datasets. In the comparison dataset, we collected retinal fundus images of T1D patients at Chang Gung Memorial Hospital in Taiwan from 2013 to 2020, and the images were divided into training and testing T1D datasets. The model was developed using 4 different convolutional neural networks (Inception-V3, DenseNet-121, VGG1, and Xception). The model performance in predicting DR was evaluated using testing images from each dataset, and area under the curve (AUC), sensitivity, and specificity were calculated. The model trained using the Kaggle dataset had an average (range) AUC of 0.74 (0.03) and 0.87 (0.01) in the testing Kaggle and T1D datasets, respectively. The model trained using the T1D dataset had an AUC of 0.88 (0.03), which decreased to 0.57 (0.02) in the testing Kaggle dataset. Heatmaps showed that the model focused on retinal hemorrhage, vessels, and exudation to predict DR. In wrong prediction images, artifacts and low-image quality affected model performance. The model developed with the high variability and T2D predominant dataset could be applied to T1D patients. Dataset homogeneity could affect the performance, trainability, and generalization of the model.",True,both,recurrent neural network
35070385,Application of artificial intelligence in COVID-19 medical area: a systematic review,"BACKGROUND: Coronavirus disease 2019 (COVID-19) has caused a large-scale global epidemic, impacting international politics and the economy. At present, there is no particularly effective medicine and treatment plan. Therefore, it is urgent and significant to find new technologies to diagnose early, isolate early, and treat early. Multimodal data drove artificial intelligence (AI) can potentially be the option. During the COVID-19 Pandemic, AI provided cutting-edge applications in disease, medicine, treatment, and target recognition. This paper reviewed the literature on the intersection of AI and medicine to analyze and compare different AI model applications in the COVID-19 Pandemic, evaluate their effectiveness, show their advantages and differences, and introduce the main models and their characteristics.
METHODS: We searched PubMed, arXiv, medRxiv, and Google Scholar through February 2020 to identify studies on AI applications in the medical areas for the COVID-19 Pandemic.
RESULTS: We summarize the main AI applications in six areas: (I) epidemiology, (II) diagnosis, (III) progression, (IV) treatment, (V) psychological health impact, and (VI) data security. The ongoing development in AI has significantly improved prediction, contact tracing, screening, diagnosis, treatment, medication, and vaccine development for the COVID-19 Pandemic and reducing human intervention in medical practice.
DISCUSSION: This paper provides strong advice for using AI-based auxiliary tools for related applications of human diseases. We also discuss the clinicians' role in the further development of AI. They and AI researchers can integrate AI technology with current clinical processes and information systems into applications. In the future, AI personnel and medical workers will further cooperate closely.",True,other,CNN
35062101,A Deep Learning Program to Predict Acute Kidney Injury,"Acute kidney injury is a dangerous and sometime fatal clinical situation, which can cause irreversible damage. If we can predict it earlier and make appropriate prevention before its outbreak, kidney injury could be avoided. One challenge of early recognition of AKI is that the most e-alerts have focused on creatinine-based algorithms, but the elevation of serum creatinine lags behind renal injury. We use recurrent neural network (RNN) to make data mining on laboratory results of MIMIC-III Database. At first, we transfer the case data into Pandas DataFrame of series framed for supervised learning. Then we can use RNN predicts the next serum creatinine values (SCr) based on the last laboratory test results after emergency admissions. We train the RNN on whole dataset (i.e. multi-cases prediction) with LSTM. As the result shown, this prototype can predict criteria (SCr) of AKI with a RMSE (Root Mean Square Error) of 0.017mg/dL.",True,other,RNN
35034623,"Using deep learning to predict the outcome of live birth from more than 10,000 embryo data","BACKGROUND: Recently, the combination of deep learning and time-lapse imaging provides an objective, standard and scientific solution for embryo selection. However, the reported studies were based on blastocyst formation or clinical pregnancy as the end point. To the best of our knowledge, there is no predictive model that uses the outcome of live birth as the predictive end point. Can a deep learning model predict the probability of live birth from time-lapse system?
METHODS: This study retrospectively analyzed the time-lapse data and live birth outcomes of embryos samples from January 2018 to November 2019. We used the SGD optimizer with an initial learning rate of 0.025 and cosine learning rate reduction strategy. The network is randomly initialized and trained for 200 epochs from scratch. The model is quantitively evaluated over a hold-out test and a 5-fold cross-validation by the average area under the curve (AUC) of the receiver operating characteristic (ROC) curve.
RESULTS: The deep learning model was able to predict live birth outcomes from time-lapse images with an AUC of 0.968 in 5-fold stratified cross-validation.
CONCLUSIONS: This research reported a deep learning model that predicts the live birth outcome of a single blastocyst transfer. This efficient model for predicting the outcome of live births can automatically analyze the time-lapse images of the patient's embryos without the need for manual embryo annotation and evaluation, and then give a live birth prediction score for each embryo, and sort the embryos by the predicted value.",True,other,recurrent neural network
35025860,Machine learning and deep learning techniques to support clinical diagnosis of arboviral diseases: A systematic review,"BACKGROUND: Neglected tropical diseases (NTDs) primarily affect the poorest populations, often living in remote, rural areas, urban slums or conflict zones. Arboviruses are a significant NTD category spread by mosquitoes. Dengue, Chikungunya, and Zika are three arboviruses that affect a large proportion of the population in Latin and South America. The clinical diagnosis of these arboviral diseases is a difficult task due to the concurrent circulation of several arboviruses which present similar symptoms, inaccurate serologic tests resulting from cross-reaction and co-infection with other arboviruses.
OBJECTIVE: The goal of this paper is to present evidence on the state of the art of studies investigating the automatic classification of arboviral diseases to support clinical diagnosis based on Machine Learning (ML) and Deep Learning (DL) models.
METHOD: We carried out a Systematic Literature Review (SLR) in which Google Scholar was searched to identify key papers on the topic. From an initial 963 records (956 from string-based search and seven from a single backward snowballing procedure), only 15 relevant papers were identified.
RESULTS: Results show that current research is focused on the binary classification of Dengue, primarily using tree-based ML algorithms. Only one paper was identified using DL. Five papers presented solutions for multi-class problems, covering Dengue (and its variants) and Chikungunya. No papers were identified that investigated models to differentiate between Dengue, Chikungunya, and Zika.
CONCLUSIONS: The use of an efficient clinical decision support system for arboviral diseases can improve the quality of the entire clinical process, thus increasing the accuracy of the diagnosis and the associated treatment. It should help physicians in their decision-making process and, consequently, improve the use of resources and the patient's quality of life.",True,other,Not specified
35005197,Deep learning improves utility of tau PET in the study of Alzheimer's disease,"INTRODUCTION: Positron emission tomography (PET) imaging targeting neurofibrillary tau tangles is increasingly used in the study of Alzheimer's disease (AD), but its utility may be limited by conventional quantitative or qualitative evaluation techniques in earlier disease states. Convolutional neural networks (CNNs) are effective in learning spatial patterns for image classification.
METHODS: 18F-MK6240 (n = 320) and AV-1451 (n = 446) PET images were pooled from multiple studies. We performed iterations with differing permutations of radioligands, heuristics, and architectures. Performance was compared to a standard region of interest (ROI)-based approach on prediction of memory impairment. We visualized attention of the network to illustrate decision making.
RESULTS: Overall, models had high accuracy (> 80%) with good average sensitivity and specificity (75% and 82%, respectively), and had comparable or higher accuracy to the ROI standard. Visualizations of model attention highlight known characteristics of tau radioligand binding.
DISCUSSION: CNNs could improve tau PET's role in early disease and extend the utility of tau PET across generations of radioligands.",True,other,convolutional neural network
34997958,Development of Deep Learning Models for Predicting In-Hospital Mortality Using an Administrative Claims Database: Retrospective Cohort Study,"BACKGROUND: Administrative claims databases have been used widely in studies because they have large sample sizes and are easily available. However, studies using administrative databases lack information on disease severity, so a risk adjustment method needs to be developed.
OBJECTIVE: We aimed to develop and validate deep learning-based prediction models for in-hospital mortality of acute care patients.
METHODS: The main model was developed using only administrative claims data (age, sex, diagnoses, and procedures on the day of admission). We also constructed disease-specific models for acute myocardial infarction, heart failure, stroke, and pneumonia using common severity indices for these diseases. Using the Japanese Diagnosis Procedure Combination data from July 2010 to March 2017, we identified 46,665,933 inpatients and divided them into derivation and validation cohorts in a ratio of 95:5. The main model was developed using a 9-layer deep neural network with 4 hidden dense layers that had 1000 nodes and were fully connected to adjacent layers. We evaluated model discrimination ability by an area under the receiver operating characteristic curve (AUC) and calibration ability by calibration plot.
RESULTS: Among the eligible patients, 2,005,035 (4.3%) died. Discrimination and calibration of the models were satisfactory. The AUC of the main model in the validation cohort was 0.954 (95% CI 0.954-0.955). The main model had higher discrimination ability than the disease-specific models.
CONCLUSIONS: Our deep learning-based model using diagnoses and procedures produced valid predictions of in-hospital mortality.",True,other,RNN
34990643,DeepLensNet: Deep Learning Automated Diagnosis and Quantitative Classification of Cataract Type and Severity,"PURPOSE: To develop deep learning models to perform automated diagnosis and quantitative classification of age-related cataract from anterior segment photographs.
DESIGN: DeepLensNet was trained by applying deep learning models to the Age-Related Eye Disease Study (AREDS) dataset.
PARTICIPANTS: A total of 18 999 photographs (6333 triplets) from longitudinal follow-up of 1137 eyes (576 AREDS participants).
METHODS: Deep learning models were trained to detect and quantify nuclear sclerosis (NS; scale 0.9-7.1) from 45-degree slit-lamp photographs and cortical lens opacity (CLO; scale 0%-100%) and posterior subcapsular cataract (PSC; scale 0%-100%) from retroillumination photographs. DeepLensNet performance was compared with that of 14 ophthalmologists and 24 medical students.
MAIN OUTCOME MEASURES: Mean squared error (MSE).
RESULTS: On the full test set, mean MSE for DeepLensNet was 0.23 (standard deviation [SD], 0.01) for NS, 13.1 (SD, 1.6) for CLO, and 16.6 (SD, 2.4) for PSC. On a subset of the test set (substantially enriched for positive cases of CLO and PSC), for NS, mean MSE for DeepLensNet was 0.23 (SD, 0.02), compared with 0.98 (SD, 0.24; P = 0.000001) for the ophthalmologists and 1.24 (SD, 0.34; P = 0.000005) for the medical students. For CLO, mean MSE was 53.5 (SD, 14.8), compared with 134.9 (SD, 89.9; P = 0.003) for the ophthalmologists and 433.6 (SD, 962.1; P = 0.0007) for the medical students. For PSC, mean MSE was 171.9 (SD, 38.9), compared with 176.8 (SD, 98.0; P = 0.67) for the ophthalmologists and 398.2 (SD, 645.4; P = 0.18) for the medical students. In external validation on the Singapore Malay Eye Study (sampled to reflect the cataract severity distribution in AREDS), the MSE for DeepSeeNet was 1.27 for NS and 25.5 for PSC.
CONCLUSIONS: DeepLensNet performed automated and quantitative classification of cataract severity for all 3 types of age-related cataract. For the 2 most common types (NS and CLO), the accuracy was significantly superior to that of ophthalmologists; for the least common type (PSC), it was similar. DeepLensNet may have wide potential applications in both clinical and research domains. In the future, such approaches may increase the accessibility of cataract assessment globally. The code and models are available at https://github.com/ncbi/deeplensnet.",True,other,recurrent neural network
34983362,Hierarchical shared transfer learning for biomedical named entity recognition,"BACKGROUND: Biomedical named entity recognition (BioNER) is a basic and important medical information extraction task to extract medical entities with special meaning from medical texts. In recent years, deep learning has become the main research direction of BioNER due to its excellent data-driven context coding ability. However, in BioNER task, deep learning has the problem of poor generalization and instability.
RESULTS: we propose the hierarchical shared transfer learning, which combines multi-task learning and fine-tuning, and realizes the multi-level information fusion between the underlying entity features and the upper data features. We select 14 datasets containing 4 types of entities for training and evaluate the model. The experimental results showed that the F1-scores of the five gold standard datasets BC5CDR-chemical, BC5CDR-disease, BC2GM, BC4CHEMD, NCBI-disease and LINNAEUS were increased by 0.57, 0.90, 0.42, 0.77, 0.98 and - 2.16 compared to the single-task XLNet-CRF model. BC5CDR-chemical, BC5CDR-disease and BC4CHEMD achieved state-of-the-art results.The reasons why LINNAEUS's multi-task results are lower than single-task results are discussed at the dataset level.
CONCLUSION: Compared with using multi-task learning and fine-tuning alone, the model has more accurate recognition ability of medical entities, and has higher generalization and stability.",True,other,convolutional neural network
34976110,Deep-Learning-Based Survival Prediction of Patients in Coronary Care Units,"BACKGROUND: A survival prediction model based on deep learning has higher accuracy than the CPH model in predicting the survival of CCU patients, and it also has a better discrimination ability. We collected information on patients with various diseases in coronary care units (CCUs) from the Medical Information Mart for Intensive Care III (MIMIC-III) database. The purpose of this study was to use this information to construct a neural-network model based on deep learning to predict the survival probabilities of patients with conditions that are common in CCUs.
METHOD: We collected information on patients in the United States with five common diseases in CCUs from 2001 to 2012. We randomly divided the patients into a training cohort and a testing cohort at a ratio of 7 : 3 and applied a survival prediction method based on deep learning to predict their survival probability. We compared our model with the Cox proportional-hazards regression (CPH) model and used the concordance indexes (C-indexes), receiver operating characteristic (ROC) curve, and calibration plots to evaluate the predictive performance of the model.
RESULTS: The 3,388 CCU patients included in the study were randomly divided into 2,371 in the training cohort and 1,017 in the testing cohort. The stepwise regression results showed that the important factors affecting patient survival were the type of disease, age, race, anion gap, glucose, neutrophils, white blood cells, potassium, creatine kinase, and blood urea nitrogen (P &lt; 0.05). We used the training cohort to construct a deep-learning model, for which the C-index was 0.833, or about 5% higher than that for the CPH model (0.786). The C-index of the deep-learning model for the test cohort was 0.822, which was also higher than that for the CPH model (0.782). The areas under the ROC curve for the 28-day, 90-day, and 1-year survival probabilities were 0.875, 0.865, and 0.874, respectively, in the deep-learning model, respectively, and 0.830, 0.843, and 0.806 in the CPH model. These values indicate that the survival analysis model based on deep learning is better than the traditional CPH model in predicting the survival of CCU patients.
CONCLUSION: A survival prediction model based on deep learning has higher accuracy than the CPH model in predicting the survival of CCU patients, and it also has a better discrimination ability.",True,other,recurrent neural network
34954992,[Progress on the application of data mining in the prognosis of cardiovascular disease],"Data mining has been widely used in the study of cardiovascular disease prognosis. For stroke prognosis, the focus was mainly on the prediction of intervention effectiveness. In contrast, the focus was primarily on predicting natural prognostic and intervention safety for other cardiovascular diseases. In addition, compared with traditional statistical methods, machine learning, especially deep learning based on neural networks has much better performance in predicting the prognosis of cardiovascular diseases, which is worthy of further promotion and application. Therefore, this study systematically reviewed the recent application progress of data mining in cardiovascular disease prognosis, summarized the shortcomings of current studies, and put forward future directions.",True,other,recurrent neural network
34945914,Empirical Frequentist Coverage of Deep Learning Uncertainty Quantification Procedures,"Uncertainty quantification for complex deep learning models is increasingly important as these techniques see growing use in high-stakes, real-world settings. Currently, the quality of a model's uncertainty is evaluated using point-prediction metrics, such as the negative log-likelihood (NLL), expected calibration error (ECE) or the Brier score on held-out data. Marginal coverage of prediction intervals or sets, a well-known concept in the statistical literature, is an intuitive alternative to these metrics but has yet to be systematically studied for many popular uncertainty quantification techniques for deep learning models. With marginal coverage and the complementary notion of the width of a prediction interval, downstream users of deployed machine learning models can better understand uncertainty quantification both on a global dataset level and on a per-sample basis. In this study, we provide the first large-scale evaluation of the empirical frequentist coverage properties of well-known uncertainty quantification techniques on a suite of regression and classification tasks. We find that, in general, some methods do achieve desirable coverage properties on in distribution samples, but that coverage is not maintained on out-of-distribution data. Our results demonstrate the failings of current uncertainty quantification techniques as dataset shift increases and reinforce coverage as an important metric in developing models for real-world applications.",True,other,convolutional neural network
34943479,Predicting Prolonged Length of ICU Stay through Machine Learning,"This study aimed to construct machine learning (ML) models for predicting prolonged length of stay (pLOS) in intensive care units (ICU) among general ICU patients. A multicenter database called eICU (Collaborative Research Database) was used for model derivation and internal validation, and the Medical Information Mart for Intensive Care (MIMIC) III database was used for external validation. We used four different ML methods (random forest, support vector machine, deep learning, and gradient boosting decision tree (GBDT)) to develop prediction models. The prediction performance of the four models were compared with the customized simplified acute physiology score (SAPS) II. The area under the receiver operation characteristic curve (AUROC), area under the precision-recall curve (AUPRC), estimated calibration index (ECI), and Brier score were used to measure performance. In internal validation, the GBDT model achieved the best overall performance (Brier score, 0.164), discrimination (AUROC, 0.742; AUPRC, 0.537), and calibration (ECI, 8.224). In external validation, the GBDT model also achieved the best overall performance (Brier score, 0.166), discrimination (AUROC, 0.747; AUPRC, 0.536), and calibration (ECI, 8.294). External validation showed that the calibration curve of the GBDT model was an optimal fit, and four ML models outperformed the customized SAPS II model. The GBDT-based pLOS-ICU prediction model had the best prediction performance among the five models on both internal and external datasets. Furthermore, it has the potential to assist ICU physicians to identify patients with pLOS-ICU risk and provide appropriate clinical interventions to improve patient outcomes.",True,other,RNN
34938362,Optimization: Molecular Communication Networks for Viral Disease Analysis Using Deep Leaning Autoencoder,"Developing new treatments for emerging infectious diseases in infectious and noninfectious diseases has attracted a particular attention. The emergence of viral diseases is expected to accelerate; these data indicate the need for a proactive approach to develop widely active family specific and cross family therapies for future disease outbreaks. Viral disease such as pneumonia, severe acute respiratory syndrome type 2, HIV infection, and Hepatitis-C virus can cause directly and indirectly cardiovascular disease (CVD). Emphasis should be placed not only on the development of broad-spectrum molecules and antibodies but also on host factor therapy, including the reutilization of previously approved or developing drugs. Another new class of therapeutics with great antiviral therapeutic potential is molecular communication networks using deep learning autoencoder (DL-AEs). The use of DL-AEs for diagnosis and prognosis prediction of infectious and noninfectious diseases has attracted a particular attention. MCN is map to molecular signaling and communication that are found inside and outside the human body where the goal is to develop a new black box mechanism that can serve the future robust healthcare industry (HCI). MCN has the ability to characterize the signaling process between cells and infectious disease locations at various levels of the human body called point-to-point MCN through DL-AE and provide targeted drug delivery (TDD) environment. Through MCN, and DL-AE healthcare provider can remotely measure biological signals and control certain processes in the required organism for the maintenance of the patient's health state. We use biomicrodevices to promote the real-time monitoring of human health and storage of the gathered data in the cloud. In this paper, we use the DL-based AE approach to design and implement a new drug source and target for the MCN under white Gaussian noise. Simulation results show that transceiver executions for a given medium model that reduces the bit error rate which can be learned. Then, next development of molecular diagnosis such as heart sounds is classified. Furthermore, biohealth interface for the inside and outside human body mechanism is presented, comparative perspective with up-to-date current situation about MCN.",True,other,Not specified
34934420,Novel Prediction Model for COVID-19 in Saudi Arabia Based on an LSTM Algorithm,"The rapid emergence of the novel SARS-CoV-2 poses a challenge and has attracted worldwide attention. Artificial intelligence (AI) can be used to combat this pandemic and control the spread of the virus. In particular, deep learning-based time-series techniques are used to predict worldwide COVID-19 cases for short-term and medium-term dependencies using adaptive learning. This study aimed to predict daily COVID-19 cases and investigate the critical factors that increase the transmission rate of this outbreak by examining different influential factors. Furthermore, the study analyzed the effectiveness of COVID-19 prevention measures. A fully connected deep neural network, long short-term memory (LSTM), and transformer model were used as the AI models for the prediction of new COVID-19 cases. Initially, data preprocessing and feature extraction were performed using COVID-19 datasets from Saudi Arabia. The performance metrics for all models were computed, and the results were subjected to comparative analysis to detect the most reliable model. Additionally, statistical hypothesis analysis and correlation analysis were performed on the COVID-19 datasets by including features such as daily mobility, total cases, people fully vaccinated per hundred, weekly hospital admissions per million, intensive care unit patients, and new deaths per million. The results show that the LSTM algorithm had the highest accuracy of all the algorithms and an error of less than 2%. The findings of this study contribute to our understanding of COVID-19 containment. This study also provides insights into the prevention of future outbreaks.",True,other,recurrent neural network
34932550,SWIFT: A deep learning approach to prediction of hypoxemic events in critically-Ill patients using SpO2 waveform prediction,"Hypoxemia is a significant driver of mortality and poor clinical outcomes in conditions such as brain injury and cardiac arrest in critically ill patients, including COVID-19 patients. Given the host of negative clinical outcomes attributed to hypoxemia, identifying patients likely to experience hypoxemia would offer valuable opportunities for early and thus more effective intervention. We present SWIFT (SpO2 Waveform ICU Forecasting Technique), a deep learning model that predicts blood oxygen saturation (SpO2) waveforms 5 and 30 minutes in the future using only prior SpO2 values as inputs. When tested on novel data, SWIFT predicts more than 80% and 60% of hypoxemic events in critically ill and COVID-19 patients, respectively. SWIFT also predicts SpO2 waveforms with average MSE below .0007. SWIFT predicts both occurrence and magnitude of potential hypoxemic events 30 minutes in the future, allowing it to be used to inform clinical interventions, patient triaging, and optimal resource allocation. SWIFT may be used in clinical decision support systems to inform the management of critically ill patients during the COVID-19 pandemic and beyond.",True,other,Not specified
34926274,Predicting Breast Cancer Gene Expression Signature by Applying Deep Convolutional Neural Networks From Unannotated Pathological Images,"We proposed a highly versatile two-step transfer learning pipeline for predicting the gene signature defining the intrinsic breast cancer subtypes using unannotated pathological images. Deciphering breast cancer molecular subtypes by deep learning approaches could provide a convenient and efficient method for the diagnosis of breast cancer patients. It could reduce costs associated with transcriptional profiling and subtyping discrepancy between IHC assays and mRNA expression. Four pretrained models such as VGG16, ResNet50, ResNet101, and Xception were trained with our in-house pathological images from breast cancer patient with recurrent status in the first transfer learning step and TCGA-BRCA dataset for the second transfer learning step. Furthermore, we also trained ResNet101 model with weight from ImageNet for comparison to the aforementioned models. The two-step deep learning models showed promising classification results of the four breast cancer intrinsic subtypes with accuracy ranging from 0.68 (ResNet50) to 0.78 (ResNet101) in both validation and testing sets. Additionally, the overall accuracy of slide-wise prediction showed even higher average accuracy of 0.913 with ResNet101 model. The micro- and macro-average area under the curve (AUC) for these models ranged from 0.88 (ResNet50) to 0.94 (ResNet101), whereas ResNet101_imgnet weighted with ImageNet archived an AUC of 0.92. We also show the deep learning model prediction performance is significantly improved relatively to the common Genefu tool for breast cancer classification. Our study demonstrated the capability of deep learning models to classify breast cancer intrinsic subtypes without the region of interest annotation, which will facilitate the clinical applicability of the proposed models.",True,other,recurrent neural network
34912370,Deep Learning Algorithms Achieved Satisfactory Predictions When Trained on a Novel Collection of Anticoronavirus Molecules,"Drug discovery and repurposing against COVID-19 is a highly relevant topic with huge efforts dedicated to delivering novel therapeutics targeting SARS-CoV-2. In this context, computer-aided drug discovery is of interest in orienting the early high throughput screenings and in optimizing the hit identification rate. We herein propose a pipeline for Ligand-Based Drug Discovery (LBDD) against SARS-CoV-2. Through an extensive search of the literature and multiple steps of filtering, we integrated information on 2,610 molecules having a validated effect against SARS-CoV and/or SARS-CoV-2. The chemical structures of these molecules were encoded through multiple systems to be readily useful as input to conventional machine learning (ML) algorithms or deep learning (DL) architectures. We assessed the performances of seven ML algorithms and four DL algorithms in achieving molecule classification into two classes: active and inactive. The Random Forests (RF), Graph Convolutional Network (GCN), and Directed Acyclic Graph (DAG) models achieved the best performances. These models were further optimized through hyperparameter tuning and achieved ROC-AUC scores through cross-validation of 85, 83, and 79% for RF, GCN, and DAG models, respectively. An external validation step on the FDA-approved drugs collection revealed a superior potential of DL algorithms to achieve drug repurposing against SARS-CoV-2 based on the dataset herein presented. Namely, GCN and DAG achieved more than 50% of the true positive rate assessed on the confirmed hits of a PubChem bioassay.",True,other,Not specified
34910160,Predicting cardiovascular risk from national administrative databases using a combined survival analysis and deep learning approach,"BACKGROUND: Machine learning-based risk prediction models may outperform traditional statistical models in large datasets with many variables, by identifying both novel predictors and the complex interactions between them. This study compared deep learning extensions of survival analysis models with Cox proportional hazards models for predicting cardiovascular disease (CVD) risk in national health administrative datasets.
METHODS: Using individual person linkage of administrative datasets, we constructed a cohort of all New Zealanders aged 30-74 who interacted with public health services during 2012. After excluding people with prior CVD, we developed sex-specific deep learning and Cox proportional hazards models to estimate the risk of CVD events within 5 years. Models were compared based on the proportion of explained variance, model calibration and discrimination, and hazard ratios for predictor variables.
RESULTS: First CVD events occurred in 61 927 of 2 164 872 people. Within the reference group, the largest hazard ratios estimated by the deep learning models were for tobacco use in women (2.04, 95% CI: 1.99, 2.10) and chronic obstructive pulmonary disease with acute lower respiratory infection in men (1.56, 95% CI: 1.50, 1.62). Other identified predictors (e.g. hypertension, chest pain, diabetes) aligned with current knowledge about CVD risk factors. Deep learning outperformed Cox proportional hazards models on the basis of proportion of explained variance (R2: 0.468 vs 0.425 in women and 0.383 vs 0.348 in men), calibration and discrimination (all P <0.0001).
CONCLUSIONS: Deep learning extensions of survival analysis models can be applied to large health administrative datasets to derive interpretable CVD risk prediction equations that are more accurate than traditional Cox proportional hazards models.",True,other,Not specified
34870131,A deep learning approach for predicting severity of COVID-19 patients using a parsimonious set of laboratory markers,"The SARS-CoV-2 virus has caused tremendous healthcare burden worldwide. Our focus was to develop a practical and easy-to-deploy system to predict the severe manifestation of disease in patients with COVID-19 with an aim to assist clinicians in triage and treatment decisions. Our proposed predictive algorithm is a trained artificial intelligence-based network using 8,427 COVID-19 patient records from four healthcare systems. The model provides a severity risk score along with likelihoods of various clinical outcomes, namely ventilator use and mortality. The trained model using patient age and nine laboratory markers has the prediction accuracy with an area under the curve (AUC) of 0.78, 95% CI: 0.77-0.82, and the negative predictive value NPV of 0.86, 95% CI: 0.84-0.88 for the need to use a ventilator and has an accuracy with AUC of 0.85, 95% CI: 0.84-0.86, and the NPV of 0.94, 95% CI: 0.92-0.96 for predicting in-hospital 30-day mortality.",True,other,recurrent neural network
34854737,Unsupervised learning of cross-modal mappings in multi-omics data for survival stratification of gastric cancer,"Aims: This study presents a survival stratification model based on multi-omics integration using bidirectional deep neural networks (BiDNNs) in gastric cancer. Methods: Based on the survival-related representation features yielded by BiDNNs through integrating transcriptomics and epigenomics data, K-means clustering analysis was performed to cluster tumor samples into different survival subgroups. The BiDNNs-based model was validated using tenfold cross-validation and in two independent confirmation cohorts. Results: Using the BiDNNs-based survival stratification model, patients were grouped into two survival subgroups with log-rank p-value = 9.05E-05. The subgroups classification was robustly validated in tenfold cross-validation (C-index = 0.65 ± 0.02) and in two confirmation cohorts (E-GEOD-26253, C-index = 0.609; E-GEOD-62254, C-index = 0.706). Conclusion: We propose and validate a robust and stable BiDNN-based survival stratification model in gastric cancer.",True,other,RNN
34829372,Inter-Variability Study of COVLIAS 1.0: Hybrid Deep Learning Models for COVID-19 Lung Segmentation in Computed Tomography,"Background: For COVID-19 lung severity, segmentation of lungs on computed tomography (CT) is the first crucial step. Current deep learning (DL)-based Artificial Intelligence (AI) models have a bias in the training stage of segmentation because only one set of ground truth (GT) annotations are evaluated. We propose a robust and stable inter-variability analysis of CT lung segmentation in COVID-19 to avoid the effect of bias. Methodology: The proposed inter-variability study consists of two GT tracers for lung segmentation on chest CT. Three AI models, PSP Net, VGG-SegNet, and ResNet-SegNet, were trained using GT annotations. We hypothesized that if AI models are trained on the GT tracings from multiple experience levels, and if the AI performance on the test data between these AI models is within the 5% range, one can consider such an AI model robust and unbiased. The K5 protocol (training to testing: 80%:20%) was adapted. Ten kinds of metrics were used for performance evaluation. Results: The database consisted of 5000 CT chest images from 72 COVID-19-infected patients. By computing the coefficient of correlations (CC) between the output of the two AI models trained corresponding to the two GT tracers, computing their differences in their CC, and repeating the process for all three AI-models, we show the differences as 0%, 0.51%, and 2.04% (all &lt; 5%), thereby validating the hypothesis. The performance was comparable; however, it had the following order: ResNet-SegNet &gt; PSP Net &gt; VGG-SegNet. Conclusions: The AI models were clinically robust and stable during the inter-variability analysis on the CT lung segmentation on COVID-19 patients.",True,other,Not specified
34823030,Class imbalance in out-of-distribution datasets: Improving the robustness of the TextCNN for the classification of rare cancer types,"In the last decade, the widespread adoption of electronic health record documentation has created huge opportunities for information mining. Natural language processing (NLP) techniques using machine and deep learning are becoming increasingly widespread for information extraction tasks from unstructured clinical notes. Disparities in performance when deploying machine learning models in the real world have recently received considerable attention. In the clinical NLP domain, the robustness of convolutional neural networks (CNNs) for classifying cancer pathology reports under natural distribution shifts remains understudied. In this research, we aim to quantify and improve the performance of the CNN for text classification on out-of-distribution (OOD) datasets resulting from the natural evolution of clinical text in pathology reports. We identified class imbalance due to different prevalence of cancer types as one of the sources of performance drop and analyzed the impact of previous methods for addressing class imbalance when deploying models in real-world domains. Our results show that our novel class-specialized ensemble technique outperforms other methods for the classification of rare cancer types in terms of macro F1 scores. We also found that traditional ensemble methods perform better in top classes, leading to higher micro F1 scores. Based on our findings, we formulate a series of recommendations for other ML practitioners on how to build robust models with extremely imbalanced datasets in biomedical NLP applications.",True,other,RNN
34765242,Assessment of Deep Learning Methods for Differentiating Autoimmune Disorders in Ultrasound Images,"At present, deep learning becomes an important tool in medical image analysis, with good performance in diagnosing, pattern detection, and segmentation. Ultrasound imaging offers an easy and rapid method to detect and diagnose thyroid disorders. With the help of a computer-aided diagnosis (CAD) system based on deep learning, we have the possibility of real-time and non-invasive diagnosing of thyroidal US images. This paper proposed a study based on deep learning with transfer learning for differentiating the thyroidal ultrasound images using image pixels and diagnosis labels as inputs. We trained, assessed, and compared two pre-trained models (VGG-19 and Inception v3) using a dataset of ultrasound images consisting of 2 types of thyroid ultrasound images: autoimmune and normal. The training dataset consisted of 615 thyroid ultrasound images, from which 415 images were diagnosed as autoimmune, and 200 images as normal. The models were assessed using a dataset of 120 images, from which 80 images were diagnosed as autoimmune, and 40 images diagnosed as normal. The two deep learning models obtained very good results, as follows: the pre-trained VGG-19 model obtained 98.60% for the overall test accuracy with an overall specificity of 98.94% and overall sensitivity of 97.97%, while the Inception v3 model obtained 96.4% for the overall test accuracy with an overall specificity of 95.58% and overall sensitivity of 95.58.",True,other,Not specified
34764164,Deep learning-based facial image analysis in medical research: a systematic review protocol,"INTRODUCTION: Deep learning techniques are gaining momentum in medical research. Evidence shows that deep learning has advantages over humans in image identification and classification, such as facial image analysis in detecting people's medical conditions. While positive findings are available, little is known about the state-of-the-art of deep learning-based facial image analysis in the medical context. For the consideration of patients' welfare and the development of the practice, a timely understanding of the challenges and opportunities faced by research on deep-learning-based facial image analysis is needed. To address this gap, we aim to conduct a systematic review to identify the characteristics and effects of deep learning-based facial image analysis in medical research. Insights gained from this systematic review will provide a much-needed understanding of the characteristics, challenges, as well as opportunities in deep learning-based facial image analysis applied in the contexts of disease detection, diagnosis and prognosis.
METHODS: Databases including PubMed, PsycINFO, CINAHL, IEEEXplore and Scopus will be searched for relevant studies published in English in September, 2021. Titles, abstracts and full-text articles will be screened to identify eligible articles. A manual search of the reference lists of the included articles will also be conducted. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework was adopted to guide the systematic review process. Two reviewers will independently examine the citations and select studies for inclusion. Discrepancies will be resolved by group discussions till a consensus is reached. Data will be extracted based on the research objective and selection criteria adopted in this study.
ETHICS AND DISSEMINATION: As the study is a protocol for a systematic review, ethical approval is not required. The study findings will be disseminated via peer-reviewed publications and conference presentations.
PROSPERO REGISTRATION NUMBER: CRD42020196473.",True,other,Not specified
34756513,Improved breast cancer histological grading using deep learning,"BACKGROUND: The Nottingham histological grade (NHG) is a well-established prognostic factor for breast cancer that is broadly used in clinical decision making. However, ∼50% of patients are classified as grade 2, an intermediate risk group with low clinical value. To improve risk stratification of NHG 2 breast cancer patients, we developed and validated a novel histological grade model (DeepGrade) based on digital whole-slide histopathology images (WSIs) and deep learning.
PATIENTS AND METHODS: In this observational retrospective study, routine WSIs stained with haematoxylin and eosin from 1567 patients were utilised for model optimisation and validation. Model generalisability was further evaluated in an external test set with 1262 patients. NHG 2 cases were stratified into two groups, DG2-high and DG2-low, and the prognostic value was assessed. The main outcome was recurrence-free survival.
RESULTS: DeepGrade provides independent prognostic information for stratification of NHG 2 cases in the internal test set, where DG2-high showed an increased risk for recurrence (hazard ratio [HR] 2.94, 95% confidence interval [CI] 1.24-6.97, P = 0.015) compared with the DG2-low group after adjusting for established risk factors (independent test data). DG2-low also shared phenotypic similarities with NHG 1, and DG2-high with NHG 3, suggesting that the model identifies morphological patterns in NHG 2 that are associated with more aggressive tumours. The prognostic value of DeepGrade was further assessed in the external test set, confirming an increased risk for recurrence in DG2-high (HR 1.91, 95% CI 1.11-3.29, P = 0.019).
CONCLUSIONS: The proposed model-based stratification of patients with NHG 2 tumours is prognostic and adds clinically relevant information over routine histological grading. The methodology offers a cost-effective alternative to molecular profiling to extract information relevant for clinical decisions.",True,other,Not specified
34750962,Using infrared imaging and deep learning in fit-checking of respiratory protective devices among healthcare professionals,"AIMS: This study aimed to investigate the application of infrared thermal imaging and adopt deep learning to detect air leakage for determining the fitness of respirators during fit-checks.
BACKGROUND: The outbreak of Covid-19 virus constitutes a public health crisis with substantial resultant morbidities and mortalities; has exerted profound impacts.
METHODS: This was a prospective observational study, employing a non-probability sampling method on a convenience sample to recruit the participants and followed the Strengthening the Reporting of Observational Studies in Epidemiology statement guidelines.
RESULTS: The use of infrared thermal imaging identified air leakage points as a disruption to the facial thermal pattern distribution at (a) front of face; (b) right lateral of the face; (c) left lateral of the face; (d) top of the facemask with the head facing down; and (e) bottom of the facemask with the head facing up. Results also indicated that artificial intelligence tools and the proliferation of deep learning have the potential to detect the location of air leakage locations.
CONCLUSION: The use of infrared thermal imaging provides evidence of the feasibility and applicability of infrared thermal imaging techniques in detecting air leakage for individuals wearing respirators.
CLINICAL RELEVANCE: The use of infrared thermal technology can serve a potential role in complement fit-checking of respiratory protective devices and offers promising practical utility in determining the fitness of respirators for nurses at the frontline to protect against the air-borne viruses.",True,other,Not specified
34749095,Deep neural survival networks for cardiovascular risk prediction: The Multi-Ethnic Study of Atherosclerosis (MESA),"BACKGROUND: There is growing interest in utilizing machine learning techniques for routine atherosclerotic cardiovascular disease (ASCVD) risk prediction. We investigated whether novel deep learning survival models can augment ASCVD risk prediction over existing statistical and machine learning approaches.
METHODS: 6814 participants from the Multi-Ethnic Study of Atherosclerosis (MESA) were followed over 16 years to assess incidence of all-cause mortality (mortality) or a composite of major adverse events (MAE). Features were evaluated within the categories of traditional risk factors, inflammatory biomarkers, and imaging markers. Data was split into an internal training/testing (four centers) and external validation (two centers). Both machine learning (COXPH, RSF, and lSVM) and deep learning (nMTLR and DeepSurv) models were evaluated.
RESULTS: In comparison to the COXPH model, DeepSurv significantly improved ASCVD risk prediction for MAE (AUC: 0.82 vs. 0.80, P ≤ 0.001) and mortality (AUC: 0.87 vs. 0.84, P ≤ 0.001) with traditional risk factors alone. Implementing non-categorical NRI, we noted a >40% increase in correct reclassification compared to the COXPH model for both MAE and mortality (P ≤ 0.05). Assessing the relative risk of participants, DeepSurv was the only learning algorithm to develop a significantly improved risk score criteria, which outcompeted COXPH for both MAE (4.22 vs. 3.61, P = 0.043) and mortality (6.81 vs. 5.52, P = 0.044). The addition of inflammatory or imaging biomarkers to traditional risk factors showed minimal/no significant improvement in model prediction.
CONCLUSION: DeepSurv can leverage simple office-based clinical features alone to accurately predict ASCVD risk and cardiovascular outcomes, without the need for additional features, such as inflammatory and imaging biomarkers.",True,other,Not specified
34745489,Susceptible-Infected-Removed Mathematical Model under Deep Learning in Hospital Infection Control of Novel Coronavirus Pneumonia,"OBJECTIVE: This research aimed to explore the application of a mathematical model based on deep learning in hospital infection control of novel coronavirus (COVID-19) pneumonia.
METHODS: First, the epidemic data of Beijing, China, were utilized to make a definite susceptible-infected-removed (SIR) model fitting to determine the estimated value of the COVID-19 removal intensity β, which was then used to do a determined SIR model and a stochastic SIR model fitting for the hospital. In addition, the reasonable β and γ estimates of the hospital were determined, and the spread of the epidemic in hospital was simulated, to discuss the impact of basal reproductive number changes, isolation, vaccination, and so forth on COVID-19.
RESULTS: There was a certain gap between the fitting of SIR to the remover and the actual data. The fitting of the number of infections was accurate. The growth rate of the number of infections decreased after measures, such as isolation, were taken. The effect of herd immunity was achieved after the overall immunity reached 70.9%.
CONCLUSION: The SIR model based on deep learning and the stochastic SIR fitting model were accurate in judging the development trend of the epidemic, which can provide basis and reference for hospital epidemic infection control.",True,computer vision,Not specified
34743558,Deep Learning of the Retina Enables Phenome- and Genome-Wide Analyses of the Microvasculature,"BACKGROUND: The microvasculature, the smallest blood vessels in the body, has key roles in maintenance of organ health and tumorigenesis. The retinal fundus is a window for human in vivo noninvasive assessment of the microvasculature. Large-scale complementary machine learning-based assessment of the retinal vasculature with phenome-wide and genome-wide analyses may yield new insights into human health and disease.
METHODS: We used 97 895 retinal fundus images from 54 813 UK Biobank participants. Using convolutional neural networks to segment the retinal microvasculature, we calculated vascular density and fractal dimension as a measure of vascular branching complexity. We associated these indices with 1866 incident International Classification of Diseases-based conditions (median 10-year follow-up) and 88 quantitative traits, adjusting for age, sex, smoking status, and ethnicity.
RESULTS: Low retinal vascular fractal dimension and density were significantly associated with higher risks for incident mortality, hypertension, congestive heart failure, renal failure, type 2 diabetes, sleep apnea, anemia, and multiple ocular conditions, as well as corresponding quantitative traits. Genome-wide association of vascular fractal dimension and density identified 7 and 13 novel loci, respectively, that were enriched for pathways linked to angiogenesis (eg, vascular endothelial growth factor, platelet-derived growth factor receptor, angiopoietin, and WNT signaling pathways) and inflammation (eg, interleukin, cytokine signaling).
CONCLUSIONS: Our results indicate that the retinal vasculature may serve as a biomarker for future cardiometabolic and ocular disease and provide insights into genes and biological pathways influencing microvascular indices. Moreover, such a framework highlights how deep learning of images can quantify an interpretable phenotype for integration with electronic health record, biomarker, and genetic data to inform risk prediction and risk modification.",True,other,recurrent neural network
34741093,Spatio-temporal prediction of the COVID-19 pandemic in US counties: modeling with a deep LSTM neural network,"Prediction of complex epidemiological systems such as COVID-19 is challenging on many grounds. Commonly used compartmental models struggle to handle an epidemiological process that evolves rapidly and is spatially heterogeneous. On the other hand, machine learning methods are limited at the beginning of the pandemics due to small data size for training. We propose a deep learning approach to predict future COVID-19 infection cases and deaths 1 to 4 weeks ahead at the fine granularity of US counties. The multi-variate Long Short-term Memory (LSTM) recurrent neural network is trained on multiple time series samples at the same time, including a mobility series. Results show that adding mobility as a variable and using multiple samples to train the network improve predictive performance both in terms of bias and of variance of the forecasts. We also show that the predicted results have similar accuracy and spatial patterns with a standard ensemble model used as benchmark. The model is attractive in many respects, including the fine geographic granularity of predictions and great predictive performance several weeks ahead. Furthermore, data requirement and computational intensity are reduced by substituting a single model to multiple models folded in an ensemble model.",True,other,recurrent neural network
34741028,Physics-informed deep learning characterizes morphodynamics of Asian soybean rust disease,"Medicines and agricultural biocides are often discovered using large phenotypic screens across hundreds of compounds, where visible effects of whole organisms are compared to gauge efficacy and possible modes of action. However, such analysis is often limited to human-defined and static features. Here, we introduce a novel framework that can characterize shape changes (morphodynamics) for cell-drug interactions directly from images, and use it to interpret perturbed development of Phakopsora pachyrhizi, the Asian soybean rust crop pathogen. We describe population development over a 2D space of shapes (morphospace) using two models with condition-dependent parameters: a top-down Fokker-Planck model of diffusive development over Waddington-type landscapes, and a bottom-up model of tip growth. We discover a variety of landscapes, describing phenotype transitions during growth, and identify possible perturbations in the tip growth machinery that cause this variation. This demonstrates a widely-applicable integration of unsupervised learning and biophysical modeling.",True,text mining,Not specified
34735607,AI MSK clinical applications: cartilage and osteoarthritis,"The advancements of artificial intelligence (AI) for osteoarthritis (OA) applications have been rapid in recent years, particularly innovations of deep learning for image classification, lesion detection, cartilage segmentation, and prediction modeling of future knee OA development. This review article focuses on AI applications in OA research, first describing machine learning (ML) techniques and workflow, followed by how these algorithms are used for OA classification tasks through imaging and non-imaging-based ML models. Deep learning applications for OA research, including analysis of both radiographs for automatic detection of OA severity, and MR images for detection of cartilage/meniscus lesions and cartilage segmentation for automatic T<sub>2</sub> quantification will be described. In addition, information on ML models that identify individuals at high risk of OA development will be provided. The future vision of machine learning applications in imaging of OA and cartilage hinges on implementation of AI for optimizing imaging protocols, quantitative assessment of cartilage, and automated analysis of disease burden yielding a faster and more efficient workflow for a radiologist with a higher level of reproducibility and precision. It may also provide risk assessment tools for individual patients, which is an integral part of precision medicine.",True,other,Not specified
34698568,Deep Learning for Prediction of N2 Metastasis and Survival for Clinical Stage I Non-Small Cell Lung Cancer,"Background Preoperative mediastinal staging is crucial for the optimal management of clinical stage I non-small cell lung cancer (NSCLC). Purpose To develop a deep learning signature for N2 metastasis prediction and prognosis stratification in clinical stage I NSCLC. Materials and Methods In this retrospective study conducted from May 2020 to October 2020 in a population with clinical stage I NSCLC, an internal cohort was adopted to establish a deep learning signature. Subsequently, the predictive efficacy and biologic basis of the proposed signature were investigated in an external cohort. A multicenter diagnostic trial (registration number: ChiCTR2000041310) was also performed to evaluate its clinical utility. Finally, on the basis of the N2 risk scores, the instructive significance of the signature in prognostic stratification was explored. The diagnostic efficiency was quantified with the area under the receiver operating characteristic curve (AUC), and the survival outcomes were assessed using the Cox proportional hazards model. Results A total of 3096 patients (mean age ± standard deviation, 60 years ± 9; 1703 men) were included in the study. The proposed signature achieved AUCs of 0.82, 0.81, and 0.81 in an internal test set (n = 266), external test cohort (n = 133), and prospective test cohort (n = 300), respectively. In addition, higher deep learning scores were associated with a lower frequency of EGFR mutation (P = .04), higher rate of ALK fusion (P = .02), and more activation of pathways of tumor proliferation (P &lt; .001). Furthermore, in the internal test set and external cohort, higher deep learning scores were predictive of poorer overall survival (adjusted hazard ratio, 2.9; 95% CI: 1.2, 6.9; P = .02) and recurrence-free survival (adjusted hazard ratio, 3.2; 95% CI: 1.4, 7.4; P = .007). Conclusion The deep learning signature could accurately predict N2 disease and stratify prognosis in clinical stage I non-small cell lung cancer. © RSNA, 2021 Online supplemental material is available for this article. See also the editorial by Park and Lee in this issue.",True,other,Not specified
34689829,Prediction of pandemic risk for animal-origin coronavirus using a deep learning method,"BACKGROUND: Coronaviruses can be isolated from bats, civets, pangolins, birds and other wild animals. As an animal-origin pathogen, coronavirus can cross species barrier and cause pandemic in humans. In this study, a deep learning model for early prediction of pandemic risk was proposed based on the sequences of viral genomes.
METHODS: A total of 3257 genomes were downloaded from the Coronavirus Genome Resource Library. We present a deep learning model of cross-species coronavirus infection that combines a bidirectional gated recurrent unit network with a one-dimensional convolution. The genome sequence of animal-origin coronavirus was directly input to extract features and predict pandemic risk. The best performances were explored with the use of pre-trained DNA vector and attention mechanism. The area under the receiver operating characteristic curve (AUROC) and the area under precision-recall curve (AUPR) were used to evaluate the predictive models.
RESULTS: The six specific models achieved good performances for the corresponding virus groups (1 for AUROC and 1 for AUPR). The general model with pre-training vector and attention mechanism provided excellent predictions for all virus groups (1 for AUROC and 1 for AUPR) while those without pre-training vector or attention mechanism had obviously reduction of performance (about 5-25%). Re-training experiments showed that the general model has good capabilities of transfer learning (average for six groups: 0.968 for AUROC and 0.942 for AUPR) and should give reasonable prediction for potential pathogen of next pandemic. The artificial negative data with the replacement of the coding region of the spike protein were also predicted correctly (100% accuracy). With the application of the Python programming language, an easy-to-use tool was created to implements our predictor.
CONCLUSIONS: Robust deep learning model with pre-training vector and attention mechanism mastered the features from the whole genomes of animal-origin coronaviruses and could predict the risk of cross-species infection for early warning of next pandemic.",True,other,Not specified
34674660,GACDN: generative adversarial feature completion and diagnosis network for COVID-19,"BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) causes tens of million infection world-wide. Many machine learning methods have been proposed for the computer-aided diagnosis between COVID-19 and community-acquired pneumonia (CAP) from chest computed tomography (CT) images. Most of these methods utilized the location-specific handcrafted features based on the segmentation results to improve the diagnose performance. However, the prerequisite segmentation step is time-consuming and needs the intervention by lots of expert radiologists, which cannot be achieved in the areas with limited medical resources.
METHODS: We propose a generative adversarial feature completion and diagnosis network (GACDN) that simultaneously generates handcrafted features by radiomic counterparts and makes accurate diagnoses based on both original and generated features. Specifically, we first calculate the radiomic features from the CT images. Then, in order to fast obtain the location-specific handcrafted features, we use the proposed GACDN to generate them by its corresponding radiomic features. Finally, we use both radiomic features and location-specific handcrafted features for COVID-19 diagnosis.
RESULTS: For the performance of our generated location-specific handcrafted features, the results of four basic classifiers show that it has an average of 3.21% increase in diagnoses accuracy. Besides, the experimental results on COVID-19 dataset show that our proposed method achieved superior performance in COVID-19 vs. community acquired pneumonia (CAP) classification compared with the state-of-the-art methods.
CONCLUSIONS: The proposed method significantly improves the diagnoses accuracy of COVID-19 vs. CAP in the condition of incomplete location-specific handcrafted features. Besides, it is also applicable in some regions lacking of expert radiologists and high-performance computing resources.",True,other,Not specified
34661658,Updates in deep learning research in ophthalmology,"Ophthalmology has been one of the early adopters of artificial intelligence (AI) within the medical field. Deep learning (DL), in particular, has garnered significant attention due to the availability of large amounts of data and digitized ocular images. Currently, AI in Ophthalmology is mainly focused on improving disease classification and supporting decision-making when treating ophthalmic diseases such as diabetic retinopathy, age-related macular degeneration (AMD), glaucoma and retinopathy of prematurity (ROP). However, most of the DL systems (DLSs) developed thus far remain in the research stage and only a handful are able to achieve clinical translation. This phenomenon is due to a combination of factors including concerns over security and privacy, poor generalizability, trust and explainability issues, unfavorable end-user perceptions and uncertain economic value. Overcoming this challenge would require a combination approach. Firstly, emerging techniques such as federated learning (FL), generative adversarial networks (GANs), autonomous AI and blockchain will be playing an increasingly critical role to enhance privacy, collaboration and DLS performance. Next, compliance to reporting and regulatory guidelines, such as CONSORT-AI and STARD-AI, will be required to in order to improve transparency, minimize abuse and ensure reproducibility. Thirdly, frameworks will be required to obtain patient consent, perform ethical assessment and evaluate end-user perception. Lastly, proper health economic assessment (HEA) must be performed to provide financial visibility during the early phases of DLS development. This is necessary to manage resources prudently and guide the development of DLS.",True,other,recurrent neural network
34649700,Proteomics-Enabled Deep Learning Machine Algorithms Can Enhance Prediction of Mortality,"BACKGROUND: Individualized risk prediction represents a prerequisite for providing personalized medicine.
OBJECTIVES: This study compared proteomics-enabled machine-learning (ML) algorithms with classical and clinical risk prediction methods for all-cause mortality in cohorts of patients with cardiovascular risk factors in the LIFE-Heart Study, followed by validation in the PLIC (Progressione della Lesione Intimale Carotidea) study.
METHODS: Using the OLINK-Cardiovascular-II panel, 92 proteins were measured in a cohort of 1,998 individuals from the LIFE-Heart Study (derivation) and 772 subjects from the PLIC cohort (external validation). We constructed protein-based mortality prediction models using eXtreme Gradient Boosting (XGBoost) and a neural network, comparing the prediction performance with classical clinical risk scores (Systemic Coronary Risk Evaluation, Framingham), logistic and Cox regression models.
RESULTS: All-cause mortality occurred in 156 (8%) patients in the internal validation and 68 (9%) patients in the external validation cohort, within a median follow-up of 10 and 11 years, respectively. On internal and external validation, the Framingham Risk Score achieved areas under the curve (AUCs) of 0.64 (95% CI: 0.59-0.68) and 0.65 (95% CI: 0.58-0.74), logistic regression AUCs of 0.65 (95% CI: 0.57-0.73) and 0.67 (95% CI: 0.59-0.74), Cox regression AUCs of 0.55 (95% CI: 0.51-0.59) and 0.65 (95% CI: 0.57-0.73), the XGBoost classifier AUCs of 0.83 (95% CI: 0.79-0.87) and 0.91 (95% CI: 0.86-0.95), the XGBoost survival estimator AUCs of 0.83 (95% CI: 0.79-0.87) and 0.93 (95% CI: 0.88-0.97), and the neural network AUCs of 0.87 (95% CI: 0.83-0.91) and 0.94 (95% CI: 0.90-0.98), respectively (modern vs classical ML: P < 0.001).
CONCLUSIONS: ML-driven multiprotein risk models outperform classical regression models and clinical scores for prediction of all-cause mortality in patients at increased cardiovascular risk.",True,other,Not specified
34636634,Content-based Image Retrieval by Using Deep Learning for Interstitial Lung Disease Diagnosis with Chest CT,"Background Evaluation of interstitial lung disease (ILD) at CT is a challenging task that requires experience and is subject to substantial interreader variability. Purpose To investigate whether a proposed content-based image retrieval (CBIR) of similar chest CT images by using deep learning can aid in the diagnosis of ILD by readers with different levels of experience. Materials and Methods This retrospective study included patients with confirmed ILD after multidisciplinary discussion and available CT images identified between January 2000 and December 2015. Database was composed of four disease classes: usual interstitial pneumonia (UIP), nonspecific interstitial pneumonia (NSIP), cryptogenic organizing pneumonia, and chronic hypersensitivity pneumonitis. Eighty patients were selected as queries from the database. The proposed CBIR retrieved the top three similar CT images with diagnosis from the database by comparing the extent and distribution of different regional disease patterns quantified by a deep learning algorithm. Eight readers with varying experience interpreted the query CT images and provided their most probable diagnosis in two reading sessions 2 weeks apart, before and after applying CBIR. Diagnostic accuracy was analyzed by using McNemar test and generalized estimating equation, and interreader agreement was analyzed by using Fleiss κ. Results A total of 288 patients were included (mean age, 58 years ± 11 [standard deviation]; 145 women). After applying CBIR, the overall diagnostic accuracy improved in all readers (before CBIR, 46.1% [95% CI: 37.1, 55.3]; after CBIR, 60.9% [95% CI: 51.8, 69.3]; P &lt; .001). In terms of disease category, the diagnostic accuracy improved after applying CBIR in UIP (before vs after CBIR, 52.4% vs 72.8%, respectively; P &lt; .001) and NSIP cases (before vs after CBIR, 42.9% vs 61.6%, respectively; P &lt; .001). Interreader agreement improved after CBIR (before vs after CBIR Fleiss κ, 0.32 vs 0.47, respectively; P = .005). Conclusion The proposed content-based image retrieval system for chest CT images with deep learning improved the diagnostic accuracy of interstitial lung disease and interreader agreement in readers with different levels of experience. © RSNA, 2021 Online supplemental material is available for this article. See also the editorial by Wielpütz in this issue.",True,other,Not specified
34630626,Pancreatic Cancer Survival Prediction: A Survey of the State-of-the-Art,"Cancer early detection increases the chances of survival. Some cancer types, like pancreatic cancer, are challenging to diagnose or detect early, and the stages have a fast progression rate. This paper presents the state-of-the-art techniques used in cancer survival prediction, suggesting how these techniques can be implemented in predicting the overall survival of pancreatic ductal adenocarcinoma cancer (pdac) patients. Because of bewildering and high volumes of data, the recent studies highlight the importance of machine learning (ML) algorithms like support vector machines and convolutional neural networks. Studies predict pancreatic ductal adenocarcinoma cancer (pdac) survival is within the limits of 41.7% at one year, 8.7% at three years, and 1.9% at five years. There is no significant correlation found between the disease stages and the overall survival rate. The implementation of ML algorithms can improve our understanding of cancer progression. ML methods need an appropriate level of validation to be considered in everyday clinical practice. The objective of these techniques is to perform classification, prediction, and estimation. Accurate predictions give pathologists information on the patient's state, surgical treatment to be done, optimal use of resources, individualized therapy, drugs to prescribe, and better patient management.",True,other,Not specified
34629796,Artificial intelligence for hepatitis evaluation,"Recently, increasing attention has been paid to the application of artificial intelligence (AI) to the diagnosis of diverse hepatic diseases, which comprises traditional machine learning and deep learning. Recent studies have shown the possible value of AI based data mining in predicting the incidence of hepatitis, classifying the different stages of hepatitis, diagnosing or screening for hepatitis, forecasting the progression of hepatitis, and predicting response to antiviral drugs in chronic hepatitis C patients. More importantly, AI based on radiology has been proven to be useful in predicting hepatitis and liver fibrosis as well as grading hepatocellular carcinoma (HCC) and differentiating it from benign liver tumors. It can predict the risk of vascular invasion of HCC, the risk of hepatic encephalopathy secondary to hepatitis B related cirrhosis, and the risk of liver failure after hepatectomy in HCC patients. In this review, we summarize the application of AI in hepatitis, and identify the challenges and future perspectives.",True,other,Not specified
34581296,Deep Learning for Discrimination Between Fungal Keratitis and Bacterial Keratitis: DeepKeratitis,"PURPOSE: Microbial keratitis is an urgent condition in ophthalmology that requires prompt treatment. This study aimed to apply deep learning algorithms for rapidly discriminating between fungal keratitis (FK) and bacterial keratitis (BK).
METHODS: A total of 2167 anterior segment images retrospectively acquired from 194 patients with 128 patients with BK (1388 images, 64.1%) and 66 patients with FK (779 images, 35.9%) were used to develop the model. The images were split into training, validation, and test sets. Three convolutional neural networks consisting of VGG19, ResNet50, and DenseNet121 were trained to classify images. Performance of each model was evaluated using precision (positive predictive value), sensitivity (recall), F1 score (test's accuracy), and area under the precision-recall curve (AUPRC). Ensemble learning was then applied to improve classification performance.
RESULTS: The classification performance in F1 score (95% confident interval) of VGG19, DenseNet121, and RestNet50 was 0.78 (0.72-0.84), 0.71 (0.64-0.78), and 0.68 (0.61-0.75), respectively. VGG19 also demonstrated the highest AUPRC of 0.86 followed by RestNet50 (0.73) and DenseNet (0.60). The ensemble learning could improve performance with the sensitivity and F1 score of 0.77 (0.81-0.83) and 0.83 (0.77-0.89) with an AUPRC of 0.904.
CONCLUSIONS: Convolutional neural network with ensemble learning showed the best performance in discriminating FK from BK compared with single architecture models. Our model can potentially be considered as an adjunctive tool for providing rapid provisional diagnosis in patients with microbial keratitis.",True,other,recurrent neural network
34580407,Identifying individuals with recent COVID-19 through voice classification using deep learning,"Recently deep learning has attained a breakthrough in model accuracy for the classification of images due mainly to convolutional neural networks. In the present study, we attempted to investigate the presence of subclinical voice feature alteration in COVID-19 patients after the recent resolution of disease using deep learning. The study was a prospective study of 76 post COVID-19 patients and 40 healthy individuals. The diagnoses of post COVID-19 patients were based on more than the eighth week after onset of symptoms. Voice samples of an 'ah' sound, coughing sound and a polysyllabic sentence were collected and preprocessed to log-mel spectrogram. Transfer learning using the VGG19 pre-trained convolutional neural network was performed with all voice samples. The performance of the model using the polysyllabic sentence yielded the highest classification performance of all models. The coughing sound produced the lowest classification performance while the ability of the monosyllabic 'ah' sound to predict the recent COVID-19 fell between the other two vocalizations. The model using the polysyllabic sentence achieved 85% accuracy, 89% sensitivity, and 77% specificity. In conclusion, deep learning is able to detect the subtle change in voice features of COVID-19 patients after recent resolution of the disease.",True,other,recurrent neural network
34571160,Deep learning from MRI-derived labels enables automatic brain tissue classification on human brain CT,"Automatic methods for feature extraction, volumetry, and morphometric analysis in clinical neuroscience typically operate on images obtained with magnetic resonance (MR) imaging equipment. Although CT scans are less expensive to acquire and more widely available than MR scans, their application is currently limited to the visual assessment of brain integrity and the exclusion of co-pathologies. CT has rarely been used for tissue classification because the contrast between grey matter and white matter was considered insufficient. In this study, we propose an automatic method for segmenting grey matter (GM), white matter (WM), cerebrospinal fluid (CSF), and intracranial volume (ICV) from head CT images. A U-Net deep learning model was trained and validated on CT images with MRI-derived segmentation labels. We used data from 744 participants of the Gothenburg H70 Birth Cohort Studies for whom CT and T1-weighted MR images had been acquired on the same day. Our proposed model predicted brain tissue classes accurately from unseen CT images (Dice coefficients of 0.79, 0.82, 0.75, 0.93 and 0.98 for GM, WM, CSF, brain volume and ICV, respectively). To contextualize these results, we generated benchmarks based on established MR-based methods and intentional image degradation. Our findings demonstrate that CT-derived segmentations can be used to delineate and quantify brain tissues, opening new possibilities for the use of CT in clinical practice and research.",True,both,Not specified
34561876,Weakly supervised annotation-free cancer detection and prediction of genotype in routine histopathology,"Deep learning is a powerful tool in computational pathology: it can be used for tumor detection and for predicting genetic alterations based on histopathology images alone. Conventionally, tumor detection and prediction of genetic alterations are two separate workflows. Newer methods have combined them, but require complex, manually engineered computational pipelines, restricting reproducibility and robustness. To address these issues, we present a new method for simultaneous tumor detection and prediction of genetic alterations: The Slide-Level Assessment Model (SLAM) uses a single off-the-shelf neural network to predict molecular alterations directly from routine pathology slides without any manual annotations, improving upon previous methods by automatically excluding normal and non-informative tissue regions. SLAM requires only standard programming libraries and is conceptually simpler than previous approaches. We have extensively validated SLAM for clinically relevant tasks using two large multicentric cohorts of colorectal cancer patients, Darmkrebs: Chancen der Verhütung durch Screening (DACHS) from Germany and Yorkshire Cancer Research Bowel Cancer Improvement Programme (YCR-BCIP) from the UK. We show that SLAM yields reliable slide-level classification of tumor presence with an area under the receiver operating curve (AUROC) of 0.980 (confidence interval 0.975, 0.984; n = 2,297 tumor and n = 1,281 normal slides). In addition, SLAM can detect microsatellite instability (MSI)/mismatch repair deficiency (dMMR) or microsatellite stability/mismatch repair proficiency with an AUROC of 0.909 (0.888, 0.929; n = 2,039 patients) and BRAF mutational status with an AUROC of 0.821 (0.786, 0.852; n = 2,075 patients). The improvement with respect to previous methods was validated in a large external testing cohort in which MSI/dMMR status was detected with an AUROC of 0.900 (0.864, 0.931; n = 805 patients). In addition, SLAM provides human-interpretable visualization maps, enabling the analysis of multiplexed network predictions by human experts. In summary, SLAM is a new simple and powerful method for computational pathology that could be applied to multiple disease contexts. © 2021 The Authors. The Journal of Pathology published by John Wiley & Sons, Ltd. on behalf of The Pathological Society of Great Britain and Ireland.",True,other,recurrent neural network
34559310,Machine learning in gastrointestinal surgery,"Machine learning (ML) is a collection of algorithms allowing computers to learn directly from data without predetermined equations. It is used widely to analyze ""big data"". In gastrointestinal surgery, surgeons deal with various data such as clinical parameters, surgical videos, and pathological images, to stratify surgical risk, perform safe surgery and predict patient prognosis. In the current ""big data"" era, the accelerating accumulation of a large amount of data drives studies using ML algorithms. Three subfields of ML are supervised learning, unsupervised learning, and reinforcement learning. In this review, we summarize applications of ML to surgical practice in the preoperative, intraoperative, and postoperative phases of care. Prediction and stratification using ML is promising; however, the current overarching concern is the availability of ML models. Information systems that can manage ""big data"" and integrate ML models into electronic health records are essential to incorporate ML into daily practice. ML is fundamental technology to meaningfully process data that exceeds the capacity of the human mind to comprehend. The accelerating accumulation of a large amount of data is changing the nature of surgical practice fundamentally. Artificial intelligence (AI), represented by ML, is being incorporated into daily surgical practice.",True,other,recurrent neural network
36417211,Data-Driven Deep-Learning Algorithm for Asymptomatic COVID-19 Model with Varying Mitigation Measures and Transmission Rate,"Epidemiological models with constant parameters may not capture satisfactory infection patterns in the presence of pharmaceutical and non-pharmaceutical mitigation measures during a pandemic, since infectiousness is a function of time. In this paper, an Epidemiology-Informed Neural Network algorithm is introduced to learn the time-varying transmission rate for the COVID-19 pandemic in the presence of various mitigation scenarios. There are asymptomatic infectives, mostly unreported, and the proposed algorithm learns the proportion of the total infective individuals that are asymptomatic infectives. Using cumulative and daily reported cases of the symptomatic infectives, we simulate the impact of non-pharmaceutical mitigation measures such as early detection of infectives, contact tracing, and social distancing on the basic reproduction number. We demonstrate the effectiveness of vaccination on the transmission of COVID-19. The accuracy of the proposed algorithm is demonstrated using error metrics in the data-driven simulation for COVID-19 data of Italy, South Korea, the United Kingdom, and the United States.",True,other,Not specified
34546931,New Insights Into Drug Repurposing for COVID-19 Using Deep Learning,"The coronavirus disease 2019 (COVID-19) has continued to spread worldwide since late 2019. To expedite the process of providing treatment to those who have contracted the disease and to ensure the accessibility of effective drugs, numerous strategies have been implemented to find potential anti-COVID-19 drugs in a short span of time. Motivated by this critical global challenge, in this review, we detail approaches that have been used for drug repurposing for COVID-19 and suggest improvements to the existing deep learning (DL) approach to identify and repurpose drugs to treat this complex disease. By optimizing hyperparameter settings, deploying suitable activation functions, and designing optimization algorithms, the improved DL approach will be able to perform feature extraction from quality big data, turning the traditional DL approach, referred to as a ""black box,"" which generalizes and learns the transmitted data, into a ""glass box"" that will have the interpretability of its rationale while maintaining a high level of prediction accuracy. When adopted for drug repurposing for COVID-19, this improved approach will create a new generation of DL approaches that can establish a cause and effect relationship as to why the repurposed drugs are suitable for treating COVID-19. Its ability can also be extended to repurpose drugs for other complex diseases, develop appropriate treatment strategies for new diseases, and provide precision medical treatment to patients, thus paving the way to discover new drugs that can potentially be effective for treating COVID-19.",True,other,Not specified
34541769,Medical student knowledge and critical appraisal of machine learning: a multicentre international cross-sectional study,"To utilise effectively tools that employ machine learning (ML) in clinical practice medical students and doctors will require a degree of understanding of ML models. To evaluate current levels of understanding, a formative examination and survey was conducted across three centres in Australia, New Zealand and the United States. Of the 245 individuals who participated in the study (response rate = 45.4%), the majority had difficulty with identifying weaknesses in model performance analysis. Further studies examining educational interventions addressing such ML topics are warranted.",True,other,Not specified
34535759,GenNet framework: interpretable deep learning for predicting phenotypes from genetic data,"Applying deep learning in population genomics is challenging because of computational issues and lack of interpretable models. Here, we propose GenNet, a novel open-source deep learning framework for predicting phenotypes from genetic variants. In this framework, interpretable and memory-efficient neural network architectures are constructed by embedding biologically knowledge from public databases, resulting in neural networks that contain only biologically plausible connections. We applied the framework to seventeen phenotypes and found well-replicated genes such as HERC2 and OCA2 for hair and eye color, and novel genes such as ZNF773 and PCNT for schizophrenia. Additionally, the framework identified ubiquitin mediated proteolysis, endocrine system and viral infectious diseases as most predictive biological pathways for schizophrenia. GenNet is a freely available, end-to-end deep learning framework that allows researchers to develop and use interpretable neural networks to obtain novel insights into the genetic architecture of complex traits and diseases.",True,other,recurrent neural network
34531005,Resolution-based distillation for efficient histology image classification,"Developing deep learning models to analyze histology images has been computationally challenging, as the massive size of the images causes excessive strain on all parts of the computing pipeline. This paper proposes a novel deep learning-based methodology for improving the computational efficiency of histology image classification. The proposed approach is robust when used with images that have reduced input resolution, and it can be trained effectively with limited labeled data. Moreover, our approach operates at either the tissue- or slide-level, removing the need for laborious patch-level labeling. Our method uses knowledge distillation to transfer knowledge from a teacher model pre-trained at high resolution to a student model trained on the same images at a considerably lower resolution. Also, to address the lack of large-scale labeled histology image datasets, we perform the knowledge distillation in a self-supervised fashion. We evaluate our approach on three distinct histology image datasets associated with celiac disease, lung adenocarcinoma, and renal cell carcinoma. Our results on these datasets demonstrate that a combination of knowledge distillation and self-supervision allows the student model to approach and, in some cases, surpass the teacher model's classification accuracy while being much more computationally efficient. Additionally, we observe an increase in student classification performance as the size of the unlabeled dataset increases, indicating that there is potential for this method to scale further with additional unlabeled data. Our model outperforms the high-resolution teacher model for celiac disease in accuracy, F1-score, precision, and recall while requiring 4 times fewer computations. For lung adenocarcinoma, our results at 1.25× magnification are within 1.5% of the results for the teacher model at 10× magnification, with a reduction in computational cost by a factor of 64. Our model on renal cell carcinoma at 1.25× magnification performs within 1% of the teacher model at 5× magnification while requiring 16 times fewer computations. Furthermore, our celiac disease outcomes benefit from additional performance scaling with the use of more unlabeled data. In the case of 0.625× magnification, using unlabeled data improves accuracy by 4% over the tissue-level baseline. Therefore, our approach can improve the feasibility of deep learning solutions for digital pathology on standard computational hardware and infrastructures.",True,other,convolutional neural network
34524095,Deep Learning for Identification of Alcohol-Related Content on Social Media (Reddit and Twitter): Exploratory Analysis of Alcohol-Related Outcomes,"BACKGROUND: Many social media studies have explored the ability of thematic structures, such as hashtags and subreddits, to identify information related to a wide variety of mental health disorders. However, studies and models trained on specific themed communities are often difficult to apply to different social media platforms and related outcomes. A deep learning framework using thematic structures from Reddit and Twitter can have distinct advantages for studying alcohol abuse, particularly among the youth in the United States.
OBJECTIVE: This study proposes a new deep learning pipeline that uses thematic structures to identify alcohol-related content across different platforms. We apply our method on Twitter to determine the association of the prevalence of alcohol-related tweets with alcohol-related outcomes reported from the National Institute of Alcoholism and Alcohol Abuse, Centers for Disease Control Behavioral Risk Factor Surveillance System, county health rankings, and the National Industry Classification System.
METHODS: The Bidirectional Encoder Representations From Transformers neural network learned to classify 1,302,524 Reddit posts as either alcohol-related or control subreddits. The trained model identified 24 alcohol-related hashtags from an unlabeled data set of 843,769 random tweets. Querying alcohol-related hashtags identified 25,558,846 alcohol-related tweets, including 790,544 location-specific (geotagged) tweets. We calculated the correlation between the prevalence of alcohol-related tweets and alcohol-related outcomes, controlling for confounding effects of age, sex, income, education, and self-reported race, as recorded by the 2013-2018 American Community Survey.
RESULTS: Significant associations were observed: between alcohol-hashtagged tweets and alcohol consumption (P=.01) and heavy drinking (P=.005) but not binge drinking (P=.37), self-reported at the metropolitan-micropolitan statistical area level; between alcohol-hashtagged tweets and self-reported excessive drinking behavior (P=.03) but not motor vehicle fatalities involving alcohol (P=.21); between alcohol-hashtagged tweets and the number of breweries (P<.001), wineries (P<.001), and beer, wine, and liquor stores (P<.001) but not drinking places (P=.23), per capita at the US county and county-equivalent level; and between alcohol-hashtagged tweets and all gallons of ethanol consumed (P<.001), as well as ethanol consumed from wine (P<.001) and liquor (P=.01) sources but not beer (P=.63), at the US state level.
CONCLUSIONS: Here, we present a novel natural language processing pipeline developed using Reddit's alcohol-related subreddits that identify highly specific alcohol-related Twitter hashtags. The prevalence of identified hashtags contains interpretable information about alcohol consumption at both coarse (eg, US state) and fine-grained (eg, metropolitan-micropolitan statistical area level and county) geographical designations. This approach can expand research and deep learning interventions on alcohol abuse and other behavioral health outcomes.",True,other,Not specified
34506041,Deep learning versus ophthalmologists for screening for glaucoma on fundus examination: A systematic review and meta-analysis,"BACKGROUND: In this systematic review and meta-analysis, we aimed to compare deep learning versus ophthalmologists in glaucoma diagnosis on fundus examinations.
METHOD: PubMed, Cochrane, Embase, ClinicalTrials.gov and ScienceDirect databases were searched for studies reporting a comparison between the glaucoma diagnosis performance of deep learning and ophthalmologists on fundus examinations on the same datasets, until 10 December 2020. Studies had to report an area under the receiver operating characteristics (AUC) with SD or enough data to generate one.
RESULTS: We included six studies in our meta-analysis. There was no difference in AUC between ophthalmologists (AUC = 82.0, 95% confidence intervals [CI] 65.4-98.6) and deep learning (97.0, 89.4-104.5). There was also no difference using several pessimistic and optimistic variants of our meta-analysis: the best (82.2, 60.0-104.3) or worst (77.7, 53.1-102.3) ophthalmologists versus the best (97.1, 89.5-104.7) or worst (97.1, 88.5-105.6) deep learning of each study. We did not retrieve any factors influencing those results.
CONCLUSION: Deep learning had similar performance compared to ophthalmologists in glaucoma diagnosis from fundus examinations. Further studies should evaluate deep learning in clinical situations.",True,other,Not specified
34504594,Emerging deep learning techniques using magnetic resonance imaging data applied in multiple sclerosis and clinical isolated syndrome patients (Review),"Computer-aided diagnosis systems aim to assist clinicians in the early identification of abnormal signs in order to optimize the interpretation of medical images and increase diagnostic precision. Multiple sclerosis (MS) and clinically isolated syndrome (CIS) are chronic inflammatory, demyelinating diseases affecting the central nervous system. Recent advances in deep learning (DL) techniques have led to novel computational paradigms in MS and CIS imaging designed for automatic segmentation and detection of areas of interest and automatic classification of anatomic structures, as well as optimization of neuroimaging protocols. To this end, there are several publications presenting artificial intelligence-based predictive models aiming to increase diagnostic accuracy and to facilitate optimal clinical management in patients diagnosed with MS and/or CIS. The current study presents a thorough review covering DL techniques that have been applied in MS and CIS during recent years, shedding light on their current advances and limitations.",True,both,recurrent neural network
34503679,Hypertrophic Cardiomyopathy in the General Population: Leveraging the UK Biobank Database and Machine Learning Phenotyping,,True,other,GAN
34491135,Breast Cancer Risk Prediction Using Deep Learning,,True,other,GAN
34491131,Deep Learning Predicts Interval and Screening-detected Cancer from Screening Mammograms: A Case-Case-Control Study in 6369 Women,"Background The ability of deep learning (DL) models to classify women as at risk for either screening mammography-detected or interval cancer (not detected at mammography) has not yet been explored in the literature. Purpose To examine the ability of DL models to estimate the risk of interval and screening-detected breast cancers with and without clinical risk factors. Materials and Methods This study was performed on 25 096 digital screening mammograms obtained from January 2006 to December 2013. The mammograms were obtained in 6369 women without breast cancer, 1609 of whom developed screening-detected breast cancer and 351 of whom developed interval invasive breast cancer. A DL model was trained on the negative mammograms to classify women into those who did not develop cancer and those who developed screening-detected cancer or interval invasive cancer. Model effectiveness was evaluated as a matched concordance statistic (C statistic) in a held-out 26% (1669 of 6369) test set of the mammograms. Results The C statistics and odds ratios for comparing patients with screening-detected cancer versus matched controls were 0.66 (95% CI: 0.63, 0.69) and 1.25 (95% CI: 1.17, 1.33), respectively, for the DL model, 0.62 (95% CI: 0.59, 0.65) and 2.14 (95% CI: 1.32, 3.45) for the clinical risk factors with the Breast Imaging Reporting and Data System (BI-RADS) density model, and 0.66 (95% CI: 0.63, 0.69) and 1.21 (95% CI: 1.13, 1.30) for the combined DL and clinical risk factors model. For comparing patients with interval cancer versus controls, the C statistics and odds ratios were 0.64 (95% CI: 0.58, 0.71) and 1.26 (95% CI: 1.10, 1.45), respectively, for the DL model, 0.71 (95% CI: 0.65, 0.77) and 7.25 (95% CI: 2.94, 17.9) for the risk factors with BI-RADS density (b rated vs non-b rated) model, and 0.72 (95% CI: 0.66, 0.78) and 1.10 (95% CI: 0.94, 1.29) for the combined DL and clinical risk factors model. The P values between the DL, BI-RADS, and combined model's ability to detect screen and interval cancer were .99, .002, and .03, respectively. Conclusion The deep learning model outperformed in determining screening-detected cancer risk but underperformed for interval cancer risk when compared with clinical risk factors including breast density. © RSNA, 2021 Online supplemental material is available for this article. See also the editorial by Bae and Kim in this issue.",True,other,Not specified
34475453,Identification of vaccine targets in pathogens and design of a vaccine using computational approaches,"Antigen identification is an important step in the vaccine development process. Computational approaches including deep learning systems can play an important role in the identification of vaccine targets using genomic and proteomic information. Here, we present a new computational system to discover and analyse novel vaccine targets leading to the design of a multi-epitope subunit vaccine candidate. The system incorporates reverse vaccinology and immuno-informatics tools to screen genomic and proteomic datasets of several pathogens such as Trypanosoma cruzi, Plasmodium falciparum, and Vibrio cholerae to identify potential vaccine candidates (PVC). Further, as a case study, we performed a detailed analysis of the genomic and proteomic dataset of T. cruzi (CL Brenner and Y strain) to shortlist eight proteins as possible vaccine antigen candidates using properties such as secretory/surface-exposed nature, low transmembrane helix (< 2), essentiality, virulence, antigenic, and non-homology with host/gut flora proteins. Subsequently, highly antigenic and immunogenic MHC class I, MHC class II and B cell epitopes were extracted from top-ranking vaccine targets. The designed vaccine construct containing 24 epitopes, 3 adjuvants, and 4 linkers was analysed for its physicochemical properties using different tools, including docking analysis. Immunological simulation studies suggested significant levels of T-helper, T-cytotoxic cells, and IgG1 will be elicited upon administration of such a putative multi-epitope vaccine construct. The vaccine construct is predicted to be soluble, stable, non-allergenic, non-toxic, and to offer cross-protection against related Trypanosoma species and strains. Further, studies are required to validate safety and immunogenicity of the vaccine.",True,other,Not specified
34465838,Predicting hosts based on early SARS-CoV-2 samples and analyzing the 2020 pandemic,"The SARS-CoV-2 pandemic has raised concerns in the identification of the hosts of the virus since the early stages of the outbreak. To address this problem, we proposed a deep learning method, DeepHoF, based on extracting viral genomic features automatically, to predict the host likelihood scores on five host types, including plant, germ, invertebrate, non-human vertebrate and human, for novel viruses. DeepHoF made up for the lack of an accurate tool, reaching a satisfactory AUC of 0.975 in the five-classification, and could make a reliable prediction for the novel viruses without close neighbors in phylogeny. Additionally, to fill the gap in the efficient inference of host species for SARS-CoV-2 using existing tools, we conducted a deep analysis on the host likelihood profile calculated by DeepHoF. Using the isolates sequenced in the earliest stage of the COVID-19 pandemic, we inferred that minks, bats, dogs and cats were potential hosts of SARS-CoV-2, while minks might be one of the most noteworthy hosts. Several genes of SARS-CoV-2 demonstrated their significance in determining the host range. Furthermore, a large-scale genome analysis, based on DeepHoF's computation for the later pandemic in 2020, disclosed the uniformity of host range among SARS-CoV-2 samples and the strong association of SARS-CoV-2 between humans and minks.",True,other,recurrent neural network
34464403,Predicting mortality among patients with liver cirrhosis in electronic health records with machine learning,"OBJECTIVE: Liver cirrhosis is a leading cause of death and effects millions of people in the United States. Early mortality prediction among patients with cirrhosis might give healthcare providers more opportunity to effectively treat the condition. We hypothesized that laboratory test results and other related diagnoses would be associated with mortality in this population. Our another assumption was that a deep learning model could outperform the current Model for End Stage Liver disease (MELD) score in predicting mortality.
MATERIALS AND METHODS: We utilized electronic health record data from 34,575 patients with a diagnosis of cirrhosis from a large medical center to study associations with mortality. Three time-windows of mortality (365 days, 180 days and 90 days) and two cases with different number of variables (all 41 available variables and 4 variables in MELD-NA) were studied. Missing values were imputed using multiple imputation for continuous variables and mode for categorical variables. Deep learning and machine learning algorithms, i.e., deep neural networks (DNN), random forest (RF) and logistic regression (LR) were employed to study the associations between baseline features such as laboratory measurements and diagnoses for each time window by 5-fold cross validation method. Metrics such as area under the receiver operating curve (AUC), overall accuracy, sensitivity, and specificity were used to evaluate models.
RESULTS: Performance of models comprising all variables outperformed those with 4 MELD-NA variables for all prediction cases and the DNN model outperformed the LR and RF models. For example, the DNN model achieved an AUC of 0.88, 0.86, and 0.85 for 90, 180, and 365-day mortality respectively as compared to the MELD score, which resulted in corresponding AUCs of 0.81, 0.79, and 0.76 for the same instances. The DNN and LR models had a significantly better f1 score compared to MELD at all time points examined.
CONCLUSION: Other variables such as alkaline phosphatase, alanine aminotransferase, and hemoglobin were also top informative features besides the 4 MELD-Na variables. Machine learning and deep learning models outperformed the current standard of risk prediction among patients with cirrhosis. Advanced informatics techniques showed promise for risk prediction in patients with cirrhosis.",True,other,Not specified
34454080,Long-term prediction for temporal propagation of seasonal influenza using Transformer-based model,"Influenza is one of the most common infectious diseases worldwide, which causes a considerable economic burden on hospitals and other healthcare costs. Predicting new and urgent trends in epidemiological data is an effective way to prevent influenza outbreaks and protect public health. Traditional autoregressive(AR) methods and new deep learning models like Recurrent Neural Network(RNN) have been actively studied to solve the problem. Most existing studies focus on the short-term prediction of influenza. Recently, Transformer models show superior performance in capturing long-range dependency than RNN models. In this paper, we develop a Transformer-based model, which utilizes the potential of the Transformer to increase the prediction capacity. To fuse information from data of different sources and capture the spatial dependency, we design a sources selection module based on measuring curve similarity. Our model is compared with the widely used AR models and RNN-based models on USA and Japan datasets. Results show that our approach provides approximate performance in short-term forecasting and better performance in long-term forecasting.",True,other,recurrent neural network
34453631,"Exploring domains, clinical implications and environmental associations of a deep learning marker of biological ageing","Deep Neural Networks (DNN) have been recently developed for the estimation of Biological Age (BA), the hypothetical underlying age of an organism, which can differ from its chronological age (CA). Although promising, these population-specific algorithms warrant further characterization and validation, since their biological, clinical and environmental correlates remain largely unexplored. Here, an accurate DNN was trained to compute BA based on 36 circulating biomarkers in an Italian population (N = 23,858; age ≥ 35 years; 51.7% women). This estimate was heavily influenced by markers of metabolic, heart, kidney and liver function. The resulting Δage (BA-CA) significantly predicted mortality and hospitalization risk for all and specific causes. Slowed biological aging (Δage < 0) was associated with higher physical and mental wellbeing, healthy lifestyles (e.g. adherence to Mediterranean diet) and higher socioeconomic status (educational attainment, household income and occupational status), while accelerated aging (Δage > 0) was associated with smoking and obesity. Together, lifestyles and socioeconomic variables explained ~48% of the total variance in Δage, potentially suggesting the existence of a genetic basis. These findings validate blood-based biological aging as a marker of public health in adult Italians and provide a robust body of knowledge on its biological architecture, clinical implications and potential environmental influences.",True,other,recurrent neural network
34453413,The role of deep learning-based survival model in improving survival prediction of patients with glioblastoma,"This retrospective study has been conducted to validate the performance of deep learning-based survival models in glioblastoma (GBM) patients alongside the Cox proportional hazards model (CoxPH) and the random survival forest (RSF). Furthermore, the effect of hyperparameters optimization methods on improving the prediction accuracy of deep learning-based survival models was investigated. Of the 305 cases, 260 GBM patients were included in our analysis based on the following criteria: demographic information (i.e., age, Karnofsky performance score, gender, and race), tumor characteristic (i.e., laterality and location), details of post-surgical treatment (i.e., time to initiate concurrent chemoradiation therapy, standard treatment, and radiotherapy techniques), and last follow-up time as well as the molecular markers (i.e., O-6-methylguanine methyltransferase and isocitrate dehydrogenase 1 status). Experimental results have demonstrated that age (Elderly > 65: hazard ratio [HR] = 1.63; 95% confidence interval [CI]: 1.213-2.18; p value = 0.001) and tumors located at multiple lobes ([HR] = 1.75; 95% [CI]: 1.177-2.61; p value = 0.006) were associated with poorer prognosis. In contrast, age (young < 40: [HR] = 0.57; 95% [CI]: 0.343-0.96; p value = 0.034) and type of radiotherapy (others include stereotactic and brachytherapy: [HR] = 0.5; 95%[CI]: 0.266-0.95; p value = 0.035) were significantly related to better prognosis. Furthermore, the proposed deep learning-based survival model (concordance index [c-index] = 0.823 configured by Bayesian hyperparameter optimization), outperformed the RSF (c-index = 0.728), and the CoxPH model (c-index = 0.713) in the training dataset. Our results show the ability of deep learning in learning a complex association of risk factors. Moreover, the remarkable performance of the deep-learning-based survival model could be promising to support decision-making systems in personalized medicine for patients with GBM.",True,other,Not specified
34441052,Effect of Patient Clinical Variables in Osteoporosis Classification Using Hip X-rays in Deep Learning Analysis,"Background and Objectives: A few deep learning studies have reported that combining image features with patient variables enhanced identification accuracy compared with image-only models. However, previous studies have not statistically reported the additional effect of patient variables on the image-only models. This study aimed to statistically evaluate the osteoporosis identification ability of deep learning by combining hip radiographs with patient variables. Materials andMethods: We collected a dataset containing 1699 images from patients who underwent skeletal-bone-mineral density measurements and hip radiography at a general hospital from 2014 to 2021. Osteoporosis was assessed from hip radiographs using convolutional neural network (CNN) models (ResNet18, 34, 50, 101, and 152). We also investigated ensemble models with patient clinical variables added to each CNN. Accuracy, precision, recall, specificity, F1 score, and area under the curve (AUC) were calculated as performance metrics. Furthermore, we statistically compared the accuracy of the image-only model with that of an ensemble model that included images plus patient factors, including effect size for each performance metric. Results: All metrics were improved in the ResNet34 ensemble model compared with the image-only model. The AUC score in the ensemble model was significantly improved compared with the image-only model (difference 0.004; 95% CI 0.002-0.0007; p = 0.0004, effect size: 0.871). Conclusions: This study revealed the additional effect of patient variables in identification of osteoporosis using deep CNNs with hip radiographs. Our results provided evidence that the patient variables had additive synergistic effects on the image in osteoporosis identification.",True,other,Not specified
34415016,DLpTCR: an ensemble deep learning framework for predicting immunogenic peptide recognized by T cell receptor,"Accurate prediction of immunogenic peptide recognized by T cell receptor (TCR) can greatly benefit vaccine development and cancer immunotherapy. However, identifying immunogenic peptides accurately is still a huge challenge. Most of the antigen peptides predicted in silico fail to elicit immune responses in vivo without considering TCR as a key factor. This inevitably causes costly and time-consuming experimental validation test for predicted antigens. Therefore, it is necessary to develop novel computational methods for precisely and effectively predicting immunogenic peptide recognized by TCR. Here, we described DLpTCR, a multimodal ensemble deep learning framework for predicting the likelihood of interaction between single/paired chain(s) of TCR and peptide presented by major histocompatibility complex molecules. To investigate the generality and robustness of the proposed model, COVID-19 data and IEDB data were constructed for independent evaluation. The DLpTCR model exhibited high predictive power with area under the curve up to 0.91 on COVID-19 data while predicting the interaction between peptide and single TCR chain. Additionally, the DLpTCR model achieved the overall accuracy of 81.03% on IEDB data while predicting the interaction between peptide and paired TCR chains. The results demonstrate that DLpTCR has the ability to learn general interaction rules and generalize to antigen peptide recognition by TCR. A user-friendly webserver is available at http://jianglab.org.cn/DLpTCR/. Additionally, a stand-alone software package that can be downloaded from https://github.com/jiangBiolab/DLpTCR.",True,other,Not specified
34412841,The Physiological Deep Learner: First application of multitask deep learning to predict hypotension in critically ill patients,"Critical care clinicians are trained to analyze simultaneously multiple physiological parameters to predict critical conditions such as hemodynamic instability. We developed the Multi-task Learning Physiological Deep Learner (MTL-PDL), a deep learning algorithm that predicts simultaneously the mean arterial pressure (MAP) and the heart rate (HR). In an external validation dataset, our model exhibited very good calibration: R2 of 0.747 (95% confidence interval, 0.692 to 0.794) and 0.850 (0.815 to 0.879) for respectively, MAP and HR prediction 60-minutes ahead of time. For acute hypotensive episodes defined as a MAP below 65 mmHg for 5 min, our MTL-PDL reached a predictive value of 90% for patients at very high risk (predicted MAP ≤ 60 mmHg) and 2‰ for patients at low risk (predicted MAP &gt;70 mmHg). Based on its excellent prediction performance, the Physiological Deep Learner has the potential to help the clinician proactively adjust the treatment in order to avoid hypotensive episodes and end-organ hypoperfusion.",True,other,RNN
34402800,Gender Prediction for a Multiethnic Population via Deep Learning Across Different Retinal Fundus Photograph Fields: Retrospective Cross-sectional Study,"BACKGROUND: Deep learning algorithms have been built for the detection of systemic and eye diseases based on fundus photographs. The retina possesses features that can be affected by gender differences, and the extent to which these features are captured via photography differs depending on the retinal image field.
OBJECTIVE: We aimed to compare deep learning algorithms' performance in predicting gender based on different fields of fundus photographs (optic disc-centered, macula-centered, and peripheral fields).
METHODS: This retrospective cross-sectional study included 172,170 fundus photographs of 9956 adults aged ≥40 years from the Singapore Epidemiology of Eye Diseases Study. Optic disc-centered, macula-centered, and peripheral field fundus images were included in this study as input data for a deep learning model for gender prediction. Performance was estimated at the individual level and image level. Receiver operating characteristic curves for binary classification were calculated.
RESULTS: The deep learning algorithms predicted gender with an area under the receiver operating characteristic curve (AUC) of 0.94 at the individual level and an AUC of 0.87 at the image level. Across the three image field types, the best performance was seen when using optic disc-centered field images (younger subgroups: AUC=0.91; older subgroups: AUC=0.86), and algorithms that used peripheral field images had the lowest performance (younger subgroups: AUC=0.85; older subgroups: AUC=0.76). Across the three ethnic subgroups, algorithm performance was lowest in the Indian subgroup (AUC=0.88) compared to that in the Malay (AUC=0.91) and Chinese (AUC=0.91) subgroups when the algorithms were tested on optic disc-centered images. Algorithms' performance in gender prediction at the image level was better in younger subgroups (aged <65 years; AUC=0.89) than in older subgroups (aged ≥65 years; AUC=0.82).
CONCLUSIONS: We confirmed that gender among the Asian population can be predicted with fundus photographs by using deep learning, and our algorithms' performance in terms of gender prediction differed according to the field of fundus photographs, age subgroups, and ethnic groups. Our work provides a further understanding of using deep learning models for the prediction of gender-related diseases. Further validation of our findings is still needed.",True,both,recurrent neural network
34394982,Accuracy of Deep Learning Algorithms for the Diagnosis of Retinopathy of Prematurity by Fundus Images: A Systematic Review and Meta-Analysis,"BACKGROUND: Retinopathy of prematurity (ROP) occurs in preterm infants and may contribute to blindness. Deep learning (DL) models have been used for ophthalmologic diagnoses. We performed a systematic review and meta-analysis of published evidence to summarize and evaluate the diagnostic accuracy of DL algorithms for ROP by fundus images.
METHODS: We searched PubMed, EMBASE, Web of Science, and Institute of Electrical and Electronics Engineers Xplore Digital Library on June 13, 2021, for studies using a DL algorithm to distinguish individuals with ROP of different grades, which provided accuracy measurements. The pooled sensitivity and specificity values and the area under the curve (AUC) of summary receiver operating characteristics curves (SROC) summarized overall test performance. The performances in validation and test datasets were assessed together and separately. Subgroup analyses were conducted between the definition and grades of ROP. Threshold and nonthreshold effects were tested to assess biases and evaluate accuracy factors associated with DL models.
RESULTS: Nine studies with fifteen classifiers were included in our meta-analysis. A total of 521,586 objects were applied to DL models. For combined validation and test datasets in each study, the pooled sensitivity and specificity were 0.953 (95% confidence intervals (CI): 0.946-0.959) and 0.975 (0.973-0.977), respectively, and the AUC was 0.984 (0.978-0.989). For the validation dataset and test dataset, the AUC was 0.977 (0.968-0.986) and 0.987 (0.982-0.992), respectively. In the subgroup analysis of ROP vs. normal and differentiation of two ROP grades, the AUC was 0.990 (0.944-0.994) and 0.982 (0.964-0.999), respectively.
CONCLUSIONS: Our study shows that DL models can play an essential role in detecting and grading ROP with high sensitivity, specificity, and repeatability. The application of a DL-based automated system may improve ROP screening and diagnosis in the future.",True,other,Not specified
34389782,Deep learning-based gene selection in comprehensive gene analysis in pancreatic cancer,"The selection of genes that are important for obtaining gene expression data is challenging. Here, we developed a deep learning-based feature selection method suitable for gene selection. Our novel deep learning model includes an additional feature-selection layer. After model training, the units in this layer with high weights correspond to the genes that worked effectively in the processing of the networks. Cancer tissue samples and adjacent normal pancreatic tissue samples were collected from 13 patients with pancreatic ductal adenocarcinoma during surgery and subsequently frozen. After processing, gene expression data were extracted from the specimens using RNA sequencing. Task 1 for the model training was to discriminate between cancerous and normal pancreatic tissue in six patients. Task 2 was to discriminate between patients with pancreatic cancer (n = 13) who survived for more than one year after surgery. The most frequently selected genes were ACACB, ADAMTS6, NCAM1, and CADPS in Task 1, and CD1D, PLA2G16, DACH1, and SOWAHA in Task 2. According to The Cancer Genome Atlas dataset, these genes are all prognostic factors for pancreatic cancer. Thus, the feasibility of using our deep learning-based method for the selection of genes associated with pancreatic cancer development and prognosis was confirmed.",True,other,Not specified
34386786,Propensity score synthetic augmentation matching using generative adversarial networks (PSSAM-GAN),"Understanding causality is of crucial importance in biomedical sciences, where developing prediction models is insufficient because the models need to be actionable. However, data sources, such as electronic health records, are observational and often plagued with various types of biases, e.g. confounding. Although randomized controlled trials are the gold standard to estimate the causal effects of treatment interventions on health outcomes, they are not always possible. Propensity score matching (PSM) is a popular statistical technique for observational data that aims at balancing the characteristics of the population assigned either to a treatment or to a control group, making treatment assignment and outcome independent upon these characteristics. However, matching subjects can reduce the sample size. Inverse probability weighting (IPW) maintains the sample size, but extreme values can lead to instability. While PSM and IPW have been historically used in conjunction with linear regression, machine learning methods -including deep learning with propensity dropout- have been proposed to account for nonlinear treatment assignments. In this work, we propose a novel deep learning approach -the Propensity Score Synthetic Augmentation Matching using Generative Adversarial Networks (PSSAM-GAN)- that aims at keeping the sample size, without IPW, by generating synthetic matches. PSSAM-GAN can be used in conjunction with any other prediction method to estimate treatment effects. Experiments performed on both semi-synthetic (perinatal interventions) and real-world observational data (antibiotic treatments, and job interventions) show that the PSSAM-GAN approach effectively creates balanced datasets, relaxing the weighting/dropout needs for downstream methods, and providing competitive performance in effects estimation as compared to simple GAN and in conjunction with other deep counterfactual learning architectures, e.g. TARNet.",True,other,Not specified
34385900,Evaluation of Effect of Curcumin on Psychological State of Patients with Pulmonary Hypertension by Magnetic Resonance Image under Deep Learning,"This research aimed to evaluate the right ventricular segmentation ability of magnetic resonance imaging (MRI) images based on deep learning and evaluate the influence of curcumin (Cur) on the psychological state of patients with pulmonary hypertension (PH). The heart MRI images were detected based on the You Only Look Once (YOLO) algorithm, and then the MRI image right ventricle segmentation algorithm was established based on the convolutional neural network (CNN) algorithm. The segmentation effect of the right ventricle in cardiac MRI images was evaluated regarding intersection-over-union (IOU), Dice coefficient, accuracy, and Jaccard coefficient. 30 cases of PH patients were taken as the research object. According to different treatments, they were rolled into control group (conventional treatment) and Cur group (conventional treatment + Cur), with 15 cases in each group. Changes in the scores of the self-rating anxiety scale (SAS) and self-rating depression scale (SDS) of the two groups of patients before and after treatment were analyzed. It was found that the average IOU of the heart target detection frame of the MRI image and the true bounding box before correction was 0.7023, and the IOU after correction was 0.9016. The Loss of the MRI image processed by the CNN algorithm was 0.05, which was greatly smaller than those processed by other algorithms. The Dice coefficient, Jaccard coefficient, and accuracy of the MRI image processed by CNN were 0.89, 0.881, and 0.994, respectively. The MRI images of PH patients showed that the anterior wall of the right ventricle was notably thickened, and the main pulmonary artery was greatly widened. After treatment, the SAR and SDS scores of the two groups were lower than those before treatment (P &lt; 0.05), and the SAR and SDS scores of the curcumin group were lower than those of the control group (P &lt; 0.05). To sum up, the right ventricular segmentation ability of MRI images based on deep learning was improved, and Cur can remarkably alleviate the psychological state of PH patients, which provided a reference for the diagnosis and treatment for PH patients.",True,other,convolutional neural network
34375851,TEM virus images: Benchmark dataset and deep learning classification,"BACKGROUND AND OBJECTIVE: To achieve the full potential of deep learning (DL) models, such as understanding the interplay between model (size), training strategy, and amount of training data, researchers and developers need access to new dedicated image datasets; i.e., annotated collections of images representing real-world problems with all their variations, complexity, limitations, and noise. Here, we present, describe and make freely available an annotated transmission electron microscopy (TEM) image dataset. It constitutes an interesting challenge for many practical applications in virology and epidemiology; e.g., virus detection, segmentation, classification, and novelty detection. We also present benchmarking results for virus detection and recognition using some of the top-performing (large and small) networks as well as a handcrafted very small network. We compare and evaluate transfer learning and training from scratch hypothesizing that with a limited dataset, transfer learning is crucial for good performance of a large network whereas our handcrafted small network performs relatively well when training from scratch. This is one step towards understanding how much training data is needed for a given task.
METHODS: The benchmark dataset contains 1245 images of 22 virus classes. We propose a representative data split into training, validation, and test sets for this dataset. Moreover, we compare different established DL networks and present a baseline DL solution for classifying a subset of the 14 most-represented virus classes in the dataset.
RESULTS: Our best model, DenseNet201 pre-trained on ImageNet and fine-tuned on the training set, achieved a 0.921 F1-score and 93.1% accuracy on the proposed representative test set.
CONCLUSIONS: Public and real biomedical datasets are an important contribution and a necessity to increase the understanding of shortcomings, requirements, and potential improvements for deep learning solutions on biomedical problems or deploying solutions in clinical settings. We compared transfer learning to learning from scratch on this dataset and hypothesize that for limited-sized datasets transfer learning is crucial for achieving good performance for large models. Last but not least, we demonstrate the importance of application knowledge in creating datasets for training DL models and analyzing their results.",True,other,convolutional neural network
34373530,Validating deep learning inference during chest X-ray classification for COVID-19 screening,"The new coronavirus unleashed a worldwide pandemic in early 2020, and a fatality rate several times that of the flu. As the number of infections soared, and capabilities for testing lagged behind, chest X-ray (CXR) imaging became more relevant in the early diagnosis and treatment planning for patients with suspected or confirmed COVID-19 infection. In a few weeks, proposed new methods for lung screening using deep learning rapidly appeared, while quality assurance discussions lagged behind. This paper proposes a set of protocols to validate deep learning algorithms, including our ROI Hide-and-Seek protocol, which emphasizes or hides key regions of interest from CXR data. Our protocol allows assessing the classification performance for anomaly detection and its correlation to radiological signatures, an important issue overlooked in several deep learning approaches proposed so far. By running a set of systematic tests over CXR representations using public image datasets, we demonstrate the weaknesses of current techniques and offer perspectives on the advantages and limitations of automated radiography analysis when using heterogeneous data sources.",True,other,Not specified
34368837,A novel framework integrating AI model and enzymological experiments promotes identification of SARS-CoV-2 3CL protease inhibitors and activity-based probe,"The identification of protein-ligand interaction plays a key role in biochemical research and drug discovery. Although deep learning has recently shown great promise in discovering new drugs, there remains a gap between deep learning-based and experimental approaches. Here, we propose a novel framework, named AIMEE, integrating AI model and enzymological experiments, to identify inhibitors against 3CL protease of SARS-CoV-2 (Severe acute respiratory syndrome coronavirus 2), which has taken a significant toll on people across the globe. From a bioactive chemical library, we have conducted two rounds of experiments and identified six novel inhibitors with a hit rate of 29.41%, and four of them showed an IC50 value <3 μM. Moreover, we explored the interpretability of the central model in AIMEE, mapping the deep learning extracted features to the domain knowledge of chemical properties. Based on this knowledge, a commercially available compound was selected and was proven to be an activity-based probe of 3CLpro. This work highlights the great potential of combining deep learning models and biochemical experiments for intelligent iteration and for expanding the boundaries of drug discovery. The code and data are available at https://github.com/SIAT-code/AIMEE.",True,other,Not specified
34365472,Development of an AI system for accurately diagnose hepatocellular carcinoma from computed tomography imaging data,"BACKGROUND AND AIMS: Computed tomography (CT) scan is frequently used to detect hepatocellular carcinoma (HCC) in routine clinical practice. The aim of this study is to develop a deep-learning AI system to improve the diagnostic accuracy of HCC by analysing liver CT imaging data.
METHODS: We developed a deep-learning AI system by training on CT images from 7512 patients at Henan Provincial Peoples' Hospital. Its performance was validated on one internal test set (Henan Provincial Peoples' Hospital, n = 385) and one external test set (Henan Provincial Cancer Hospital, n = 556). The area under the receiver-operating characteristic curve (AUROC) was used as the primary classification metric. Accuracy, sensitivity, specificity, precision, negative predictive value and F1 metric were used to measure the performance of AI systems and radiologists.
RESULTS: AI system achieved high performance in identifying HCC patients, with AUROC of 0.887 (95% CI 0.855-0.919) on the internal test set and 0.883 (95% CI 0.855-0.911) on the external test set. For internal test set, accuracy was 81.0% (76.8-84.8%), sensitivity was 78.4% (72.4-83.7%), specificity was 84.4% (78.0-89.6%) and F1 (harmonic average of precision and recall rate) was 0.824. For external test set, accuracy was 81.3% (77.8-84.5%), sensitivity was 89.4% (85.0-92.8%), specificity was 74.0% (68.5-78.9%) and F1 was 0.819. Compared with radiologists, AI system achieved comparable accuracy and F1 metric on internal test set (0.853 versus 0.818, P = 0.107; 0.863 vs. 0.824, P = 0.082) and external test set (0.805 vs. 0.793, P = 0.663; 0.810 vs. 0.814, P = 0.866). The predicted HCC risk scores by AI system in HCC patients with multiple tumours and high fibrosis stage were higher than those with solitary tumour and low fibrosis stage (tumour number: 0.197 vs. 0.138, P = 0.006; fibrosis stage: 0.183 vs. 0.127, P < 0.001). Radiologists' review showed that the accuracy of saliency heatmaps predicted by algorithms was 92.1% (95% CI: 89.2-95.0%).
CONCLUSIONS: AI system achieved high performance in the detection of HCC compared with a group of specialised radiologists. Further investigation by prospective clinical trials was necessitated to verify this model.",True,other,Not specified
34354055,Deep learning of contagion dynamics on complex networks,"Forecasting the evolution of contagion dynamics is still an open problem to which mechanistic models only offer a partial answer. To remain mathematically or computationally tractable, these models must rely on simplifying assumptions, thereby limiting the quantitative accuracy of their predictions and the complexity of the dynamics they can model. Here, we propose a complementary approach based on deep learning where effective local mechanisms governing a dynamic on a network are learned from time series data. Our graph neural network architecture makes very few assumptions about the dynamics, and we demonstrate its accuracy using different contagion dynamics of increasing complexity. By allowing simulations on arbitrary network structures, our approach makes it possible to explore the properties of the learned dynamics beyond the training data. Finally, we illustrate the applicability of our approach using real data of the COVID-19 outbreak in Spain. Our results demonstrate how deep learning offers a new and complementary perspective to build effective models of contagion dynamics on networks.",True,other,convolutional neural network
34344910,Using normative modelling to detect disease progression in mild cognitive impairment and Alzheimer's disease in a cross-sectional multi-cohort study,"Normative modelling is an emerging method for quantifying how individuals deviate from the healthy populational pattern. Several machine learning models have been implemented to develop normative models to investigate brain disorders, including regression, support vector machines and Gaussian process models. With the advance of deep learning technology, the use of deep neural networks has also been proposed. In this study, we assessed normative models based on deep autoencoders using structural neuroimaging data from patients with Alzheimer's disease (n = 206) and mild cognitive impairment (n = 354). We first trained the autoencoder on an independent dataset (UK Biobank dataset) with 11,034 healthy controls. Then, we estimated how each patient deviated from this norm and established which brain regions were associated to this deviation. Finally, we compared the performance of our normative model against traditional classifiers. As expected, we found that patients exhibited deviations according to the severity of their clinical condition. The model identified medial temporal regions, including the hippocampus, and the ventricular system as critical regions for the calculation of the deviation score. Overall, the normative model had comparable cross-cohort generalizability to traditional classifiers. To promote open science, we are making all scripts and the trained models available to the wider research community.",True,other,convolutional neural network
34342588,Artificial Intelligence-Based Prediction of Lung Cancer Risk Using Nonimaging Electronic Medical Records: Deep Learning Approach,"BACKGROUND: Artificial intelligence approaches can integrate complex features and can be used to predict a patient's risk of developing lung cancer, thereby decreasing the need for unnecessary and expensive diagnostic interventions.
OBJECTIVE: The aim of this study was to use electronic medical records to prescreen patients who are at risk of developing lung cancer.
METHODS: We randomly selected 2 million participants from the Taiwan National Health Insurance Research Database who received care between 1999 and 2013. We built a predictive lung cancer screening model with neural networks that were trained and validated using pre-2012 data, and we tested the model prospectively on post-2012 data. An age- and gender-matched subgroup that was 10 times larger than the original lung cancer group was used to assess the predictive power of the electronic medical record. Discrimination (area under the receiver operating characteristic curve [AUC]) and calibration analyses were performed.
RESULTS: The analysis included 11,617 patients with lung cancer and 1,423,154 control patients. The model achieved AUCs of 0.90 for the overall population and 0.87 in patients ≥55 years of age. The AUC in the matched subgroup was 0.82. The positive predictive value was highest (14.3%) among people aged ≥55 years with a pre-existing history of lung disease.
CONCLUSIONS: Our model achieved excellent performance in predicting lung cancer within 1 year and has potential to be deployed for digital patient screening. Convolution neural networks facilitate the effective use of EMRs to identify individuals at high risk for developing lung cancer.",True,other,Not specified
34341396,A stacking ensemble deep learning approach to cancer type classification based on TCGA data,"Cancer tumor classification based on morphological characteristics alone has been shown to have serious limitations. Breast, lung, colorectal, thyroid, and ovarian are the most commonly diagnosed cancers among women. Precise classification of cancers into their types is considered a vital problem for cancer diagnosis and therapy. In this paper, we proposed a stacking ensemble deep learning model based on one-dimensional convolutional neural network (1D-CNN) to perform a multi-class classification on the five common cancers among women based on RNASeq data. The RNASeq gene expression data was downloaded from Pan-Cancer Atlas using GDCquery function of the TCGAbiolinks package in the R software. We used least absolute shrinkage and selection operator (LASSO) as feature selection method. We compared the results of the new proposed model with and without LASSO with the results of the single 1D-CNN and machine learning methods which include support vector machines with radial basis function, linear, and polynomial kernels; artificial neural networks; k-nearest neighbors; bagging trees. The results show that the proposed model with and without LASSO has a better performance compared to other classifiers. Also, the results show that the machine learning methods (SVM-R, SVM-L, SVM-P, ANN, KNN, and bagging trees) with under-sampling have better performance than with over-sampling techniques. This is supported by the statistical significance test of accuracy where the p-values for differences between the SVM-R and SVM-P, SVM-R and ANN, SVM-R and KNN are found to be p = 0.003, p =  < 0.001, and p =  < 0.001, respectively. Also, SVM-L had a significant difference compared to ANN p = 0.009. Moreover, SVM-P and ANN, SVM-P and KNN are found to be significantly different with p-values p =  < 0.001 and p =  < 0.001, respectively. In addition, ANN and bagging trees, ANN and KNN were found to be significantly different with p-values p =  < 0.001 and p = 0.004, respectively. Thus, the proposed model can help in the early detection and diagnosis of cancer in women, and hence aid in designing early treatment strategies to improve survival.",True,other,Not specified
37117770,"Author Correction: An inflammatory aging clock (iAge) based on deep learning tracks multimorbidity, immunosenescence, frailty and cardiovascular aging",,True,other,GAN
34321592,An ensemble learning approach to digital corona virus preliminary screening from cough sounds,"This work develops a robust classifier for a COVID-19 pre-screening model from crowdsourced cough sound data. The crowdsourced cough recordings contain a variable number of coughs, with some input sound files more informative than the others. Accurate detection of COVID-19 from the sound datasets requires overcoming two main challenges (i) the variable number of coughs in each recording and (ii) the low number of COVID-positive cases compared to healthy coughs in the data. We use two open datasets of crowdsourced cough recordings and segment each cough recording into non-overlapping coughs. The segmentation enriches the original data without oversampling by splitting the original cough sound files into non-overlapping segments. Splitting the sound files enables us to increase the samples of the minority class (COVID-19) without changing the feature distribution of the COVID-19 samples resulted from applying oversampling techniques. Each cough sound segment is transformed into six image representations for further analyses. We conduct extensive experiments with shallow machine learning, Convolutional Neural Network (CNN), and pre-trained CNN models. The results of our models were compared to other recently published papers that apply machine learning to cough sound data for COVID-19 detection. Our method demonstrated a high performance using an ensemble model on the testing dataset with area under receiver operating characteristics curve = 0.77, precision = 0.80, recall = 0.71, F1 measure = 0.75, and Kappa = 0.53. The results show an improvement in the prediction accuracy of our COVID-19 pre-screening model compared to the other models.",True,text mining,Not specified
34306171,Analysis of DNA Sequence Classification Using CNN and Hybrid Models,"In a general computational context for biomedical data analysis, DNA sequence classification is a crucial challenge. Several machine learning techniques have used to complete this task in recent years successfully. Identification and classification of viruses are essential to avoid an outbreak like COVID-19. Regardless, the feature selection process remains the most challenging aspect of the issue. The most commonly used representations worsen the case of high dimensionality, and sequences lack explicit features. It also helps in detecting the effect of viruses and drug design. In recent days, deep learning (DL) models can automatically extract the features from the input. In this work, we employed CNN, CNN-LSTM, and CNN-Bidirectional LSTM architectures using Label and K-mer encoding for DNA sequence classification. The models are evaluated on different classification metrics. From the experimental results, the CNN and CNN-Bidirectional LSTM with K-mer encoding offers high accuracy with 93.16% and 93.13%, respectively, on testing data.",True,other,convolutional neural network
34297817,ENNAVIA is a novel method which employs neural networks for antiviral and anti-coronavirus activity prediction for therapeutic peptides,"Viruses represent one of the greatest threats to human health, necessitating the development of new antiviral drug candidates. Antiviral peptides often possess excellent biological activity and a favourable toxicity profile, and therefore represent a promising field of novel antiviral drugs. As the quantity of sequencing data grows annually, the development of an accurate in silico method for the prediction of peptide antiviral activities is important. This study leverages advances in deep learning and cheminformatics to produce a novel sequence-based deep neural network classifier for the prediction of antiviral peptide activity. The method outperforms the existent best-in-class, with an external test accuracy of 93.9%, Matthews correlation coefficient of 0.87 and an Area Under the Curve of 0.93 on the dataset of experimentally validated peptide activities. This cutting-edge classifier is available as an online web server at https://research.timmons.eu/ennavia, facilitating in silico screening and design of peptide antiviral drugs by the wider research community.",True,other,Not specified
34297793,Deep learning-based real-time detection of novel pathogens during sequencing,"Novel pathogens evolve quickly and may emerge rapidly, causing dangerous outbreaks or even global pandemics. Next-generation sequencing is the state of the art in open-view pathogen detection, and one of the few methods available at the earliest stages of an epidemic, even when the biological threat is unknown. Analyzing the samples as the sequencer is running can greatly reduce the turnaround time, but existing tools rely on close matches to lists of known pathogens and perform poorly on novel species. Machine learning approaches can predict if single reads originate from more distant, unknown pathogens but require relatively long input sequences and processed data from a finished sequencing run. Incomplete sequences contain less information, leading to a trade-off between sequencing time and detection accuracy. Using a workflow for real-time pathogenic potential prediction, we investigate which subsequences already allow accurate inference. We train deep neural networks to classify Illumina and Nanopore reads and integrate the models with HiLive2, a real-time Illumina mapper. This approach outperforms alternatives based on machine learning and sequence alignment on simulated and real data, including SARS-CoV-2 sequencing runs. After just 50 Illumina cycles, we observe an 80-fold sensitivity increase compared to real-time mapping. The first 250 bp of Nanopore reads, corresponding to 0.5 s of sequencing time, are enough to yield predictions more accurate than mapping the finished long reads. The approach could also be used for screening synthetic sequences against biosecurity threats.",True,other,recurrent neural network
34293465,Deep learning for sex classification in resting-state and task functional brain networks from the UK Biobank,"Classification of whole-brain functional connectivity MRI data with convolutional neural networks (CNNs) has shown promise, but the complexity of these models impedes understanding of which aspects of brain activity contribute to classification. While visualization techniques have been developed to interpret CNNs, bias inherent in the method of encoding abstract input data, as well as the natural variance of deep learning models, detract from the accuracy of these techniques. We introduce a stochastic encoding method in an ensemble of CNNs to classify functional connectomes by sex. We applied our method to resting-state and task data from the UK BioBank, using two visualization techniques to measure the salience of three brain networks involved in task- and resting-states, and their interaction. To regress confounding factors such as head motion, age, and intracranial volume, we introduced a multivariate balancing algorithm to ensure equal distributions of such covariates between classes in our data. We achieved a final AUROC of 0.8459. We found that resting-state data classifies more accurately than task data, with the inner salience network playing the most important role of the three networks overall in classification of resting-state data and connections to the central executive network in task data.",True,other,convolutional neural network
34290286,Integrating ensemble systems biology feature selection and bimodal deep neural network for breast cancer prognosis prediction,"Breast cancer is a heterogeneous disease. To guide proper treatment decisions for each patient, robust prognostic biomarkers, which allow reliable prognosis prediction, are necessary. Gene feature selection based on microarray data is an approach to discover potential biomarkers systematically. However, standard pure-statistical feature selection approaches often fail to incorporate prior biological knowledge and select genes that lack biological insights. Besides, due to the high dimensionality and low sample size properties of microarray data, selecting robust gene features is an intrinsically challenging problem. We hence combined systems biology feature selection with ensemble learning in this study, aiming to select genes with biological insights and robust prognostic predictive power. Moreover, to capture breast cancer's complex molecular processes, we adopted a multi-gene approach to predict the prognosis status using deep learning classifiers. We found that all ensemble approaches could improve feature selection robustness, wherein the hybrid ensemble approach led to the most robust result. Among all prognosis prediction models, the bimodal deep neural network (DNN) achieved the highest test performance, further verified by survival analysis. In summary, this study demonstrated the potential of combining ensemble learning and bimodal DNN in guiding precision medicine.",True,other,Not specified
34286831,Chest X-ray Analysis With Deep Learning-Based Software as a Triage Test for Pulmonary Tuberculosis: An Individual Patient Data Meta-Analysis of Diagnostic Accuracy,"BACKGROUND: Automated radiologic analysis using computer-aided detection software (CAD) could facilitate chest X-ray (CXR) use in tuberculosis diagnosis. There is little to no evidence on the accuracy of commercially available deep learning-based CAD in different populations, including patients with smear-negative tuberculosis and people living with human immunodeficiency virus (HIV, PLWH).
METHODS: We collected CXRs and individual patient data (IPD) from studies evaluating CAD in patients self-referring for tuberculosis symptoms with culture or nucleic acid amplification testing as the reference. We reanalyzed CXRs with three CAD programs (CAD4TB version (v) 6, Lunit v3.1.0.0, and qXR v2). We estimated sensitivity and specificity within each study and pooled using IPD meta-analysis. We used multivariable meta-regression to identify characteristics modifying accuracy.
RESULTS: We included CXRs and IPD of 3727/3967 participants from 4/7 eligible studies. 17% (621/3727) were PLWH. 17% (645/3727) had microbiologically confirmed tuberculosis. Despite using the same threshold score for classifying CXR in every study, sensitivity and specificity varied from study to study. The software had similar unadjusted accuracy (at 90% pooled sensitivity, pooled specificities were: CAD4TBv6, 56.9% [95% confidence interval {CI}: 51.7-61.9]; Lunit, 54.1% [95% CI: 44.6-63.3]; qXRv2, 60.5% [95% CI: 51.7-68.6]). Adjusted absolute differences in pooled sensitivity between PLWH and HIV-uninfected participants were: CAD4TBv6, -13.4% [-21.1, -6.9]; Lunit, +2.2% [-3.6, +6.3]; qXRv2: -13.4% [-21.5, -6.6]; between smear-negative and smear-positive tuberculosis was: were CAD4TBv6, -12.3% [-19.5, -6.1]; Lunit, -17.2% [-24.6, -10.5]; qXRv2, -16.6% [-24.4, -9.9]. Accuracy was similar to human readers.
CONCLUSIONS: For CAD CXR analysis to be implemented as a high-sensitivity tuberculosis rule-out test, users will need threshold scores identified from their own patient populations and stratified by HIV and smear status.",True,other,Not specified
34261540,DeepProg: an ensemble of deep-learning and machine-learning models for prognosis prediction using multi-omics data,"Multi-omics data are good resources for prognosis and survival prediction; however, these are difficult to integrate computationally. We introduce DeepProg, a novel ensemble framework of deep-learning and machine-learning approaches that robustly predicts patient survival subtypes using multi-omics data. It identifies two optimal survival subtypes in most cancers and yields significantly better risk-stratification than other multi-omics integration methods. DeepProg is highly predictive, exemplified by two liver cancer (C-index 0.73-0.80) and five breast cancer datasets (C-index 0.68-0.73). Pan-cancer analysis associates common genomic signatures in poor survival subtypes with extracellular matrix modeling, immune deregulation, and mitosis processes. DeepProg is freely available at https://github.com/lanagarmire/DeepProg.",True,other,convolutional neural network
34253768,COUnty aggRegation mixup AuGmEntation (COURAGE) COVID-19 prediction,"The global spread of COVID-19, the disease caused by the novel coronavirus SARS-CoV-2, has casted a significant threat to mankind. As the COVID-19 situation continues to evolve, predicting localized disease severity is crucial for advanced resource allocation. This paper proposes a method named COURAGE (COUnty aggRegation mixup AuGmEntation) to generate a short-term prediction of 2-week-ahead COVID-19 related deaths for each county in the United States, leveraging modern deep learning techniques. Specifically, our method adopts a self-attention model from Natural Language Processing, known as the transformer model, to capture both short-term and long-term dependencies within the time series while enjoying computational efficiency. Our model solely utilizes publicly available information for COVID-19 related confirmed cases, deaths, community mobility trends and demographic information, and can produce state-level predictions as an aggregation of the corresponding county-level predictions. Our numerical experiments demonstrate that our model achieves the state-of-the-art performance among the publicly available benchmark models.",True,other,recurrent neural network
34253751,Deep learning identifies antigenic determinants of severe SARS-CoV-2 infection within T-cell repertoires,"SARS-CoV-2 infection is characterized by a highly variable clinical course with patients experiencing asymptomatic infection all the way to requiring critical care support. This variation in clinical course has led physicians and scientists to study factors that may predispose certain individuals to more severe clinical presentations in hopes of either identifying these individuals early in their illness or improving their medical management. We sought to understand immunogenomic differences that may result in varied clinical outcomes through analysis of T-cell receptor sequencing (TCR-Seq) data in the open access ImmuneCODE database. We identified two cohorts within the database that had clinical outcomes data reflecting severity of illness and utilized DeepTCR, a multiple-instance deep learning repertoire classifier, to predict patients with severe SARS-CoV-2 infection from their repertoire sequencing. We demonstrate that patients with severe infection have repertoires with higher T-cell responses associated with SARS-CoV-2 epitopes and identify the epitopes that result in these responses. Our results provide evidence that the highly variable clinical course seen in SARS-CoV-2 infection is associated to certain antigen-specific responses.",True,other,Not specified
36247813,Improving Interpretability in Machine Diagnosis: Detection of Geographic Atrophy in OCT Scans,"PURPOSE: Manually identifying geographic atrophy (GA) presence and location on OCT volume scans can be challenging and time consuming. This study developed a deep learning model simultaneously (1) to perform automated detection of GA presence or absence from OCT volume scans and (2) to provide interpretability by demonstrating which regions of which B-scans show GA.
DESIGN: Med-XAI-Net, an interpretable deep learning model was developed to detect GA presence or absence from OCT volume scans using only volume scan labels, as well as to interpret the most relevant B-scans and B-scan regions.
PARTICIPANTS: One thousand two hundred eighty-four OCT volume scans (each containing 100 B-scans) from 311 participants, including 321 volumes with GA and 963 volumes without GA.
METHODS: Med-XAI-Net simulates the human diagnostic process by using a region-attention module to locate the most relevant region in each B-scan, followed by an image-attention module to select the most relevant B-scans for classifying GA presence or absence in each OCT volume scan. Med-XAI-Net was trained and tested (80% and 20% participants, respectively) using gold standard volume scan labels from human expert graders.
MAIN OUTCOME MEASURES: Accuracy, area under the receiver operating characteristic (ROC) curve, F<sub>1</sub> score, sensitivity, and specificity.
RESULTS: In the detection of GA presence or absence, Med-XAI-Net obtained superior performance (91.5%, 93.5%, 82.3%, 82.8%, and 94.6% on accuracy, area under the ROC curve, F<sub>1</sub> score, sensitivity, and specificity, respectively) to that of 2 other state-of-the-art deep learning methods. The performance of ophthalmologists grading only the 5 B-scans selected by Med-XAI-Net as most relevant (95.7%, 95.4%, 91.2%, and 100%, respectively) was almost identical to that of ophthalmologists grading all volume scans (96.0%, 95.7%, 91.8%, and 100%, respectively). Even grading only 1 region in 1 B-scan, the ophthalmologists demonstrated moderately high performance (89.0%, 87.4%, 77.6%, and 100%, respectively).
CONCLUSIONS: Despite using ground truth labels during training at the volume scan level only, Med-XAI-Net was effective in locating GA in B-scans and selecting relevant B-scans within each volume scan for GA diagnosis. These results illustrate the strengths of Med-XAI-Net in interpreting which regions and B-scans contribute to GA detection in the volume scan.",True,other,Not specified
34247133,Deep learning in diabetic foot ulcers detection: A comprehensive evaluation,"There has been a substantial amount of research involving computer methods and technology for the detection and recognition of diabetic foot ulcers (DFUs), but there is a lack of systematic comparisons of state-of-the-art deep learning object detection frameworks applied to this problem. DFUC2020 provided participants with a comprehensive dataset consisting of 2,000 images for training and 2,000 images for testing. This paper summarizes the results of DFUC2020 by comparing the deep learning-based algorithms proposed by the winning teams: Faster R-CNN, three variants of Faster R-CNN and an ensemble method; YOLOv3; YOLOv5; EfficientDet; and a new Cascade Attention Network. For each deep learning method, we provide a detailed description of model architecture, parameter settings for training and additional stages including pre-processing, data augmentation and post-processing. We provide a comprehensive evaluation for each method. All the methods required a data augmentation stage to increase the number of images available for training and a post-processing stage to remove false positives. The best performance was obtained from Deformable Convolution, a variant of Faster R-CNN, with a mean average precision (mAP) of 0.6940 and an F1-Score of 0.7434. Finally, we demonstrate that the ensemble method based on different deep learning methods can enhance the F1-Score but not the mAP.",True,other,recurrent neural network
34242349,The predictive skill of convolutional neural networks models for disease forecasting,"In this paper we investigate the utility of one-dimensional convolutional neural network (CNN) models in epidemiological forecasting. Deep learning models, in particular variants of recurrent neural networks (RNNs) have been studied for ILI (Influenza-Like Illness) forecasting, and have achieved a higher forecasting skill compared to conventional models such as ARIMA. In this study, we adapt two neural networks that employ one-dimensional temporal convolutional layers as a primary building block-temporal convolutional networks and simple neural attentive meta-learners-for epidemiological forecasting. We then test them with influenza data from the US collected over 2010-2019. We find that epidemiological forecasting with CNNs is feasible, and their forecasting skill is comparable to, and at times, superior to, plain RNNs. Thus CNNs and RNNs bring the power of nonlinear transformations to purely data-driven epidemiological models, a capability that heretofore has been limited to more elaborate mechanistic/compartmental disease models.",True,other,convolutional neural network
34197330,Self-Attention-Based Deep Learning Network for Regional Influenza Forecasting,"Early prediction of influenza plays an important role in minimizing the damage caused, as it provides the resources and time needed to formulate preventive measures. Compared to traditional mechanistic approach, deep/machine learning-based models have demonstrated excellent forecasting performance by efficiently handling various data such as weather and internet data. However, due to the limited availability and reliability of such data, many forecasting models use only historical occurrence data and formulate the influenza forecasting as a multivariate time-series task. Recently, attention mechanisms have been exploited to deal with this issue by selecting valuable data in the input data and giving them high weights. Particularly, self-attention has shown its potential in various forecasting tasks by utilizing the predictive relationship between objects from the input data describing target objects. Hence, in this study, we propose a forecasting model based on self-attention for regional influenza forecasting, called SAIFlu-Net. The model exploits a long short-term memory network for extracting time-series patterns of each region and the self-attention mechanism to find the similarities between the occurrence patterns. To evaluate its performance, we conducted extensive experiments with existing forecasting models using weekly regional influenza datasets. The results show that the proposed model outperforms other models in terms of root mean square error and Pearson correlation coefficient.",True,other,recurrent neural network
34184738,DeepIPs: comprehensive assessment and computational identification of phosphorylation sites of SARS-CoV-2 infection using a deep learning-based approach,"The rapid spread of SARS-CoV-2 infection around the globe has caused a massive health and socioeconomic crisis. Identification of phosphorylation sites is an important step for understanding the molecular mechanisms of SARS-CoV-2 infection and the changes within the host cells pathways. In this study, we present DeepIPs, a first specific deep-learning architecture to identify phosphorylation sites in host cells infected with SARS-CoV-2. DeepIPs consists of the most popular word embedding method and convolutional neural network-long short-term memory network architecture to make the final prediction. The independent test demonstrates that DeepIPs improves the prediction performance compared with other existing tools for general phosphorylation sites prediction. Based on the proposed model, a web-server called DeepIPs was established and is freely accessible at http://lin-group.cn/server/DeepIPs. The source code of DeepIPs is freely available at the repository https://github.com/linDing-group/DeepIPs.",True,other,convolutional neural network
34158233,[Artificial Intelligence in epidemiology],"Artificial Intelligence can be leveraged to analyze great amounts of data. It can be used on images or textual data to define the epidemiology of diseases, such as cancer. In this review, we will present and discuss the applications of AI in this setting.",True,other,convolutional neural network
34153076,Deep learning for classification of pediatric chest radiographs by WHO's standardized methodology,"BACKGROUND: The World Health Organization (WHO)-defined radiological pneumonia is a preferred endpoint in pneumococcal vaccine efficacy and effectiveness studies in children. Automating the WHO methodology may support more widespread application of this endpoint.
METHODS: We trained a deep learning model to classify pneumonia CXRs in children using the World Health Organization (WHO)'s standardized methodology. The model was pretrained on CheXpert, a dataset containing 224,316 adult CXRs, and fine-tuned on PERCH, a pediatric dataset containing 4,172 CXRs. The model was then tested on two pediatric CXR datasets released by WHO. We also compared the model's performance to that of radiologists and pediatricians.
RESULTS: The average area under the receiver operating characteristic curve (AUC) for primary endpoint pneumonia (PEP) across 10-fold validation of PERCH images was 0.928; average AUC after testing on WHO images was 0.977. The model's classification performance was better on test images with high inter-observer agreement; however, the model still outperformed human assessments in AUC and precision-recall spaces on low agreement images.
CONCLUSION: A deep learning model can classify pneumonia CXR images in children at a performance comparable to human readers. Our method lays a strong foundation for the potential inclusion of computer-aided readings of pediatric CXRs in vaccine trials and epidemiology studies.",True,computer vision,LSTM
34151222,Microscopy deep learning predicts virus infections and reveals mechanics of lytic-infected cells,"Imaging across scales reveals disease mechanisms in organisms, tissues, and cells. Yet, particular infection phenotypes, such as virus-induced cell lysis, have remained difficult to study. Here, we developed imaging modalities and deep learning procedures to identify herpesvirus and adenovirus (AdV) infected cells without virus-specific stainings. Fluorescence microscopy of vital DNA-dyes and live-cell imaging revealed learnable virus-specific nuclear patterns transferable to related viruses of the same family. Deep learning predicted two major AdV infection outcomes, non-lytic (nonspreading) and lytic (spreading) infections, up to about 20 hr prior to cell lysis. Using these predictive algorithms, lytic and non-lytic nuclei had the same levels of green fluorescent protein (GFP)-tagged virion proteins but lytic nuclei enriched the virion proteins faster, and collapsed more extensively upon laser-rupture than non-lytic nuclei, revealing impaired mechanical properties of lytic nuclei. Our algorithms may be used to infer infection phenotypes of emerging viruses, enhance single cell biology, and facilitate differential diagnosis of non-lytic and lytic infections.",True,other,recurrent neural network
34117734,DeepR2cov: deep representation learning on heterogeneous drug networks to discover anti-inflammatory agents for COVID-19,"Recent studies have demonstrated that the excessive inflammatory response is an important factor of death in coronavirus disease 2019 (COVID-19) patients. In this study, we propose a deep representation on heterogeneous drug networks, termed DeepR2cov, to discover potential agents for treating the excessive inflammatory response in COVID-19 patients. This work explores the multi-hub characteristic of a heterogeneous drug network integrating eight unique networks. Inspired by the multi-hub characteristic, we design 3 billion special meta paths to train a deep representation model for learning low-dimensional vectors that integrate long-range structure dependency and complex semantic relation among network nodes. Based on the representation vectors and transcriptomics data, we predict 22 drugs that bind to tumor necrosis factor-α or interleukin-6, whose therapeutic associations with the inflammation storm in COVID-19 patients, and molecular binding model are further validated via data from PubMed publications, ongoing clinical trials and a docking program. In addition, the results on five biomedical applications suggest that DeepR2cov significantly outperforms five existing representation approaches. In summary, DeepR2cov is a powerful network representation approach and holds the potential to accelerate treatment of the inflammatory responses in COVID-19 patients. The source code and data can be downloaded from https://github.com/pengsl-lab/DeepR2cov.git.",True,other,Not specified
34081143,A transferable deep learning approach to fast screen potential antiviral drugs against SARS-CoV-2,"The COVID-19 pandemic calls for rapid development of effective treatments. Although various drug repurpose approaches have been used to screen the FDA-approved drugs and drug candidates in clinical phases against SARS-CoV-2, the coronavirus that causes this disease, no magic bullets have been found until now. In this study, we used directed message passing neural network to first build a broad-spectrum anti-beta-coronavirus compound prediction model, which gave satisfactory predictions on newly reported active compounds against SARS-CoV-2. Then, we applied transfer learning to fine-tune the model with the recently reported anti-SARS-CoV-2 compounds and derived a SARS-CoV-2 specific prediction model COVIDVS-3. We used COVIDVS-3 to screen a large compound library with 4.9 million drug-like molecules from ZINC15 database and recommended a list of potential anti-SARS-CoV-2 compounds for further experimental testing. As a proof-of-concept, we experimentally tested seven high-scored compounds that also demonstrated good binding strength in docking studies against the 3C-like protease of SARS-CoV-2 and found one novel compound that can inhibit the enzyme. Our model is highly efficient and can be used to screen large compound databases with millions or more compounds to accelerate the drug discovery process for the treatment of COVID-19.",True,other,Not specified
34073854,"Classification and Prediction on the Effects of Nutritional Intake on Overweight/Obesity, Dyslipidemia, Hypertension and Type 2 Diabetes Mellitus Using Deep Learning Model: 4-7th Korea National Health and Nutrition Examination Survey","Few studies have been conducted to classify and predict the influence of nutritional intake on overweight/obesity, dyslipidemia, hypertension and type 2 diabetes mellitus (T2DM) based on deep learning such as deep neural network (DNN). The present study aims to classify and predict associations between nutritional intake and risk of overweight/obesity, dyslipidemia, hypertension and T2DM by developing a DNN model, and to compare a DNN model with the most popular machine learning models such as logistic regression and decision tree. Subjects aged from 40 to 69 years in the 4-7th (from 2007 through 2018) Korea National Health and Nutrition Examination Survey (KNHANES) were included. Diagnostic criteria of dyslipidemia (n = 10,731), hypertension (n = 10,991), T2DM (n = 3889) and overweight/obesity (n = 10,980) were set as dependent variables. Nutritional intakes were set as independent variables. A DNN model comprising one input layer with 7 nodes, three hidden layers with 30 nodes, 12 nodes, 8 nodes in each layer and one output layer with one node were implemented in Python programming language using Keras with tensorflow backend. In DNN, binary cross-entropy loss function for binary classification was used with Adam optimizer. For avoiding overfitting, dropout was applied to each hidden layer. Structural equation modelling (SEM) was also performed to simultaneously estimate multivariate causal association between nutritional intake and overweight/obesity, dyslipidemia, hypertension and T2DM. The DNN model showed the higher prediction accuracy with 0.58654 for dyslipidemia, 0.79958 for hypertension, 0.80896 for T2DM and 0.62496 for overweight/obesity compared with two other machine leaning models with five-folds cross-validation. Prediction accuracy for dyslipidemia, hypertension, T2DM and overweight/obesity were 0.58448, 0.79929, 0.80818 and 0.62486, respectively, when analyzed by a logistic regression, also were 0.52148, 0.66773, 0.71587 and 0.54026, respectively, when analyzed by a decision tree. This study observed a DNN model with three hidden layers with 30 nodes, 12 nodes, 8 nodes in each layer had better prediction accuracy than two conventional machine learning models of a logistic regression and decision tree.",True,other,Not specified
34055238,Prediction of repurposed drugs for Coronaviruses using artificial intelligence and machine learning,"The world is facing the COVID-19 pandemic caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2). Likewise, other viruses of the Coronaviridae family were responsible for causing epidemics earlier. To tackle these viruses, there is a lack of approved antiviral drugs. Therefore, we have developed robust computational methods to predict the repurposed drugs using machine learning techniques namely Support Vector Machine, Random Forest, k-Nearest Neighbour, Artificial Neural Network, and Deep Learning. We used the experimentally validated drugs/chemicals with anticorona activity (IC<sub>50</sub>/EC<sub>50</sub>) from 'DrugRepV' repository. The unique entries of SARS-CoV-2 (142), SARS (221), MERS (123), and overall Coronaviruses (414) were subdivided into the training/testing and independent validation datasets, followed by the extraction of chemical/structural descriptors and fingerprints (17968). The highly relevant features were filtered using the recursive feature selection algorithm. The selected chemical descriptors were used to develop prediction models with Pearson's correlation coefficients ranging from 0.60 to 0.90 on training/testing. The robustness of the predictive models was further ensured using external independent validation datasets, decoy datasets, applicability domain, and chemical analyses. The developed models were used to predict promising repurposed drug candidates against coronaviruses after scanning the DrugBank. Top predicted molecules for SARS-CoV-2 were further validated by molecular docking against the spike protein complex with ACE receptor. We found potential repurposed drugs namely Verteporfin, Alatrofloxacin, Metergoline, Rescinnamine, Leuprolide, and Telotristat ethyl with high binding affinity. These 'anticorona' computational models would assist in antiviral drug discovery against SARS-CoV-2 and other Coronaviruses.",True,other,Not specified
34051452,Improving influenza surveillance based on multi-granularity deep spatiotemporal neural network,"Influenza is a common respiratory disease that can cause human illness and death. Timely and accurate prediction of disease risk is of great importance for public health management and prevention. The influenza data belong to typical spatiotemporal data in that influenza transmission is influenced by regional and temporal interactions. Many existing methods only use the historical time series information for prediction, which ignores the effect of spatial correlations of neighboring regions and temporal correlations of different time periods. Mining spatiotemporal information for risk prediction is a significant and challenging issue. In this paper, we propose a new end-to-end spatiotemporal deep neural network structure for influenza risk prediction. The proposed model mainly consists of two parts. The first stage is the spatiotemporal feature extraction stage where two-stream convolutional and recurrent neural networks are constructed to extract the different regions and time granularity information. Then, a dynamically parametric-based fusion method is adopted to integrate the two-stream features and making predictions. In our work, we demonstrate that our method, tested on two influenza-like illness (ILI) datasets (US-HHS and SZ-HIC), achieved the best performance across all evaluation metrics. The results imply that our method has outstanding performance for spatiotemporal feature extraction and enables accurate predictions compared to other well-known influenza forecasting models.",True,other,recurrent neural network
34046742,Deep learning for cephalometric landmark detection: systematic review and meta-analysis,"OBJECTIVES: Deep learning (DL) has been increasingly employed for automated landmark detection, e.g., for cephalometric purposes. We performed a systematic review and meta-analysis to assess the accuracy and underlying evidence for DL for cephalometric landmark detection on 2-D and 3-D radiographs.
METHODS: Diagnostic accuracy studies published in 2015-2020 in Medline/Embase/IEEE/arXiv and employing DL for cephalometric landmark detection were identified and extracted by two independent reviewers. Random-effects meta-analysis, subgroup, and meta-regression were performed, and study quality was assessed using QUADAS-2. The review was registered (PROSPERO no. 227498).
DATA: From 321 identified records, 19 studies (published 2017-2020), all employing convolutional neural networks, mainly on 2-D lateral radiographs (n=15), using data from publicly available datasets (n=12) and testing the detection of a mean of 30 (SD: 25; range.: 7-93) landmarks, were included. The reference test was established by two experts (n=11), 1 expert (n=4), 3 experts (n=3), and a set of annotators (n=1). Risk of bias was high, and applicability concerns were detected for most studies, mainly regarding the data selection and reference test conduct. Landmark prediction error centered around a 2-mm error threshold (mean; 95% confidence interval: (-0.581; 95 CI: -1.264 to 0.102 mm)). The proportion of landmarks detected within this 2-mm threshold was 0.799 (0.770 to 0.824).
CONCLUSIONS: DL shows relatively high accuracy for detecting landmarks on cephalometric imagery. The overall body of evidence is consistent but suffers from high risk of bias. Demonstrating robustness and generalizability of DL for landmark detection is needed.
CLINICAL SIGNIFICANCE: Existing DL models show consistent and largely high accuracy for automated detection of cephalometric landmarks. The majority of studies so far focused on 2-D imagery; data on 3-D imagery are sparse, but promising. Future studies should focus on demonstrating generalizability, robustness, and clinical usefulness of DL for this objective.",True,other,Not specified
34043172,Predicting COVID-19 cases using bidirectional LSTM on multivariate time series,"To assist policymakers in making adequate decisions to stop the spread of the COVID-19 pandemic, accurate forecasting of the disease propagation is of paramount importance. This paper presents a deep learning approach to forecast the cumulative number of COVID-19 cases using bidirectional Long Short-Term Memory (Bi-LSTM) network applied to multivariate time series. Unlike other forecasting techniques, our proposed approach first groups the countries having similar demographic and socioeconomic aspects and health sector indicators using K-means clustering algorithm. The cumulative case data of the clustered countries enriched with data related to the lockdown measures are fed to the bidirectional LSTM to train the forecasting model. We validate the effectiveness of the proposed approach by studying the disease outbreak in Qatar and the proposed model prediction from December 1st until December 31st, 2020. The quantitative evaluation shows that the proposed technique outperforms state-of-art forecasting approaches.",True,other,recurrent neural network
34042937,Peel learning for pathway-related outcome prediction,"MOTIVATION: Traditional regression models are limited in outcome prediction due to their parametric nature. Current deep learning methods allow for various effects and interactions and have shown improved performance, but they typically need to be trained on a large amount of data to obtain reliable results. Gene expression studies often have small sample sizes but high dimensional correlated predictors so that traditional deep learning methods are not readily applicable.
RESULTS: In this article, we proposed peel learning, a novel neural network that incorporates the prior relationship among genes. In each layer of learning, overall structure is peeled into multiple local substructures. Within the substructure, dependency among variables is reduced through linear projections. The overall structure is gradually simplified over layers and weight parameters are optimized through a revised backpropagation. We applied PL to a small lung transplantation study to predict recipients' post-surgery primary graft dysfunction using donors' gene expressions within several immunology pathways, where PL showed improved prediction accuracy compared to conventional penalized regression, classification trees, feed-forward neural network and a neural network assuming prior network structure. Through simulation studies, we also demonstrated the advantage of adding specific structure among predictor variables in neural network, over no or uniform group structure, which is more favorable in smaller studies. The empirical evidence is consistent with our theoretical proof of improved upper bound of PL's complexity over ordinary neural networks.
AVAILABILITY AND IMPLEMENTATION: PL algorithm was implemented in Python and the open-source code and instruction will be available at https://github.com/Likelyt/Peel-Learning.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",True,other,recurrent neural network
34035047,"A joint deep learning model enables simultaneous batch effect correction, denoising, and clustering in single-cell transcriptomics","Recent developments of single-cell RNA-seq (scRNA-seq) technologies have led to enormous biological discoveries. As the scale of scRNA-seq studies increases, a major challenge in analysis is batch effects, which are inevitable in studies involving human tissues. Most existing methods remove batch effects in a low-dimensional embedding space. Although useful for clustering, batch effects are still present in the gene expression space, leaving downstream gene-level analysis susceptible to batch effects. Recent studies have shown that batch effect correction in the gene expression space is much harder than in the embedding space. Methods such as Seurat 3.0 rely on the mutual nearest neighbor (MNN) approach to remove batch effects in gene expression, but MNN can only analyze two batches at a time, and it becomes computationally infeasible when the number of batches is large. Here, we present CarDEC, a joint deep learning model that simultaneously clusters and denoises scRNA-seq data while correcting batch effects both in the embedding and the gene expression space. Comprehensive evaluations spanning different species and tissues showed that CarDEC outperforms Scanorama, DCA + Combat, scVI, and MNN. With CarDEC denoising, non-highly variable genes offer as much signal for clustering as the highly variable genes (HVGs), suggesting that CarDEC substantially boosted information content in scRNA-seq. We also showed that trajectory analysis using CarDEC's denoised and batch-corrected expression as input revealed marker genes and transcription factors that are otherwise obscured in the presence of batch effects. CarDEC is computationally fast, making it a desirable tool for large-scale scRNA-seq studies.",True,other,Not specified
34009266,DeepImmuno: deep learning-empowered prediction and generation of immunogenic peptides for T-cell immunity,"Cytolytic T-cells play an essential role in the adaptive immune system by seeking out, binding and killing cells that present foreign antigens on their surface. An improved understanding of T-cell immunity will greatly aid in the development of new cancer immunotherapies and vaccines for life-threatening pathogens. Central to the design of such targeted therapies are computational methods to predict non-native peptides to elicit a T-cell response, however, we currently lack accurate immunogenicity inference methods. Another challenge is the ability to accurately simulate immunogenic peptides for specific human leukocyte antigen alleles, for both synthetic biological applications, and to augment real training datasets. Here, we propose a beta-binomial distribution approach to derive peptide immunogenic potential from sequence alone. We conducted systematic benchmarking of five traditional machine learning (ElasticNet, K-nearest neighbors, support vector machine, Random Forest and AdaBoost) and three deep learning models (convolutional neural network (CNN), Residual Net and graph neural network) using three independent prior validated immunogenic peptide collections (dengue virus, cancer neoantigen and SARS-CoV-2). We chose the CNN as the best prediction model, based on its adaptivity for small and large datasets and performance relative to existing methods. In addition to outperforming two highly used immunogenicity prediction algorithms, DeepImmuno-CNN correctly predicts which residues are most important for T-cell antigen recognition and predicts novel impacts of SARS-CoV-2 variants. Our independent generative adversarial network (GAN) approach, DeepImmuno-GAN, was further able to accurately simulate immunogenic peptides with physicochemical properties and immunogenicity predictions similar to that of real antigens. We provide DeepImmuno-CNN as source code and an easy-to-use web interface.",True,text mining,Not specified
33997679,Deep learning predicts chromosomal instability from histopathology images,"Chromosomal instability (CIN) is a hallmark of human cancer yet not readily testable for patients with cancer in routine clinical setting. In this study, we sought to explore whether CIN status can be predicted using ubiquitously available hematoxylin and eosin histology through a deep learning-based model. When applied to a cohort of 1,010 patients with breast cancer (Training set: n = 858, Test set: n = 152) from The Cancer Genome Atlas where 485 patients have high CIN status, our model accurately classified CIN status, achieving an area under the curve of 0.822 with 81.2% sensitivity and 68.7% specificity in the test set. Patch-level predictions of CIN status suggested intra-tumor heterogeneity within slides. Moreover, presence of patches with high predicted CIN score within an entire slide was more predictive of clinical outcome than the average CIN score of the slide, thus underscoring the clinical importance of intra-tumor heterogeneity.",True,other,RNN
33991230,Current state of machine learning for non-melanoma skin cancer,"BACKGROUND: Machine learning (ML) has been increasingly utilized for skin cancer screening, primarily of melanomas but also of non-melanoma skin cancers (NMSC).
OBJECTIVE: This study presents the first quantitative review of the success of these techniques in NMSC screening.
METHODS: A primary literature search was conducted using PubMed, MEDLINE, and arXiv, capturing all articles involving ML techniques and NMSC screening.
RESULTS: 52 articles were included for quantitative analysis, resulting in a mean sensitivity of 89.2% (n = 52, 95% confidence interval (CI) 87.0-91.3) and a mean specificity of 81.1% (n = 44, 95% CI 74.5-87.8) for ML algorithms in the diagnosis of NMSC. Studies were further grouped by skin cancer type, algorithm type, diagnostic gold standard, data set source, and data set size.
CONCLUSION: There is insufficient evidence to conclude that an ML algorithm is superior at NMSC screening than a trained dermatologist utilizing dermoscopy for either BCC or SCC. Given that the studies included in this review were performed in silico, further study in the form of randomized clinical trials are needed to further elucidate the role of NMSC screening algorithms in dermatology.",True,other,Not specified
33984043,Deep reinforcement learning approaches for global public health strategies for COVID-19 pandemic,"BACKGROUND: Unprecedented public health measures have been used during this coronavirus 2019 (COVID-19) pandemic to control the spread of SARS-CoV-2 virus. It is a challenge to implement timely and appropriate public health interventions.
METHODS AND FINDINGS: Population and COVID-19 epidemiological data between 21st January 2020 to 15th November 2020 from 216 countries and territories were included with the implemented public health interventions. We used deep reinforcement learning, and the algorithm was trained to enable agents to try to find optimal public health strategies that maximized total reward on controlling the spread of COVID-19. The results suggested by the algorithm were analyzed against the actual timing and intensity of lockdown and travel restrictions. Early implementations of the actual lockdown and travel restriction policies, usually at the time of local index case were associated with less burden of COVID-19. In contrast, our agent suggested to initiate at least minimal intensity of lockdown or travel restriction even before or on the day of the index case in each country and territory. In addition, the agent mostly recommended a combination of lockdown and travel restrictions and higher intensity policies than the policies implemented by governments, but did not always encourage rapid full lockdown and full border closures. The limitation of this study was that it was done with incomplete data due to the emerging COVID-19 epidemic, inconsistent testing and reporting. In addition, our research focuses only on population health benefits by controlling the spread of COVID-19 without balancing the negative impacts of economic and social consequences.
INTERPRETATION: Compared to actual government implementation, our algorithm mostly recommended earlier intensity of lockdown and travel restrictions. Reinforcement learning may be used as a decision support tool for implementation of public health interventions during COVID-19 and future pandemics.",True,computer vision,Not specified
33979715,Artificial intelligence and machine learning for medical imaging: A technology review,"Artificial intelligence (AI) has recently become a very popular buzzword, as a consequence of disruptive technical advances and impressive experimental results, notably in the field of image analysis and processing. In medicine, specialties where images are central, like radiology, pathology or oncology, have seized the opportunity and considerable efforts in research and development have been deployed to transfer the potential of AI to clinical applications. With AI becoming a more mainstream tool for typical medical imaging analysis tasks, such as diagnosis, segmentation, or classification, the key for a safe and efficient use of clinical AI applications relies, in part, on informed practitioners. The aim of this review is to present the basic technological pillars of AI, together with the state-of-the-art machine learning methods and their application to medical imaging. In addition, we discuss the new trends and future research directions. This will help the reader to understand how AI methods are now becoming an ubiquitous tool in any medical image analysis workflow and pave the way for the clinical implementation of AI-based solutions.",True,other,CNN
33977077,DeepVISP: Deep Learning for Virus Site Integration Prediction and Motif Discovery,"Approximately 15% of human cancers are estimated to be attributed to viruses. Virus sequences can be integrated into the host genome, leading to genomic instability and carcinogenesis. Here, a new deep convolutional neural network (CNN) model is developed with attention architecture, namely DeepVISP, for accurately predicting oncogenic virus integration sites (VISs) in the human genome. Using the curated benchmark integration data of three viruses, hepatitis B virus (HBV), human herpesvirus (HPV), and Epstein-Barr virus (EBV), DeepVISP achieves high accuracy and robust performance for all three viruses through automatically learning informative features and essential genomic positions only from the DNA sequences. In comparison, DeepVISP outperforms conventional machine learning methods by 8.43-34.33% measured by area under curve (AUC) value enhancement in three viruses. Moreover, DeepVISP can decode cis-regulatory factors that are potentially involved in virus integration and tumorigenesis, such as HOXB7, IKZF1, and LHX6. These findings are supported by multiple lines of evidence in literature. The clustering analysis of the informative motifs reveales that the representative k-mers in clusters could help guide virus recognition of the host genes. A user-friendly web server is developed for predicting putative oncogenic VISs in the human genome using DeepVISP.",True,other,convolutional neural network
33969307,Automated CT Staging of Chronic Obstructive Pulmonary Disease Severity for Predicting Disease Progression and Mortality with a Deep Learning Convolutional Neural Network,"PURPOSE: To develop a deep learning-based algorithm to stage the severity of chronic obstructive pulmonary disease (COPD) through quantification of emphysema and air trapping on CT images and to assess the ability of the proposed stages to prognosticate 5-year progression and mortality.
MATERIALS AND METHODS: In this retrospective study, an algorithm using co-registration and lung segmentation was developed in-house to automate quantification of emphysema and air trapping from inspiratory and expiratory CT images. The algorithm was then tested in a separate group of 8951 patients from the COPD Genetic Epidemiology study (date range, 2007-2017). With measurements of emphysema and air trapping, bivariable thresholds were determined to define CT stages of severity (mild, moderate, severe, and very severe) and were evaluated for their ability to prognosticate disease progression and mortality using logistic regression and Cox regression.
RESULTS: On the basis of CT stages, the odds of disease progression were greatest among patients with very severe disease (odds ratio [OR], 2.67; 95% CI: 2.02, 3.53; P &lt; .001) and were elevated in patients with moderate disease (OR, 1.50; 95% CI: 1.22, 1.84; P = .001). The hazard ratio of mortality for very severe disease at CT was 2.23 times the normal ratio (95% CI: 1.93, 2.58; P &lt; .001). When combined with Global Initiative for Chronic Obstructive Lung Disease (GOLD) staging, patients with GOLD stage 2 disease had the greatest odds of disease progression when the CT stage was severe (OR, 4.48; 95% CI: 3.18, 6.31; P &lt; .001) or very severe (OR, 4.72; 95% CI: 3.13, 7.13; P &lt; .001).
CONCLUSION: Automated CT algorithms can facilitate staging of COPD severity, have diagnostic performance comparable with that of spirometric GOLD staging, and provide further prognostic value when used in conjunction with GOLD staging.Supplemental material is available for this article.© RSNA, 2021See also commentary by Kalra and Ebrahimian in this issue.",True,other,Not specified
33961681,MGP-AttTCN: An interpretable machine learning model for the prediction of sepsis,"With a mortality rate of 5.4 million lives worldwide every year and a healthcare cost of more than 16 billion dollars in the USA alone, sepsis is one of the leading causes of hospital mortality and an increasing concern in the ageing western world. Recently, medical and technological advances have helped re-define the illness criteria of this disease, which is otherwise poorly understood by the medical society. Together with the rise of widely accessible Electronic Health Records, the advances in data mining and complex nonlinear algorithms are a promising avenue for the early detection of sepsis. This work contributes to the research effort in the field of automated sepsis detection with an open-access labelling of the medical MIMIC-III data set. Moreover, we propose MGP-AttTCN: a joint multitask Gaussian Process and attention-based deep learning model to early predict the occurrence of sepsis in an interpretable manner. We show that our model outperforms the current state-of-the-art and present evidence that different labelling heuristics lead to discrepancies in task difficulty. For instance, when predicting sepsis five hours prior to onset on our new realistic labels, our proposed model achieves an area under the ROC curve of 0.660 and an area under the PR curve of 0.483, whereas the (less interpretable) previous state-of-the-art model (MGP-TCN) achieves 0.635 AUROC and 0.460 AUPR and the popular commercial InSight model achieves 0.490 AUROC and 0.359 AUPR.",True,other,Not specified
33961635,ai-corona: Radiologist-assistant deep learning framework for COVID-19 diagnosis in chest CT scans,"The development of medical assisting tools based on artificial intelligence advances is essential in the global fight against COVID-19 outbreak and the future of medical systems. In this study, we introduce ai-corona, a radiologist-assistant deep learning framework for COVID-19 infection diagnosis using chest CT scans. Our framework incorporates an EfficientNetB3-based feature extractor. We employed three datasets; the CC-CCII set, the MasihDaneshvari Hospital (MDH) cohort, and the MosMedData cohort. Overall, these datasets constitute 7184 scans from 5693 subjects and include the COVID-19, non-COVID abnormal (NCA), common pneumonia (CP), non-pneumonia, and Normal classes. We evaluate ai-corona on test sets from the CC-CCII set, MDH cohort, and the entirety of the MosMedData cohort, for which it gained AUC scores of 0.997, 0.989, and 0.954, respectively. Our results indicates ai-corona outperforms all the alternative models. Lastly, our framework's diagnosis capabilities were evaluated as assistant to several experts. Accordingly, We observed an increase in both speed and accuracy of expert diagnosis when incorporating ai-corona's assistance.",True,other,RNN
33953523,Deep direct likelihood knockoffs,"Predictive modeling often uses black box machine learning methods, such as deep neural networks, to achieve state-of-the-art performance. In scientific domains, the scientist often wishes to discover which features are actually important for making the predictions. These discoveries may lead to costly follow-up experiments and as such it is important that the error rate on discoveries is not too high. Model-X knockoffs [2] enable important features to be discovered with control of the false discovery rate (fdr). However, knockoffs require rich generative models capable of accurately modeling the knockoff features while ensuring they obey the so-called ""swap"" property. We develop Deep Direct Likelihood Knockoffs (ddlk), which directly minimizes the KL divergence implied by the knockoff swap property. ddlk consists of two stages: it first maximizes the explicit likelihood of the features, then minimizes the KL divergence between the joint distribution of features and knockoffs and any swap between them. To ensure that the generated knockoffs are valid under any possible swap, ddlk uses the Gumbel-Softmax trick to optimize the knockoff generator under the worst-case swap. We find ddlk has higher power than baselines while controlling the false discovery rate on a variety of synthetic and real benchmarks including a task involving a large dataset from one of the epicenters of COVID-19.",True,other,convolutional neural network
33947697,Deep Learning for Fully Automated Prediction of Overall Survival in Patients with Oropharyngeal Cancer Using FDG-PET Imaging,"PURPOSE: Accurate prognostic stratification of patients with oropharyngeal squamous cell carcinoma (OPSCC) is crucial. We developed an objective and robust deep learning-based fully-automated tool called the DeepPET-OPSCC biomarker for predicting overall survival (OS) in OPSCC using [18F]fluorodeoxyglucose (FDG)-PET imaging.
EXPERIMENTAL DESIGN: The DeepPET-OPSCC prediction model was built and tested internally on a discovery cohort (n = 268) by integrating five convolutional neural network models for volumetric segmentation and ten models for OS prognostication. Two external test cohorts were enrolled-the first based on the Cancer Imaging Archive (TCIA) database (n = 353) and the second being a clinical deployment cohort (n = 31)-to assess the DeepPET-OPSCC performance and goodness of fit.
RESULTS: After adjustment for potential confounders, DeepPET-OPSCC was found to be an independent predictor of OS in both discovery and TCIA test cohorts [HR = 2.07; 95% confidence interval (CI), 1.31-3.28 and HR = 2.39; 95% CI, 1.38-4.16; both P = 0.002]. The tool also revealed good predictive performance, with a c-index of 0.707 (95% CI, 0.658-0.757) in the discovery cohort, 0.689 (95% CI, 0.621-0.757) in the TCIA test cohort, and 0.787 (95% CI, 0.675-0.899) in the clinical deployment test cohort; the average time taken was 2 minutes for calculation per exam. The integrated nomogram of DeepPET-OPSCC and clinical risk factors significantly outperformed the clinical model [AUC at 5 years: 0.801 (95% CI, 0.727-0.874) vs. 0.749 (95% CI, 0.649-0.842); P = 0.031] in the TCIA test cohort.
CONCLUSIONS: DeepPET-OPSCC achieved an accurate OS prediction in patients with OPSCC and enabled an objective, unbiased, and rapid assessment for OPSCC prognostication.",True,other,convolutional neural network
33946756,A Radiogenomics Ensemble to Predict EGFR and KRAS Mutations in NSCLC,"Lung cancer causes more deaths globally than any other type of cancer. To determine the best treatment, detecting EGFR and KRAS mutations is of interest. However, non-invasive ways to obtain this information are not available. Furthermore, many times there is a lack of big enough relevant public datasets, so the performance of single classifiers is not outstanding. In this paper, an ensemble approach is applied to increase the performance of EGFR and KRAS mutation prediction using a small dataset. A new voting scheme, Selective Class Average Voting (SCAV), is proposed and its performance is assessed both for machine learning models and CNNs. For the EGFR mutation, in the machine learning approach, there was an increase in the sensitivity from 0.66 to 0.75, and an increase in AUC from 0.68 to 0.70. With the deep learning approach, an AUC of 0.846 was obtained, and with SCAV, the accuracy of the model was increased from 0.80 to 0.857. For the KRAS mutation, both in the machine learning models (0.65 to 0.71 AUC) and the deep learning models (0.739 to 0.778 AUC), a significant increase in performance was found. The results obtained in this work show how to effectively learn from small image datasets to predict EGFR and KRAS mutations, and that using ensembles with SCAV increases the performance of machine learning classifiers and CNNs. The results provide confidence that as large datasets become available, tools to augment clinical capabilities can be fielded.",True,other,Not specified
33941991,"Multimodal deep learning from satellite and street-level imagery for measuring income, overcrowding, and environmental deprivation in urban areas","Data collected at large scale and low cost (e.g. satellite and street level imagery) have the potential to substantially improve resolution, spatial coverage, and temporal frequency of measurement of urban inequalities. Multiple types of data from different sources are often available for a given geographic area. Yet, most studies utilize a single type of input data when making measurements due to methodological difficulties in their joint use. We propose two deep learning-based methods for jointly utilizing satellite and street level imagery for measuring urban inequalities. We use London as a case study for three selected outputs, each measured in decile classes: income, overcrowding, and environmental deprivation. We compare the performances of our proposed multimodal models to corresponding unimodal ones using mean absolute error (MAE). First, satellite tiles are appended to street level imagery to enhance predictions at locations where street images are available leading to improvements in accuracy by 20, 10, and 9% in units of decile classes for income, overcrowding, and living environment. The second approach, novel to the best of our knowledge, uses a U-Net architecture to make predictions for all grid cells in a city at high spatial resolution (e.g. for 3 m × 3 m pixels in London in our experiments). It can utilize city wide availability of satellite images as well as more sparse information from street-level images where they are available leading to improvements in accuracy by 6, 10, and 11%. We also show examples of prediction maps from both approaches to visually highlight performance differences.",True,other,Not specified
33941145,Artificial intelligence improves the accuracy of residents in the diagnosis of hip fractures: a multicenter study,"BACKGROUND: Less experienced clinicians sometimes make misdiagnosis of hip fractures. We developed computer-aided diagnosis (CAD) system for hip fractures on plain X-rays using a deep learning model trained on a large dataset. In this study, we examined whether the accuracy of the diagnosis of hip fracture of the residents could be improved by using this system.
METHODS: A deep convolutional neural network approach was used for machine learning. Pytorch 1.3 and Fast.ai 1.0 were applied as frameworks, and an EfficientNet-B4 model (a pre-trained ImageNet model) was used. We handled the 5295 X-rays from the patients with femoral neck fracture or femoral trochanteric fracture from 2009 to 2019. We excluded cases in which the bilateral hips were not included within an image range, and cases of femoral shaft fracture and periprosthetic fracture. Finally, we included 5242 AP pelvic X-rays from 4851 cases. We divided these 5242 images into two images per image, and prepared 5242 images including fracture site and 5242 images without fracture site. Thus, a total of 10,484 images were used for machine learning. The accuracy, sensitivity, specificity, F-value, and area under the curve (AUC) were assessed. Gradient-weighted class activation mapping (Grad-CAM) was used to conceptualize the basis for the diagnosis of the fracture by the deep learning algorithm. Secondly, we conducted a controlled experiment with clinicians. Thirty-one residents;young doctors within 2 years of graduation from medical school who rotate through various specialties, were tested using 300 hip fracture images that were randomly extracted from the dataset. We evaluated the diagnostic accuracy with and without the use of the CAD system for each of the 300 images.
RESULTS: The accuracy, sensitivity, specificity, F-value, and AUC were 96.1, 95.2, 96.9%, 0.961, and 0.99, respectively, with the correct diagnostic basis generated by Grad-CAM. In the controlled experiment, the diagnostic accuracy of the residents significantly improved when they used the CAD system.
CONCLUSIONS: We developed a newly CAD system with a deep learning algorithm from a relatively large dataset from multiple institutions. Our system achieved high diagnostic performance. Our system improved the diagnostic accuracy of residents for hip fractures.
LEVEL OF EVIDENCE: Level III, Foundational evidence, before-after study.
CLINICAL RELEVANCE: high.",True,other,recurrent neural network
33936451,Multi-task Learning via Adaptation to Similar Tasks for Mortality Prediction of Diverse Rare Diseases,"The mortality prediction of diverse rare diseases using electronic health record (EHR) data is a crucial task for intelligent healthcare. However, data insufficiency and the clinical diversity of rare diseases make it hard for deep learning models to be trained. Mortality prediction for these patients with different diseases can be viewed as a multi-task learning problem with insufficient data but a large number of tasks. On the other hand, insufficient training data makes it difficult to train task-specific modules in multi-task learning models. To address the challenges of data insufficiency and task diversity, we propose an initialization-sharing multi-task learning method (Ada-SiT). Ada-Sit can learn the parameter initialization and dynamically measure the tasks' similarities, used for fast adaptation. We use Ada-SiT to train long short-term memory networks (LSTM) based prediction models on longitudinal EHR data. The experimental results demonstrate that the proposed model is effective for mortality prediction of diverse rare diseases.",True,other,RNN
33930734,Evaluation of deep learning approaches for identification of different corona-virus species and time series prediction,"Novel corona-virus (nCOV) has been declared as a pandemic that started from the city Wuhan of China. This deadly virus is infecting people rapidly and has targeted 4.93 million people across the world, with 227 K people being infected only in Italy. Cases of nCOV are quickly increasing whereas the number of nCOV test kits available in hospitals are limited. Under these conditions, an automated system for the classification of patients into nCOV positive and negative cases, is a much needed tool against the pandemic, helping in a selective use of the limited number of test kits. In this research, Convolutional Neural Network-based models (one block VGG, two block VGG, three block VGG, four block VGG, LetNet-5, AlexNet, and Resnet-50) have been employed for the detection of Corona-virus and SARS_MERS infected patients, distinguishing them from the healthy subjects, using lung X-ray scans, which has proven to be a challenging task, due to overlapping characteristics of different corona virus types. Furthermore, LSTM model has been used for time series forecasting of nCOV cases, in the following 10 days, in Italy. The evaluation results obtained, proved that the VGG1 model distinguishes the three classes at an accuracy of almost 91%, as compared to other models, whereas the approach based on the LSTM predicts the number of nCOV cases with 99% accuracy.",True,other,Not specified
33927746,Deep Learning Enables Fast and Accurate Imputation of Gene Expression,"A question of fundamental biological significance is to what extent the expression of a subset of genes can be used to recover the full transcriptome, with important implications for biological discovery and clinical application. To address this challenge, we propose two novel deep learning methods, PMI and GAIN-GTEx, for gene expression imputation. In order to increase the applicability of our approach, we leverage data from GTEx v8, a reference resource that has generated a comprehensive collection of transcriptomes from a diverse set of human tissues. We show that our approaches compare favorably to several standard and state-of-the-art imputation methods in terms of predictive performance and runtime in two case studies and two imputation scenarios. In comparison conducted on the protein-coding genes, PMI attains the highest performance in inductive imputation whereas GAIN-GTEx outperforms the other methods in in-place imputation. Furthermore, our results indicate strong generalization on RNA-Seq data from 3 cancer types across varying levels of missingness. Our work can facilitate a cost-effective integration of large-scale RNA biorepositories into genomic studies of disease, with high applicability across diverse tissue types.",True,text mining,Not specified
33923155,Investigating Cellular Trajectories in the Severity of COVID-19 and Their Transcriptional Programs Using Machine Learning Approaches,"Single-cell RNA sequencing of the bronchoalveolar lavage fluid (BALF) samples from COVID-19 patients has enabled us to examine gene expression changes of human tissue in response to the SARS-CoV-2 virus infection. However, the underlying mechanisms of COVID-19 pathogenesis at single-cell resolution, its transcriptional drivers, and dynamics require further investigation. In this study, we applied machine learning algorithms to infer the trajectories of cellular changes and identify their transcriptional programs. Our study generated cellular trajectories that show the COVID-19 pathogenesis of healthy-to-moderate and healthy-to-severe on macrophages and T cells, and we observed more diverse trajectories in macrophages compared to T cells. Furthermore, our deep-learning algorithm DrivAER identified several pathways (e.g., xenobiotic pathway and complement pathway) and transcription factors (e.g., MITF and GATA3) that could be potential drivers of the transcriptomic changes for COVID-19 pathogenesis and the markers of the COVID-19 severity. Moreover, macrophages-related functions corresponded more to the disease severity compared to T cells-related functions. Our findings more proficiently dissected the transcriptomic changes leading to the severity of a COVID-19 infection.",True,other,Not specified
33921978,Performance Comparison of Deep Learning Autoencoders for Cancer Subtype Detection Using Multi-Omics Data,"A heterogeneous disease such as cancer is activated through multiple pathways and different perturbations. Depending upon the activated pathway(s), the survival of the patients varies significantly and shows different efficacy to various drugs. Therefore, cancer subtype detection using genomics level data is a significant research problem. Subtype detection is often a complex problem, and in most cases, needs multi-omics data fusion to achieve accurate subtyping. Different data fusion and subtyping approaches have been proposed over the years, such as kernel-based fusion, matrix factorization, and deep learning autoencoders. In this paper, we compared the performance of different deep learning autoencoders for cancer subtype detection. We performed cancer subtype detection on four different cancer types from The Cancer Genome Atlas (TCGA) datasets using four autoencoder implementations. We also predicted the optimal number of subtypes in a cancer type using the silhouette score and found that the detected subtypes exhibit significant differences in survival profiles. Furthermore, we compared the effect of feature selection and similarity measures for subtype detection. For further evaluation, we used the Glioblastoma multiforme (GBM) dataset and identified the differentially expressed genes in each of the subtypes. The results obtained are consistent with other genomic studies and can be corroborated with the involved pathways and biological functions. Thus, it shows that the results from the autoencoders, obtained through the interaction of different datatypes of cancer, can be used for the prediction and characterization of patient subgroups and survival profiles.",True,other,Not specified
33921597,Intelligent Diagnosis of Thyroid Ultrasound Imaging Using an Ensemble of Deep Learning Methods,"Background and Objectives: At present, thyroid disorders have a great incidence in the worldwide population, so the development of alternative methods for improving the diagnosis process is necessary. Materials and Methods: For this purpose, we developed an ensemble method that fused two deep learning models, one based on convolutional neural network and the other based on transfer learning. For the first model, called 5-CNN, we developed an efficient end-to-end trained model with five convolutional layers, while for the second model, the pre-trained VGG-19 architecture was repurposed, optimized and trained. We trained and validated our models using a dataset of ultrasound images consisting of four types of thyroidal images: autoimmune, nodular, micro-nodular, and normal. Results: Excellent results were obtained by the ensemble CNN-VGG method, which outperformed the 5-CNN and VGG-19 models: 97.35% for the overall test accuracy with an overall specificity of 98.43%, sensitivity of 95.75%, positive and negative predictive value of 95.41%, and 98.05%. The micro average areas under each receiver operating characteristic curves was 0.96. The results were also validated by two physicians: an endocrinologist and a pediatrician. Conclusions: We proposed a new deep learning study for classifying ultrasound thyroidal images to assist physicians in the diagnosis process.",True,other,recurrent neural network
33918368,Deep Transfer Learning Approach for Automatic Recognition of Drug Toxicity and Inhibition of SARS-CoV-2,"Severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) causes COVID-19 and is responsible for the ongoing pandemic. Screening of potential antiviral drugs against SARS-CoV-2 depend on in vitro experiments, which are based on the quantification of the virus titer. Here, we used virus-induced cytopathic effects (CPE) in brightfield microscopy of SARS-CoV-2-infected monolayers to quantify the virus titer. Images were classified using deep transfer learning (DTL) that fine-tune the last layers of a pre-trained Resnet18 (ImageNet). To exclude toxic concentrations of potential drugs, the network was expanded to include a toxic score (TOX) that detected cell death (CPETOXnet). With this analytic tool, the inhibitory effects of chloroquine, hydroxychloroquine, remdesivir, and emetine were validated. Taken together we developed a simple method and provided open access implementation to quantify SARS-CoV-2 titers and drug toxicity in experimental settings, which may be adaptable to assays with other viruses. The quantification of virus titers from brightfield images could accelerate the experimental approach for antiviral testing.",True,other,Not specified
33907522,Artificial intelligence in the diagnosis of COVID-19: challenges and perspectives,"Artificial intelligence (AI) is being used to aid in various aspects of the COVID-19 crisis, including epidemiology, molecular research and drug development, medical diagnosis and treatment, and socioeconomics. The association of AI and COVID-19 can accelerate to rapidly diagnose positive patients. To learn the dynamics of a pandemic with relevance to AI, we search the literature using the different academic databases (PubMed, PubMed Central, Scopus, Google Scholar) and preprint servers (bioRxiv, medRxiv, arXiv). In the present review, we address the clinical applications of machine learning and deep learning, including clinical characteristics, electronic medical records, medical images (CT, X-ray, ultrasound images, etc.) in the COVID-19 diagnosis. The current challenges and future perspectives provided in this review can be used to direct an ideal deployment of AI technology in a pandemic.",True,other,CNN
33905341,A Deep Learning Radiomics Model to Identify Poor Outcome in COVID-19 Patients With Underlying Health Conditions: A Multicenter Study,"OBJECTIVE: Coronavirus disease 2019 (COVID-19) has caused considerable morbidity and mortality, especially in patients with underlying health conditions. A precise prognostic tool to identify poor outcomes among such cases is desperately needed.
METHODS: Total 400 COVID-19 patients with underlying health conditions were retrospectively recruited from 4 centers, including 54 dead cases (labeled as poor outcomes) and 346 patients discharged or hospitalized for at least 7 days since initial CT scan. Patients were allocated to a training set (n = 271), a test set (n = 68), and an external test set (n = 61). We proposed an initial CT-derived hybrid model by combining a 3D-ResNet10 based deep learning model and a quantitative 3D radiomics model to predict the probability of COVID-19 patients reaching poor outcome. The model performance was assessed by area under the receiver operating characteristic curve (AUC), survival analysis, and subgroup analysis.
RESULTS: The hybrid model achieved AUCs of 0.876 (95% confidence interval: 0.752-0.999) and 0.864 (0.766-0.962) in test and external test sets, outperforming other models. The survival analysis verified the hybrid model as a significant risk factor for mortality (hazard ratio, 2.049 [1.462-2.871], P < 0.001) that could well stratify patients into high-risk and low-risk of reaching poor outcomes (P < 0.001).
CONCLUSION: The hybrid model that combined deep learning and radiomics could accurately identify poor outcomes in COVID-19 patients with underlying health conditions from initial CT scans. The great risk stratification ability could help alert risk of death and allow for timely surveillance plans.",True,other,Not specified
33903608,Machine learning and deep learning to predict mortality in patients with spontaneous coronary artery dissection,"Machine learning (ML) and deep learning (DL) can successfully predict high prevalence events in very large databases (big data), but the value of this methodology for risk prediction in smaller cohorts with uncommon diseases and infrequent events is uncertain. The clinical course of spontaneous coronary artery dissection (SCAD) is variable, and no reliable methods are available to predict mortality. Based on the hypothesis that machine learning (ML) and deep learning (DL) techniques could enhance the identification of patients at risk, we applied a deep neural network to information available in electronic health records (EHR) to predict in-hospital mortality in patients with SCAD. We extracted patient data from the EHR of an extensive urban health system and applied several ML and DL models using candidate clinical variables potentially associated with mortality. We partitioned the data into training and evaluation sets with cross-validation. We estimated model performance based on the area under the receiver-operator characteristics curve (AUC) and balanced accuracy. As sensitivity analyses, we examined results limited to cases with complete clinical information available. We identified 375 SCAD patients of which mortality during the index hospitalization was 11.5%. The best-performing DL algorithm identified in-hospital mortality with AUC 0.98 (95% CI 0.97-0.99), compared to other ML models (P < 0.0001). For prediction of mortality using ML models in patients with SCAD, the AUC ranged from 0.50 with the random forest method (95% CI 0.41-0.58) to 0.95 with the AdaBoost model (95% CI 0.93-0.96), with intermediate performance using logistic regression, decision tree, support vector machine, K-nearest neighbors, and extreme gradient boosting methods. A deep neural network model was associated with higher predictive accuracy and discriminative power than logistic regression or ML models for identification of patients with ACS due to SCAD prone to early mortality.",True,other,recurrent neural network
33900581,A deep-learning model to continuously predict severe acute kidney injury based on urine output changes in critically ill patients,"BACKGROUND: Acute Kidney Injury (AKI), a frequent complication of pateints in the Intensive Care Unit (ICU), is associated with a high mortality rate. Early prediction of AKI is essential in order to trigger the use of preventive care actions.
METHODS: The aim of this study was to ascertain the accuracy of two mathematical analysis models in obtaining a predictive score for AKI development. A deep learning model based on a urine output trends was compared with a logistic regression analysis for AKI prediction in stages 2 and 3 (defined as the simultaneous increase of serum creatinine and decrease of urine output, according to  the Acute Kidney Injury Network (AKIN) guidelines). Two retrospective datasets including 35,573 ICU patients were analyzed. Urine output data were used to train and test the logistic regression and the deep learning model.
RESULTS: The deep learning model defined an area under the curve (AUC) of 0.89 (± 0.01), sensitivity = 0.8 and specificity = 0.84, which was higher than the logistic regression analysis. The deep learning model was able to predict 88% of AKI cases more than 12 h before their onset: for every 6 patients identified as being at risk of AKI by the deep learning model, 5 experienced the event. On the contrary, for every 12 patients not considered to be at risk by the model, 2 developed AKI.
CONCLUSION: In conclusion, by using urine output trends, deep learning analysis was able to predict AKI episodes more than 12 h in advance, and with a higher accuracy than the classical urine output thresholds. We suggest that this algorithm could be integrated in the ICU setting to better manage, and potentially prevent, AKI episodes.",True,other,Not specified
33873177,Modelling dynamics of coronavirus disease 2019 spread for pandemic forecasting based on Simulink,"In this paper, we demonstrate the application of MATLAB to develop a pandemic prediction system based on Simulink. The susceptible-exposed-asymptomatic but infectious-symptomatic and infectious (severe infected population + mild infected population)-recovered-deceased (SEAI(I<sub>1</sub>+I<sub>2</sub>)RD) physical model for unsupervised learning and two types of supervised learning, namely, fuzzy proportional-integral-derivative (PID) and wavelet neural-network PID learning, are used to build a predictive-control system model that enables self-learning artificial intelligence (AI)-based control. After parameter setting, the data entering the model are predicted, and the value of the data set at a future moment is calculated. PID controllers are added to ensure that the system does not diverge at the beginning of iterative learning. To adapt to complex system conditions and afford excellent control, a wavelet neural-network PID control strategy is developed that can be adjusted and corrected in real time, according to the output error.",True,other,recurrent neural network
33858815,Long-term mortality risk stratification of liver transplant recipients: real-time application of deep learning algorithms on longitudinal data,"BACKGROUND: Survival of liver transplant recipients beyond 1 year since transplantation is compromised by an increased risk of cancer, cardiovascular events, infection, and graft failure. Few clinical tools are available to identify patients at risk of these complications, which would flag them for screening tests and potentially life-saving interventions. In this retrospective analysis, we aimed to assess the ability of deep learning algorithms of longitudinal data from two prospective cohorts to predict complications resulting in death after liver transplantation over multiple timeframes, compared with logistic regression models.
METHODS: In this machine learning analysis, model development was done on a set of 42 146 liver transplant recipients (mean age 48·6 years [SD 17·3]; 17 196 [40·8%] women) from the Scientific Registry of Transplant Recipients (SRTR) in the USA. Transferability of the model was further evaluated by fine-tuning on a dataset from the University Health Network (UHN) in Canada (n=3269; mean age 52·5 years [11·1]; 1079 [33·0%] women). The primary outcome was cause of death, as recorded in the databases, due to cardiovascular causes, infection, graft failure, or cancer, within 1 year and 5 years of each follow-up examination after transplantation. We compared the performance of four deep learning models against logistic regression, assessing performance using the area under the receiver operating characteristic curve (AUROC).
FINDINGS: In both datasets, deep learning models outperformed logistic regression, with the Transformer model achieving the highest AUROCs in both datasets (p<0·0001). The AUROC for the Transformer model across all outcomes in the SRTR dataset was 0·804 (99% CI 0·795-0·854) for 1-year predictions and 0·733 (0·729-0·769) for 5-year predictions. In the UHN dataset, the AUROC for the top-performing deep learning model was 0·807 (0·795-0·842) for 1-year predictions and 0·722 (0·705-0·764) for 5-year predictions. AUROCs ranged from 0·695 (0·680-0·713) for prediction of death from infection within 5 years to 0·859 (0·847-0·871) for prediction of death by graft failure within 1 year.
INTERPRETATION: Deep learning algorithms can incorporate longitudinal information to continuously predict long-term outcomes after liver transplantation, outperforming logistic regression models. Physicians could use these algorithms at routine follow-up visits to identify liver transplant recipients at risk for adverse outcomes and prevent these complications by modifying management based on ranked features.
FUNDING: Canadian Donation and Transplant Research Program, CIFAR AI Chairs Program.",True,other,Not specified
33835928,Multilevel Deep-Aggregated Boosted Network to Recognize COVID-19 Infection from Large-Scale Heterogeneous Radiographic Data,"In the present epidemic of the coronavirus disease 2019 (COVID-19), radiological imaging modalities, such as X-ray and computed tomography (CT), have been identified as effective diagnostic tools. However, the subjective assessment of radiographic examination is a time-consuming task and demands expert radiologists. Recent advancements in artificial intelligence have enhanced the diagnostic power of computer-aided diagnosis (CAD) tools and assisted medical specialists in making efficient diagnostic decisions. In this work, we propose an optimal multilevel deep-aggregated boosted network to recognize COVID-19 infection from heterogeneous radiographic data, including X-ray and CT images. Our method leverages multilevel deep-aggregated features and multistage training via a mutually beneficial approach to maximize the overall CAD performance. To improve the interpretation of CAD predictions, these multilevel deep features are visualized as additional outputs that can assist radiologists in validating the CAD results. A total of six publicly available datasets were fused to build a single large-scale heterogeneous radiographic collection that was used to analyze the performance of the proposed technique and other baseline methods. To preserve generality of our method, we selected different patient data for training, validation, and testing, and consequently, the data of same patient were not included in training, validation, and testing subsets. In addition, fivefold cross-validation was performed in all the experiments for a fair evaluation. Our method exhibits promising performance values of 95.38%, 95.57%, 92.53%, 98.14%, 93.16%, and 98.55% in terms of average accuracy, F-measure, specificity, sensitivity, precision, and area under the curve, respectively and outperforms various state-of-the-art methods.",True,both,Not specified
33807714,Multi-Drug Featurization and Deep Learning Improve Patient-Specific Predictions of Adverse Events,"While the clinical approval process is able to filter out medications whose utility does not offset their adverse drug reaction profile in humans, it is not well suited to characterizing lower frequency issues and idiosyncratic multi-drug interactions that can happen in real world diverse patient populations. With a growing abundance of real-world evidence databases containing hundreds of thousands of patient records, it is now feasible to build machine learning models that incorporate individual patient information to provide personalized adverse event predictions. In this study, we build models that integrate patient specific demographic, clinical, and genetic features (when available) with drug structure to predict adverse drug reactions. We develop an extensible graph convolutional approach to be able to integrate molecular effects from the variable number of medications a typical patient may be taking. Our model outperforms standard machine learning methods at the tasks of predicting hospitalization and death in the UK Biobank dataset yielding an R2 of 0.37 and an AUC of 0.90, respectively. We believe our model has potential for evaluating new therapeutic compounds for individualized toxicities in real world diverse populations. It can also be used to prioritize medications when there are multiple options being considered for treatment.",True,other,Not specified
33792724,"Multimodal, multitask, multiattention (M3) deep learning detection of reticular pseudodrusen: Toward automated and accessible classification of age-related macular degeneration","OBJECTIVE: Reticular pseudodrusen (RPD), a key feature of age-related macular degeneration (AMD), are poorly detected by human experts on standard color fundus photography (CFP) and typically require advanced imaging modalities such as fundus autofluorescence (FAF). The objective was to develop and evaluate the performance of a novel multimodal, multitask, multiattention (M3) deep learning framework on RPD detection.
MATERIALS AND METHODS: A deep learning framework (M3) was developed to detect RPD presence accurately using CFP alone, FAF alone, or both, employing >8000 CFP-FAF image pairs obtained prospectively (Age-Related Eye Disease Study 2). The M3 framework includes multimodal (detection from single or multiple image modalities), multitask (training different tasks simultaneously to improve generalizability), and multiattention (improving ensembled feature representation) operation. Performance on RPD detection was compared with state-of-the-art deep learning models and 13 ophthalmologists; performance on detection of 2 other AMD features (geographic atrophy and pigmentary abnormalities) was also evaluated.
RESULTS: For RPD detection, M3 achieved an area under the receiver-operating characteristic curve (AUROC) of 0.832, 0.931, and 0.933 for CFP alone, FAF alone, and both, respectively. M3 performance on CFP was very substantially superior to human retinal specialists (median F1 score = 0.644 vs 0.350). External validation (the Rotterdam Study) demonstrated high accuracy on CFP alone (AUROC, 0.965). The M3 framework also accurately detected geographic atrophy and pigmentary abnormalities (AUROC, 0.909 and 0.912, respectively), demonstrating its generalizability.
CONCLUSIONS: This study demonstrates the successful development, robust evaluation, and external validation of a novel deep learning framework that enables accessible, accurate, and automated AMD diagnosis and prognosis.",True,other,recurrent neural network
33785839,"Machine learning for patient risk stratification: standing on, or looking over, the shoulders of clinicians?","Machine learning can help clinicians to make individualized patient predictions only if researchers demonstrate models that contribute novel insights, rather than learning the most likely next step in a set of actions a clinician will take. We trained deep learning models using only clinician-initiated, administrative data for 42.9 million admissions using three subsets of data: demographic data only, demographic data and information available at admission, and the previous data plus charges recorded during the first day of admission. Models trained on charges during the first day of admission achieve performance close to published full EMR-based benchmarks for inpatient outcomes: inhospital mortality (0.89 AUC), prolonged length of stay (0.82 AUC), and 30-day readmission rate (0.71 AUC). Similar performance between models trained with only clinician-initiated data and those trained with full EMR data purporting to include information about patient state and physiology should raise concern in the deployment of these models. Furthermore, these models exhibited significant declines in performance when evaluated over only myocardial infarction (MI) patients relative to models trained over MI patients alone, highlighting the importance of physician diagnosis in the prognostic performance of these models. These results provide a benchmark for predictive accuracy trained only on prior clinical actions and indicate that models with similar performance may derive their signal by looking over clinician's shoulders-using clinical behavior as the expression of preexisting intuition and suspicion to generate a prediction. For models to guide clinicians in individual decisions, performance exceeding these benchmarks is necessary.",True,other,RNN
33763651,Pan-cancer image-based detection of clinically actionable genetic alterations,"Molecular alterations in cancer can cause phenotypic changes in tumor cells and their micro-environment. Routine histopathology tissue slides - which are ubiquitously available - can reflect such morphological changes. Here, we show that deep learning can consistently infer a wide range of genetic mutations, molecular tumor subtypes, gene expression signatures and standard pathology biomarkers directly from routine histology. We developed, optimized, validated and publicly released a one-stop-shop workflow and applied it to tissue slides of more than 5000 patients across multiple solid tumors. Our findings show that a single deep learning algorithm can be trained to predict a wide range of molecular alterations from routine, paraffin-embedded histology slides stained with hematoxylin and eosin. These predictions generalize to other populations and are spatially resolved. Our method can be implemented on mobile hardware, potentially enabling point-of-care diagnostics for personalized cancer treatment. More generally, this approach could elucidate and quantify genotype-phenotype links in cancer.",True,other,Not specified
33738639,Transfer learning-based ensemble support vector machine model for automated COVID-19 detection using lung computerized tomography scan data,"The novel discovered disease coronavirus popularly known as COVID-19 is caused due to severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and declared a pandemic by the World Health Organization (WHO). An early-stage detection of COVID-19 is crucial for the containment of the pandemic it has caused. In this study, a transfer learning-based COVID-19 screening technique is proposed. The motivation of this study is to design an automated system that can assist medical staff especially in areas where trained staff are outnumbered. The study investigates the potential of transfer learning-based models for automatically diagnosing diseases like COVID-19 to assist the medical force, especially in times of an outbreak. In the proposed work, a deep learning model, i.e., truncated VGG16 (Visual Geometry Group from Oxford) is implemented to screen COVID-19 CT scans. The VGG16 architecture is fine-tuned and used to extract features from CT scan images. Further principal component analysis (PCA) is used for feature selection. For the final classification, four different classifiers, namely deep convolutional neural network (DCNN), extreme learning machine (ELM), online sequential ELM, and bagging ensemble with support vector machine (SVM) are compared. The best performing classifier bagging ensemble with SVM within 385 ms achieved an accuracy of 95.7%, the precision of 95.8%, area under curve (AUC) of 0.958, and an F1 score of 95.3% on 208 test images. The results obtained on diverse datasets prove the superiority and robustness of the proposed work. A pre-processing technique has also been proposed for radiological data. The study further compares pre-trained CNN architectures and classification models against the proposed technique.",True,other,Not specified
33735088,"Integration of CNN, CBMIR, and Visualization Techniques for Diagnosis and Quantification of Covid-19 Disease","Diagnosis techniques based on medical image modalities have higher sensitivities compared to conventional RT-PCT tests. We propose two methods for diagnosing COVID-19 disease using X-ray images and differentiating it from viral pneumonia. The diagnosis section is based on deep neural networks, and the discriminating uses an image retrieval approach. Both units were trained by healthy, pneumonia, and COVID-19 images. In COVID-19 patients, the maximum intensity projection of the lung CT is visualized to a physician, and the CT Involvement Score is calculated. The performance of the CNN and image retrieval algorithms were improved by transfer learning and hashing functions. We achieved an accuracy of 97% and an overall prec@10 of 87%, respectively, concerning the CNN and the retrieval methods.",True,other,CNN
33735066,"Referral for disease-related visual impairment using retinal photograph-based deep learning: a proof-of-concept, model development study","BACKGROUND: In current approaches to vision screening in the community, a simple and efficient process is needed to identify individuals who should be referred to tertiary eye care centres for vision loss related to eye diseases. The emergence of deep learning technology offers new opportunities to revolutionise this clinical referral pathway. We aimed to assess the performance of a newly developed deep learning algorithm for detection of disease-related visual impairment.
METHODS: In this proof-of-concept study, using retinal fundus images from 15 175 eyes with complete data related to best-corrected visual acuity or pinhole visual acuity from the Singapore Epidemiology of Eye Diseases Study, we first developed a single-modality deep learning algorithm based on retinal photographs alone for detection of any disease-related visual impairment (defined as eyes from patients with major eye diseases and best-corrected visual acuity of <20/40), and moderate or worse disease-related visual impairment (eyes with disease and best-corrected visual acuity of <20/60). After development of the algorithm, we tested it internally, using a new set of 3803 eyes from the Singapore Epidemiology of Eye Diseases Study. We then tested it externally using three population-based studies (the Beijing Eye study [6239 eyes], Central India Eye and Medical study [6526 eyes], and Blue Mountains Eye Study [2002 eyes]), and two clinical studies (the Chinese University of Hong Kong's Sight Threatening Diabetic Retinopathy study [971 eyes] and the Outram Polyclinic Study [1225 eyes]). The algorithm's performance in each dataset was assessed on the basis of the area under the receiver operating characteristic curve (AUC).
FINDINGS: In the internal test dataset, the AUC for detection of any disease-related visual impairment was 94·2% (95% CI 93·0-95·3; sensitivity 90·7% [87·0-93·6]; specificity 86·8% [85·6-87·9]). The AUC for moderate or worse disease-related visual impairment was 93·9% (95% CI 92·2-95·6; sensitivity 94·6% [89·6-97·6]; specificity 81·3% [80·0-82·5]). Across the five external test datasets (16 993 eyes), the algorithm achieved AUCs ranging between 86·6% (83·4-89·7; sensitivity 87·5% [80·7-92·5]; specificity 70·0% [66·7-73·1]) and 93·6% (92·4-94·8; sensitivity 87·8% [84·1-90·9]; specificity 87·1% [86·2-88·0]) for any disease-related visual impairment, and the AUCs for moderate or worse disease-related visual impairment ranged between 85·9% (81·8-90·1; sensitivity 84·7% [73·0-92·8]; specificity 74·4% [71·4-77·2]) and 93·5% (91·7-95·3; sensitivity 90·3% [84·2-94·6]; specificity 84·2% [83·2-85·1]).
INTERPRETATION: This proof-of-concept study shows the potential of a single-modality, function-focused tool in identifying visual impairment related to major eye diseases, providing more timely and pinpointed referral of patients with disease-related visual impairment from the community to tertiary eye hospitals.
FUNDING: National Medical Research Council, Singapore.",True,other,Not specified
33710962,A Deep Learning Approach to Predict Diabetes' Cardiovascular Complications From Administrative Claims,"People with diabetes require lifelong access to healthcare services to delay the onset of complications. Their disease management processes generate great volumes of data across several domains, from clinical to administrative. Difficulties in accessing and processing these data hinder their secondary use in an institutional setting, even for highly desirable applications, such as the prediction of cardiovascular disease, the main driver of excess mortality in diabetes. Hence, in the present work, we propose a deep learning model for the prediction of major adverse cardiovascular events (MACE), developed and validated using the administrative claims of 214,676 diabetic patients of the Veneto region, in North East Italy. Specifically, we use a year of pharmacy and hospitalisation claims, together with basic patient's information, to predict the 4P-MACE composite endpoint, i.e., the first occurrence of death, heart failure, myocardial infarction, or stroke, with a variable prediction horizon of 1 to 5 years. Adapting to the time-to-event nature of this task, we cast our problem as a multi-outcome (4P-MACE and components), multi-label (1 to 5 years) classification task with a custom loss to account for the effect of censoring. Our model, purposefully specified to minimise data preparation costs, exhibits satisfactory performance in predicting 4P-MACE at all prediction horizons: AUROC from 0.812 (C.I.: 0.797 - 0.827) to 0.792 (C.I.: 0.781 - 0.802); C-index from 0.802 (C.I.: 0.788 - 0.816) to 0.770 (C.I.: 0.761 - 0.779). Components' prediction performance is also adequate, ranging from death's 0.877 1-year AUROC to stroke's 0.689 5-year AUROC.",True,other,RNN
33686818,Prediction of Patient Management in COVID-19 Using Deep Learning-Based Fully Automated Extraction of Cardiothoracic CT Metrics and Laboratory Findings,"OBJECTIVE: To extract pulmonary and cardiovascular metrics from chest CTs of patients with coronavirus disease 2019 (COVID-19) using a fully automated deep learning-based approach and assess their potential to predict patient management.
MATERIALS AND METHODS: All initial chest CTs of patients who tested positive for severe acute respiratory syndrome coronavirus 2 at our emergency department between March 25 and April 25, 2020, were identified (n = 120). Three patient management groups were defined: group 1 (outpatient), group 2 (general ward), and group 3 (intensive care unit [ICU]). Multiple pulmonary and cardiovascular metrics were extracted from the chest CT images using deep learning. Additionally, six laboratory findings indicating inflammation and cellular damage were considered. Differences in CT metrics, laboratory findings, and demographics between the patient management groups were assessed. The potential of these parameters to predict patients' needs for intensive care (yes/no) was analyzed using logistic regression and receiver operating characteristic curves. Internal and external validity were assessed using 109 independent chest CT scans.
RESULTS: While demographic parameters alone (sex and age) were not sufficient to predict ICU management status, both CT metrics alone (including both pulmonary and cardiovascular metrics; area under the curve [AUC] = 0.88; 95% confidence interval [CI] = 0.79-0.97) and laboratory findings alone (C-reactive protein, lactate dehydrogenase, white blood cell count, and albumin; AUC = 0.86; 95% CI = 0.77-0.94) were good classifiers. Excellent performance was achieved by a combination of demographic parameters, CT metrics, and laboratory findings (AUC = 0.91; 95% CI = 0.85-0.98). Application of a model that combined both pulmonary CT metrics and demographic parameters on a dataset from another hospital indicated its external validity (AUC = 0.77; 95% CI = 0.66-0.88).
CONCLUSION: Chest CT of patients with COVID-19 contains valuable information that can be accessed using automated image analysis. These metrics are useful for the prediction of patient management.",True,computer vision,Not specified
33680071,COVID-19 in Iran: Forecasting Pandemic Using Deep Learning,"COVID-19 has led to a pandemic, affecting almost all countries in a few months. In this work, we applied selected deep learning models including multilayer perceptron, random forest, and different versions of long short-term memory (LSTM), using three data sources to train the models, including COVID-19 occurrences, basic information like coded country names, and detailed information like population, and area of different countries. The main goal is to forecast the outbreak in nine countries (Iran, Germany, Italy, Japan, Korea, Switzerland, Spain, China, and the USA). The performances of the models are measured using four metrics, including mean average percentage error (MAPE), root mean square error (RMSE), normalized RMSE (NRMSE), and R 2. The best performance was found for a modified version of LSTM, called M-LSTM (winner model), to forecast the future trajectory of the pandemic in the mentioned countries. For this purpose, we collected the data from January 22 till July 30, 2020, for training, and from 1 August 2020 to 31 August 2020, for the testing phase. Through experimental results, the winner model achieved reasonably accurate predictions (MAPE, RMSE, NRMSE, and R 2 are 0.509, 458.12, 0.001624, and 0.99997, respectively). Furthermore, we stopped the training of the model on some dates related to main country actions to investigate the effect of country actions on predictions by the model.",True,other,recurrent neural network
33649429,Deep learning approaches for challenging species and gender identification of mosquito vectors,"Microscopic observation of mosquito species, which is the basis of morphological identification, is a time-consuming and challenging process, particularly owing to the different skills and experience of public health personnel. We present deep learning models based on the well-known you-only-look-once (YOLO) algorithm. This model can be used to simultaneously classify and localize the images to identify the species of the gender of field-caught mosquitoes. The results indicated that the concatenated two YOLO v3 model exhibited the optimal performance in identifying the mosquitoes, as the mosquitoes were relatively small objects compared with the large proportional environment image. The robustness testing of the proposed model yielded a mean average precision and sensitivity of 99% and 92.4%, respectively. The model exhibited high performance in terms of the specificity and accuracy, with an extremely low rate of misclassification. The area under the receiver operating characteristic curve (AUC) was 0.958 ± 0.011, which further demonstrated the model accuracy. Thirteen classes were detected with an accuracy of 100% based on a confusion matrix. Nevertheless, the relatively low detection rates for the two species were likely a result of the limited number of wild-caught biological samples available. The proposed model can help establish the population densities of mosquito vectors in remote areas to predict disease outbreaks in advance.",True,other,Not specified
33631067,Development and Validation of a Deep Learning Based Diabetes Prediction System Using a Nationwide Population-Based Cohort,"BACKGROUND: Previously developed prediction models for type 2 diabetes mellitus (T2DM) have limited performance. We developed a deep learning (DL) based model using a cohort representative of the Korean population.
METHODS: This study was conducted on the basis of the National Health Insurance Service-Health Screening (NHIS-HEALS) cohort of Korea. Overall, 335,302 subjects without T2DM at baseline were included. We developed the model based on 80% of the subjects, and verified the power in the remainder. Predictive models for T2DM were constructed using the recurrent neural network long short-term memory (RNN-LSTM) network and the Cox longitudinal summary model. The performance of both models over a 10-year period was compared using a time dependent area under the curve.
RESULTS: During a mean follow-up of 10.4±1.7 years, the mean frequency of periodic health check-ups was 2.9±1.0 per subject. During the observation period, T2DM was newly observed in 8.7% of the subjects. The annual performance of the model created using the RNN-LSTM network was superior to that of the Cox model, and the risk factors for T2DM, derived using the two models were similar; however, certain results differed.
CONCLUSION: The DL-based T2DM prediction model, constructed using a cohort representative of the population, performs better than the conventional model. After pilot tests, this model will be provided to all Korean national health screening recipients in the future.",True,text mining,recurrent neural network
33607378,Improving electrocardiogram-based detection of rare genetic heart disease using transfer learning: An application to phospholamban p.Arg14del mutation carriers,"The pathogenic mutation p.Arg14del in the gene encoding Phospholamban (PLN) is known to cause cardiomyopathy and leads to increased risk of sudden cardiac death. Automatic tools might improve the detection of patients with this rare disease. Deep learning is currently the state-of-the-art in signal processing but requires large amounts of data to train the algorithms. In situations with relatively small amounts of data, like PLN, transfer learning may improve accuracy. We propose an ECG-based detection of the PLN mutation using transfer learning from a model originally trained for sex identification. The sex identification model was trained with 256,278 ECGs and subsequently finetuned for PLN detection (155 ECGs of patients with PLN) with two control groups: a balanced age/sex matched group and a randomly selected imbalanced population. The data was split in 10 folds and 20% of the training data was used for validation and early stopping. The models were evaluated with the area under the receiver operating characteristic curve (AUROC) of the testing data. We used gradient activation for explanation of the prediction models. The models trained with transfer learning outperformed the models trained from scratch for both the balanced (AUROC 0.87 vs AUROC 0.71) and imbalanced (AUROC 0.0.90 vs AUROC 0.65) population. The proposed approach was able to improve the accuracy of a rare disease detection model by transfer learning information from a non-manual annotated and abundant label with only limited data available.",True,other,RNN
33594415,Deep propensity network using a sparse autoencoder for estimation of treatment effects,"OBJECTIVE: Drawing causal estimates from observational data is problematic, because datasets often contain underlying bias (eg, discrimination in treatment assignment). To examine causal effects, it is important to evaluate what-if scenarios-the so-called ""counterfactuals."" We propose a novel deep learning architecture for propensity score matching and counterfactual prediction-the deep propensity network using a sparse autoencoder (DPN-SA)-to tackle the problems of high dimensionality, nonlinear/nonparallel treatment assignment, and residual confounding when estimating treatment effects.
MATERIALS AND METHODS: We used 2 randomized prospective datasets, a semisynthetic one with nonlinear/nonparallel treatment selection bias and simulated counterfactual outcomes from the Infant Health and Development Program and a real-world dataset from the LaLonde's employment training program. We compared different configurations of the DPN-SA against logistic regression and LASSO as well as deep counterfactual networks with propensity dropout (DCN-PD). Models' performances were assessed in terms of average treatment effects, mean squared error in precision on effect's heterogeneity, and average treatment effect on the treated, over multiple training/test runs.
RESULTS: The DPN-SA outperformed logistic regression and LASSO by 36%-63%, and DCN-PD by 6%-10% across all datasets. All deep learning architectures yielded average treatment effects close to the true ones with low variance. Results were also robust to noise-injection and addition of correlated variables. Code is publicly available at https://github.com/Shantanu48114860/DPN-SAz.
DISCUSSION AND CONCLUSION: Deep sparse autoencoders are particularly suited for treatment effect estimation studies using electronic health records because they can handle high-dimensional covariate sets, large sample sizes, and complex heterogeneity in treatment assignments.",True,other,convolutional neural network
33594374,SEED: Symptom Extraction from English Social Media Posts using Deep Learning and Transfer Learning,"The increase of social media usage across the globe has fueled efforts in digital epidemiology for mining valuable information such as medication use, adverse drug effects and reports of viral infections that directly and indirectly affect population health. Such specific information can, however, be scarce, hard to find, and mostly expressed in very colloquial language. In this work, we focus on a fundamental problem that enables social media mining for disease monitoring. We present and make available SEED, a natural language processing approach to detect symptom and disease mentions from social media data obtained from platforms such as Twitter and DailyStrength and to normalize them into UMLS terminology. Using multi-corpus training and deep learning models, the tool achieves an overall F1 score of 0.86 and 0.72 on DailyStrength and balanced Twitter datasets, significantly improving over previous approaches on the same datasets. We apply the tool on Twitter posts that report COVID19 symptoms, particularly to quantify whether the SEED system can extract symptoms absent in the training data. The study results also draw attention to the potential of multi-corpus training for performance improvements and the need for continuous training on newly obtained data for consistent performance amidst the ever-changing nature of the social media vocabulary.",True,both,CNN
33594159,A deep learning integrated radiomics model for identification of coronavirus disease 2019 using computed tomography,"Since its first outbreak, Coronavirus Disease 2019 (COVID-19) has been rapidly spreading worldwide and caused a global pandemic. Rapid and early detection is essential to contain COVID-19. Here, we first developed a deep learning (DL) integrated radiomics model for end-to-end identification of COVID-19 using CT scans and then validated its clinical feasibility. We retrospectively collected CT images of 386 patients (129 with COVID-19 and 257 with other community-acquired pneumonia) from three medical centers to train and externally validate the developed models. A pre-trained DL algorithm was utilized to automatically segment infected lesions (ROIs) on CT images which were used for feature extraction. Five feature selection methods and four machine learning algorithms were utilized to develop radiomics models. Trained with features selected by L1 regularized logistic regression, classifier multi-layer perceptron (MLP) demonstrated the optimal performance with AUC of 0.922 (95% CI 0.856-0.988) and 0.959 (95% CI 0.910-1.000), the same sensitivity of 0.879, and specificity of 0.900 and 0.887 on internal and external testing datasets, which was equivalent to the senior radiologist in a reader study. Additionally, diagnostic time of DL-MLP was more efficient than radiologists (38 s vs 5.15 min). With an adequate performance for identifying COVID-19, DL-MLP may help in screening of suspected cases.",True,other,Not specified
33591049,"Deep Learning-based Propensity Scores for Confounding Control in Comparative Effectiveness Research: A Large-scale, Real-world Data Study","BACKGROUND: Due to the non-randomized nature of real-world data, prognostic factors need to be balanced, which is often done by propensity scores (PSs). This study aimed to investigate whether autoencoders, which are unsupervised deep learning architectures, might be leveraged to compute PS.
METHODS: We selected patient-level data of 128,368 first-line treated cancer patients from the Flatiron Health EHR-derived de-identified database. We trained an autoencoder architecture to learn a lower-dimensional patient representation, which we used to compute PS. To compare the performance of an autoencoder-based PS with established methods, we performed a simulation study. We assessed the balancing and adjustment performance using standardized mean differences, root mean square errors (RMSE), percent bias, and confidence interval coverage. To illustrate the application of the autoencoder-based PS, we emulated the PRONOUNCE trial by applying the trial's protocol elements within an observational database setting, comparing two chemotherapy regimens.
RESULTS: All methods but the manual variable selection approach led to well-balanced cohorts with average standardized mean differences <0.1. LASSO yielded on average the lowest deviation of resulting estimates (RMSE 0.0205) followed by the autoencoder approach (RMSE 0.0248). Altering the hyperparameter setup in sensitivity analysis, the autoencoder approach led to similar results as LASSO (RMSE 0.0203 and 0.0205, respectively). In the case study, all methods provided a similar conclusion with point estimates clustered around the null (e.g., HRautoencoder 1.01 [95% confidence interval = 0.80, 1.27] vs. HRPRONOUNCE 1.07 [0.83, 1.36]).
CONCLUSIONS: Autoencoder-based PS computation was a feasible approach to control for confounding but did not perform better than some established approaches like LASSO.",True,other,autoencoder
33587262,DON: Deep Learning and Optimization-Based Framework for Detection of Novel Coronavirus Disease Using X-ray Images,"In the hospital, a limited number of COVID-19 test kits are available due to the spike in cases every day. For this reason, a rapid alternative diagnostic option should be introduced as an automated detection method to prevent COVID-19 spreading among individuals. This article proposes multi-objective optimization and a deep-learning methodology for the detection of infected coronavirus patients with X-rays. J48 decision tree method classifies the deep characteristics of affected X-ray corona images to detect the contaminated patients effectively. Eleven different convolutional neuronal network-based (CNN) models were developed in this study to detect infected patients with coronavirus pneumonia using X-ray images (AlexNet, VGG16, VGG19, GoogleNet, ResNet18, ResNet500, ResNet101, InceptionV3, InceptionResNetV2, DenseNet201 and XceptionNet). In addition, the parameters of the CNN profound learning model are described using an emperor penguin optimizer with several objectives (MOEPO). A broad review reveals that the proposed model can categorise the X-ray images at the correct rates of precision, accuracy, recall, specificity and F1-score. Extensive test results show that the proposed model outperforms competitive models with well-known efficiency metrics. The proposed model is, therefore, useful for the real-time classification of X-ray chest images of COVID-19 disease.",True,other,convolutional neural network
33565152,Prediction Model of Amyotrophic Lateral Sclerosis by Deep Learning with Patient Induced Pluripotent Stem Cells,"In amyotrophic lateral sclerosis (ALS), early diagnosis is essential for both current and potential treatments. To find a supportive approach for the diagnosis, we constructed an artificial intelligence-based prediction model of ALS using induced pluripotent stem cells (iPSCs). Images of spinal motor neurons derived from healthy control subject and ALS patient iPSCs were analyzed by a convolutional neural network, and the algorithm achieved an area under the curve of 0.97 for classifying healthy control and ALS. This prediction model by deep learning algorithm with iPSC technology could support the diagnosis and may provide proactive treatment of ALS through future prospective research. ANN NEUROL 2021;89:1226-1233.",True,other,recurrent neural network
33565124,Deep learning detects genetic alterations in cancer histology generated by adversarial networks,"Deep learning can detect microsatellite instability (MSI) from routine histology images in colorectal cancer (CRC). However, ethical and legal barriers impede sharing of images and genetic data, hampering development of new algorithms for detection of MSI and other biomarkers. We hypothesized that histology images synthesized by conditional generative adversarial networks (CGANs) retain information about genetic alterations. To test this, we developed a 'histology CGAN' which was trained on 256 patients (training cohort 1) and 1457 patients (training cohort 2). The CGAN synthesized 10 000 synthetic MSI and non-MSI images which contained a range of tissue types and were deemed realistic by trained observers in a blinded study. Subsequently, we trained a deep learning detector of MSI on real or synthetic images and evaluated the performance of MSI detection in a held-out set of 142 patients. When trained on real images from training cohort 1, this system achieved an area under the receiver operating curve (AUROC) of 0.742 [0.681, 0.854]. Training on the larger cohort 2 only marginally improved the AUROC to 0.757 [0.707, 0.869]. Training on purely synthetic data resulted in an AUROC of 0.743 [0.658, 0.801]. Training on both real and synthetic data further increased AUROC to 0.777 [0.715, 0.821]. We conclude that synthetic histology images retain information reflecting underlying genetic alterations in colorectal cancer. Using synthetic instead of real images to train deep learning systems yields non-inferior classifiers. This approach can be used to create large shareable data sets or to augment small data sets with rare molecular features. © 2021 The Authors. The Journal of Pathology published by John Wiley & Sons, Ltd. on behalf of The Pathological Society of Great Britain and Ireland.",True,other,Not specified
33565027,Classification of COVID-19 by Compressed Chest CT Image through Deep Learning on a Large Patients Cohort,"Corona Virus Disease (COVID-19) has spread globally quickly, and has resulted in a large number of causalities and medical resources insufficiency in many countries. Reverse-transcriptase polymerase chain reaction (RT-PCR) testing is adopted as biopsy tool for confirmation of virus infection. However, its accuracy is as low as 60-70%, which is inefficient to uncover the infected. In comparison, the chest CT has been considered as the prior choice in diagnosis and monitoring progress of COVID-19 infection. Although the COVID-19 diagnostic systems based on artificial intelligence have been developed for assisting doctors in diagnosis, the small sample size and the excessive time consumption limit their applications. To this end, this paper proposed a diagnosis prototype system for COVID-19 infection testing. The proposed deep learning model is trained and is tested on 2267 CT sequences from 1357 patients clinically confirmed with COVID-19 and 1235 CT sequences from non-infected people. The main highlights of the prototype system are: (1) no data augmentation is needed to accurately discriminate the COVID-19 from normal controls with the specificity of 0.92 and sensitivity of 0.93; (2) the raw DICOM image is not necessary in testing. Highly compressed image like Jpeg can be used to allow a quick diagnosis; and (3) it discriminates the virus infection within 6 seconds and thus allows an online test with light cost. We also applied our model on 48 asymptomatic patients diagnosed with COVID-19. We found that: (1) the positive rate of RT-PCR assay is 63.5% (687/1082). (2) 45.8% (22/48) of the RT-PCR assay is negative for asymptomatic patients, yet the accuracy of CT scans is 95.8%. The online detection system is available: http://212.64.70.65/covid .",True,other,recurrent neural network
33558735,Deep-learning-assisted analysis of echocardiographic videos improves predictions of all-cause mortality,"Machine learning promises to assist physicians with predictions of mortality and of other future clinical events by learning complex patterns from historical data, such as longitudinal electronic health records. Here we show that a convolutional neural network trained on raw pixel data in 812,278 echocardiographic videos from 34,362 individuals provides superior predictions of one-year all-cause mortality. The model's predictions outperformed the widely used pooled cohort equations, the Seattle Heart Failure score (measured in an independent dataset of 2,404 patients with heart failure who underwent 3,384 echocardiograms), and a machine learning model involving 58 human-derived variables from echocardiograms and 100 clinical variables derived from electronic health records. We also show that cardiologists assisted by the model substantially improved the sensitivity of their predictions of one-year all-cause mortality by 13% while maintaining prediction specificity. Large unstructured datasets may enable deep learning to improve a wide range of clinical prediction models.",True,other,recurrent neural network
33556604,Lung cancer prediction by Deep Learning to identify benign lung nodules,"INTRODUCTION: Deep Learning has been proposed as promising tool to classify malignant nodules. Our aim was to retrospectively validate our Lung Cancer Prediction Convolutional Neural Network (LCP-CNN), which was trained on US screening data, on an independent dataset of indeterminate nodules in an European multicentre trial, to rule out benign nodules maintaining a high lung cancer sensitivity.
METHODS: The LCP-CNN has been trained to generate a malignancy score for each nodule using CT data from the U.S. National Lung Screening Trial (NLST), and validated on CT scans containing 2106 nodules (205 lung cancers) detected in patients from from the Early Lung Cancer Diagnosis Using Artificial Intelligence and Big Data (LUCINDA) study, recruited from three tertiary referral centers in the UK, Germany and Netherlands. We pre-defined a benign nodule rule-out test, to identify benign nodules whilst maintaining a high sensitivity, by calculating thresholds on the malignancy score that achieve at least 99 % sensitivity on the NLST data. Overall performance per validation site was evaluated using Area-Under-the-ROC-Curve analysis (AUC).
RESULTS: The overall AUC across the European centers was 94.5 % (95 %CI 92.6-96.1). With a high sensitivity of 99.0 %, malignancy could be ruled out in 22.1 % of the nodules, enabling 18.5 % of the patients to avoid follow-up scans. The two false-negative results both represented small typical carcinoids.
CONCLUSION: The LCP-CNN, trained on participants with lung nodules from the US NLST dataset, showed excellent performance on identification of benign lung nodules in a multi-center external dataset, ruling out malignancy with high accuracy in about one fifth of the patients with 5-15 mm nodules.",True,other,Not specified
33552965,SurvNet: A Novel Deep Neural Network for Lung Cancer Survival Analysis With Missing Values,"Survival analysis is important for guiding further treatment and improving lung cancer prognosis. It is a challenging task because of the poor distinguishability of features and the missing values in practice. A novel multi-task based neural network, SurvNet, is proposed in this paper. The proposed SurvNet model is trained in a multi-task learning framework to jointly learn across three related tasks: input reconstruction, survival classification, and Cox regression. It uses an input reconstruction mechanism cooperating with incomplete-aware reconstruction loss for latent feature learning of incomplete data with missing values. Besides, the SurvNet model introduces a context gating mechanism to bridge the gap between survival classification and Cox regression. A new real-world dataset of 1,137 patients with IB-IIA stage non-small cell lung cancer is collected to evaluate the performance of the SurvNet model. The proposed SurvNet achieves a higher concordance index than the traditional Cox model and Cox-Net. The difference between high-risk and low-risk groups obtained by SurvNet is more significant than that of high-risk and low-risk groups obtained by the other models. Moreover, the SurvNet outperforms the other models even though the input data is randomly cropped and it achieves better generalization performance on the Surveillance, Epidemiology, and End Results Program (SEER) dataset.",True,other,recurrent neural network
33547415,Unraveling the deep learning gearbox in optical coherence tomography image segmentation towards explainable artificial intelligence,"Machine learning has greatly facilitated the analysis of medical data, while the internal operations usually remain intransparent. To better comprehend these opaque procedures, a convolutional neural network for optical coherence tomography image segmentation was enhanced with a Traceable Relevance Explainability (T-REX) technique. The proposed application was based on three components: ground truth generation by multiple graders, calculation of Hamming distances among graders and the machine learning algorithm, as well as a smart data visualization ('neural recording'). An overall average variability of 1.75% between the human graders and the algorithm was found, slightly minor to 2.02% among human graders. The ambiguity in ground truth had noteworthy impact on machine learning results, which could be visualized. The convolutional neural network balanced between graders and allowed for modifiable predictions dependent on the compartment. Using the proposed T-REX setup, machine learning processes could be rendered more transparent and understandable, possibly leading to optimized applications.",True,other,convolutional neural network
33546587,Investigating the relevance of major signaling pathways in cancer survival using a biologically meaningful deep learning model,"BACKGROUND: Survival analysis is an important part of cancer studies. In addition to the existing Cox proportional hazards model, deep learning models have recently been proposed in survival prediction, which directly integrates multi-omics data of a large number of genes using the fully connected dense deep neural network layers, which are hard to interpret. On the other hand, cancer signaling pathways are important and interpretable concepts that define the signaling cascades regulating cancer development and drug resistance. Thus, it is important to investigate potential associations between patient survival and individual signaling pathways, which can help domain experts to understand deep learning models making specific predictions.
RESULTS: In this exploratory study, we proposed to investigate the relevance and influence of a set of core cancer signaling pathways in the survival analysis of cancer patients. Specifically, we built a simplified and partially biologically meaningful deep neural network, DeepSigSurvNet, for survival prediction. In the model, the gene expression and copy number data of 1967 genes from 46 major signaling pathways were integrated in the model. We applied the model to four types of cancer and investigated the influence of the 46 signaling pathways in the cancers. Interestingly, the interpretable analysis identified the distinct patterns of these signaling pathways, which are helpful in understanding the relevance of signaling pathways in terms of their application to the prediction of cancer patients' survival time. These highly relevant signaling pathways, when combined with other essential signaling pathways inhibitors, can be novel targets for drug and drug combination prediction to improve cancer patients' survival time.
CONCLUSION: The proposed DeepSigSurvNet model can facilitate the understanding of the implications of signaling pathways on cancer patients' survival by integrating multi-omics data and clinical factors.",True,other,Not specified
33544803,Agreement of two pre-trained deep-learning neural networks built with transfer learning with six pathologists on 6000 patches of prostate cancer from Gleason2019 Challenge,"INTRODUCTION: While the visual inspection of histopathology images by expert pathologists remains the golden standard method for grading of prostate cancer the quest for developing automated algorithms for the job is set and deep-learning techniques have emerged on top of other approaches.
METHODS: Two pre-trained deep-learning networks, obtained with transfer learning from two general purpose classification networks - AlexNet and GoogleNet, originally trained on a proprietary dataset of prostate cancer were used to classify 6000 cropped images from Gleason2019 Challenge.
RESULTS: The average agreement between the two networks and the six pathologists was found to be substantial for AlexNet and moderate for GoogleNet. When tested against the majority vote of the six pathologists the agreement was perfect and moderate for AlexNet, and GoogleNet, respectively. Despite our expectations, the average inter-pathologist agreement was moderate, while between the two networks it was substantial. Resulted accuracy for AlexNet and GoogleNet when tested against the majority vote as ground truth was of 85.51% and 74.75%, respectively. This result was higher than the score obtained on the dataset that they were trained on, showing their generalization capabilities.
CONCLUSIONS: Both the agreement and the accuracy indicate a better performance of AlexNet over GoogleNet, making it suitable for clinical deployment thus could potentially contribute to faster, more accurate and with higher reproducibility prostate cancer diagnosis.",True,other,Not specified
33539308,Using Automated Machine Learning to Predict the Mortality of Patients With COVID-19: Prediction Model Development Study,"BACKGROUND: During a pandemic, it is important for clinicians to stratify patients and decide who receives limited medical resources. Machine learning models have been proposed to accurately predict COVID-19 disease severity. Previous studies have typically tested only one machine learning algorithm and limited performance evaluation to area under the curve analysis. To obtain the best results possible, it may be important to test different machine learning algorithms to find the best prediction model.
OBJECTIVE: In this study, we aimed to use automated machine learning (autoML) to train various machine learning algorithms. We selected the model that best predicted patients' chances of surviving a SARS-CoV-2 infection. In addition, we identified which variables (ie, vital signs, biomarkers, comorbidities, etc) were the most influential in generating an accurate model.
METHODS: Data were retrospectively collected from all patients who tested positive for COVID-19 at our institution between March 1 and July 3, 2020. We collected 48 variables from each patient within 36 hours before or after the index time (ie, real-time polymerase chain reaction positivity). Patients were followed for 30 days or until death. Patients' data were used to build 20 machine learning models with various algorithms via autoML. The performance of machine learning models was measured by analyzing the area under the precision-recall curve (AUPCR). Subsequently, we established model interpretability via Shapley additive explanation and partial dependence plots to identify and rank variables that drove model predictions. Afterward, we conducted dimensionality reduction to extract the 10 most influential variables. AutoML models were retrained by only using these 10 variables, and the output models were evaluated against the model that used 48 variables.
RESULTS: Data from 4313 patients were used to develop the models. The best model that was generated by using autoML and 48 variables was the stacked ensemble model (AUPRC=0.807). The two best independent models were the gradient boost machine and extreme gradient boost models, which had an AUPRC of 0.803 and 0.793, respectively. The deep learning model (AUPRC=0.73) was substantially inferior to the other models. The 10 most influential variables for generating high-performing models were systolic and diastolic blood pressure, age, pulse oximetry level, blood urea nitrogen level, lactate dehydrogenase level, D-dimer level, troponin level, respiratory rate, and Charlson comorbidity score. After the autoML models were retrained with these 10 variables, the stacked ensemble model still had the best performance (AUPRC=0.791).
CONCLUSIONS: We used autoML to develop high-performing models that predicted the survival of patients with COVID-19. In addition, we identified important variables that correlated with mortality. This is proof of concept that autoML is an efficient, effective, and informative method for generating machine learning-based clinical decision support tools.",True,other,recurrent neural network
33532975,Six artificial intelligence paradigms for tissue characterisation and classification of non-COVID-19 pneumonia against COVID-19 pneumonia in computed tomography lungs,"BACKGROUND: COVID-19 pandemic has currently no vaccines. Thus, the only feasible solution for prevention relies on the detection of COVID-19-positive cases through quick and accurate testing. Since artificial intelligence (AI) offers the powerful mechanism to automatically extract the tissue features and characterise the disease, we therefore hypothesise that AI-based strategies can provide quick detection and classification, especially for radiological computed tomography (CT) lung scans.
METHODOLOGY: Six models, two traditional machine learning (ML)-based (k-NN and RF), two transfer learning (TL)-based (VGG19 and InceptionV3), and the last two were our custom-designed deep learning (DL) models (CNN and iCNN), were developed for classification between COVID pneumonia (CoP) and non-COVID pneumonia (NCoP). K10 cross-validation (90% training: 10% testing) protocol on an Italian cohort of 100 CoP and 30 NCoP patients was used for performance evaluation and bispectrum analysis for CT lung characterisation.
RESULTS: Using K10 protocol, our results showed the accuracy in the order of DL > TL > ML, ranging the six accuracies for k-NN, RF, VGG19, IV3, CNN, iCNN as 74.58 ± 2.44%, 96.84 ± 2.6, 94.84 ± 2.85%, 99.53 ± 0.75%, 99.53 ± 1.05%, and 99.69 ± 0.66%, respectively. The corresponding AUCs were 0.74, 0.94, 0.96, 0.99, 0.99, and 0.99 (p-values < 0.0001), respectively. Our Bispectrum-based characterisation system suggested CoP can be separated against NCoP using AI models. COVID risk severity stratification also showed a high correlation of 0.7270 (p < 0.0001) with clinical scores such as ground-glass opacities (GGO), further validating our AI models.
CONCLUSIONS: We prove our hypothesis by demonstrating that all the six AI models successfully classified CoP against NCoP due to the strong presence of contrasting features such as ground-glass opacities (GGO), consolidations, and pleural effusion in CoP patients. Further, our online system takes < 2 s for inference.",True,other,autoencoder
33513487,Prediction of death status on the course of treatment in SARS-COV-2 patients with deep learning and machine learning methods,"BACKGROUND AND OBJECTIVE: The new type of Coronavirus (2019-nCov) epidemic spread rapidly, causing more than 250 thousand deaths worldwide. The virus, which first appeared as a sign of pneumonia, was later called the SARS-COV-2 with Severe Acute Respiratory Syndrome by the World Health Organization. The SARS-COV-2 virus is triggered by binding to the Angiotensin-Converting Enzyme 2 (ACE 2) inhibitor, which is vital in cardiovascular diseases and the immune system, especially in conditions such as cerebrovascular, hypertension, and diabetes. This study aims to evaluate the prediction performance of death status based on the demographic/clinical factors (including COVID-19 severity) by data mining methods.
METHODS: The dataset consists of 1603 SARS-COV-2 patients and 13 variables obtained from an open-source web address. The current dataset contains age, gender, chronic disease (hypertension, diabetes, renal, cardiovascular, etc.), some enzymes (ACE, angiotensin II receptor blockers), and COVID-19 severity, which are used to predict death status using deep learning and machine learning approaches (random forest, k-nearest neighbor, extreme gradient boosting [XGBoost]). A grid search algorithm tunes hyperparameters of the models, and predictions are assessed through performance metrics. Steps of knowledge discovery in databases are applied to obtain the relevant information.
RESULTS: The accuracy rate of deep learning (97.15%) was more successful than the accuracy rate based on classical machine learning (92.15% for RF and 93.4% for k-NN), but the ensemble classifier XGBoost method gave the highest accuracy (99.7%). While COVID-19 severity and age calculated from XGBoost were the two most important factors associated with death status, the most determining variables for death status estimated from deep learning were COVID-19 severity and hypertension.
CONCLUSIONS: The proposed model (XGBoost) achieved the best prediction of death status based on the factors as compared to the other algorithms. The results of this study can guide patients with certain variables to take early measures and access preventive health care services before they become infected with the virus.",True,other,Not specified
33499405,Artificial Intelligence in Nutrients Science Research: A Review,"Artificial intelligence (AI) as a branch of computer science, the purpose of which is to imitate thought processes, learning abilities and knowledge management, finds more and more applications in experimental and clinical medicine. In recent decades, there has been an expansion of AI applications in biomedical sciences. The possibilities of artificial intelligence in the field of medical diagnostics, risk prediction and support of therapeutic techniques are growing rapidly. The aim of the article is to analyze the current use of AI in nutrients science research. The literature review was conducted in PubMed. A total of 399 records published between 1987 and 2020 were obtained, of which, after analyzing the titles and abstracts, 261 were rejected. In the next stages, the remaining records were analyzed using the full-text versions and, finally, 55 papers were selected. These papers were divided into three areas: AI in biomedical nutrients research (20 studies), AI in clinical nutrients research (22 studies) and AI in nutritional epidemiology (13 studies). It was found that the artificial neural network (ANN) methodology was dominant in the group of research on food composition study and production of nutrients. However, machine learning (ML) algorithms were widely used in studies on the influence of nutrients on the functioning of the human body in health and disease and in studies on the gut microbiota. Deep learning (DL) algorithms prevailed in a group of research works on clinical nutrients intake. The development of dietary systems using AI technology may lead to the creation of a global network that will be able to both actively support and monitor the personalized supply of nutrients.",True,other,Not specified
33486527,STAN: spatio-temporal attention network for pandemic prediction using real-world evidence,"OBJECTIVE: We aim to develop a hybrid model for earlier and more accurate predictions for the number of infected cases in pandemics by (1) using patients' claims data from different counties and states that capture local disease status and medical resource utilization; (2) utilizing demographic similarity and geographical proximity between locations; and (3) integrating pandemic transmission dynamics into a deep learning model.
MATERIALS AND METHODS: We proposed a spatio-temporal attention network (STAN) for pandemic prediction. It uses a graph attention network to capture spatio-temporal trends of disease dynamics and to predict the number of cases for a fixed number of days into the future. We also designed a dynamics-based loss term for enhancing long-term predictions. STAN was tested using both real-world patient claims data and COVID-19 statistics over time across US counties.
RESULTS: STAN outperforms traditional epidemiological models such as susceptible-infectious-recovered (SIR), susceptible-exposed-infectious-recovered (SEIR), and deep learning models on both long-term and short-term predictions, achieving up to 87% reduction in mean squared error compared to the best baseline prediction model.
CONCLUSIONS: By combining information from real-world claims data and disease case counts data, STAN can better predict disease status and medical resource utilization.",True,both,recurrent neural network
33462882,Demystifying machine learning: a primer for physicians,"Machine learning is a tool for analysing digitised data sets and formulating predictions that can optimise clinical decision-making. It aims to identify complex patterns in large data sets and encode them into models that can then classify new unseen cases or make predictions on new data. Machine learning methods take several forms and individual models can be of many different types. More than 50 models have been approved for use in routine healthcare, and the numbers continue to grow exponentially. The reliability and robustness of any model depends on multiple factors, including the quality and quantity of the data used to develop the models, and the selection of features in the data considered most important to maximising accuracy. In ensuring models are safe, effective and reproducible in routine care, physicians need to have some understanding of how these models are developed and evaluated, and to collaborate with data and computer scientists in their design and validation. This narrative review introduces principles, methods and examples of machine learning in a way that does not require mastery of highly complex statistical and computational concepts.",True,other,recurrent neural network
33461009,Lung cancer survival period prediction and understanding: Deep learning approaches,"INTRODUCTION: Survival period prediction through early diagnosis of cancer has many benefits. It allows both patients and caregivers to plan resources, time and intensity of care to provide the best possible treatment path for the patients. In this paper, by focusing on lung cancer patients, we build several survival prediction models using deep learning techniques to tackle both cancer survival classification and regression problems. We also conduct feature importance analysis to understand how lung cancer patients' relevant factors impact their survival periods. We contribute to identifying an approach to estimate survivability that are commonly and practically appropriate for medical use.
METHODOLOGIES: We have compared the performance across three of the most popular deep learning architectures - Artificial Neural Networks (ANN), Convolutional Neural Networks (CNN), and Recurrent Neural Networks (RNN) while comparing the performing of deep learning models against traditional machine learning models. The data was obtained from the lung cancer section of Surveillance, Epidemiology, and End Results (SEER) cancer registry.
RESULTS: The deep learning models outperformed traditional machine learning models across both classification and regression approaches. We obtained a best of 71.18 % accuracy for the classification approach when patients' survival periods are segmented into classes of '&lt;=6 months',' 0.5 - 2 years' and '&gt;2 years' and Root Mean Squared Error (RMSE) of 13.5 % andR2 value of 0.5 for the regression approach for the deep learning models while the traditional machine learning models saturated at 61.12 % classification accuracy and 14.87 % RMSE in regression.
CONCLUSIONS: This approach can be a baseline for early prediction with predictions that can be further improved with more temporal treatment information collected from treated patients. In addition, we evaluated the feature importance to investigate the model interpretability, gaining further insight into the survival analysis models and the factors that are important in cancer survival period prediction.",True,other,Not specified
33446870,Improving prognostic performance in resectable pancreatic ductal adenocarcinoma using radiomics and deep learning features fusion in CT images,"As an analytic pipeline for quantitative imaging feature extraction and analysis, radiomics has grown rapidly in the past decade. On the other hand, recent advances in deep learning and transfer learning have shown significant potential in the quantitative medical imaging field, raising the research question of whether deep transfer learning features have predictive information in addition to radiomics features. In this study, using CT images from Pancreatic Ductal Adenocarcinoma (PDAC) patients recruited in two independent hospitals, we discovered most transfer learning features have weak linear relationships with radiomics features, suggesting a potential complementary relationship between these two feature sets. We also tested the prognostic performance for overall survival using four feature fusion and reduction methods for combining radiomics and transfer learning features and compared the results with our proposed risk score-based feature fusion method. It was shown that the risk score-based feature fusion method significantly improves the prognosis performance for predicting overall survival in PDAC patients compared to other traditional feature reduction methods used in previous radiomics studies (40% increase in area under ROC curve (AUC) yielding AUC of 0.84).",True,other,Not specified
33440674,Explainable COVID-19 Detection Using Chest CT Scans and Deep Learning,"This paper explores how well deep learning models trained on chest CT images can diagnose COVID-19 infected people in a fast and automated process. To this end, we adopted advanced deep network architectures and proposed a transfer learning strategy using custom-sized input tailored for each deep architecture to achieve the best performance. We conducted extensive sets of experiments on two CT image datasets, namely, the SARS-CoV-2 CT-scan and the COVID19-CT. The results show superior performances for our models compared with previous studies. Our best models achieved average accuracy, precision, sensitivity, specificity, and F1-score values of 99.4%, 99.6%, 99.8%, 99.6%, and 99.4% on the SARS-CoV-2 dataset, and 92.9%, 91.3%, 93.7%, 92.2%, and 92.5% on the COVID19-CT dataset, respectively. For better interpretability of the results, we applied visualization techniques to provide visual explanations for the models' predictions. Feature visualizations of the learned features show well-separated clusters representing CT images of COVID-19 and non-COVID-19 cases. Moreover, the visualizations indicate that our models are not only capable of identifying COVID-19 cases but also provide accurate localization of the COVID-19-associated regions, as indicated by well-trained radiologists.",True,other,recurrent neural network
33422330,Transfer Learning for COVID-19 cases and deaths forecast using LSTM network,"In this paper, Transfer Learning is used in LSTM networks to forecast new COVID cases and deaths. Models trained in data from early COVID infected countries like Italy and the United States are used to forecast the spread in other countries. Single and multistep forecasting is performed from these models. The results from these models are tested with data from Germany, France, Brazil, India, and Nepal to check the validity of the method. The obtained forecasts are promising and can be helpful for policymakers coping with the threats of COVID-19.",True,other,recurrent neural network
33406530,Towards deep phenotyping pregnancy: a systematic review on artificial intelligence and machine learning methods to improve pregnancy outcomes,"OBJECTIVE: Development of novel informatics methods focused on improving pregnancy outcomes remains an active area of research. The purpose of this study is to systematically review the ways that artificial intelligence (AI) and machine learning (ML), including deep learning (DL), methodologies can inform patient care during pregnancy and improve outcomes.
MATERIALS AND METHODS: We searched English articles on EMBASE, PubMed and SCOPUS. Search terms included ML, AI, pregnancy and informatics. We included research articles and book chapters, excluding conference papers, editorials and notes.
RESULTS: We identified 127 distinct studies from our queries that were relevant to our topic and included in the review. We found that supervised learning methods were more popular (n = 69) than unsupervised methods (n = 9). Popular methods included support vector machines (n = 30), artificial neural networks (n = 22), regression analysis (n = 17) and random forests (n = 16). Methods such as DL are beginning to gain traction (n = 13). Common areas within the pregnancy domain where AI and ML methods were used the most include prenatal care (e.g. fetal anomalies, placental functioning) (n = 73); perinatal care, birth and delivery (n = 20); and preterm birth (n = 13). Efforts to translate AI into clinical care include clinical decision support systems (n = 24) and mobile health applications (n = 9).
CONCLUSIONS: Overall, we found that ML and AI methods are being employed to optimize pregnancy outcomes, including modern DL methods (n = 13). Future research should focus on less-studied pregnancy domain areas, including postnatal and postpartum care (n = 2). Also, more work on clinical adoption of AI methods and the ethical implications of such adoption is needed.",True,other,Not specified
33399979,Deep learning model for prediction of extended-spectrum beta-lactamase (ESBL) production in community-onset Enterobacteriaceae bacteraemia from a high ESBL prevalence multi-centre cohort,"Adequate empirical antimicrobial coverage is instrumental in clinical management of community-onset Enterobacteriaceae bacteraemia in areas with high ESBL prevalence, while balancing the risk of carbapenem overuse and emergence of carbapenem-resistant organisms. It is unknown whether machine learning offers additional advantages to conventional statistical methods in prediction of ESBL production. To develop a validated model to predict ESBL production in Enterobacteriaceae causing community-onset bacteraemia. 5625 patients with community-onset bacteraemia caused by Escherichia coli, Klebsiella species and Proteus mirabilis during 1 January 2015-31 December 2019 from three regional hospitals in Hong Kong were included in the analysis, after exclusion of blood cultures obtained beyond 48 h of admission. The prevalence of ESBL-producing Enterobacteriaceae was 23.7% (1335/5625). Deep neural network and other machine learning algorithms were compared against conventional statistical model via multivariable logistic regression. Primary outcomes compared consisted of predictive model area under curve of receiver-operator characteristic curve (AUC), and macro-averaged F1 score. Secondary outcomes included sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). Deep neural network yielded an AUC of 0.761 (95% CI 0.725-0.797) and F1 score of 0.661 (95% CI 0.633-0.689), which was superior to logistic regression (AUC 0.667 (95% CI 0.627-0.707), F1 score 0.596 (95% CI 0.567-0.625)). Deep neural network had a specificity of 91.5%, sensitivity of 37.5%, NPV of 82.5%, and PPV of 57.9%. Deep neural network is superior to logistic regression in predicting ESBL production in Enterobacteriaceae causing community-onset bacteraemia in high-ESBL prevalence area. Machine learning offers clinical utility in guiding judicious empirical antibiotics use.",True,other,Not specified
33398067,Fast automated detection of COVID-19 from medical images using convolutional neural networks,"Coronavirus disease 2019 (COVID-19) is a global pandemic posing significant health risks. The diagnostic test sensitivity of COVID-19 is limited due to irregularities in specimen handling. We propose a deep learning framework that identifies COVID-19 from medical images as an auxiliary testing method to improve diagnostic sensitivity. We use pseudo-coloring methods and a platform for annotating X-ray and computed tomography images to train the convolutional neural network, which achieves a performance similar to that of experts and provides high scores for multiple statistical indices (F1 scores > 96.72% (0.9307, 0.9890) and specificity >99.33% (0.9792, 1.0000)). Heatmaps are used to visualize the salient features extracted by the neural network. The neural network-based regression provides strong correlations between the lesion areas in the images and five clinical indicators, resulting in high accuracy of the classification framework. The proposed method represents a potential computer-aided diagnosis method for COVID-19 in clinical practice.",True,other,recurrent neural network
33387306,A machine learning-based framework for diagnosis of COVID-19 from chest X-ray images,"Corona virus disease (COVID-19) acknowledged as a pandemic by the WHO and mankind all over the world is vulnerable to this virus. Alternative tools are needed that can help in diagnosis of the coronavirus. Researchers of this article investigated the potential of machine learning methods for automatic diagnosis of corona virus with high accuracy from X-ray images. Two most commonly used classifiers were selected: logistic regression (LR) and convolutional neural networks (CNN). The main reason was to make the system fast and efficient. Moreover, a dimensionality reduction approach was also investigated based on principal component analysis (PCA) to further speed up the learning process and improve the classification accuracy by selecting the highly discriminate features. The deep learning-based methods demand large amount of training samples compared to conventional approaches, yet adequate amount of labelled training samples was not available for COVID-19 X-ray images. Therefore, data augmentation technique using generative adversarial network (GAN) was employed to further increase the training samples and reduce the overfitting problem. We used the online available dataset and incorporated GAN to have 500 X-ray images in total for this study. Both CNN and LR showed encouraging results for COVID-19 patient identification. The LR and CNN models showed 95.2-97.6% overall accuracy without PCA and 97.6-100% with PCA for positive cases identification, respectively.",True,other,convolutional neural network
33352801,Deep Learning Prediction of Cancer Prevalence from Satellite Imagery,"The worldwide growth of cancer incidence can be explained in part by changes in the prevalence and distribution of risk factors. There are geographical gaps in the estimates of cancer prevalence, which could be filled with innovative methods. We used deep learning (DL) features extracted from satellite images to predict cancer prevalence at the census tract level in seven cities in the United States. We trained the model using detailed cancer prevalence estimates from 2018 available in the CDC (Center for Disease Control) 500 Cities project. Data from 3500 census tracts covering 14,483,366 inhabitants were included. Features were extracted from 170,210 satellite images with deep learning. This method explained up to 64.37% (median = 43.53%) of the variation of cancer prevalence. Satellite features are highly correlated with individual socioeconomic and health measures that are linked to cancer prevalence (age, smoking and drinking status, and obesity). A higher similarity between two environments is associated with better generalization of the model (p = 1.10-6). This method can be used to accurately estimate cancer prevalence at a high spatial resolution without using surveys at a fraction of the cost.",True,other,Not specified
33335183,Dynamic survival prediction in intensive care units from heterogeneous time series without the need for variable selection or curation,"Extensive monitoring in intensive care units (ICUs) generates large quantities of data which contain numerous trends that are difficult for clinicians to systematically evaluate. Current approaches to such heterogeneity in electronic health records (EHRs) discard pertinent information. We present a deep learning pipeline that uses all uncurated chart, lab, and output events for prediction of in-hospital mortality without variable selection. Over 21,000 ICU patients and tens of thousands of variables derived from the MIMIC-III database were used to train and validate our model. Recordings in the first few hours of a patient's stay were found to be strongly predictive of mortality, outperforming models using SAPS II and OASIS scores, AUROC 0.72 and 0.76 at 24 h respectively, within just 12 h of ICU admission. Our model achieves a very strong predictive performance of AUROC 0.85 (95% CI 0.83-0.86) after 48 h. Predictive performance increases over the first 48 h, but suffers from diminishing returns, providing rationale for time-limited trials of critical care and suggesting that the timing of decision making can be optimised and individualised.",True,other,recurrent neural network
33328123,A deep learning algorithm to detect chronic kidney disease from retinal photographs in community-based populations,"BACKGROUND: Screening for chronic kidney disease is a challenge in community and primary care settings, even in high-income countries. We developed an artificial intelligence deep learning algorithm (DLA) to detect chronic kidney disease from retinal images, which could add to existing chronic kidney disease screening strategies.
METHODS: We used data from three population-based, multiethnic, cross-sectional studies in Singapore and China. The Singapore Epidemiology of Eye Diseases study (SEED, patients aged ≥40 years) was used to develop (5188 patients) and validate (1297 patients) the DLA. External testing was done on two independent datasets: the Singapore Prospective Study Program (SP2, 3735 patients aged ≥25 years) and the Beijing Eye Study (BES, 1538 patients aged ≥40 years). Chronic kidney disease was defined as estimated glomerular filtration rate less than 60 mL/min per 1·73m2. Three models were trained: 1) image DLA; 2) risk factors (RF) including age, sex, ethnicity, diabetes, and hypertension; and 3) hybrid DLA combining image and RF. Model performances were evaluated using the area under the receiver operating characteristic curve (AUC).
FINDINGS: In the SEED validation dataset, the AUC was 0·911 for image DLA (95% CI 0·886 -0·936), 0·916 for RF (0·891-0·941), and 0·938 for hybrid DLA (0·917-0·959). Corresponding estimates in the SP2 testing dataset were 0·733 for image DLA (95% CI 0·696-0·770), 0·829 for RF (0·797-0·861), and 0·810 for hybrid DLA (0·776-0·844); and in the BES testing dataset estimates were 0·835 for image DLA (0·767-0·903), 0·887 for RF (0·828-0·946), and 0·858 for hybrid DLA (0·794-0·922). AUC estimates were similar in subgroups of people with diabetes (image DLA 0·889 [95% CI 0·850-0·928], RF 0·899 [0·862-0·936], hybrid 0·925 [0·893-0·957]) and hypertension (image DLA 0·889 [95% CI 0·860-0·918], RF 0·889 [0·860-0·918], hybrid 0·918 [0·893-0·943]).
INTERPRETATION: A retinal image DLA shows good performance for estimating chronic kidney disease, underlying the feasibility of using retinal photography as an adjunctive or opportunistic screening tool for chronic kidney disease in community populations.
FUNDING: National Medical Research Council, Singapore.",True,other,Not specified
33325832,Limitations of Deep Learning Attention Mechanisms in Clinical Research: Empirical Case Study Based on the Korean Diabetic Disease Setting,"BACKGROUND: Despite excellent prediction performance, noninterpretability has undermined the value of applying deep-learning algorithms in clinical practice. To overcome this limitation, attention mechanism has been introduced to clinical research as an explanatory modeling method. However, potential limitations of using this attractive method have not been clarified to clinical researchers. Furthermore, there has been a lack of introductory information explaining attention mechanisms to clinical researchers.
OBJECTIVE: The aim of this study was to introduce the basic concepts and design approaches of attention mechanisms. In addition, we aimed to empirically assess the potential limitations of current attention mechanisms in terms of prediction and interpretability performance.
METHODS: First, the basic concepts and several key considerations regarding attention mechanisms were identified. Second, four approaches to attention mechanisms were suggested according to a two-dimensional framework based on the degrees of freedom and uncertainty awareness. Third, the prediction performance, probability reliability, concentration of variable importance, consistency of attention results, and generalizability of attention results to conventional statistics were assessed in the diabetic classification modeling setting. Fourth, the potential limitations of attention mechanisms were considered.
RESULTS: Prediction performance was very high for all models. Probability reliability was high in models with uncertainty awareness. Variable importance was concentrated in several variables when uncertainty awareness was not considered. The consistency of attention results was high when uncertainty awareness was considered. The generalizability of attention results to conventional statistics was poor regardless of the modeling approach.
CONCLUSIONS: The attention mechanism is an attractive technique with potential to be very promising in the future. However, it may not yet be desirable to rely on this method to assess variable importance in clinical settings. Therefore, along with theoretical studies enhancing attention mechanisms, more empirical studies investigating potential limitations should be encouraged.",True,other,Not specified
33323492,Machine Learning for Child and Adolescent Health: A Systematic Review,"CONTEXT: In the last few decades, data acquisition and processing has seen tremendous amount of growth, thus sparking interest in machine learning (ML) within the health care system.
OBJECTIVE: Our aim for this review is to provide an evidence map of the current available evidence on ML in pediatrics and adolescent medicine and provide insight for future research.
DATA SOURCES: A literature search was conducted by using Medline, the Cochrane Library, the Cumulative Index to Nursing and Allied Health Literature Plus, Web of Science Library, and EBSCO Dentistry & Oral Science Source.
STUDY SELECTION: Articles in which an ML model was assessed for the diagnosis, prediction, or management of any condition in children and adolescents (0-18 years) were included.
DATA EXTRACTION: Data were extracted for year of publication, geographical location, age range, number of participants, disease or condition under investigation, study methodology, reference standard, type, category, and performance of ML algorithms.
RESULTS: The review included 363 studies, with subspecialties such as psychiatry, neonatology, and neurology having the most literature. A majority of the studies were from high-income (82%; n = 296) and upper middle-income countries (15%; n = 56), whereas only 3% (n = 11) were from low middle-income countries. Neural networks and ensemble methods were most commonly tested in the 1990s, whereas deep learning and clustering emerged rapidly in the current decade.
LIMITATIONS: Only studies conducted in the English language could be used in this review.
CONCLUSIONS: The interest in ML has been growing across various subspecialties and countries, suggesting a potential role in health service delivery for children and adolescents in the years to come.",True,other,RNN
33320858,Optimised genetic algorithm-extreme learning machine approach for automatic COVID-19 detection,"The coronavirus disease (COVID-19), is an ongoing global pandemic caused by severe acute respiratory syndrome. Chest Computed Tomography (CT) is an effective method for detecting lung illnesses, including COVID-19. However, the CT scan is expensive and time-consuming. Therefore, this work focus on detecting COVID-19 using chest X-ray images because it is widely available, faster, and cheaper than CT scan. Many machine learning approaches such as Deep Learning, Neural Network, and Support Vector Machine; have used X-ray for detecting the COVID-19. Although the performance of those approaches is acceptable in terms of accuracy, however, they require high computational time and more memory space. Therefore, this work employs an Optimised Genetic Algorithm-Extreme Learning Machine (OGA-ELM) with three selection criteria (i.e., random, K-tournament, and roulette wheel) to detect COVID-19 using X-ray images. The most crucial strength factors of the Extreme Learning Machine (ELM) are: (i) high capability of the ELM in avoiding overfitting; (ii) its usability on binary and multi-type classifiers; and (iii) ELM could work as a kernel-based support vector machine with a structure of a neural network. These advantages make the ELM efficient in achieving an excellent learning performance. ELMs have successfully been applied in many domains, including medical domains such as breast cancer detection, pathological brain detection, and ductal carcinoma in situ detection, but not yet tested on detecting COVID-19. Hence, this work aims to identify the effectiveness of employing OGA-ELM in detecting COVID-19 using chest X-ray images. In order to reduce the dimensionality of a histogram oriented gradient features, we use principal component analysis. The performance of OGA-ELM is evaluated on a benchmark dataset containing 188 chest X-ray images with two classes: a healthy and a COVID-19 infected. The experimental result shows that the OGA-ELM achieves 100.00% accuracy with fast computation time. This demonstrates that OGA-ELM is an efficient method for COVID-19 detecting using chest X-ray images.",True,other,Not specified
33285482,COVID-AL: The diagnosis of COVID-19 with deep active learning,"The efficient diagnosis of COVID-19 plays a key role in preventing the spread of this disease. The computer-aided diagnosis with deep learning methods can perform automatic detection of COVID-19 using CT scans. However, large scale annotation of CT scans is impossible because of limited time and heavy burden on the healthcare system. To meet the challenge, we propose a weakly-supervised deep active learning framework called COVID-AL to diagnose COVID-19 with CT scans and patient-level labels. The COVID-AL consists of the lung region segmentation with a 2D U-Net and the diagnosis of COVID-19 with a novel hybrid active learning strategy, which simultaneously considers sample diversity and predicted loss. With a tailor-designed 3D residual network, the proposed COVID-AL can diagnose COVID-19 efficiently and it is validated on a large CT scan dataset collected from the CC-CCII. The experimental results demonstrate that the proposed COVID-AL outperforms the state-of-the-art active learning approaches in the diagnosis of COVID-19. With only 30% of the labeled data, the COVID-AL achieves over 95% accuracy of the deep learning method using the whole dataset. The qualitative and quantitative analysis proves the effectiveness and efficiency of the proposed COVID-AL framework.",True,other,recurrent neural network
33270183,Use of Machine Learning Approaches in Clinical Epidemiological Research of Diabetes,"PURPOSE OF REVIEW: Machine learning approaches-which seek to predict outcomes or classify patient features by recognizing patterns in large datasets-are increasingly applied to clinical epidemiology research on diabetes. Given its novelty and emergence in fields outside of biomedical research, machine learning terminology, techniques, and research findings may be unfamiliar to diabetes researchers. Our aim was to present the use of machine learning approaches in an approachable way, drawing from clinical epidemiological research in diabetes published from 1 Jan 2017 to 1 June 2020.
RECENT FINDINGS: Machine learning approaches using tree-based learners-which produce decision trees to help guide clinical interventions-frequently have higher sensitivity and specificity than traditional regression models for risk prediction. Machine learning approaches using neural networking and ""deep learning"" can be applied to medical image data, particularly for the identification and staging of diabetic retinopathy and skin ulcers. Among the machine learning approaches reviewed, researchers identified new strategies to develop standard datasets for rigorous comparisons across older and newer approaches, methods to illustrate how a machine learner was treating underlying data, and approaches to improve the transparency of the machine learning process. Machine learning approaches have the potential to improve risk stratification and outcome prediction for clinical epidemiology applications. Achieving this potential would be facilitated by use of universal open-source datasets for fair comparisons. More work remains in the application of strategies to communicate how the machine learners are generating their predictions.",True,other,Not specified
33263111,Supervised Machine Learning Models for Prediction of COVID-19 Infection using Epidemiology Dataset,"COVID-19 or 2019-nCoV is no longer pandemic but rather endemic, with more than 651,247 people around world having lost their lives after contracting the disease. Currently, there is no specific treatment or cure for COVID-19, and thus living with the disease and its symptoms is inevitable. This reality has placed a massive burden on limited healthcare systems worldwide especially in the developing nations. Although neither an effective, clinically proven antiviral agents' strategy nor an approved vaccine exist to eradicate the COVID-19 pandemic, there are alternatives that may reduce the huge burden on not only limited healthcare systems but also the economic sector; the most promising include harnessing non-clinical techniques such as machine learning, data mining, deep learning and other artificial intelligence. These alternatives would facilitate diagnosis and prognosis for 2019-nCoV pandemic patients. Supervised machine learning models for COVID-19 infection were developed in this work with learning algorithms which include logistic regression, decision tree, support vector machine, naive Bayes, and artificial neutral network using epidemiology labeled dataset for positive and negative COVID-19 cases of Mexico. The correlation coefficient analysis between various dependent and independent features was carried out to determine a strength relationship between each dependent feature and independent feature of the dataset prior to developing the models. The 80% of the training dataset were used for training the models while the remaining 20% were used for testing the models. The result of the performance evaluation of the models showed that decision tree model has the highest accuracy of 94.99% while the Support Vector Machine Model has the highest sensitivity of 93.34% and Naïve Bayes Model has the highest specificity of 94.30%.",True,computer vision,Not specified
35117369,Leveraging well-annotated databases for deep learning in biomedical research,,True,other,GAN
33232368,Deep-learning algorithms for the interpretation of chest radiographs to aid in the triage of COVID-19 patients: A multicenter retrospective study,"The recent medical applications of deep-learning (DL) algorithms have demonstrated their clinical efficacy in improving speed and accuracy of image interpretation. If the DL algorithm achieves a performance equivalent to that achieved by physicians in chest radiography (CR) diagnoses with Coronavirus disease 2019 (COVID-19) pneumonia, the automatic interpretation of the CR with DL algorithms can significantly reduce the burden on clinicians and radiologists in sudden surges of suspected COVID-19 patients. The aim of this study was to evaluate the efficacy of the DL algorithm for detecting COVID-19 pneumonia on CR compared with formal radiology reports. This is a retrospective study of adult patients that were diagnosed as positive COVID-19 cases based on the reverse transcription polymerase chain reaction among all the patients who were admitted to five emergency departments and one community treatment center in Korea from February 18, 2020 to May 1, 2020. The CR images were evaluated with a publicly available DL algorithm. For reference, CR images without chest computed tomography (CT) scans classified as positive for COVID-19 pneumonia were used given that the radiologist identified ground-glass opacity, consolidation, or other infiltration in retrospectively reviewed CR images. Patients with evidence of pneumonia on chest CT scans were also classified as COVID-19 pneumonia positive outcomes. The overall sensitivity and specificity of the DL algorithm for detecting COVID-19 pneumonia on CR were 95.6%, and 88.7%, respectively. The area under the curve value of the DL algorithm for the detection of COVID-19 with pneumonia was 0.921. The DL algorithm demonstrated a satisfactory diagnostic performance comparable with that of formal radiology reports in the CR-based diagnosis of pneumonia in COVID-19 patients. The DL algorithm may offer fast and reliable examinations that can facilitate patient screening and isolation decisions, which can reduce the medical staff workload during COVID-19 pandemic situations.",True,other,Not specified
33218680,"Decision-making in pediatric blunt solid organ injury: A deep learning approach to predict massive transfusion, need for operative management, and mortality risk","BACKGROUND: The principal triggers for intervention in the setting of pediatric blunt solid organ injury (BSOI) are declining hemoglobin values and hemodynamic instability. The clinical management of BSOI is, however, complex. We therefore hypothesized that state-of-art machine learning (computer-based) algorithms could be leveraged to discover new combinations of clinical variables that might herald the need for an escalation in care. We developed algorithms to predict the need for massive transfusion (MT), failure of non-operative management (NOM), mortality, and successful non-operative management without intervention, all within 4 hours of emergency department (ED) presentation.
METHODS: Children (≤18 years) who sustained a BSOI (liver, spleen, and/or kidney) between 2009 and 2018 were identified in the trauma registry at a pediatric level 1 trauma center. Deep learning models were developed using clinical values [vital signs, shock index-pediatric adjusted (SIPA), organ injured, and blood products received], laboratory results [hemoglobin, base deficit, INR, lactate, thromboelastography (TEG)], and imaging findings [focused assessment with sonography in trauma (FAST) and grade of injury on computed tomography scan] from pre-hospital to ED settings for prediction of MT, failure of NOM, mortality, and successful NOM without intervention. Sensitivity, specificity, accuracy, and area under the receiver operating characteristic curve (AUC) were used to evaluate each model's performance.
RESULTS: A total of 477 patients were included, of which 5.7% required MT (27/477), 7.2% failed NOM (34/477), 4.4% died (21/477), and 89.1% had successful NOM (425/477). The accuracy of the models in the validation set was as follows: MT (90.5%), failure of NOM (83.8%), mortality (91.9%), and successful NOM without intervention (90.3%). Serial vital signs, the grade of organ injury, hemoglobin, and positive FAST had low correlations with outcomes.
CONCLUSION: Deep learning-based models using a combination of clinical, laboratory and radiographic features can predict the need for emergent intervention (MT, angioembolization, or operative management) and mortality with high accuracy and sensitivity using data available in the first 4 hours of admission. Further research is needed to externally validate and determine the feasibility of prospectively applying this framework to improve care and outcomes.
LEVEL OF EVIDENCE: III STUDY TYPE: Retrospective comparative study (Prognosis/Care Management).",True,other,Not specified
33217660,"Coronary artery disease detection using artificial intelligence techniques: A survey of trends, geographical differences and diagnostic features 1991-2020","While coronary angiography is the gold standard diagnostic tool for coronary artery disease (CAD), but it is associated with procedural risk, it is an invasive technique requiring arterial puncture, and it subjects the patient to radiation and iodinated contrast exposure. Artificial intelligence (AI) can provide a pretest probability of disease that can be used to triage patients for angiography. This review comprehensively investigates published papers in the domain of CAD detection using different AI techniques from 1991 to 2020, in order to discern broad trends and geographical differences. Moreover, key decision factors affecting CAD diagnosis are identified for different parts of the world by aggregating the results from different studies. In this study, all datasets that have been used for the studies for CAD detection, their properties, and achieved performances using various AI techniques, are presented, compared, and analyzed. In particular, the effectiveness of machine learning (ML) and deep learning (DL) techniques to diagnose and predict CAD are reviewed. From PubMed, Scopus, Ovid MEDLINE, and Google Scholar search, 500 papers were selected to be investigated. Among these selected papers, 256 papers met our criteria and hence were included in this study. Our findings demonstrate that AI-based techniques have been increasingly applied for the detection of CAD since 2008. AI-based techniques that utilized electrocardiography (ECG), demographic characteristics, symptoms, physical examination findings, and heart rate signals, reported high accuracy for the detection of CAD. In these papers, the authors ranked the features based on their assessed clinical importance with ML techniques. The results demonstrate that the attribution of the relative importance of ML features for CAD diagnosis is different among countries. More recently, DL methods have yielded high CAD detection performance using ECG signals, which drives its burgeoning adoption.",True,other,Not specified
33208974,Artificial intelligence is improving the detection of lung cancer,,True,other,GAN
33208927,Open resource of clinical data from patients with pneumonia for the prediction of COVID-19 outcomes via deep learning,"Data from patients with coronavirus disease 2019 (COVID-19) are essential for guiding clinical decision making, for furthering the understanding of this viral disease, and for diagnostic modelling. Here, we describe an open resource containing data from 1,521 patients with pneumonia (including COVID-19 pneumonia) consisting of chest computed tomography (CT) images, 130 clinical features (from a range of biochemical and cellular analyses of blood and urine samples) and laboratory-confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) clinical status. We show the utility of the database for prediction of COVID-19 morbidity and mortality outcomes using a deep learning algorithm trained with data from 1,170 patients and 19,685 manually labelled CT slices. In an independent validation cohort of 351 patients, the algorithm discriminated between negative, mild and severe cases with areas under the receiver operating characteristic curve of 0.944, 0.860 and 0.884, respectively. The open database may have further uses in the diagnosis and management of patients with COVID-19.",True,computer vision,Not specified
33199801,DeepLMS: a deep learning predictive model for supporting online learning in the Covid-19 era,"Coronavirus (Covid-19) pandemic has imposed a complete shut-down of face-to-face teaching to universities and schools, forcing a crash course for online learning plans and technology for students and faculty. In the midst of this unprecedented crisis, video conferencing platforms (e.g., Zoom, WebEx, MS Teams) and learning management systems (LMSs), like Moodle, Blackboard and Google Classroom, are being adopted and heavily used as online learning environments (OLEs). However, as such media solely provide the platform for e-interaction, effective methods that can be used to predict the learner's behavior in the OLEs, which should be available as supportive tools to educators and metacognitive triggers to learners. Here we show, for the first time, that Deep Learning techniques can be used to handle LMS users' interaction data and form a novel predictive model, namely DeepLMS, that can forecast the quality of interaction (QoI) with LMS. Using Long Short-Term Memory (LSTM) networks, DeepLMS results in average testing Root Mean Square Error (RMSE) [Formula: see text], and average correlation coefficient between ground truth and predicted QoI values [Formula: see text] [Formula: see text], when tested on QoI data from one database pre- and two ones during-Covid-19 pandemic. DeepLMS personalized QoI forecasting scaffolds user's online learning engagement and provides educators with an evaluation path, additionally to the content-related assessment, enriching the overall view on the learners' motivation and participation in the learning process.",True,other,CNN
33189772,Predicting the diagnosis of HIV and sexually transmitted infections among men who have sex with men using machine learning approaches,"OBJECTIVES: We aimed to develop machine learning models and evaluate their performance in predicting HIV and sexually transmitted infections (STIs) diagnosis based on a cohort of Australian men who have sex with men (MSM).
METHODS: We collected clinical records of 21,273 Australian MSM during 2011-2017. We compared accuracies for predicting HIV and STIs (syphilis, gonorrhoea, chlamydia) diagnosis using four machine learning approaches against a multivariable logistic regression (MLR) model.
RESULTS: Machine learning approaches consistently outperformed MLR. Gradient boosting machine (GBM) achieved the highest area under the receiver operator characteristic curve for HIV (76.3%) and STIs (syphilis, 85.8%; gonorrhoea, 75.5%; chlamydia, 68.0%), followed by extreme gradient boosting (71.1%, 82.2%, 70.3%, 66.4%), random forest (72.0%, 81.9%, 67.2%, 64.3%), deep learning (75.8%, 81.0%, 67.5%, 65.4%) and MLR (69.8%, 80.1%, 67.2%, 63.2%). GBM models demonstrated the ten greatest predictors collectively explained 62.7-73.6% of variations in predicting HIV/STIs. STIs symptoms, past syphilis infection, age, time living in Australia, frequency of condom use with casual male sexual partners during receptive anal sex and the number of casual male sexual partners in the past 12 months were most commonly identified predictors.
CONCLUSIONS: Machine learning approaches are advantageous over multivariable logistic regression models in predicting HIV/STIs diagnosis.",True,other,recurrent neural network
33178576,A Deep Learning Approach Validates Genetic Risk Factors for Late Toxicity After Prostate Cancer Radiotherapy in a REQUITE Multi-National Cohort,"Background: REQUITE (validating pREdictive models and biomarkers of radiotherapy toxicity to reduce side effects and improve QUalITy of lifE in cancer survivors) is an international prospective cohort study. The purpose of this project was to analyse a cohort of patients recruited into REQUITE using a deep learning algorithm to identify patient-specific features associated with the development of toxicity, and test the approach by attempting to validate previously published genetic risk factors. Methods: The study involved REQUITE prostate cancer patients treated with external beam radiotherapy who had complete 2-year follow-up. We used five separate late toxicity endpoints: ≥grade 1 late rectal bleeding, ≥grade 2 urinary frequency, ≥grade 1 haematuria, ≥ grade 2 nocturia, ≥ grade 1 decreased urinary stream. Forty-three single nucleotide polymorphisms (SNPs) already reported in the literature to be associated with the toxicity endpoints were included in the analysis. No SNP had been studied before in the REQUITE cohort. Deep Sparse AutoEncoders (DSAE) were trained to recognize features (SNPs) identifying patients with no toxicity and tested on a different independent mixed population including patients without and with toxicity. Results: One thousand, four hundred and one patients were included, and toxicity rates were: rectal bleeding 11.7%, urinary frequency 4%, haematuria 5.5%, nocturia 7.8%, decreased urinary stream 17.1%. Twenty-four of the 43 SNPs that were associated with the toxicity endpoints were validated as identifying patients with toxicity. Twenty of the 24 SNPs were associated with the same toxicity endpoint as reported in the literature: 9 SNPs for urinary symptoms and 11 SNPs for overall toxicity. The other 4 SNPs were associated with a different endpoint. Conclusion: Deep learning algorithms can validate SNPs associated with toxicity after radiotherapy for prostate cancer. The method should be studied further to identify polygenic SNP risk signatures for radiotherapy toxicity. The signatures could then be included in integrated normal tissue complication probability models and tested for their ability to personalize radiotherapy treatment planning.",True,both,Not specified
33170789,COVIDGR Dataset and COVID-SDNet Methodology for Predicting COVID-19 Based on Chest X-Ray Images,"Currently, Coronavirus disease (COVID-19), one of the most infectious diseases in the 21st century, is diagnosed using RT-PCR testing, CT scans and/or Chest X-Ray (CXR) images. CT (Computed Tomography) scanners and RT-PCR testing are not available in most medical centers and hence in many cases CXR images become the most time/cost effective tool for assisting clinicians in making decisions. Deep learning neural networks have a great potential for building COVID-19 triage systems and detecting COVID-19 patients, especially patients with low severity. Unfortunately, current databases do not allow building such systems as they are highly heterogeneous and biased towards severe cases. This article is three-fold: (i) we demystify the high sensitivities achieved by most recent COVID-19 classification models, (ii) under a close collaboration with Hospital Universitario Clínico San Cecilio, Granada, Spain, we built COVIDGR-1.0, a homogeneous and balanced database that includes all levels of severity, from normal with Positive RT-PCR, Mild, Moderate to Severe. COVIDGR-1.0 contains 426 positive and 426 negative PA (PosteroAnterior) CXR views and (iii) we propose COVID Smart Data based Network (COVID-SDNet) methodology for improving the generalization capacity of COVID-classification models. Our approach reaches good and stable results with an accuracy of [Formula: see text], [Formula: see text], [Formula: see text] in severe, moderate and mild COVID-19 severity levels. Our approach could help in the early detection of COVID-19. COVIDGR-1.0 along with the severity level labels are available to the scientific community through this link https://dasci.es/es/transferencia/open-data/covidgr/.",True,other,recurrent neural network
33166256,Classification of Severe and Critical Covid-19 Using Deep Learning and Radiomics,"OBJECTIVE: The coronavirus disease 2019 (COVID-19) is rapidly spreading inside China and internationally. We aimed to construct a model integrating information from radiomics and deep learning (DL) features to discriminate critical cases from severe cases of COVID-19 using computed tomography (CT) images.
METHODS: We retrospectively enrolled 217 patients from three centers in China, including 82 patients with severe disease and 135 with critical disease. Patients were randomly divided into a training cohort (n = 174) and a test cohort (n = 43). We extracted 102 3-dimensional radiomic features from automatically segmented lung volume and selected the significant features. We also developed a 3-dimensional DL network based on center-cropped slices. Using multivariable logistic regression, we then created a merged model based on significant radiomic features and DL scores. We employed the area under the receiver operating characteristic curve (AUC) to evaluate the model's performance. We then conducted cross validation, stratified analysis, survival analysis, and decision curve analysis to evaluate the robustness of our method.
RESULTS: The merged model can distinguish critical patients with AUCs of 0.909 (95% confidence interval [CI]: 0.859-0.952) and 0.861 (95% CI: 0.753-0.968) in the training and test cohorts, respectively. Stratified analysis indicated that our model was not affected by sex, age, or chronic disease. Moreover, the results of the merged model showed a strong correlation with patient outcomes.
SIGNIFICANCE: A model combining radiomic and DL features of the lung could help distinguish critical cases from severe cases of COVID-19.",True,computer vision,Not specified
33161334,The importance of standardisation - COVID-19 CT & Radiograph Image Data Stock for deep learning purpose,"With the number of affected individuals still growing world-wide, the research on COVID-19 is continuously expanding. The deep learning community concentrates their efforts on exploring if neural networks can potentially support the diagnosis using CT and radiograph images of patients' lungs. The two most popular publicly available datasets for COVID-19 classification are COVID-CT and COVID-19 Image Data Collection. In this work, we propose a new dataset which we call COVID-19 CT & Radiograph Image Data Stock. It contains both CT and radiograph samples of COVID-19 lung findings and combines them with additional data to ensure a sufficient number of diverse COVID-19-negative samples. Moreover, it is supplemented with a carefully defined split. The aim of COVID-19 CT & Radiograph Image Data Stock is to create a public pool of CT and radiograph images of lungs to increase the efficiency of distinguishing COVID-19 disease from other types of pneumonia and from healthy chest. We hope that the creation of this dataset would allow standardisation of the approach taken for training deep neural networks for COVID-19 classification and eventually for building more reliable models.",True,other,convolutional neural network
33126245,Identification of pan-cancer Ras pathway activation with deep learning,"The identification of hidden responders is often an essential challenge in precision oncology. A recent attempt based on machine learning has been proposed for classifying aberrant pathway activity from multiomic cancer data. However, we note several critical limitations there, such as high-dimensionality, data sparsity and model performance. Given the central importance and broad impact of precision oncology, we propose nature-inspired deep Ras activation pan-cancer (NatDRAP), a deep neural network (DNN) model, to address those restrictions for the identification of hidden responders. In this study, we develop the nature-inspired deep learning model that integrates bulk RNA sequencing, copy number and mutation data from PanCanAltas to detect pan-cancer Ras pathway activation. In NatDRAP, we propose to synergize the nature-inspired artificial bee colony algorithm with different gradient-based optimizers in one framework for optimizing DNNs in a collaborative manner. Multiple experiments were conducted on 33 different cancer types across PanCanAtlas. The experimental results demonstrate that the proposed NatDRAP can provide superior performance over other benchmark methods with strong robustness towards diagnosing RAS aberrant pathway activity across different cancer types. In addition, gene ontology enrichment and pathological analysis are conducted to reveal novel insights into the RAS aberrant pathway activity identification and characterization. NatDRAP is written in Python and available at https://github.com/lixt314/NatDRAP1.",True,other,RNN
33123133,Artificial Intelligence Applied to in vitro Gene Expression Testing (IVIGET) to Predict Trivalent Inactivated Influenza Vaccine Immunogenicity in HIV Infected Children,"The number of patients affected by chronic diseases with special vaccination needs is burgeoning. In this scenario, predictive markers of immunogenicity, as well as signatures of immune responses are typically missing even though it would especially improve the identification of personalized immunization practices in these populations. We aimed to develop a predictive score of immunogenicity to Influenza Trivalent Inactivated Vaccination (TIV) by applying deep machine learning algorithms using transcriptional data from sort-purified lymphocyte subsets after in vitro stimulation. Peripheral blood mononuclear cells (PBMCs) collected before TIV from 23 vertically HIV infected children under ART and virally controlled were stimulated in vitro with p09/H1N1 peptides (stim) or left unstimulated (med). A multiplexed-qPCR for 96 genes was made on fixed numbers of 3 B cell subsets, 3 T cell subsets and total PBMCs. The ability to respond to TIV was assessed through hemagglutination Inhibition Assay (HIV) and ELIspot and patients were classified as Responders (R) and Non Responders (NR). A predictive modeling framework was applied to the data set in order to define genes and conditions with the higher predicted probability able to inform the final score. Twelve NR and 11 R were analyzed for gene expression differences in all subsets and 3 conditions [med, stim or Δ (stim-med)]. Differentially expressed genes between R and NR were selected and tested with the Adaptive Boosting Model to build a prediction score. The score obtained from subsets revealed the best prediction score from 46 genes from 5 different subsets and conditions. Calculating a combined score based on these 5 categories, we achieved a model accuracy of 95.6% and only one misclassified patient. These data show how a predictive bioinformatic model applied to transcriptional analysis deriving from in-vitro stimulated lymphocytes subsets may predict poor or protective vaccination immune response in vulnerable populations, such as HIV-infected individuals. Future studies on larger cohorts are needed to validate such strategy in the context of vaccination trials.",True,other,Not specified
33121959,Evaluation of a Deep Learning-Derived Quantitative Retinopathy of Prematurity Severity Scale,"PURPOSE: To evaluate the clinical usefulness of a quantitative deep learning-derived vascular severity score for retinopathy of prematurity (ROP) by assessing its correlation with clinical ROP diagnosis and by measuring clinician agreement in applying a novel scale.
DESIGN: Analysis of existing database of posterior pole fundus images and corresponding ophthalmoscopic examinations using 2 methods of assigning a quantitative scale to vascular severity.
PARTICIPANTS: Images were from clinical examinations of patients in the Imaging and Informatics in ROP Consortium. Four ophthalmologists and 1 study coordinator evaluated vascular severity on a scale from 1 to 9.
METHODS: A quantitative vascular severity score (1-9) was applied to each image using a deep learning algorithm. A database of 499 images was developed for assessment of interobserver agreement.
MAIN OUTCOME MEASURES: Distribution of deep learning-derived vascular severity scores with the clinical assessment of zone (I, II, or III), stage (0, 1, 2, or 3), and extent (<3 clock hours, 3-6 clock hours, and >6 clock hours) of stage 3 evaluated using multivariate linear regression and weighted κ values and Pearson correlation coefficients for interobserver agreement on a 1-to-9 vascular severity scale.
RESULTS: For deep learning analysis, a total of 6344 clinical examinations were analyzed. A higher deep learning-derived vascular severity score was associated with more posterior disease, higher disease stage, and higher extent of stage 3 disease (P < 0.001 for all). For a given ROP stage, the vascular severity score was higher in zone I than zones II or III (P < 0.001). Multivariate regression found zone, stage, and extent all were associated independently with the severity score (P < 0.001 for all). For interobserver agreement, the mean ± standard deviation weighted κ value was 0.67 ± 0.06, and the Pearson correlation coefficient ± standard deviation was 0.88 ± 0.04 on the use of a 1-to-9 vascular severity scale.
CONCLUSIONS: A vascular severity scale for ROP seems feasible for clinical adoption; corresponds with zone, stage, extent of stage 3, and plus disease; and facilitates the use of objective technology such as deep learning to improve the consistency of ROP diagnosis.",True,other,Not specified
33106108,Incorporating Artificial Intelligence Into Stroke Care and Research,,True,other,GAN
33102623,Deep neural network to locate and segment brain tumors outperformed the expert technicians who created the training data,"Purpose: Deep learning (DL) algorithms have shown promising results for brain tumor segmentation in MRI. However, validation is required prior to routine clinical use. We report the first randomized and blinded comparison of DL and trained technician segmentations. Approach: We compiled a multi-institutional database of 741 pretreatment MRI exams. Each contained a postcontrast T1-weighted exam, a T2-weighted fluid-attenuated inversion recovery exam, and at least one technician-derived tumor segmentation. The database included 729 unique patients (470 males and 259 females). Of these exams, 641 were used for training the DL system, and 100 were reserved for testing. We developed a platform to enable qualitative, blinded, controlled assessment of lesion segmentations made by technicians and the DL method. On this platform, 20 neuroradiologists performed 400 side-by-side comparisons of segmentations on 100 test cases. They scored each segmentation between 0 (poor) and 10 (perfect). Agreement between segmentations from technicians and the DL method was also evaluated quantitatively using the Dice coefficient, which produces values between 0 (no overlap) and 1 (perfect overlap). Results: The neuroradiologists gave technician and DL segmentations mean scores of 6.97 and 7.31, respectively ( p &lt; 0.00007  ). The DL method achieved a mean Dice coefficient of 0.87 on the test cases. Conclusions: This was the first objective comparison of automated and human segmentation using a blinded controlled assessment study. Our DL system learned to outperform its ""human teachers"" and produced output that was better, on average, than its training data.",True,other,recurrent neural network
33100943,Convergent learning-based model for leukemia classification from gene expression,"Microarray data analysis is a major challenging field of research in recent days. Machine learning-based automated gene data classification is an essential aspect for diagnosis of gene related any malfunctions and diseases. As the size of the data is very large, it is essential to design a suitable classifier that can process huge amount of data. Deep learning is one of the advanced machine learning techniques to mitigate these types of problems. Due the presence of more number of hidden layers, it can easily handle the big amount of data. We have presented a method of classification to understand the convergence of training deep neural network (DNN). The assumptions are taken as the inputs do not degenerate and the network is over-parameterized. Also the number of hidden neurons is sufficiently large. Authors in this piece of work have used DNN for classifying the gene expressions data. The dataset used in the work contains the bone marrow expressions of 72 leukemia patients. A five-layer DNN classifier is designed for classifying acute lymphocyte (ALL) and acute myelocytic (AML) samples. The network is trained with 80% data and rest 20% data is considered for validation purpose. Proposed DNN classifier is providing a satisfactory result as compared to other classifiers. Two types of leukemia are classified with 98.2% accuracy, 96.59% sensitivity, and 97.9% specificity. The different types of computer-aided analyses of genes can be helpful to genetic and virology researchers as well in future generation.",True,other,recurrent neural network
33092313,Application of deep learning to predict advanced neoplasia using big clinical data in colorectal cancer screening of asymptomatic adults,"BACKGROUND/AIMS: We aimed to develop a deep learning model for the prediction of the risk of advanced colorectal neoplasia (ACRN) in asymptomatic adults, based on which colorectal cancer screening could be customized.
METHODS: We collected data on 26 clinical and laboratory parameters, including age, sex, smoking status, body mass index, complete blood count, blood chemistry, and tumor marker, from 70,336 first-time colonoscopy screening recipients. For reference, we used a logistic regression (LR) model with nine variables manually selected from the 26 variables. A deep neural network (DNN) model was developed using all 26 variables. The area under the receiver operating characteristic curve (AUC), sensitivity, and specificity of the models were compared in a randomly split validation group.
RESULTS: In comparison with the LR model (AUC, 0.724; 95% confidence interval [CI], 0.684 to 0.765), the DNN model (AUC, 0.760; 95% CI, 0.724 to 0.795) demonstrated significantly improved performance with respect to the prediction of ACRN (p < 0.001). At a sensitivity of 90%, the specificity significantly increased with the application of the DNN model (41.0%) in comparison with the LR model (26.5%) (p < 0.001), indicating that the colonoscopy workload required to detect the same number of ACRNs could be reduced by 20%.
CONCLUSION: The application of DNN to big clinical data could significantly improve the prediction of ACRNs in comparison with the LR model, potentially realizing further customization by utilizing large quantities and various types of biomedical information.",True,other,Not specified
33088315,The outcome in patients with brain stroke: A deep learning neural network modeling,"BACKGROUND: The artificial intelligence field is obtaining ever-increasing interests for enhancing the accuracy of diagnosis and the quality of patient care. Deep learning neural network (DLNN) approach was considered in patients with brain stroke (BS) to predict and classify the outcome by the risk factors.
MATERIALS AND METHODS: A total of 332 patients with BS (mean age: 77.4 [standard deviation: 10.4] years, 50.6% - male) from Imam Khomeini Hospital, Ardabil, Iran, during 2008-2018 participated in this prospective study. Data were gathered from the available documents of the BS registry. Furthermore, the diagnosis of BS was considered based on computerized tomography scans and magnetic resonance imaging. The DLNN strategy was applied to predict the effects of the main risk factors on mortality. The quality of the model was measured by diagnostic indices.
RESULTS: The finding of this study for 81 selected models demonstrated that ranges of accuracy, sensitivity, and specificity are 90.5%-99.7%, 83.8%-100%, and 89.8%-99.5%, respectively. Based on the optimal model (tangent hyperbolic activation function with the minimum-maximum hidden units of 10-20, max epochs of 400, momentum of 0.5, and learning rate of 0.1), the most important predictors for BS mortality were time interval after 10 years (accuracy = 92.2%), age category (75.6%), the history of hyperlipoproteinemia (66.9%), and education level (66.9%). The other independent variables are at moderate importance (66.6%) which include sex, employment status, residential place, smoking habits, history of heart disease, cerebrovascular accident type, blood pressure, diabetes, oral contraceptive pill use, and physical activity.
CONCLUSION: The best means for dropping the BS load is effective BS prevention. DLNN strategy showed a surprising presentation in the prediction of BS mortality based on the main risk factors with an excellent diagnostic accuracy. Moreover, the time interval after 10 years, age, the history of hyperlipoproteinemia, and education level are the most important predictors for BS.",True,other,recurrent neural network
33070540,Usefulness of machine learning in COVID-19 for the detection and prognosis of cardiovascular complications,"Since January 2020, coronavirus disease 2019 (COVID-19) has rapidly become a global concern, and its cardiovascular manifestations have highlighted the need for fast, sensitive and specific tools for early identification and risk stratification. Machine learning is a software solution with the ability to analyze large amounts of data and make predictions without prior programming. When faced with new problems with unique challenges as evident in the COVID-19 pandemic, machine learning can offer solutions that are not apparent on the surface by sifting quickly through massive quantities of data and making associations that may have been missed. Artificial intelligence is a broad term that encompasses different tools, including various types of machine learning and deep learning. Here, we review several cardiovascular applications of machine learning and artificial intelligence and their potential applications to cardiovascular diagnosis, prognosis, and therapy in COVID-19 infection.",True,other,recurrent neural network
33067442,Non-invasive decision support for NSCLC treatment using PET/CT radiomics,"Two major treatment strategies employed in non-small cell lung cancer, NSCLC, are tyrosine kinase inhibitors, TKIs, and immune checkpoint inhibitors, ICIs. The choice of strategy is based on heterogeneous biomarkers that can dynamically change during therapy. Thus, there is a compelling need to identify comprehensive biomarkers that can be used longitudinally to help guide therapy choice. Herein, we report a 18F-FDG-PET/CT-based deep learning model, which demonstrates high accuracy in EGFR mutation status prediction across patient cohorts from different institutions. A deep learning score (EGFR-DLS) was significantly and positively associated with longer progression free survival (PFS) in patients treated with EGFR-TKIs, while EGFR-DLS is significantly and negatively associated with higher durable clinical benefit, reduced hyperprogression, and longer PFS among patients treated with ICIs. Thus, the EGFR-DLS provides a non-invasive method for precise quantification of EGFR mutation status in NSCLC patients, which is promising to identify NSCLC patients sensitive to EGFR-TKI or ICI-treatments.",True,other,Not specified
33059369,DeepHPV: a deep learning model to predict human papillomavirus integration sites,"Human papillomavirus (HPV) integrating into human genome is the main cause of cervical carcinogenesis. HPV integration selection preference shows strong dependence on local genomic environment. Due to this theory, it is possible to predict HPV integration sites. However, a published bioinformatic tool is not available to date. Thus, we developed an attention-based deep learning model DeepHPV to predict HPV integration sites by learning environment features automatically. In total, 3608 known HPV integration sites were applied to train the model, and 584 reviewed HPV integration sites were used as the testing dataset. DeepHPV showed an area under the receiver-operating characteristic (AUROC) of 0.6336 and an area under the precision recall (AUPR) of 0.5670. Adding RepeatMasker and TCGA Pan Cancer peaks improved the model performance to 0.8464 and 0.8501 in AUROC and 0.7985 and 0.8106 in AUPR, respectively. Next, we tested these trained models on independent database VISDB and found the model adding TCGA Pan Cancer performed better (AUROC: 0.7175, AUPR: 0.6284) than the model adding RepeatMasker peaks (AUROC: 0.6102, AUPR: 0.5577). Moreover, we introduced attention mechanism in DeepHPV and enriched the transcription factor binding sites including BHLHA15, CHR, COUP-TFII, DMRTA2, E2A, HIC1, INR, NPAS, Nr5a2, RARa, SCL, Snail1, Sox10, Sox3, Sox4, Sox6, STAT6, Tbet, Tbx5, TEAD, Tgif2, ZNF189, ZNF416 near attention intensive sites. Together, DeepHPV is a robust and explainable deep learning model, providing new insights into HPV integration preference and mechanism. Availability: DeepHPV is available as an open-source software and can be downloaded from https://github.com/JiuxingLiang/DeepHPV.git, Contact: huzheng1998@163.com, liangjiuxing@m.scnu.edu.cn, lizheyzy@163.com.",True,other,Not specified
33048773,M (3)Lung-Sys: A Deep Learning System for Multi-Class Lung Pneumonia Screening From CT Imaging,"To counter the outbreak of COVID-19, the accurate diagnosis of suspected cases plays a crucial role in timely quarantine, medical treatment, and preventing the spread of the pandemic. Considering the limited training cases and resources (e.g, time and budget), we propose a Multi-task Multi-slice Deep Learning System (M 3Lung-Sys) for multi-class lung pneumonia screening from CT imaging, which only consists of two 2D CNN networks, i.e., slice- and patient-level classification networks. The former aims to seek the feature representations from abundant CT slices instead of limited CT volumes, and for the overall pneumonia screening, the latter one could recover the temporal information by feature refinement and aggregation between different slices. In addition to distinguish COVID-19 from Healthy, H1N1, and CAP cases, our M 3Lung-Sys also be able to locate the areas of relevant lesions, without any pixel-level annotation. To further demonstrate the effectiveness of our model, we conduct extensive experiments on a chest CT imaging dataset with a total of 734 patients (251 healthy people, 245 COVID-19 patients, 105 H1N1 patients, and 133 CAP patients). The quantitative results with plenty of metrics indicate the superiority of our proposed model on both slice- and patient-level classification tasks. More importantly, the generated lesion location maps make our system interpretable and more valuable to clinicians.",True,other,CNN
33044938,Severity and Consolidation Quantification of COVID-19 From CT Images Using Deep Learning Based on Hybrid Weak Labels,"Early and accurate diagnosis of Coronavirus disease (COVID-19) is essential for patient isolation and contact tracing so that the spread of infection can be limited. Computed tomography (CT) can provide important information in COVID-19, especially for patients with moderate to severe disease as well as those with worsening cardiopulmonary status. As an automatic tool, deep learning methods can be utilized to perform semantic segmentation of affected lung regions, which is important to establish disease severity and prognosis prediction. Both the extent and type of pulmonary opacities help assess disease severity. However, manually pixel-level multi-class labelling is time-consuming, subjective, and non-quantitative. In this article, we proposed a hybrid weak label-based deep learning method that utilize both the manually annotated pulmonary opacities from COVID-19 pneumonia and the patient-level disease-type information available from the clinical report. A UNet was firstly trained with semantic labels to segment the total infected region. It was used to initialize another UNet, which was trained to segment the consolidations with patient-level information using the Expectation-Maximization (EM) algorithm. To demonstrate the performance of the proposed method, multi-institutional CT datasets from Iran, Italy, South Korea, and the United States were utilized. Results show that our proposed method can predict the infected regions as well as the consolidation regions with good correlation to human annotation.",True,other,Not specified
33033164,Utilization of Deep Learning for Subphenotype Identification in Sepsis-Associated Acute Kidney Injury,"BACKGROUND AND OBJECTIVES: Sepsis-associated AKI is a heterogeneous clinical entity. We aimed to agnostically identify sepsis-associated AKI subphenotypes using deep learning on routinely collected data in electronic health records.
DESIGN, SETTING, PARTICIPANTS, & MEASUREMENTS: We used the Medical Information Mart for Intensive Care III database, which consists of electronic health record data from intensive care units in a tertiary care hospital in the United States. We included patients ≥18 years with sepsis who developed AKI within 48 hours of intensive care unit admission. We then used deep learning to utilize all available vital signs, laboratory measurements, and comorbidities to identify subphenotypes. Outcomes were mortality 28 days after AKI and dialysis requirement.
RESULTS: We identified 4001 patients with sepsis-associated AKI. We utilized 2546 combined features for K-means clustering, identifying three subphenotypes. Subphenotype 1 had 1443 patients, and subphenotype 2 had 1898 patients, whereas subphenotype 3 had 660 patients. Subphenotype 1 had the lowest proportion of liver disease and lowest Simplified Acute Physiology Score II scores compared with subphenotypes 2 and 3. The proportions of patients with CKD were similar between subphenotypes 1 and 3 (15%) but highest in subphenotype 2 (21%). Subphenotype 1 had lower median bilirubin levels, aspartate aminotransferase, and alanine aminotransferase compared with subphenotypes 2 and 3. Patients in subphenotype 1 also had lower median lactate, lactate dehydrogenase, and white blood cell count than patients in subphenotypes 2 and 3. Subphenotype 1 also had lower creatinine and BUN than subphenotypes 2 and 3. Dialysis requirement was lowest in subphenotype 1 (4% versus 7% [subphenotype 2] versus 26% [subphenotype 3]). The mortality 28 days after AKI was lowest in subphenotype 1 (23% versus 35% [subphenotype 2] versus 49% [subphenotype 3]). After adjustment, the adjusted odds ratio for mortality for subphenotype 3, with subphenotype 1 as a reference, was 1.9 (95% confidence interval, 1.5 to 2.4).
CONCLUSIONS: Utilizing routinely collected laboratory variables, vital signs, and comorbidities, we were able to identify three distinct subphenotypes of sepsis-associated AKI with differing outcomes.",True,computer vision,Not specified
33008368,Prediction of incident myocardial infarction using machine learning applied to harmonized electronic health record data,"BACKGROUND: With cardiovascular disease increasing, substantial research has focused on the development of prediction tools. We compare deep learning and machine learning models to a baseline logistic regression using only 'known' risk factors in predicting incident myocardial infarction (MI) from harmonized EHR data.
METHODS: Large-scale case-control study with outcome of 6-month incident MI, conducted using the top 800, from an initial 52 k procedures, diagnoses, and medications within the UCHealth system, harmonized to the Observational Medical Outcomes Partnership common data model, performed on 2.27 million patients. We compared several over- and under- sampling techniques to address the imbalance in the dataset. We compared regularized logistics regression, random forest, boosted gradient machines, and shallow and deep neural networks. A baseline model for comparison was a logistic regression using a limited set of 'known' risk factors for MI. Hyper-parameters were identified using 10-fold cross-validation.
RESULTS: Twenty thousand Five hundred and ninety-one patients were diagnosed with MI compared with 2.25 million who did not. A deep neural network with random undersampling provided superior classification compared with other methods. However, the benefit of the deep neural network was only moderate, showing an F1 Score of 0.092 and AUC of 0.835, compared to a logistic regression model using only 'known' risk factors. Calibration for all models was poor despite adequate discrimination, due to overfitting from low frequency of the event of interest.
CONCLUSIONS: Our study suggests that DNN may not offer substantial benefit when trained on harmonized data, compared to traditional methods using established risk factors for MI.",True,other,Not specified
32998878,Exploring prognostic indicators in the pathological images of hepatocellular carcinoma based on deep learning,"OBJECTIVE: Tumour pathology contains rich information, including tissue structure and cell morphology, that reflects disease progression and patient survival. However, phenotypic information is subtle and complex, making the discovery of prognostic indicators from pathological images challenging.
DESIGN: An interpretable, weakly supervised deep learning framework incorporating prior knowledge was proposed to analyse hepatocellular carcinoma (HCC) and explore new prognostic phenotypes on pathological whole-slide images (WSIs) from the Zhongshan cohort of 1125 HCC patients (2451 WSIs) and TCGA cohort of 320 HCC patients (320 WSIs). A 'tumour risk score (TRS)' was established to evaluate patient outcomes, and then risk activation mapping (RAM) was applied to visualise the pathological phenotypes of TRS. The multi-omics data of The Cancer Genome Atlas(TCGA) HCC were used to assess the potential pathogenesis underlying TRS.
RESULTS: Survival analysis revealed that TRS was an independent prognosticator in both the Zhongshan cohort (p&lt;0.0001) and TCGA cohort (p=0.0003). The predictive ability of TRS was superior to and independent of clinical staging systems, and TRS could evenly stratify patients into up to five groups with significantly different prognoses. Notably, sinusoidal capillarisation, prominent nucleoli and karyotheca, the nucleus/cytoplasm ratio and infiltrating inflammatory cells were identified as the main underlying features of TRS. The multi-omics data of TCGA HCC hint at the relevance of TRS to tumour immune infiltration and genetic alterations such as the FAT3 and RYR2 mutations.
CONCLUSION: Our deep learning framework is an effective and labour-saving method for decoding pathological images, providing a valuable means for HCC risk stratification and precise patient treatment.",True,other,Not specified
32996368,Exploring the Potential of Artificial Intelligence and Machine Learning to Combat COVID-19 and Existing Opportunities for LMIC: A Scoping Review,"BACKGROUND: In the face of the current time-sensitive COVID-19 pandemic, the limited capacity of healthcare systems resulted in an emerging need to develop newer methods to control the spread of the pandemic. Artificial Intelligence (AI), and Machine Learning (ML) have a vast potential to exponentially optimize health care research. The use of AI-driven tools in LMIC can help in eradicating health inequalities and decrease the burden on health systems.
METHODS: The literature search for this Scoping review was conducted through the PubMed database using keywords: COVID-19, Artificial Intelligence (AI), Machine Learning (ML), and Low Middle-Income Countries (LMIC). Forty-three articles were identified and screened for eligibility and 13 were included in the final review. All the items of this Scoping review are reported using guidelines for PRISMA extension for scoping reviews (PRISMA-ScR).
RESULTS: Results were synthesized and reported under 4 themes. (a) The need of AI during this pandemic: AI can assist to increase the speed and accuracy of identification of cases and through data mining to deal with the health crisis efficiently, (b) Utility of AI in COVID-19 screening, contact tracing, and diagnosis: Efficacy for virus detection can a be increased by deploying the smart city data network using terminal tracking system along-with prediction of future outbreaks, (c) Use of AI in COVID-19 patient monitoring and drug development: A Deep learning system provides valuable information regarding protein structures associated with COVID-19 which could be utilized for vaccine formulation, and (d) AI beyond COVID-19 and opportunities for Low-Middle Income Countries (LMIC): There is a lack of financial, material, and human resources in LMIC, AI can minimize the workload on human labor and help in analyzing vast medical data, potentiating predictive and preventive healthcare.
CONCLUSION: AI-based tools can be a game-changer for diagnosis, treatment, and management of COVID-19 patients with the potential to reshape the future of healthcare in LMIC.",True,other,convolutional neural network
32980820,Deep learning algorithms to isolate and quantify the structures of the anterior segment in optical coherence tomography images,"BACKGROUND/AIMS: Accurate isolation and quantification of intraocular dimensions in the anterior segment (AS) of the eye using optical coherence tomography (OCT) images is important in the diagnosis and treatment of many eye diseases, especially angle-closure glaucoma.
METHOD: In this study, we developed a deep convolutional neural network (DCNN) for the localisation of the scleral spur; moreover, we introduced an information-rich segmentation approach for this localisation problem. An ensemble of DCNNs for the segmentation of AS structures (iris, corneosclera shell adn anterior chamber) was developed. Based on the results of two previous processes, an algorithm to automatically quantify clinically important measurements were created. 200 images from 58 patients (100 eyes) were used for testing.
RESULTS: With limited training data, the DCNN was able to detect the scleral spur on unseen anterior segment optical coherence tomography (ASOCT) images as accurately as an experienced ophthalmologist on the given test dataset and simultaneously isolated the AS structures with a Dice coefficient of 95.7%. We then automatically extracted eight clinically relevant ASOCT measurements and proposed an automated quality check process that asserts the reliability of these measurements. When combined with an OCT machine capable of imaging multiple radial sections, the algorithms can provide a more complete objective assessment. The total segmentation and measurement time for a single scan is less than 2 s.
CONCLUSION: This is an essential step towards providing a robust automated framework for reliable quantification of ASOCT scans, for applications in the diagnosis and management of angle-closure glaucoma.",True,both,convolutional neural network
32976486,Sociodemographic data and APOE-ε4 augmentation for MRI-based detection of amnestic mild cognitive impairment using deep learning systems,"Detection and diagnosis of early and subclinical stages of Alzheimer's Disease (AD) play an essential role in the implementation of intervention and prevention strategies. Neuroimaging techniques predominantly provide insight into anatomic structure changes associated with AD. Deep learning methods have been extensively applied towards creating and evaluating models capable of differentiating between cognitively unimpaired, patients with Mild Cognitive Impairment (MCI) and AD dementia. Several published approaches apply information fusion techniques, providing ways of combining several input sources in the medical domain, which contributes to knowledge of broader and enriched quality. The aim of this paper is to fuse sociodemographic data such as age, marital status, education and gender, and genetic data (presence of an apolipoprotein E (APOE)-ε4 allele) with Magnetic Resonance Imaging (MRI) scans. This enables enriched multi-modal features, that adequately represent the MRI scan visually and is adopted for creating and modeling classification systems capable of detecting amnestic MCI (aMCI). To fully utilize the potential of deep convolutional neural networks, two extra color layers denoting contrast intensified and blurred image adaptations are virtually augmented to each MRI scan, completing the Red-Green-Blue (RGB) color channels. Deep convolutional activation features (DeCAF) are extracted from the average pooling layer of the deep learning system Inception_v3. These features from the fused MRI scans are used as visual representation for the Long Short-Term Memory (LSTM) based Recurrent Neural Network (RNN) classification model. The proposed approach is evaluated on a sub-study containing 120 participants (aMCI = 61 and cognitively unimpaired = 59) of the Heinz Nixdorf Recall (HNR) Study with a baseline model accuracy of 76%. Further evaluation was conducted on the ADNI Phase 1 dataset with 624 participants (aMCI = 397 and cognitively unimpaired = 227) with a baseline model accuracy of 66.27%. Experimental results show that the proposed approach achieves 90% accuracy and 0.90 F1-Score at classification of aMCI vs. cognitively unimpaired participants on the HNR Study dataset, and 77% accuracy and 0.83 F1-Score on the ADNI dataset.",True,other,convolutional neural network
32971995,Unveiling COVID-19 from CHEST X-Ray with Deep Learning: A Hurdles Race with Small Data,"The possibility to use widespread and simple chest X-ray (CXR) imaging for early screening of COVID-19 patients is attracting much interest from both the clinical and the AI community. In this study we provide insights and also raise warnings on what is reasonable to expect by applying deep learning to COVID classification of CXR images. We provide a methodological guide and critical reading of an extensive set of statistical results that can be obtained using currently available datasets. In particular, we take the challenge posed by current small size COVID data and show how significant can be the bias introduced by transfer-learning using larger public non-COVID CXR datasets. We also contribute by providing results on a medium size COVID CXR dataset, just collected by one of the major emergency hospitals in Northern Italy during the peak of the COVID pandemic. These novel data allow us to contribute to validate the generalization capacity of preliminary results circulating in the scientific community. Our conclusions shed some light into the possibility to effectively discriminate COVID using CXR.",True,other,Not specified
32970677,Deep neural network models for identifying incident dementia using claims and EHR datasets,"This study investigates the use of deep learning methods to improve the accuracy of a predictive model for dementia, and compares the performance to a traditional machine learning model. With sufficient accuracy the model can be deployed as a first round screening tool for clinical follow-up including neurological examination, neuropsychological testing, imaging and recruitment to clinical trials. Seven cohorts with two years of data, three to eight years prior to index date, and an incident cohort were created. Four trained models for each cohort, boosted trees, feed forward network, recurrent neural network and recurrent neural network with pre-trained weights, were constructed and their performance compared using validation and test data. The incident model had an AUC of 94.4% and F1 score of 54.1%. Eight years removed from index date the AUC and F1 scores were 80.7% and 25.6%, respectively. The results for the remaining cohorts were between these ranges. Deep learning models can result in significant improvement in performance but come at a cost in terms of run times and hardware requirements. The results of the model at index date indicate that this modeling can be effective at stratifying patients at risk of dementia. At this time, the inability to sustain this quality at longer lead times is more an issue of data availability and quality rather than one of algorithm choices.",True,other,recurrent neural network
32968435,Advancing COVID-19 differentiation with a robust preprocessing and integration of multi-institutional open-repository computer tomography datasets for deep learning analysis,"The coronavirus pandemic and its unprecedented consequences globally has spurred the interest of the artificial intelligence research community. A plethora of published studies have investigated the role of imaging such as chest X-rays and computer tomography in coronavirus disease 2019 (COVID-19) automated diagnosis. Οpen repositories of medical imaging data can play a significant role by promoting cooperation among institutes in a world-wide scale. However, they may induce limitations related to variable data quality and intrinsic differences due to the wide variety of scanner vendors and imaging parameters. In this study, a state-of-the-art custom U-Net model is presented with a dice similarity coefficient performance of 99.6% along with a transfer learning VGG-19 based model for COVID-19 versus pneumonia differentiation exhibiting an area under curve of 96.1%. The above was significantly improved over the baseline model trained with no segmentation in selected tomographic slices of the same dataset. The presented study highlights the importance of a robust preprocessing protocol for image analysis within a heterogeneous imaging dataset and assesses the potential diagnostic value of the presented COVID-19 model by comparing its performance to the state of the art.",True,other,Not specified
32959234,COVID19XrayNet: A Two-Step Transfer Learning Model for the COVID-19 Detecting Problem Based on a Limited Number of Chest X-Ray Images,"The novel coronavirus severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a major pandemic outbreak recently. Various diagnostic technologies have been under active development. The novel coronavirus disease (COVID-19) may induce pulmonary failures, and chest X-ray imaging becomes one of the major confirmed diagnostic technologies. The very limited number of publicly available samples has rendered the training of the deep neural networks unstable and inaccurate. This study proposed a two-step transfer learning pipeline and a deep residual network framework COVID19XrayNet for the COVID-19 detection problem based on chest X-ray images. COVID19XrayNet firstly tunes the transferred model on a large dataset of chest X-ray images, which is further tuned using a small dataset of annotated chest X-ray images. The final model achieved 0.9108 accuracy. The experimental data also suggested that the model may be improved with more training samples being released. COVID19XrayNet, a two-step transfer learning framework designed for biomedical images.",True,other,Not specified
32943643,Evaluating the informativeness of deep learning annotations for human complex diseases,"Deep learning models have shown great promise in predicting regulatory effects from DNA sequence, but their informativeness for human complex diseases is not fully understood. Here, we evaluate genome-wide SNP annotations from two previous deep learning models, DeepSEA and Basenji, by applying stratified LD score regression to 41 diseases and traits (average N = 320K), conditioning on a broad set of coding, conserved and regulatory annotations. We aggregated annotations across all (respectively blood or brain) tissues/cell-types in meta-analyses across all (respectively 11 blood or 8 brain) traits. The annotations were highly enriched for disease heritability, but produced only limited conditionally significant results: non-tissue-specific and brain-specific Basenji-H3K4me3 for all traits and brain traits respectively. We conclude that deep learning models have yet to achieve their full potential to provide considerable unique information for complex disease, and that their conditional informativeness for disease cannot be inferred from their accuracy in predicting regulatory annotations.",True,other,recurrent neural network
32915901,"Inconsistency in the use of the term ""validation"" in studies reporting the performance of deep learning algorithms in providing diagnosis from medical imaging","BACKGROUND: The development of deep learning (DL) algorithms is a three-step process-training, tuning, and testing. Studies are inconsistent in the use of the term ""validation"", with some using it to refer to tuning and others testing, which hinders accurate delivery of information and may inadvertently exaggerate the performance of DL algorithms. We investigated the extent of inconsistency in usage of the term ""validation"" in studies on the accuracy of DL algorithms in providing diagnosis from medical imaging.
METHODS AND FINDINGS: We analyzed the full texts of research papers cited in two recent systematic reviews. The papers were categorized according to whether the term ""validation"" was used to refer to tuning alone, both tuning and testing, or testing alone. We analyzed whether paper characteristics (i.e., journal category, field of study, year of print publication, journal impact factor [JIF], and nature of test data) were associated with the usage of the terminology using multivariable logistic regression analysis with generalized estimating equations. Of 201 papers published in 125 journals, 118 (58.7%), 9 (4.5%), and 74 (36.8%) used the term to refer to tuning alone, both tuning and testing, and testing alone, respectively. A weak association was noted between higher JIF and using the term to refer to testing (i.e., testing alone or both tuning and testing) instead of tuning alone (vs. JIF <5; JIF 5 to 10: adjusted odds ratio 2.11, P = 0.042; JIF >10: adjusted odds ratio 2.41, P = 0.089). Journal category, field of study, year of print publication, and nature of test data were not significantly associated with the terminology usage.
CONCLUSIONS: Existing literature has a significant degree of inconsistency in using the term ""validation"" when referring to the steps in DL algorithm development. Efforts are needed to improve the accuracy and clarity in the terminology usage.",True,other,recurrent neural network
32911053,Computer versus cardiologist: Is a machine learning algorithm able to outperform an expert in diagnosing a phospholamban p.Arg14del mutation on the electrocardiogram?,"BACKGROUND: Phospholamban (PLN) p.Arg14del mutation carriers are known to develop dilated and/or arrhythmogenic cardiomyopathy, and typical electrocardiographic (ECG) features have been identified for diagnosis. Machine learning is a powerful tool used in ECG analysis and has shown to outperform cardiologists.
OBJECTIVES: We aimed to develop machine learning and deep learning models to diagnose PLN p.Arg14del cardiomyopathy using ECGs and evaluate their accuracy compared to an expert cardiologist.
METHODS: We included 155 adult PLN mutation carriers and 155 age- and sex-matched control subjects. Twenty-one PLN mutation carriers (13.4%) were classified as symptomatic (symptoms of heart failure or malignant ventricular arrhythmias). The data set was split into training and testing sets using 4-fold cross-validation. Multiple models were developed to discriminate between PLN mutation carriers and control subjects. For comparison, expert cardiologists classified the same data set. The best performing models were validated using an external PLN p.Arg14del mutation carrier data set from Murcia, Spain (n = 50). We applied occlusion maps to visualize the most contributing ECG regions.
RESULTS: In terms of specificity, expert cardiologists (0.99) outperformed all models (range 0.53-0.81). In terms of accuracy and sensitivity, experts (0.28 and 0.64) were outperformed by all models (sensitivity range 0.65-0.81). T-wave morphology was most important for classification of PLN p.Arg14del carriers. External validation showed comparable results, with the best model outperforming experts.
CONCLUSION: This study shows that machine learning can outperform experienced cardiologists in the diagnosis of PLN p.Arg14del cardiomyopathy and suggests that the shape of the T wave is of added importance to this diagnosis.",True,other,RNN
32907811,Detection of features associated with neovascular age-related macular degeneration in ethnically distinct data sets by an optical coherence tomography: trained deep learning algorithm,"BACKGROUND: The ability of deep learning (DL) algorithms to identify eyes with neovascular age-related macular degeneration (nAMD) from optical coherence tomography (OCT) scans has been previously established. We herewith evaluate the ability of a DL model, showing excellent performance on a Korean data set, to generalse onto an American data set despite ethnic differences. In addition, expert graders were surveyed to verify if the DL model was appropriately identifying lesions indicative of nAMD on the OCT scans.
METHODS: Model development data set-12 247 OCT scans from South Korea; external validation data set-91 509 OCT scans from Washington, USA. In both data sets, normal eyes or eyes with nAMD were included. After internal testing, the algorithm was sent to the University of Washington, USA, for external validation. Area under the receiver operating characteristic curve (AUC) and precision-recall curve (AUPRC) were calculated. For model explanation, saliency maps were generated using Guided GradCAM.
RESULTS: On external validation, AUC and AUPRC remained high at 0.952 (95% CI 0.942 to 0.962) and 0.891 (95% CI 0.875 to 0.908) at the individual level. Saliency maps showed that in normal OCT scans, the fovea was the main area of interest; in nAMD OCT scans, the appropriate pathological features were areas of model interest. Survey of 10 retina specialists confirmed this.
CONCLUSION: Our DL algorithm exhibited high performance for nAMD identification in a Korean population, and generalised well to an ethnically distinct, American population. The model correctly focused on the differences within the macular area to extract features associated with nAMD.",True,other,Not specified
32885818,Synthetic minority oversampling of vital statistics data with generative adversarial networks,"OBJECTIVE: Minority oversampling is a standard approach used for adjusting the ratio between the classes on imbalanced data. However, established methods often provide modest improvements in classification performance when applied to data with extremely imbalanced class distribution and to mixed-type data. This is usual for vital statistics data, in which the outcome incidence dictates the amount of positive observations. In this article, we developed a novel neural network-based oversampling method called actGAN (activation-specific generative adversarial network) that can derive useful synthetic observations in terms of increasing prediction performance in this context.
MATERIALS AND METHODS: From vital statistics data, the outcome of early stillbirth was chosen to be predicted based on demographics, pregnancy history, and infections. The data contained 363 560 live births and 139 early stillbirths, resulting in class imbalance of 99.96% and 0.04%. The hyperparameters of actGAN and a baseline method SMOTE-NC (Synthetic Minority Over-sampling Technique-Nominal Continuous) were tuned with Bayesian optimization, and both were compared against a cost-sensitive learning-only approach.
RESULTS: While SMOTE-NC provided mixed results, actGAN was able to improve true positive rate at a clinically significant false positive rate and area under the curve from the receiver-operating characteristic curve consistently.
DISCUSSION: Including an activation-specific output layer to a generator network of actGAN enables the addition of information about the underlying data structure, which overperforms the nominal mechanism of SMOTE-NC.
CONCLUSIONS: actGAN provides an improvement to the prediction performance for our learning task. Our developed method could be applied to other mixed-type data prediction tasks that are known to be afflicted by class imbalance and limited data availability.",True,other,recurrent neural network
32870314,Assessment of a Deep Learning Model to Predict Hepatocellular Carcinoma in Patients With Hepatitis C Cirrhosis,"IMPORTANCE: Deep learning, a family of machine learning models that use artificial neural networks, has achieved great success at predicting outcomes in nonmedical domains.
OBJECTIVE: To examine whether deep learning recurrent neural network (RNN) models that use raw longitudinal data extracted directly from electronic health records outperform conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC).
DESIGN, SETTING, AND PARTICIPANTS: This prognostic study included 48 151 patients with hepatitis C virus (HCV)-related cirrhosis in the national Veterans Health Administration who had at least 3 years of follow-up after the diagnosis of cirrhosis. Patients were identified by having at least 1 positive HCV RNA test between January 1, 2000, to January 1, 2016, and were followed up from the diagnosis of cirrhosis to January 1, 2019, for the development of incident HCC. A total of 3 models predicting HCC during a 3-year period were developed and compared, as follows: (1) logistic regression (LR) with cross-sectional inputs (cross-sectional LR); (2) LR with longitudinal inputs (longitudinal LR); and (3) RNN with longitudinal inputs. Data analysis was conducted from April 2018 to August 2020.
EXPOSURES: Development of HCC.
MAIN OUTCOMES AND MEASURES: Area under the receiver operating characteristic curve, area under the precision-recall curve, and Brier score.
RESULTS: During a mean (SD) follow-up of 11.6 (5.0) years, 10 741 of 48 151 patients (22.3%) developed HCC (annual incidence, 3.1%), and a total of 52 983 samples (51 948 [98.0%] from men) were collected. Patients who developed HCC within 3 years were older than patients who did not (mean [SD] age, 58.2 [6.6] years vs 56.9 [6.9] years). RNN models had superior mean (SD) area under the receiver operating characteristic curve (0.759 [0.009]) and mean (SD) Brier score (0.136 [0.003]) than cross-sectional LR (0.689 [0.009] and 0.149 [0.003], respectively) and longitudinal LR (0.682 [0.007] and 0.150 [0.003], respectively) models. Using the RNN model, the samples with the mean (SD) highest 51% (1.5%) of HCC risk, in which 80% of all HCCs occurred, or the mean (SD) highest 66% (1.2%) of HCC risk, in which 90% of all HCCs occurred, could potentially be targeted. Among samples from patients who achieved sustained virologic response, the performance of the RNN models was even better (mean [SD] area under receiver operating characteristic curve, 0.806 [0.025]; mean [SD] Brier score, 0.117 [0.007]).
CONCLUSIONS AND RELEVANCE: In this study, deep learning RNN models outperformed conventional LR models, suggesting that RNN models could be used to identify patients with HCV-related cirrhosis with a high risk of developing HCC for risk-based HCC outreach and surveillance strategies.",True,other,RNN
34756221,Exploiting complex medical data with interpretable deep learning for adverse drug event prediction,"A variety of deep learning architectures have been developed for the goal of predictive modelling and knowledge extraction from medical records. Several models have placed strong emphasis on temporal attention mechanisms and decay factors as a means to include highly temporally relevant information regarding the recency of medical event occurrence while facilitating medical code-level interpretability. In this study we utilise such models with a large Electronic Patient Record (EPR) data set consisting of diagnoses, medication, and clinical text data for the purpose of adverse drug event (ADE) prediction. The first contribution of this work is an empirical evaluation of two state-of-the-art medical-code based models in terms of objective performance metrics for ADE prediction on diagnosis and medication data. Secondly, as an extension of previous work, we augment an interpretable deep learning architecture to permit numerical risk and clinical text features and demonstrate how this approach yields improved predictive performance compared to the other baselines. Finally, we assess the importance of attention mechanisms in regards to their usefulness for medical code-level and text-level interpretability, which may facilitate novel insights pertaining to the nature of ADE occurrence within the health care domain.",True,other,convolutional neural network
32866415,Artificial Intelligence and Data Mining to Assess Lung Cancer Risk: Challenges and Opportunities,,True,other,GAN
32866413,Deep Learning Using Chest Radiographs to Identify High-Risk Smokers for Lung Cancer Screening Computed Tomography: Development and Validation of a Prediction Model,"BACKGROUND: Lung cancer screening with chest computed tomography (CT) reduces lung cancer death. Centers for Medicare & Medicaid Services (CMS) eligibility criteria for lung cancer screening with CT require detailed smoking information and miss many incident lung cancers. An automated deep-learning approach based on chest radiograph images may identify more smokers at high risk for lung cancer who could benefit from screening with CT.
OBJECTIVE: To develop and validate a convolutional neural network (CXR-LC) that predicts long-term incident lung cancer using data commonly available in the electronic medical record (EMR) (chest radiograph, age, sex, and whether currently smoking).
DESIGN: Risk prediction study.
SETTING: U.S. lung cancer screening trials.
PARTICIPANTS: The CXR-LC model was developed in the PLCO (Prostate, Lung, Colorectal, and Ovarian) Cancer Screening Trial (n = 41 856). The final CXR-LC model was validated in additional PLCO smokers (n = 5615, 12-year follow-up) and NLST (National Lung Screening Trial) heavy smokers (n = 5493, 6-year follow-up). Results are reported for validation data sets only.
MEASUREMENTS: Up to 12-year lung cancer incidence predicted by CXR-LC.
RESULTS: The CXR-LC model had better discrimination (area under the receiver-operating characteristic curve [AUC]) for incident lung cancer than CMS eligibility (PLCO AUC, 0.755 vs. 0.634; P &lt; 0.001). The CXR-LC model's performance was similar to that of PLCO<sub>M2012</sub>, a state-of-the-art risk score with 11 inputs, in both the PLCO data set (CXR-LC AUC of 0.755 vs. PLCO<sub>M2012</sub> AUC of 0.751) and the NLST data set (0.659 vs. 0.650). When compared in equal-sized screening populations, CXR-LC was more sensitive than CMS eligibility in the PLCO data set (74.9% vs. 63.8%; P = 0.012) and missed 30.7% fewer incident lung cancers. On decision curve analysis, CXR-LC had higher net benefit than CMS eligibility and similar benefit to PLCO<sub>M2012</sub>.
LIMITATION: Validation in lung cancer screening trials and not a clinical setting.
CONCLUSION: The CXR-LC model identified smokers at high risk for incident lung cancer, beyond CMS eligibility and using information commonly available in the EMR.
PRIMARY FUNDING SOURCE: None.",True,other,Not specified
32864315,Risk Assessment Program of Highly Pathogenic Avian Influenza with Deep Learning Algorithm,"OBJECTIVES: This study presents the development and validation of a risk assessment program of highly pathogenic avian influenza (HPAI). This program was developed by the Korean government (Animal and Plant Quarantine Agency) and a private corporation (Korea Telecom, KT), using a national database (Korean animal health integrated system, KAHIS).
METHODS: Our risk assessment program was developed using the multilayer perceptron method using R Language. HPAI outbreaks on 544 poultry farms (307 with H5N6, and 237 with H5N8) that had available visit records of livestock-related vehicles amongst the 812 HPAI outbreaks that were confirmed between January 2014 and June 2017 were involved in this study.
RESULTS: After 140,000 iterations without drop-out, a model with 3 hidden layers and 10 nodes per layer, were selected. The activation function of the model was hyperbolic tangent. Precision and recall of the test gave F1 measures of 0.41, 0.68 and 0.51, respectively, at validation. The predicted risk values were higher for the ""outbreak"" (average ± SD, 0.20 ± 0.31) than ""non-outbreak"" (0.18 ± 0.30) farms (p &lt; 0.001).
CONCLUSION: The risk assessment model developed was employed during the epidemics of 2016/2017 (pilot version) and 2017/2018 (complementary version). This risk assessment model enhanced risk management activities by enabling preemptive control measures to prevent the spread of diseases.",True,computer vision,Not specified
32858170,Sharpening the resolution on data matters: a brief roadmap for understanding deep learning for medical data,,True,other,GAN
32832047,Identifying COVID19 from Chest CT Images: A Deep Convolutional Neural Networks Based Approach,"Coronavirus Disease (COVID19) is a fast-spreading infectious disease that is currently causing a healthcare crisis around the world. Due to the current limitations of the reverse transcription-polymerase chain reaction (RT-PCR) based tests for detecting COVID19, recently radiology imaging based ideas have been proposed by various works. In this work, various Deep CNN based approaches are explored for detecting the presence of COVID19 from chest CT images. A decision fusion based approach is also proposed, which combines predictions from multiple individual models, to produce a final prediction. Experimental results show that the proposed decision fusion based approach is able to achieve above 86% results across all the performance metrics under consideration, with average AUROC and F1-Score being 0.883 and 0.867, respectively. The experimental observations suggest the potential applicability of such Deep CNN based approach in real diagnostic scenarios, which could be of very high utility in terms of achieving fast testing for COVID19.",True,both,recurrent neural network
32815519,Determination of disease severity in COVID-19 patients using deep learning in chest X-ray images,"PURPOSE: Chest X-ray plays a key role in diagnosis and management of COVID-19 patients and imaging features associated with clinical elements may assist with the development or validation of automated image analysis tools. We aimed to identify associations between clinical and radiographic features as well as to assess the feasibility of deep learning applied to chest X-rays in the setting of an acute COVID-19 outbreak.
METHODS: A retrospective study of X-rays, clinical, and laboratory data was performed from 48 SARS-CoV-2 RT-PCR positive patients (age 60±17 years, 15 women) between February 22 and March 6, 2020 from a tertiary care hospital in Milan, Italy. Sixty-five chest X-rays were reviewed by two radiologists for alveolar and interstitial opacities and classified by severity on a scale from 0 to 3. Clinical factors (age, symptoms, comorbidities) were investigated for association with opacity severity and also with placement of central line or endotracheal tube. Deep learning models were then trained for two tasks: lung segmentation and opacity detection. Imaging characteristics were compared to clinical datapoints using the unpaired student's t-test or Mann-Whitney U test. Cohen's kappa analysis was used to evaluate the concordance of deep learning to conventional radiologist interpretation.
RESULTS: Fifty-six percent of patients presented with alveolar opacities, 73% had interstitial opacities, and 23% had normal X-rays. The presence of alveolar or interstitial opacities was statistically correlated with age (P = 0.008) and comorbidities (P = 0.005). The extent of alveolar or interstitial opacities on baseline X-ray was significantly associated with the presence of endotracheal tube (P = 0.0008 and P = 0.049) or central line (P = 0.003 and P = 0.007). In comparison to human interpretation, the deep learning model achieved a kappa concordance of 0.51 for alveolar opacities and 0.71 for interstitial opacities.
CONCLUSION: Chest X-ray analysis in an acute COVID-19 outbreak showed that the severity of opacities was associated with advanced age, comorbidities, as well as acuity of care. Artificial intelligence tools based upon deep learning of COVID-19 chest X-rays are feasible in the acute outbreak setting.",True,other,Not specified
32774444,Research of Epidemic Big Data Based on Improved Deep Convolutional Neural Network,"In recent years, with the acceleration of the aging process and the aggravation of life pressure, the proportion of chronic epidemics has gradually increased. A large amount of medical data will be generated during the hospitalization of diabetics. It will have important practical significance and social value to discover potential medical laws and valuable information among medical data. In view of this, an improved deep convolutional neural network (""CNN+"" for short) algorithm was proposed to predict the changes of diabetes. Firstly, the bagging integrated classification algorithm was used instead of the output layer function of the deep CNN, which can help the improved deep CNN algorithm constructed for the data set of diabetic patients and improve the accuracy of classification. In this way, the ""CNN+"" algorithm can take the advantages of both the deep CNN and the bagging algorithm. On the one hand, it can extract the potential features of the data set by using the powerful feature extraction ability of deep CNN. On the other hand, the bagging integrated classification algorithm can be used for feature classification, so as to improve the classification accuracy and obtain better disease prediction effect to assist doctors in diagnosis and treatment. Experimental results show that compared with the traditional convolutional neural network and other classification algorithm, the ""CNN+"" model can get more reliable prediction results.",True,other,recurrent neural network
32763892,Dynamics and Development of the COVID-19 Epidemic in the United States: A Compartmental Model Enhanced With Deep Learning Techniques,"BACKGROUND: Compartmental models dominate epidemic modeling. Transmission parameters between compartments are typically estimated through stochastic parameterization processes that depends on detailed statistics of transmission characteristics, which are economically and resource-wise expensive to collect.
OBJECTIVE: We aim to apply deep learning techniques as a lower data dependency alternative to estimate transmission parameters of a customized compartmental model, for the purpose of simulating the dynamics of the US coronavirus disease (COVID-19) epidemic and projecting its further development.
METHODS: We constructed a compartmental model and developed a multistep deep learning methodology to estimate the model's transmission parameters. We then fed the estimated transmission parameters to the model to predict development of the US COVID-19 epidemic for 35 and 42 days. Epidemics are considered suppressed when the basic reproduction number (R<sub>0</sub>) is less than 1.
RESULTS: The deep learning-enhanced compartmental model predicts that R<sub>0</sub> will fall to &lt;1 around August 17-19, 2020, at which point the epidemic will effectively start to die out, and that the US ""infected"" population will peak around August 16-18, 2020, at 3,228,574 to 3,308,911 individual cases. The model also predicted that the number of accumulative confirmed cases will cross the 5 million mark around August 7, 2020.
CONCLUSIONS: Current compartmental models require stochastic parameterization to estimate the transmission parameters. These models' effectiveness depends upon detailed statistics on transmission characteristics. As an alternative, deep learning techniques are effective in estimating these stochastic parameters with greatly reduced dependency on data particularity.",True,other,convolutional neural network
32759979,Artificial intelligence assistance significantly improves Gleason grading of prostate biopsies by pathologists,"The Gleason score is the most important prognostic marker for prostate cancer patients, but it suffers from significant observer variability. Artificial intelligence (AI) systems based on deep learning can achieve pathologist-level performance at Gleason grading. However, the performance of such systems can degrade in the presence of artifacts, foreign tissue, or other anomalies. Pathologists integrating their expertise with feedback from an AI system could result in a synergy that outperforms both the individual pathologist and the system. Despite the hype around AI assistance, existing literature on this topic within the pathology domain is limited. We investigated the value of AI assistance for grading prostate biopsies. A panel of 14 observers graded 160 biopsies with and without AI assistance. Using AI, the agreement of the panel with an expert reference standard increased significantly (quadratically weighted Cohen's kappa, 0.799 vs. 0.872; p = 0.019). On an external validation set of 87 cases, the panel showed a significant increase in agreement with a panel of international experts in prostate pathology (quadratically weighted Cohen's kappa, 0.733 vs. 0.786; p = 0.003). In both experiments, on a group-level, AI-assisted pathologists outperformed the unassisted pathologists and the standalone AI system. Our results show the potential of AI systems for Gleason grading, but more importantly, show the benefits of pathologist-AI synergy.",True,other,Not specified
32752997,Mathematical models and deep learning for predicting the number of individuals reported to be infected with SARS-CoV-2,"We introduce a novel methodology for predicting the time evolution of the number of individuals in a given country reported to be infected with SARS-CoV-2. This methodology, which is based on the synergy of explicit mathematical formulae and deep learning networks, yields algorithms whose input is only the existing data in the given country of the accumulative number of individuals who are reported to be infected. The analytical formulae involve several constant parameters that were determined from the available data using an error-minimizing algorithm. The same data were also used for the training of a bidirectional long short-term memory network. We applied the above methodology to the epidemics in Italy, Spain, France, Germany, USA and Sweden. The significance of these results for evaluating the impact of easing the lockdown measures is discussed.",True,text mining,recurrent neural network
32750973,Introducing the GEV Activation Function for Highly Unbalanced Data to Develop COVID-19 Diagnostic Models,"Fast and accurate diagnosis is essential for the efficient and effective control of the COVID-19 pandemic that is currently disrupting the whole world. Despite the prevalence of the COVID-19 outbreak, relatively few diagnostic images are openly available to develop automatic diagnosis algorithms. Traditional deep learning methods often struggle when data is highly unbalanced with many cases in one class and only a few cases in another; new methods must be developed to overcome this challenge. We propose a novel activation function based on the generalized extreme value (GEV) distribution from extreme value theory, which improves performance over the traditional sigmoid activation function when one class significantly outweighs the other. We demonstrate the proposed activation function on a publicly available dataset and externally validate on a dataset consisting of 1,909 healthy chest X-rays and 84 COVID-19 X-rays. The proposed method achieves an improved area under the receiver operating characteristic (DeLong's p-value < 0.05) compared to the sigmoid activation. Our method is also demonstrated on a dataset of healthy and pneumonia vs. COVID-19 X-rays and a set of computerized tomography images, achieving improved sensitivity. The proposed GEV activation function significantly improves upon the previously used sigmoid activation for binary classification. This new paradigm is expected to play a significant role in the fight against COVID-19 and other diseases, with relatively few training cases available.",True,other,recurrent neural network
32730939,Deep learning of lumbar spine X-ray for osteopenia and osteoporosis screening: A multicenter retrospective cohort study,"Osteoporosis is a prevalent but underdiagnosed condition. As compared to dual-energy X-ray absorptiometry (DXA) measures, we aimed to develop a deep convolutional neural network (DCNN) model to classify osteopenia and osteoporosis with the use of lumbar spine X-ray images. Herein, we developed the DCNN models based on the training dataset, which comprising 1616 lumbar spine X-ray images from 808 postmenopausal women (aged 50 to 92 years). DXA-derived bone mineral density (BMD) measures were used as the reference standard. We categorized patients into three groups according to DXA BMD T-score: normal (T ≥ -1.0), osteopenia (-2.5 < T < -1.0), and osteoporosis (T ≤ -2.5). T-scores were calculated by using the BMD dataset of young Chinese female aged 20-40 years as a reference. A 3-class DCNN model was trained to classify normal BMD, osteoporosis, and osteopenia. Model performance was tested in a validation dataset (204 images from 102 patients) and two test datasets (396 images from 198 patients and 348 images from 147 patients respectively). Model performance was assessed by the receiver operating characteristic (ROC) curve analysis. The results showed that in the test dataset 1, the model diagnosing osteoporosis achieved an AUC of 0.767 (95% confidence interval [CI]: 0.701-0.824) with sensitivity of 73.7% (95% CI: 62.3-83.1), the model diagnosing osteopenia achieved an AUC of 0.787 (95% CI: 0.723-0.842) with sensitivity of 81.8% (95% CI: 67.3-91.8); In the test dataset 2, the model diagnosing osteoporosis yielded an AUC of 0.726 (95% CI: 0.646-0.796) with sensitivity of 68.4% (95% CI: 54.8-80.1), the model diagnosing osteopenia yielded an AUC of 0.810 (95% CI, 0.737-0.870) with sensitivity of 85.3% (95% CI, 68.9-95.0). Accordingly, a deep learning diagnostic network may have the potential in screening osteoporosis and osteopenia based on lumbar spine radiographs. However, further studies are necessary to verify and improve the diagnostic performance of DCNN models.",True,both,Not specified
32704420,"Introduction to Machine Learning, Neural Networks, and Deep Learning","PURPOSE: To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning.
METHODS: A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology.
RESULTS: A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background.
CONCLUSIONS: Artificial intelligence has a promising future in medicine; however, many challenges remain.
TRANSLATIONAL RELEVANCE: The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.",True,other,RNN
32703973,[Formula: see text]: deep learning-based radiomics for the time-to-event outcome prediction in lung cancer,"Hand-crafted radiomics has been used for developing models in order to predict time-to-event clinical outcomes in patients with lung cancer. Hand-crafted features, however, are pre-defined and extracted without taking the desired target into account. Furthermore, accurate segmentation of the tumor is required for development of a reliable predictive model, which may be objective and a time-consuming task. To address these drawbacks, we propose a deep learning-based radiomics model for the time-to-event outcome prediction, referred to as DRTOP that takes raw images as inputs, and calculates the image-based risk of death or recurrence, for each patient. Our experiments on an in-house dataset of 132 lung cancer patients show that the obtained image-based risks are significant predictors of the time-to-event outcomes. Computed Tomography (CT)-based features are predictors of the overall survival (OS), with the hazard ratio (HR) of 1.35, distant control (DC), with HR of 1.06, and local control (LC), with HR of 2.66. The Positron Emission Tomography (PET)-based features are predictors of OS and recurrence free survival (RFS), with hazard ratios of 1.67 and 1.18, respectively. The concordance indices of [Formula: see text], [Formula: see text], and [Formula: see text] for predicting the OS, DC, and RFS show that the deep learning-based radiomics model is as accurate or better in predicting predefined clinical outcomes compared to hand-crafted radiomics, with concordance indices of [Formula: see text], [Formula: see text], and [Formula: see text], for predicting the OS, DC, and RFS, respectively. Deep learning-based radiomics has the potential to offer complimentary predictive information in the personalized management of lung cancer patients.",True,other,Not specified
32701148,Development and Validation of a Deep Learning Algorithm for Gleason Grading of Prostate Cancer From Biopsy Specimens,"IMPORTANCE: For prostate cancer, Gleason grading of the biopsy specimen plays a pivotal role in determining case management. However, Gleason grading is associated with substantial interobserver variability, resulting in a need for decision support tools to improve the reproducibility of Gleason grading in routine clinical practice.
OBJECTIVE: To evaluate the ability of a deep learning system (DLS) to grade diagnostic prostate biopsy specimens.
DESIGN, SETTING, AND PARTICIPANTS: The DLS was evaluated using 752 deidentified digitized images of formalin-fixed paraffin-embedded prostate needle core biopsy specimens obtained from 3 institutions in the United States, including 1 institution not used for DLS development. To obtain the Gleason grade group (GG), each specimen was first reviewed by 2 expert urologic subspecialists from a multi-institutional panel of 6 individuals (years of experience: mean, 25 years; range, 18-34 years). A third subspecialist reviewed discordant cases to arrive at a majority opinion. To reduce diagnostic uncertainty, all subspecialists had access to an immunohistochemical-stained section and 3 histologic sections for every biopsied specimen. Their review was conducted from December 2018 to June 2019.
MAIN OUTCOMES AND MEASURES: The frequency of the exact agreement of the DLS with the majority opinion of the subspecialists in categorizing each tumor-containing specimen as 1 of 5 categories: nontumor, GG1, GG2, GG3, or GG4-5. For comparison, the rate of agreement of 19 general pathologists' opinions with the subspecialists' majority opinions was also evaluated.
RESULTS: For grading tumor-containing biopsy specimens in the validation set (n = 498), the rate of agreement with subspecialists was significantly higher for the DLS (71.7%; 95% CI, 67.9%-75.3%) than for general pathologists (58.0%; 95% CI, 54.5%-61.4%) (P < .001). In subanalyses of biopsy specimens from an external validation set (n = 322), the Gleason grading performance of the DLS remained similar. For distinguishing nontumor from tumor-containing biopsy specimens (n = 752), the rate of agreement with subspecialists was 94.3% (95% CI, 92.4%-95.9%) for the DLS and similar at 94.7% (95% CI, 92.8%-96.3%) for general pathologists (P = .58).
CONCLUSIONS AND RELEVANCE: In this study, the DLS showed higher proficiency than general pathologists at Gleason grading prostate needle core biopsy specimens and generalized to an independent institution. Future research is necessary to evaluate the potential utility of using the DLS as a decision support tool in clinical workflows and to improve the quality of prostate cancer grading for therapy decisions.",True,other,Not specified
32654489,Repurpose Open Data to Discover Therapeutics for COVID-19 Using Deep Learning,"There have been more than 2.2 million confirmed cases and over 120 000 deaths from the human coronavirus disease 2019 (COVID-19) pandemic, caused by the novel severe acute respiratory syndrome coronavirus (SARS-CoV-2), in the United States alone. However, there is currently a lack of proven effective medications against COVID-19. Drug repurposing offers a promising route for the development of prevention and treatment strategies for COVID-19. This study reports an integrative, network-based deep-learning methodology to identify repurposable drugs for COVID-19 (termed CoV-KGE). Specifically, we built a comprehensive knowledge graph that includes 15 million edges across 39 types of relationships connecting drugs, diseases, proteins/genes, pathways, and expression from a large scientific corpus of 24 million PubMed publications. Using Amazon's AWS computing resources and a network-based, deep-learning framework, we identified 41 repurposable drugs (including dexamethasone, indomethacin, niclosamide, and toremifene) whose therapeutic associations with COVID-19 were validated by transcriptomic and proteomics data in SARS-CoV-2-infected human cells and data from ongoing clinical trials. Whereas this study by no means recommends specific drugs, it demonstrates a powerful deep-learning methodology to prioritize existing drugs for further investigation, which holds the potential to accelerate therapeutic development for COVID-19.",True,other,Not specified
32635269,Ensemble Deep Learning for Cervix Image Selection toward Improving Reliability in Automated Cervical Precancer Screening,"Automated Visual Examination (AVE) is a deep learning algorithm that aims to improve the effectiveness of cervical precancer screening, particularly in low- and medium-resource regions. It was trained on data from a large longitudinal study conducted by the National Cancer Institute (NCI) and has been shown to accurately identify cervices with early stages of cervical neoplasia for clinical evaluation and treatment. The algorithm processes images of the uterine cervix taken with a digital camera and alerts the user if the woman is a candidate for further evaluation. This requires that the algorithm be presented with images of the cervix, which is the object of interest, of acceptable quality, i.e., in sharp focus, with good illumination, without shadows or other occlusions, and showing the entire squamo-columnar transformation zone. Our prior work has addressed some of these constraints to help discard images that do not meet these criteria. In this work, we present a novel algorithm that determines that the image contains the cervix to a sufficient extent. Non-cervix or other inadequate images could lead to suboptimal or wrong results. Manual removal of such images is labor intensive and time-consuming, particularly in working with large retrospective collections acquired with inadequate quality control. In this work, we present a novel ensemble deep learning method to identify cervix images and non-cervix images in a smartphone-acquired cervical image dataset. The ensemble method combined the assessment of three deep learning architectures, RetinaNet, Deep SVDD, and a customized CNN (Convolutional Neural Network), each using a different strategy to arrive at its decision, i.e., object detection, one-class classification, and binary classification. We examined the performance of each individual architecture and an ensemble of all three architectures. An average accuracy and F-1 score of 91.6% and 0.890, respectively, were achieved on a separate test dataset consisting of more than 30,000 smartphone-captured images.",True,both,Not specified
32634717,Application of Artificial Intelligence in COVID-19 drug repurposing,"BACKGROUND AND AIM: COVID-19 outbreak has created havoc and a quick cure for the disease will be a therapeutic medicine that has usage history in patients to resolve the current pandemic. With technological advancements in Artificial Intelligence (AI) coupled with increased computational power, the AI-empowered drug repurposing can prove beneficial in the COVID-19 scenario.
METHODS: The recent literature is studied and analyzed from various sources such as Scopus, Google Scholar, PubMed, and IEEE Xplore databases. The search terms used are 'COVID-19', ' AI ', and 'Drug Repurposing'.
RESULTS: AI is implemented in the field design through the generation of the learning-prediction model and performs a quick virtual screening to accurately display the output. With a drug-repositioning strategy, AI can quickly detect drugs that can fight against emerging diseases such as COVID-19. This technology has the potential to improve the drug discovery, planning, treatment, and reported outcomes of the COVID-19 patient, being an evidence-based medical tool.
CONCLUSIONS: Thus, there are chances that the application of the AI approach in drug discovery is feasible. With prior usage experiences in patients, few of the old drugs, if shown active against SARS-CoV-2, can be readily applied to treat the COVID-19 patients. With the collaboration of AI with pharmacology, the efficiency of drug repurposing can improve significantly.",True,other,Not specified
32617690,A deep learning approach to characterize 2019 coronavirus disease (COVID-19) pneumonia in chest CT images,"OBJECTIVES: To utilize a deep learning model for automatic detection of abnormalities in chest CT images from COVID-19 patients and compare its quantitative determination performance with radiological residents.
METHODS: A deep learning algorithm consisted of lesion detection, segmentation, and location was trained and validated in 14,435 participants with chest CT images and definite pathogen diagnosis. The algorithm was tested in a non-overlapping dataset of 96 confirmed COVID-19 patients in three hospitals across China during the outbreak. Quantitative detection performance of the model was compared with three radiological residents with two experienced radiologists' reading reports as reference standard by assessing the accuracy, sensitivity, specificity, and F1 score.
RESULTS: Of 96 patients, 88 had pneumonia lesions on CT images and 8 had no abnormities on CT images. For per-patient basis, the algorithm showed superior sensitivity of 1.00 (95% confidence interval (CI) 0.95, 1.00) and F1 score of 0.97 in detecting lesions from CT images of COVID-19 pneumonia patients. While for per-lung lobe basis, the algorithm achieved a sensitivity of 0.96 (95% CI 0.94, 0.98) and a slightly inferior F1 score of 0.86. The median volume of lesions calculated by algorithm was 40.10 cm3. An average running speed of 20.3 s ± 5.8 per case demonstrated the algorithm was much faster than the residents in assessing CT images (all p &lt; 0.017). The deep learning algorithm can also assist radiologists make quicker diagnosis (all p &lt; 0.0001) with superior diagnostic performance.
CONCLUSIONS: The algorithm showed excellent performance in detecting COVID-19 pneumonia on chest CT images compared with resident radiologists.
KEY POINTS: • The higher sensitivity of deep learning model in detecting COVID-19 pneumonia were found compared with radiological residents on a per-lobe and per-patient basis. • The deep learning model improves diagnosis efficiency by shortening processing time. • The deep learning model can automatically calculate the volume of the lesions and whole lung.",True,other,Not specified
32615586,Artificial Intelligence and Hypertension: Recent Advances and Future Outlook,"Prevention and treatment of hypertension (HTN) are a challenging public health problem. Recent evidence suggests that artificial intelligence (AI) has potential to be a promising tool for reducing the global burden of HTN, and furthering precision medicine related to cardiovascular (CV) diseases including HTN. Since AI can stimulate human thought processes and learning with complex algorithms and advanced computational power, AI can be applied to multimodal and big data, including genetics, epigenetics, proteomics, metabolomics, CV imaging, socioeconomic, behavioral, and environmental factors. AI demonstrates the ability to identify risk factors and phenotypes of HTN, predict the risk of incident HTN, diagnose HTN, estimate blood pressure (BP), develop novel cuffless methods for BP measurement, and comprehensively identify factors associated with treatment adherence and success. Moreover, AI has also been used to analyze data from major randomized controlled trials exploring different BP targets to uncover previously undescribed factors associated with CV outcomes. Therefore, AI-integrated HTN care has the potential to transform clinical practice by incorporating personalized prevention and treatment approaches, such as determining optimal and patient-specific BP goals, identifying the most effective antihypertensive medication regimen for an individual, and developing interventions targeting modifiable risk factors. Although the role of AI in HTN has been increasingly recognized over the past decade, it remains in its infancy, and future studies with big data analysis and N-of-1 study design are needed to further demonstrate the applicability of AI in HTN prevention and treatment.",True,other,RNN
32592447,Hypothesis-free deep survival learning applied to the tumour microenvironment in gastric cancer,"The biological complexity reflected in histology images requires advanced approaches for unbiased prognostication. Machine learning and particularly deep learning methods are increasingly applied in the field of digital pathology. In this study, we propose new ways to predict risk for cancer-specific death from digital images of immunohistochemically (IHC) stained tissue microarrays (TMAs). Specifically, we evaluated a cohort of 248 gastric cancer patients using convolutional neural networks (CNNs) in an end-to-end weakly supervised scheme independent of subjective pathologist input. To account for the time-to-event characteristic of the outcome data, we developed new survival models to guide the network training. In addition to the standard H&E staining, we investigated the prognostic value of a panel of immune cell markers (CD8, CD20, CD68) and a proliferation marker (Ki67). Our CNN-derived risk scores provided additional prognostic value when compared to the gold standard prognostic tool TNM stage. The CNN-derived risk scores were also shown to be superior when systematically compared to cell density measurements or a CNN score derived from binary 5-year survival classification, which ignores time-to-event. To better understand the underlying biological mechanisms, we qualitatively investigated risk heat maps for each marker which visualised the network output. We identified patterns of biological interest that were related to low risk of cancer-specific death such as the presence of B-cell predominated clusters and Ki67 positive sub-regions and showed that the corresponding risk scores had prognostic value in multivariate Cox regression analyses (Ki67&CD20 risks: hazard ratio (HR) = 1.47, 95% confidence interval (CI) = 1.15-1.89, p = 0.002; CD20&CD68 risks: HR = 1.33, 95% CI = 1.07-1.67, p = 0.009). Our study demonstrates the potential additional value that deep learning in combination with a panel of IHC markers can bring to the field of precision oncology.",True,other,recurrent neural network
32584382,Accuracy and Efficiency of Deep-Learning-Based Automation of Dual Stain Cytology in Cervical Cancer Screening,"BACKGROUND: With the advent of primary human papillomavirus testing followed by cytology for cervical cancer screening, visual interpretation of cytology slides remains the last subjective analysis step and suffers from low sensitivity and reproducibility.
METHODS: We developed a cloud-based whole-slide imaging platform with a deep-learning classifier for p16/Ki-67 dual-stained (DS) slides trained on biopsy-based gold standards. We compared it with conventional Pap and manual DS in 3 epidemiological studies of cervical and anal precancers from Kaiser Permanente Northern California and the University of Oklahoma comprising 4253 patients. All statistical tests were 2-sided.
RESULTS: In independent validation at Kaiser Permanente Northern California, artificial intelligence (AI)-based DS had lower positivity than cytology (P < .001) and manual DS (P < .001) with equal sensitivity and substantially higher specificity compared with both Pap (P < .001) and manual DS (P < .001), respectively. Compared with Pap, AI-based DS reduced referral to colposcopy by one-third (41.9% vs 60.1%, P < .001). At a higher cutoff, AI-based DS had similar performance to high-grade squamous intraepithelial lesions cytology, indicating a risk high enough to allow for immediate treatment. The classifier was robust, showing comparable performance in 2 cytology systems and in anal cytology.
CONCLUSIONS: Automated DS evaluation removes the remaining subjective component from cervical cancer screening and delivers consistent quality for providers and patients. Moving from Pap to automated DS substantially reduces the number of colposcopies and also achieves excellent performance in a simulated fully vaccinated population. Through cloud-based implementation, this approach is globally accessible. Our results demonstrate that AI not only provides automation and objectivity but also delivers a substantial benefit for women by reduction of unnecessary colposcopies.",True,other,Not specified
32574780,"Age-related Macular Degeneration: Nutrition, Genes and Deep Learning-The LXXVI Edward Jackson Memorial Lecture","PURPOSE: To evaluate the importance of nutritional supplements, dietary pattern, and genetic associations in age-related macular degeneration (AMD); and to discuss the technique of artificial intelligence/deep learning to potentially enhance research in detecting and classifying AMD.
DESIGN: Retrospective literature review.
METHODS: To review the studies of both prospective and retrospective (post hoc) analyses of nutrition, genetic variants, and deep learning in AMD in both the Age-Related Eye Disease Study (AREDS) and AREDS2.
RESULTS: In addition to demonstrating the beneficial effects of the AREDS and AREDS2 supplements of antioxidant vitamins and zinc (plus copper) for reducing the risk of progression to late AMD, these 2 studies also confirmed the importance of high adherence to Mediterranean diet in reducing progression of AMD in persons with varying severity of disease. In persons with the protective genetic alleles of complement factor H (CFH), the Mediterranean diet had further beneficial effect. However, despite the genetic association with AMD progression, prediction models found genetic information added little to the high predictive value of baseline severity of AMD for disease progression. The technique of deep learning, an arm of artificial intelligence, using color fundus photographs from AREDS/AREDS2 was superior in some cases and noninferior in others to clinical human grading (retinal specialists) and to the gold standard of the certified reading center graders.
CONCLUSIONS: Counseling individuals affected with AMD regarding the use of the AREDS2 supplements and the beneficial association of the Mediterranean diet is an important public health message. Although genetic testing is important in research, it is not recommended for prediction of disease or to guide therapies and/or dietary interventions in AMD. Techniques in deep learning hold great promise, but further prospective research is required to validate the use of this technique to provide improvement in accuracy and sensitivity/specificity in clinical research and medical management of patients with AMD.",True,other,Not specified
32573386,Prediction of Total Knee Replacement and Diagnosis of Osteoarthritis by Using Deep Learning on Knee Radiographs: Data from the Osteoarthritis Initiative,"Background The methods for assessing knee osteoarthritis (OA) do not provide enough comprehensive information to make robust and accurate outcome predictions. Purpose To develop a deep learning (DL) prediction model for risk of OA progression by using knee radiographs in patients who underwent total knee replacement (TKR) and matched control patients who did not undergo TKR. Materials and Methods In this retrospective analysis that used data from the OA Initiative, a DL model on knee radiographs was developed to predict both the likelihood of a patient undergoing TKR within 9 years and Kellgren-Lawrence (KL) grade. Study participants included a case-control matched subcohort between 45 and 79 years. Patients were matched to control patients according to age, sex, ethnicity, and body mass index. The proposed model used a transfer learning approach based on the ResNet34 architecture with sevenfold nested cross-validation. Receiver operating characteristic curve analysis and conditional logistic regression assessed model performance for predicting probability and risk of TKR compared with clinical observations and two binary outcome prediction models on the basis of radiographic readings: KL grade and OA Research Society International (OARSI) grade. Results Evaluated were 728 participants including 324 patients (mean age, 64 years ± 8 [standard deviation]; 222 women) and 324 control patients (mean age, 64 years ± 8; 222 women). The prediction model based on DL achieved an area under the receiver operating characteristic curve (AUC) of 0.87 (95% confidence interval [CI]: 0.85, 0.90), outperforming a baseline prediction model by using KL grade with an AUC of 0.74 (95% CI: 0.71, 0.77; P &lt; .001). The risk for TKR increased with probability that a person will undergo TKR from the DL model (odds ratio [OR], 7.7; 95% CI: 2.3, 25; P &lt; .001), KL grade (OR, 1.92; 95% CI: 1.17, 3.13; P = .009), and OARSI grade (OR, 1.20; 95% CI: 0.41, 3.50; P = .73). Conclusion The proposed deep learning model better predicted risk of total knee replacement in osteoarthritis than did binary outcome models by using standard grading systems. © RSNA, 2020 Online supplemental material is available for this article. See also the editorial by Richardson in this issue.",True,other,Not specified
32562732,"Optical techniques, computed tomography and deep learning role in the diagnosis of COVID-19 pandemic towards increasing the survival rate of vulnerable populations",• Severe lung complications can be explored using computed tomography during COVID-19 pandemic. • Ultra-low dose CT can enhance COVID-19 infected patients diagnostic capability. • Optically monitored CT along with deep learning is the best solution for diagnosis of COVID-19 during pandemic. • CT scans sensitivity (88 %) is preferable on clinical approach sensitivity (59 %) for COVID-19 suspected patients. • CT and Computer aided approaches helps the radiologist to make fast and accurate diagnosis during COVID-19 pandemic.,True,other,Not specified
32562722,Clinical-Grade Detection of Microsatellite Instability in Colorectal Tumors by Deep Learning,"BACKGROUND & AIMS: Microsatellite instability (MSI) and mismatch-repair deficiency (dMMR) in colorectal tumors are used to select treatment for patients. Deep learning can detect MSI and dMMR in tumor samples on routine histology slides faster and less expensively than molecular assays. However, clinical application of this technology requires high performance and multisite validation, which have not yet been performed.
METHODS: We collected H&E-stained slides and findings from molecular analyses for MSI and dMMR from 8836 colorectal tumors (of all stages) included in the MSIDETECT consortium study, from Germany, the Netherlands, the United Kingdom, and the United States. Specimens with dMMR were identified by immunohistochemistry analyses of tissue microarrays for loss of MLH1, MSH2, MSH6, and/or PMS2. Specimens with MSI were identified by genetic analyses. We trained a deep-learning detector to identify samples with MSI from these slides; performance was assessed by cross-validation (N = 6406 specimens) and validated in an external cohort (n = 771 specimens). Prespecified endpoints were area under the receiver operating characteristic (AUROC) curve and area under the precision-recall curve (AUPRC).
RESULTS: The deep-learning detector identified specimens with dMMR or MSI with a mean AUROC curve of 0.92 (lower bound, 0.91; upper bound, 0.93) and an AUPRC of 0.63 (range, 0.59-0.65), or 67% specificity and 95% sensitivity, in the cross-validation development cohort. In the validation cohort, the classifier identified samples with dMMR with an AUROC of 0.95 (range, 0.92-0.96) without image preprocessing and an AUROC of 0.96 (range, 0.93-0.98) after color normalization.
CONCLUSIONS: We developed a deep-learning system that detects colorectal cancer specimens with dMMR or MSI using H&E-stained slides; it detected tissues with dMMR with an AUROC of 0.96 in a large, international validation cohort. This system might be used for high-throughput, low-cost evaluation of colorectal tissue specimens.",True,other,Not specified
32529578,Modern machine-learning can support diagnostic differentiation of central and peripheral acute vestibular disorders,"BACKGROUND: Diagnostic classification of central vs. peripheral etiologies in acute vestibular disorders remains a challenge in the emergency setting. Novel machine-learning methods may help to support diagnostic decisions. In the current study, we tested the performance of standard and machine-learning approaches in the classification of consecutive patients with acute central or peripheral vestibular disorders.
METHODS: 40 Patients with vestibular stroke (19 with and 21 without acute vestibular syndrome (AVS), defined by the presence of spontaneous nystagmus) and 68 patients with peripheral AVS due to vestibular neuritis were recruited in the emergency department, in the context of the prospective EMVERT trial (EMergency VERTigo). All patients received a standardized neuro-otological examination including videooculography and posturography in the acute symptomatic stage and an MRI within 7 days after symptom onset. Diagnostic performance of state-of-the-art scores, such as HINTS (Head Impulse, gaze-evoked Nystagmus, Test of Skew) and ABCD2 (Age, Blood, Clinical features, Duration, Diabetes), for the differentiation of vestibular stroke vs. peripheral AVS was compared to various machine-learning approaches: (i) linear logistic regression (LR), (ii) non-linear random forest (RF), (iii) artificial neural network, and (iv) geometric deep learning (Single/MultiGMC). A prospective classification was simulated by ten-fold cross-validation. We analyzed whether machine-estimated feature importances correlate with clinical experience.
RESULTS: Machine-learning methods (e.g., MultiGMC) outperform univariate scores, such as HINTS or ABCD2, for differentiation of all vestibular strokes vs. peripheral AVS (MultiGMC area-under-the-curve (AUC): 0.96 vs. HINTS/ABCD2 AUC: 0.71/0.58). HINTS performed similarly to MultiGMC for vestibular stroke with AVS (AUC: 0.86), but more poorly for vestibular stroke without AVS (AUC: 0.54). Machine-learning models learn to put different weights on particular features, each of which is relevant from a clinical viewpoint. Established non-linear machine-learning methods like RF and linear methods like LR are less powerful classification models (AUC: 0.89 vs. 0.62).
CONCLUSIONS: Established clinical scores (such as HINTS) provide a valuable baseline assessment for stroke detection in acute vestibular syndromes. In addition, machine-learning methods may have the potential to increase sensitivity and selectivity in the establishment of a correct diagnosis.",True,other,Not specified
32518246,Deep Learning for Improved Risk Prediction in Surgical Outcomes,"The Norwood surgical procedure restores functional systemic circulation in neonatal patients with single ventricle congenital heart defects, but this complex procedure carries a high mortality rate. In this study we address the need to provide an accurate patient specific risk prediction for one-year postoperative mortality or cardiac transplantation and prolonged length of hospital stay with the purpose of assisting clinicians and patients' families in the preoperative decision making process. Currently available risk prediction models either do not provide patient specific risk factors or only predict in-hospital mortality rates. We apply machine learning models to predict and calculate individual patient risk for mortality and prolonged length of stay using the Pediatric Heart Network Single Ventricle Reconstruction trial dataset. We applied a Markov Chain Monte-Carlo simulation method to impute missing data and then fed the selected variables to multiple machine learning models. The individual risk of mortality or cardiac transplantation calculation produced by our deep neural network model demonstrated 89 ± 4% accuracy and 0.95 ± 0.02 area under the receiver operating characteristic curve (AUROC). The C-statistics results for prediction of prolonged length of stay were 85 ± 3% accuracy and AUROC 0.94 ± 0.04. These predictive models and calculator may help to inform clinical and organizational decision making.",True,other,Not specified
32498999,Early detection of sepsis utilizing deep learning on electronic health record event sequences,"BACKGROUND: The timeliness of detection of a sepsis incidence in progress is a crucial factor in the outcome for the patient. Machine learning models built from data in electronic health records can be used as an effective tool for improving this timeliness, but so far, the potential for clinical implementations has been largely limited to studies in intensive care units. This study will employ a richer data set that will expand the applicability of these models beyond intensive care units. Furthermore, we will circumvent several important limitations that have been found in the literature: (1) Model evaluations neglect the clinical consequences of a decision to start, or not start, an intervention for sepsis. (2) Models are evaluated shortly before sepsis onset without considering interventions already initiated. (3) Machine learning models are built on a restricted set of clinical parameters, which are not necessarily measured in all departments. (4) Model performance is limited by current knowledge of sepsis, as feature interactions and time dependencies are hard-coded into the model.
METHODS: In this study, we present a model to overcome these shortcomings using a deep learning approach on a diverse multicenter data set. We used retrospective data from multiple Danish hospitals over a seven-year period. Our sepsis detection system is constructed as a combination of a convolutional neural network and a long short-term memory network. We assess model quality by standard concepts of accuracy as well as clinical usefulness, and we suggest a retrospective assessment of interventions by looking at intravenous antibiotics and blood cultures preceding the prediction time.
RESULTS: Results show performance ranging from AUROC 0.856 (3 h before sepsis onset) to AUROC 0.756 (24 h before sepsis onset). Evaluating the clinical utility of the model, we find that a large proportion of septic patients did not receive antibiotic treatment or blood culture at the time of the sepsis prediction, and the model could, therefore, facilitate such interventions at an earlier point in time.
CONCLUSION: We present a deep learning system for early detection of sepsis that can learn characteristics of the key factors and interactions from the raw event sequence data itself, without relying on a labor-intensive feature extraction work. Our system outperforms baseline models, such as gradient boosting, which rely on specific data elements and therefore suffer from many missing values in our dataset.",True,other,Not specified
32498641,Automated MRI-Based Deep Learning Model for Detection of Alzheimer's Disease Process,"In the context of neuro-pathological disorders, neuroimaging has been widely accepted as a clinical tool for diagnosing patients with Alzheimer's disease (AD) and mild cognitive impairment (MCI). The advanced deep learning method, a novel brain imaging technique, was applied in this study to evaluate its contribution to improving the diagnostic accuracy of AD. Three-dimensional convolutional neural networks (3D-CNNs) were applied with magnetic resonance imaging (MRI) to execute binary and ternary disease classification models. The dataset from the Alzheimer's disease neuroimaging initiative (ADNI) was used to compare the deep learning performances across 3D-CNN, 3D-CNN-support vector machine (SVM) and two-dimensional (2D)-CNN models. The outcomes of accuracy with ternary classification for 2D-CNN, 3D-CNN and 3D-CNN-SVM were [Formula: see text]%, [Formula: see text]% and [Formula: see text]% respectively. The 3D-CNN-SVM yielded a ternary classification accuracy of 93.71%, 96.82% and 96.73% for NC, MCI and AD diagnoses, respectively. Furthermore, 3D-CNN-SVM showed the best performance for binary classification. Our study indicated that 'NC versus MCI' showed accuracy, sensitivity and specificity of 98.90%, 98.90% and 98.80%; 'NC versus AD' showed accuracy, sensitivity and specificity of 99.10%, 99.80% and 98.40%; and 'MCI versus AD' showed accuracy, sensitivity and specificity of 89.40%, 86.70% and 84.00%, respectively. This study clearly demonstrates that 3D-CNN-SVM yields better performance with MRI compared to currently utilized deep learning methods. In addition, 3D-CNN-SVM proved to be efficient without having to manually perform any prior feature extraction and is totally independent of the variability of imaging protocols and scanners. This suggests that it can potentially be exploited by untrained operators and extended to virtual patient imaging data. Furthermore, owing to the safety, noninvasiveness and nonirradiative properties of the MRI modality, 3D-CNN-SMV may serve as an effective screening option for AD in the general population. This study holds value in distinguishing AD and MCI subjects from normal controls and to improve value-based care of patients in clinical practice.",True,other,convolutional neural network
32497840,"Deep learning for predicting the occurrence of cardiopulmonary diseases in Nanjing, China","The efficiency of disease prevention and medical care service necessitated the prediction of incidence. However, predictive accuracy and power were largely impeded in a complex system including multiple environmental stressors and health outcome of which the occurrence might be episodic and irregular in time. In this study, we established four different deep learning (DL) models to capture inherent long-term dependencies in sequences and potential complex relationships among constituents by initiating with the original input into a representation at a higher abstract level. We collected 504,555 and 786,324 hospital outpatient visits of grouped categories of respiratory (RESD) and circulatory system disease (CCD), respectively, in Nanjing from 2013 through 2018. The matched observations in time-series that might pose risk to cardiopulmonary health involved conventional air pollutants concentrations and metrological conditions. The results showed that a well-trained network architecture built upon long short-term memory block and a working day enhancer achieved optimal performance by three quantitative statistics, i.e., 0.879 and 0.902 of Nash-Sutcliffe efficiency, 0.921% and 0.667% of percent bias, and 0.347 and 0.312 of root mean square error-standard deviation ratio for RESD and CCD hospital visits, respectively. We observed the non-linear association of nitrogen dioxide and ambient air temperature with CCD hospital visits. Furthermore, these two environmental stressors were identified as the most sensitive predictive variables, and exerted synergetic effect for two health outcomes, particular in winter season. Our study indicated that high-quality surveillance data of atmospheric environments could provide novel opportunity for anticipating temporal trend of cardiopulmonary health outcomes based on DL model.",True,other,recurrent neural network
32492161,Development and Validation of a Deep Learning Model for Non-Small Cell Lung Cancer Survival,"IMPORTANCE: There is a lack of studies exploring the performance of a deep learning survival neural network in non-small cell lung cancer (NSCLC).
OBJECTIVES: To compare the performances of DeepSurv, a deep learning survival neural network with a tumor, node, and metastasis staging system in the prediction of survival and test the reliability of individual treatment recommendations provided by the deep learning survival neural network.
DESIGN, SETTING, AND PARTICIPANTS: In this population-based cohort study, a deep learning-based algorithm was developed and validated using consecutive cases of newly diagnosed stages I to IV NSCLC between January 2010 and December 2015 in a Surveillance, Epidemiology, and End Results database. A total of 127 features, including patient characteristics, tumor stage, and treatment strategies, were assessed for analysis. The algorithm was externally validated on an independent test cohort, comprising 1182 patients with stage I to III NSCLC diagnosed between January 2009 and December 2013 in Shanghai Pulmonary Hospital. Analysis began January 2018 and ended June 2019.
MAIN OUTCOMES AND MEASURES: The deep learning survival neural network model was compared with the tumor, node, and metastasis staging system for lung cancer-specific survival. The C statistic was used to assess the performance of models. A user-friendly interface was provided to facilitate the survival predictions and treatment recommendations of the deep learning survival neural network model.
RESULTS: Of 17 322 patients with NSCLC included in the study, 13 361 (77.1%) were white and the median (interquartile range) age was 68 (61-74) years. The majority of tumors were stage I disease (10 273 [59.3%]) and adenocarcinoma (11 985 [69.2%]). The median (interquartile range) follow-up time was 24 (10-43) months. There were 3119 patients who had lung cancer-related death during the follow-up period. The deep learning survival neural network model showed more promising results in the prediction of lung cancer-specific survival than the tumor, node, and metastasis stage on the test data set (C statistic = 0.739 vs 0.706). The population who received the recommended treatments had superior survival rates than those who received treatments not recommended (hazard ratio, 2.99; 95% CI, 2.49-3.59; P < .001), which was verified by propensity score-matched groups. The deep learning survival neural network model visualization was realized by a user-friendly graphic interface.
CONCLUSIONS AND RELEVANCE: The deep learning survival neural network model shows potential benefits in prognostic evaluation and treatment recommendation with respect to lung cancer-specific survival. This novel analytical approach may provide reliable individual survival information and treatment recommendations.",True,other,Not specified
32492160,Prognosis and Treatment of Non-Small Cell Lung Cancer in the Age of Deep Learning,,True,other,GAN
32469924,Application of explainable ensemble artificial intelligence model to categorization of hemodialysis-patient and treatment using nationwide-real-world data in Japan,"BACKGROUND: Although dialysis patients are at a high risk of death, it is difficult for medical practitioners to simultaneously evaluate many inter-related risk factors. In this study, we evaluated the characteristics of hemodialysis patients using machine learning model, and its usefulness for screening hemodialysis patients at a high risk of one-year death using the nation-wide database of the Japanese Society for Dialysis Therapy.
MATERIALS AND METHODS: The patients were separated into two datasets (n = 39,930, 39,930, respectively). We categorized hemodialysis patients in Japan into new clusters generated by the K-means clustering method using the development dataset. The association between a cluster and the risk of death was evaluated using multivariate Cox proportional hazards models. Then, we developed an ensemble model composed of the clusters and support vector machine models in the model development phase, and compared the accuracy of the prediction of mortality between the machine learning models in the model validation phase.
RESULTS: Average age of the subjects was 65.7±12.2 years; 32.7% had diabetes mellitus. The five clusters clearly distinguished the groups on the basis of their characteristics: Cluster 1, young male, and chronic glomerulonephritis; Cluster 2, female, and chronic glomerulonephritis; Cluster 3, diabetes mellitus; Cluster 4, elderly and nephrosclerosis; Cluster 5, elderly and protein energy wasting. These clusters were associated with the risk of death; Cluster 5 compared with Cluster 1, hazard ratio 8.86 (95% CI 7.68, 10.21). The accuracy of the ensemble model for the prediction of 1-year death was 0.948 and higher than those of logistic regression model (0.938), support vector machine model (0.937), and deep learning model (0.936).
CONCLUSIONS: The clusters clearly categorized patient on their characteristics, and reflected their prognosis. Our real-world-data-based machine learning system is applicable to identifying high-risk hemodialysis patients in clinical settings, and has a strong potential to guide treatments and improve their prognosis.",True,other,Not specified
32467506,Automated Measurements of Muscle Mass Using Deep Learning Can Predict Clinical Outcomes in Patients With Liver Disease,"INTRODUCTION: There is increasing recognition of the central role of muscle mass in predicting clinical outcomes in patients with liver disease. Muscle size can be extracted from computed tomography (CT) scans, but clinical implementation will require increased automation. We hypothesize that we can achieve this by using artificial intelligence.
METHODS: Using deep convolutional neural networks, we trained an algorithm on the Reference Analytic Morphomics Population (n = 5,268) and validated the automated methodology in an external cohort of adult kidney donors with a noncontrast CT scan (n = 1,655). To test the clinical usefulness, we examined its ability to predict clinical outcomes in a prospectively followed cohort of patients with clinically diagnosed cirrhosis (n = 254).
RESULTS: Between the manual and automated methodologies, we found excellent inter-rater agreement with an intraclass correlation coefficient of 0.957 (confidence interval 0.953-0.961, P < 0.0001) in the adult kidney donor cohort. The calculated dice similarity coefficient was 0.932 ± 0.042, suggesting excellent spatial overlap between manual and automated methodologies. To assess the clinical usefulness, we examined its ability to predict clinical outcomes in a cirrhosis cohort and found that automated psoas muscle index was independently associated with mortality after adjusting for age, gender, and child's classification (P < 0.001).
DISCUSSION: We demonstrated that deep learning techniques can allow for automation of muscle measurements on clinical CT scans in a diseased cohort. These automated psoas size measurements were predictive of mortality in patients with cirrhosis showing proof of principal that this methodology may allow for wider implementation in the clinical arena.",True,other,Not specified
32445770,Multi-instance Deep Learning of Ultrasound Imaging Data for Pattern Classification of Congenital Abnormalities of the Kidney and Urinary Tract in Children,"OBJECTIVE: To reliably and quickly diagnose children with posterior urethral valves (PUV), we developed a multi-instance deep learning method to automate image analysis.
METHODS: We built a robust pattern classifier to distinguish 86 children with PUV from 71 children with mild unilateral hydronephrosis based on ultrasound images (3504 in sagittal view and 2558 in transverse view) obtained during routine clinical care.
RESULTS: The multi-instance deep learning classifier performed better than classifiers built on either single sagittal images or single transverse images. Particularly, the deep learning classifiers built on single images in the sagittal view and single images in the transverse view obtained area under the receiver operating characteristic curve (AUC) values of 0.796 ± 0.064 and 0.815 ± 0.071, respectively. AUC values of the multi-instance deep learning classifiers built on images in the sagittal and transverse views with mean pooling operation were 0.949 ± 0.035 and 0.954 ± 0.033, respectively. The multi-instance deep learning classifiers built on images in both the sagittal and transverse views with a mean pooling operation obtained an AUC of 0.961 ± 0.026 with a classification rate of 0.925 ± 0.060, specificity of 0.986 ± 0.032, and sensitivity of 0.873 ± 0.120, respectively. Discriminative regions of the kidney located using classification activation mapping demonstrated that the deep learning techniques could identify meaningful anatomical features from ultrasound images.
CONCLUSION: The multi-instance deep learning method provides an automatic and accurate means to extract informative features from ultrasound images and discriminate infants with PUV from male children with unilateral hydronephrosis.",True,other,recurrent neural network
32438586,Drug Resistance Prediction Using Deep Learning Techniques on HIV-1 Sequence Data,"The fast replication rate and lack of repair mechanisms of human immunodeficiency virus (HIV) contribute to its high mutation frequency, with some mutations resulting in the evolution of resistance to antiretroviral therapies (ART). As such, studying HIV drug resistance allows for real-time evaluation of evolutionary mechanisms. Characterizing the biological process of drug resistance is also critically important for sustained effectiveness of ART. Investigating the link between ""black box"" deep learning methods applied to this problem and evolutionary principles governing drug resistance has been overlooked to date. Here, we utilized publicly available HIV-1 sequence data and drug resistance assay results for 18 ART drugs to evaluate the performance of three architectures (multilayer perceptron, bidirectional recurrent neural network, and convolutional neural network) for drug resistance prediction, jointly with biological analysis. We identified convolutional neural networks as the best performing architecture and displayed a correspondence between the importance of biologically relevant features in the classifier and overall performance. Our results suggest that the high classification performance of deep learning models is indeed dependent on drug resistance mutations (DRMs). These models heavily weighted several features that are not known DRM locations, indicating the utility of model interpretability to address causal relationships in viral genotype-phenotype data.",True,other,Not specified
32429941,Uncovering the prognostic gene signatures for the improvement of risk stratification in cancers by using deep learning algorithm coupled with wavelet transform,"BACKGROUND: The aim of gene expression-based clinical modelling in tumorigenesis is not only to accurately predict the clinical endpoints, but also to reveal the genome characteristics for downstream analysis for the purpose of understanding the mechanisms of cancers. Most of the conventional machine learning methods involved a gene filtering step, in which tens of thousands of genes were firstly filtered based on the gene expression levels by a statistical method with an arbitrary cutoff. Although gene filtering procedure helps to reduce the feature dimension and avoid overfitting, there is a risk that some pathogenic genes important to the disease will be ignored.
RESULTS: In this study, we proposed a novel deep learning approach by combining a convolutional neural network with stationary wavelet transform (SWT-CNN) for stratifying cancer patients and predicting their clinical outcomes without gene filtering based on tumor genomic profiles. The proposed SWT-CNN overperformed the state-of-art algorithms, including support vector machine (SVM) and logistic regression (LR), and produced comparable prediction performance to random forest (RF). Furthermore, for all the cancer types, we firstly proposed a method to weight the genes with the scores, which took advantage of the representative features in the hidden layer of convolutional neural network, and then selected the prognostic genes for the Cox proportional-hazards regression. The results showed that risk stratifications can be effectively improved by using the identified prognostic genes as feature, indicating that the representative features generated by SWT-CNN can well correlate the genes with prognostic risk in cancers and be helpful for selecting the prognostic gene signatures.
CONCLUSIONS: Our results indicated that gene expression-based SWT-CNN model can be an excellent tool for stratifying the prognostic risk for cancer patients. In addition, the representative features of SWT-CNN were validated to be useful for evaluating the importance of the genes in the risk stratification and can be further used to identify the prognostic gene signatures.",True,other,Not specified
32393754,Deep learning enables accurate clustering with batch effect removal in single-cell RNA-seq analysis,"Single-cell RNA sequencing (scRNA-seq) can characterize cell types and states through unsupervised clustering, but the ever increasing number of cells and batch effect impose computational challenges. We present DESC, an unsupervised deep embedding algorithm that clusters scRNA-seq data by iteratively optimizing a clustering objective function. Through iterative self-learning, DESC gradually removes batch effects, as long as technical differences across batches are smaller than true biological variations. As a soft clustering algorithm, cluster assignment probabilities from DESC are biologically interpretable and can reveal both discrete and pseudotemporal structure of cells. Comprehensive evaluations show that DESC offers a proper balance of clustering accuracy and stability, has a small footprint on memory, does not explicitly require batch information for batch effect removal, and can utilize GPU when available. As the scale of single-cell studies continues to grow, we believe DESC will offer a valuable tool for biomedical researchers to disentangle complex cellular heterogeneity.",True,other,convolutional neural network
32383681,Deep Learning Neural Networks to Predict Serious Complications After Bariatric Surgery: Analysis of Scandinavian Obesity Surgery Registry Data,"BACKGROUND: Obesity is one of today's most visible public health problems worldwide. Although modern bariatric surgery is ostensibly considered safe, serious complications and mortality still occur in some patients.
OBJECTIVE: This study aimed to explore whether serious postoperative complications of bariatric surgery recorded in a national quality registry can be predicted preoperatively using deep learning methods.
METHODS: Patients who were registered in the Scandinavian Obesity Surgery Registry (SOReg) between 2010 and 2015 were included in this study. The patients who underwent a bariatric procedure between 2010 and 2014 were used as training data, and those who underwent a bariatric procedure in 2015 were used as test data. Postoperative complications were graded according to the Clavien-Dindo classification, and complications requiring intervention under general anesthesia or resulting in organ failure or death were considered serious. Three supervised deep learning neural networks were applied and compared in our study: multilayer perceptron (MLP), convolutional neural network (CNN), and recurrent neural network (RNN). The synthetic minority oversampling technique (SMOTE) was used to artificially augment the patients with serious complications. The performances of the neural networks were evaluated using accuracy, sensitivity, specificity, Matthews correlation coefficient, and area under the receiver operating characteristic curve.
RESULTS: In total, 37,811 and 6250 patients were used as the training data and test data, with incidence rates of serious complication of 3.2% (1220/37,811) and 3.0% (188/6250), respectively. When trained using the SMOTE data, the MLP appeared to have a desirable performance, with an area under curve (AUC) of 0.84 (95% CI 0.83-0.85). However, its performance was low for the test data, with an AUC of 0.54 (95% CI 0.53-0.55). The performance of CNN was similar to that of MLP. It generated AUCs of 0.79 (95% CI 0.78-0.80) and 0.57 (95% CI 0.59-0.61) for the SMOTE data and test data, respectively. Compared with the MLP and CNN, the RNN showed worse performance, with AUCs of 0.65 (95% CI 0.64-0.66) and 0.55 (95% CI 0.53-0.57) for the SMOTE data and test data, respectively.
CONCLUSIONS: MLP and CNN showed improved, but limited, ability for predicting the postoperative serious complications after bariatric surgery in the Scandinavian Obesity Surgery Registry data. However, the overfitting issue is still apparent and needs to be overcome by incorporating intra- and perioperative information.",True,other,Not specified
32357201,Development and validation of an interpretable deep learning framework for Alzheimer's disease classification,"Alzheimer's disease is the primary cause of dementia worldwide, with an increasing morbidity burden that may outstrip diagnosis and management capacity as the population ages. Current methods integrate patient history, neuropsychological testing and MRI to identify likely cases, yet effective practices remain variably applied and lacking in sensitivity and specificity. Here we report an interpretable deep learning strategy that delineates unique Alzheimer's disease signatures from multimodal inputs of MRI, age, gender, and Mini-Mental State Examination score. Our framework linked a fully convolutional network, which constructs high resolution maps of disease probability from local brain structure to a multilayer perceptron and generates precise, intuitive visualization of individual Alzheimer's disease risk en route to accurate diagnosis. The model was trained using clinically diagnosed Alzheimer's disease and cognitively normal subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset (n = 417) and validated on three independent cohorts: the Australian Imaging, Biomarker and Lifestyle Flagship Study of Ageing (AIBL) (n = 382), the Framingham Heart Study (n = 102), and the National Alzheimer's Coordinating Center (NACC) (n = 582). Performance of the model that used the multimodal inputs was consistent across datasets, with mean area under curve values of 0.996, 0.974, 0.876 and 0.954 for the ADNI study, AIBL, Framingham Heart Study and NACC datasets, respectively. Moreover, our approach exceeded the diagnostic performance of a multi-institutional team of practicing neurologists (n = 11), and high-risk cerebral regions predicted by the model closely tracked post-mortem histopathological findings. This framework provides a clinically adaptable strategy for using routinely available imaging techniques such as MRI to generate nuanced neuroimaging signatures for Alzheimer's disease diagnosis, as well as a generalizable approach for linking deep learning to pathophysiological processes in human disease.",True,other,recurrent neural network
32332844,Prediction of Intracranial Aneurysm Risk using Machine Learning,"An efficient method for identifying subjects at high risk of an intracranial aneurysm (IA) is warranted to provide adequate radiological screening guidelines and effectively allocate medical resources. We developed a model for pre-diagnosis IA prediction using a national claims database and health examination records. Data from the National Health Screening Program in Korea were utilized as input for several machine learning algorithms: logistic regression (LR), random forest (RF), scalable tree boosting system (XGB), and deep neural networks (DNN). Algorithm performance was evaluated through the area under the receiver operating characteristic curve (AUROC) using different test data from that employed for model training. Five risk groups were classified in ascending order of risk using model prediction probabilities. Incidence rate ratios between the lowest- and highest-risk groups were then compared. The XGB model produced the best IA risk prediction (AUROC of 0.765) and predicted the lowest IA incidence (3.20) in the lowest-risk group, whereas the RF model predicted the highest IA incidence (161.34) in the highest-risk group. The incidence rate ratios between the lowest- and highest-risk groups were 49.85, 35.85, 34.90, and 30.26 for the XGB, LR, DNN, and RF models, respectively. The developed prediction model can aid future IA screening strategies.",True,other,Not specified
32326730,Assessing the Accuracy of a Deep Learning Method to Risk Stratify Indeterminate Pulmonary Nodules,"Rationale: The management of indeterminate pulmonary nodules (IPNs) remains challenging, resulting in invasive procedures and delays in diagnosis and treatment. Strategies to decrease the rate of unnecessary invasive procedures and optimize surveillance regimens are needed.Objectives: To develop and validate a deep learning method to improve the management of IPNs.Methods: A Lung Cancer Prediction Convolutional Neural Network model was trained using computed tomography images of IPNs from the National Lung Screening Trial, internally validated, and externally tested on cohorts from two academic institutions.Measurements and Main Results: The areas under the receiver operating characteristic curve in the external validation cohorts were 83.5% (95% confidence interval [CI], 75.4-90.7%) and 91.9% (95% CI, 88.7-94.7%), compared with 78.1% (95% CI, 68.7-86.4%) and 81.9 (95% CI, 76.1-87.1%), respectively, for a commonly used clinical risk model for incidental nodules. Using 5% and 65% malignancy thresholds defining low- and high-risk categories, the overall net reclassifications in the validation cohorts for cancers and benign nodules compared with the Mayo model were 0.34 (Vanderbilt) and 0.30 (Oxford) as a rule-in test, and 0.33 (Vanderbilt) and 0.58 (Oxford) as a rule-out test. Compared with traditional risk prediction models, the Lung Cancer Prediction Convolutional Neural Network was associated with improved accuracy in predicting the likelihood of disease at each threshold of management and in our external validation cohorts.Conclusions: This study demonstrates that this deep learning algorithm can correctly reclassify IPNs into low- or high-risk categories in more than a third of cancers and benign nodules when compared with conventional risk models, potentially reducing the number of unnecessary invasive procedures and delays in diagnosis.",True,text mining,RNN
32289490,Evaluation of artificial intelligence-based telemedicine screening for retinopathy of prematurity,"Retrospective evaluation of a deep learning-derived retinopathy of prematurity (ROP) vascular severity score in an operational ROP screening program demonstrated high diagnostic performance for detection of type 2 or worse ROP. To our knowledge, this is the first report in the literature that evaluated the use of artificial intelligence for ROP screening and represents a proof of concept. With further prospective validation, this technology might improve the accuracy, efficiency, and objectivity of diagnosis and facilitate earlier detection of disease progression in patients with potentially blinding ROP.",True,other,recurrent neural network
32253623,"Machine Learning in Dermatology: Current Applications, Opportunities, and Limitations","Machine learning (ML) has the potential to improve the dermatologist's practice from diagnosis to personalized treatment. Recent advancements in access to large datasets (e.g., electronic medical records, image databases, omics), faster computing, and cheaper data storage have encouraged the development of ML algorithms with human-like intelligence in dermatology. This article is an overview of the basics of ML, current applications of ML, and potential limitations and considerations for further development of ML. We have identified five current areas of applications for ML in dermatology: (1) disease classification using clinical images; (2) disease classification using dermatopathology images; (3) assessment of skin diseases using mobile applications and personal monitoring devices; (4) facilitating large-scale epidemiology research; and (5) precision medicine. The purpose of this review is to provide a guide for dermatologists to help demystify the fundamentals of ML and its wide range of applications in order to better evaluate its potential opportunities and challenges.",True,other,Not specified
34594479,DEEP NETWORK-BASED FEATURE SELECTION FOR IMAGING GENETICS: APPLICATION TO IDENTIFYING BIOMARKERS FOR PARKINSON'S DISEASE,"Imaging genetics is a methodology for discovering associations between imaging and genetic variables. Many studies adopted sparse models such as sparse canonical correlation analysis (SCCA) for imaging genetics. These methods are limited to modeling the linear imaging genetics relationship and cannot capture the non-linear high-level relationship between the explored variables. Deep learning approaches are underexplored in imaging genetics, compared to their great successes in many other biomedical domains such as image segmentation and disease classification. In this work, we proposed a deep learning model to select genetic features that can explain the imaging features well. Our empirical study on simulated and real datasets demonstrated that our method outperformed the widely used SCCA method and was able to select important genetic features in a robust fashion. These promising results indicate our deep learning model has the potential to reveal new biomarkers to improve mechanistic understanding of the studied brain disorders.",True,other,Not specified
32222370,Association of Cardiovascular Mortality and Deep Learning-Funduscopic Atherosclerosis Score derived from Retinal Fundus Images,"PURPOSE: The prediction of atherosclerosis using retinal fundus images and deep learning has not been shown possible. The purpose of this study was to develop a deep learning model which predicted atherosclerosis by using retinal fundus images and to verify its clinical implications by conducting a retrospective cohort analysis.
DESIGN: Retrospective cohort study.
METHODS: The database at the Health Promotion Center of Seoul National University Hospital (HPC-SNUH) was used. The deep learning model was trained using 15,408 images to predict carotid artery atherosclerosis, which was named the deep-learning funduscopic atherosclerosis score (DL-FAS). A retrospective cohort was constructed of participants 30-80 years old who had completed elective health examinations at HPC-SNUH. Using DL-FAS as the main exposure, participants were followed for the primary outcome of death due to CVD until Dec. 31, 2017.
RESULTS: For predicting carotid artery atherosclerosis among subjects, the model achieved an area under receiver operating curve (AUROC) and area under the precision-recall curve (AUPRC), accuracy, sensitivity, specificity, positive and negative predictive values of 0.713, 0.569, 0.583, 0.891, 0.404, 0.465, and 0.865 respectively. The cohort consisted of 32,227 participants, 78 cardiovascular disease (CVD) deaths, and 7.6-year median follow-up visits. Those with DL-FAS greater than 0.66 had an increased risk of CVD deaths compared to those with DL-FAS <0.33 (hazard ratio: 8.33; 95% confidence interval [CI], 3.16-24.7). Risk association was significant among intermediate and high Framingham risk score (FRS) subgroups. The DL-FAS improved the concordance by 0.0266 (95% CI, 0.0043-0.0489) over the FRS-only model. The relative integrated discrimination index was 20.45% and net reclassification index was 29.5%.
CONCLUSIONS: A deep learning model was developed which could predict atherosclerosis from retinal fundus images. The resulting DL-FAS was an independent predictor of CVD deaths when adjusted for FRS and added predictive value over FRS.",True,other,recurrent neural network
32207605,NormAE: Deep Adversarial Learning Model to Remove Batch Effects in Liquid Chromatography Mass Spectrometry-Based Metabolomics Data,"Untargeted metabolomics based on liquid chromatography-mass spectrometry is affected by nonlinear batch effects, which cover up biological effects, result in nonreproducibility, and are difficult to be calibrate. In this study, we propose a novel deep learning model, called Normalization Autoencoder (NormAE), which is based on nonlinear autoencoders (AEs) and adversarial learning. An additional classifier and ranker are trained to provide adversarial regularization during the training of the AE model, latent representations are extracted by the encoder, and then the decoder reconstructs the data without batch effects. The NormAE method was tested on two real metabolomics data sets. After calibration by NormAE, the quality control samples (QCs) for both data sets gathered most closely in a PCA score plot (average distances decreased from 56.550 and 52.476 to 7.383 and 14.075, respectively) and obtained the highest average correlation coefficients (from 0.873 and 0.907 to 0.997 for both). Additionally, NormAE significantly improved biomarker discovery (median number of differential peaks increased from 322 and 466 to 1140 and 1622, respectively). NormAE was compared with four commonly used batch effect removal methods. The results demonstrated that using NormAE produces the best calibration results.",True,other,autoencoder
32204950,Evaluation of Machine Learning Algorithms for Predicting Readmission After Acute Myocardial Infarction Using Routinely Collected Clinical Data,"BACKGROUND: The ability to predict readmission accurately after hospitalization for acute myocardial infarction (AMI) is limited in current statistical models. Machine-learning (ML) methods have shown improved predictive ability in various clinical contexts, but their utility in predicting readmission after hospitalization for AMI is unknown.
METHODS: Using detailed clinical information collected from patients hospitalized with AMI, we evaluated 6 ML algorithms (logistic regression, naïve Bayes, support vector machines, random forest, gradient boosting, and deep neural networks) to predict readmission within 30 days and 1 year of discharge. A nested cross-validation approach was used to develop and test models. We used C-statistics to compare discriminatory capacity, whereas the Brier score was used to indicate overall model performance. Model calibration was assessed using calibration plots.
RESULTS: The 30-day readmission rate was 16.3%, whereas the 1-year readmission rate was 45.1%. For 30-day readmission, the discriminative ability for the ML models was modest (C-statistic 0.641; 95% confidence interval (CI), 0.621-0.662 for gradient boosting) and did not outperform previously reported methods. For 1-year readmission, different ML models showed moderate performance, with C-statistics around 0.72. Despite modest discriminatory capabilities, the observed readmission rates were markedly higher in the tenth decile of predicted risk compared with the first decile of predicted risk for both 30-day and 1-year readmission.
CONCLUSIONS: Despite including detailed clinical information and evaluating various ML methods, these models did not have better discriminatory ability to predict readmission outcomes compared with previously reported methods.",True,other,RNN
32197912,A Deep Learning Model for Segmentation of Geographic Atrophy to Study Its Long-Term Natural History,"PURPOSE: To develop and validate a deep learning model for the automatic segmentation of geographic atrophy (GA) using color fundus images (CFIs) and its application to study the growth rate of GA.
DESIGN: Prospective, multicenter, natural history study with up to 15 years of follow-up.
PARTICIPANTS: Four hundred nine CFIs of 238 eyes with GA from the Rotterdam Study (RS) and Blue Mountain Eye Study (BMES) for model development, and 3589 CFIs of 376 eyes from the Age-Related Eye Disease Study (AREDS) for analysis of GA growth rate.
METHODS: A deep learning model based on an ensemble of encoder-decoder architectures was implemented and optimized for the segmentation of GA in CFIs. Four experienced graders delineated, in consensus, GA in CFIs from the RS and BMES. These manual delineations were used to evaluate the segmentation model using 5-fold cross-validation. The model was applied further to CFIs from the AREDS to study the growth rate of GA. Linear regression analysis was used to study associations between structural biomarkers at baseline and the GA growth rate. A general estimate of the progression of GA area over time was made by combining growth rates of all eyes with GA from the AREDS set.
MAIN OUTCOME MEASURES: Automatically segmented GA and GA growth rate.
RESULTS: The model obtained an average Dice coefficient of 0.72±0.26 on the BMES and RS set while comparing the automatically segmented GA area with the graders' manual delineations. An intraclass correlation coefficient of 0.83 was reached between the automatically estimated GA area and the graders' consensus measures. Nine automatically calculated structural biomarkers (area, filled area, convex area, convex solidity, eccentricity, roundness, foveal involvement, perimeter, and circularity) were significantly associated with growth rate. Combining all growth rates indicated that GA area grows quadratically up to an area of approximately 12 mm2, after which growth rate stabilizes or decreases.
CONCLUSIONS: The deep learning model allowed for fully automatic and robust segmentation of GA on CFIs. These segmentations can be used to extract structural characteristics of GA that predict its growth rate.",True,other,Not specified
32183709,A deep learning-based framework for lung cancer survival analysis with biomarker interpretation,"BACKGROUND: Lung cancer is the leading cause of cancer-related deaths in both men and women in the United States, and it has a much lower five-year survival rate than many other cancers. Accurate survival analysis is urgently needed for better disease diagnosis and treatment management.
RESULTS: In this work, we propose a survival analysis system that takes advantage of recently emerging deep learning techniques. The proposed system consists of three major components. 1) The first component is an end-to-end cellular feature learning module using a deep neural network with global average pooling. The learned cellular representations encode high-level biologically relevant information without requiring individual cell segmentation, which is aggregated into patient-level feature vectors by using a locality-constrained linear coding (LLC)-based bag of words (BoW) encoding algorithm. 2) The second component is a Cox proportional hazards model with an elastic net penalty for robust feature selection and survival analysis. 3) The third commponent is a biomarker interpretation module that can help localize the image regions that contribute to the survival model's decision. Extensive experiments show that the proposed survival model has excellent predictive power for a public (i.e., The Cancer Genome Atlas) lung cancer dataset in terms of two commonly used metrics: log-rank test (p-value) of the Kaplan-Meier estimate and concordance index (c-index).
CONCLUSIONS: In this work, we have proposed a segmentation-free survival analysis system that takes advantage of the recently emerging deep learning framework and well-studied survival analysis methods such as the Cox proportional hazards model. In addition, we provide an approach to visualize the discovered biomarkers, which can serve as concrete evidence supporting the survival model's decision.",True,other,Not specified
32161279,Privacy-preserving distributed learning of radiomics to predict overall survival and HPV status in head and neck cancer,"A major challenge in radiomics is assembling data from multiple centers. Sharing data between hospitals is restricted by legal and ethical regulations. Distributed learning is a technique, enabling training models on multicenter data without data leaving the hospitals (""privacy-preserving"" distributed learning). This study tested feasibility of distributed learning of radiomics data for prediction of two year overall survival and HPV status in head and neck cancer (HNC) patients. Pretreatment CT images were collected from 1174 HNC patients in 6 different cohorts. 981 radiomic features were extracted using Z-Rad software implementation. Hierarchical clustering was performed to preselect features. Classification was done using logistic regression. In the validation dataset, the receiver operating characteristics (ROC) were compared between the models trained in the centralized and distributed manner. No difference in ROC was observed with respect to feature selection. The logistic regression coefficients were identical between the methods (absolute difference &lt;10-7). In comparison of the full workflow (feature selection and classification), no significant difference in ROC was found between centralized and distributed models for both studied endpoints (DeLong p &gt; 0.05). In conclusion, both feature selection and classification are feasible in a distributed manner using radiomics data, which opens new possibility for training more reliable radiomics models.",True,other,RNN
32161041,Prediction of prognosis in patients with tetralogy of Fallot based on deep learning imaging analysis,"OBJECTIVE: To assess the utility of machine learning algorithms for automatically estimating prognosis in patients with repaired tetralogy of Fallot (ToF) using cardiac magnetic resonance (CMR).
METHODS: We included 372 patients with ToF who had undergone CMR imaging as part of a nationwide prospective study. Cine loops were retrieved and subjected to automatic deep learning (DL)-based image analysis, trained on independent, local CMR data, to derive measures of cardiac dimensions and function. This information was combined with established clinical parameters and ECG markers of prognosis.
RESULTS: Over a median follow-up period of 10 years, 23 patients experienced an endpoint of death/aborted cardiac arrest or documented ventricular tachycardia (defined as >3 documented consecutive ventricular beats). On univariate Cox analysis, various DL parameters, including right atrial median area (HR 1.11/cm², p=0.003) and right ventricular long-axis strain (HR 0.80/%, p=0.009) emerged as significant predictors of outcome. DL parameters were related to adverse outcome independently of left and right ventricular ejection fraction and peak oxygen uptake (p<0.05 for all). A composite score of enlarged right atrial area and depressed right ventricular longitudinal function identified a ToF subgroup at significantly increased risk of adverse outcome (HR 2.1/unit, p=0.007).
CONCLUSIONS: We present data on the utility of machine learning algorithms trained on external imaging datasets to automatically estimate prognosis in patients with ToF. Due to the automated analysis process these two-dimensional-based algorithms may serve as surrogates for labour-intensive manually attained imaging parameters in patients with ToF.",True,other,Not specified
32118012,Artificial Intelligence in Medicine: Today and Tomorrow,"Artificial intelligence-powered medical technologies are rapidly evolving into applicable solutions for clinical practice. Deep learning algorithms can deal with increasing amounts of data provided by wearables, smartphones, and other mobile monitoring sensors in different areas of medicine. Currently, only very specific settings in clinical practice benefit from the application of artificial intelligence, such as the detection of atrial fibrillation, epilepsy seizures, and hypoglycemia, or the diagnosis of disease based on histopathological examination or medical imaging. The implementation of augmented medicine is long-awaited by patients because it allows for a greater autonomy and a more personalized treatment, however, it is met with resistance from physicians which were not prepared for such an evolution of clinical practice. This phenomenon also creates the need to validate these modern tools with traditional clinical trials, debate the educational upgrade of the medical curriculum in light of digital medicine as well as ethical consideration of the ongoing connected monitoring. The aim of this paper is to discuss recent scientific literature and provide a perspective on the benefits, future opportunities and risks of established artificial intelligence applications in clinical practice on physicians, healthcare institutions, medical education, and bioethics.",True,other,RNN
32093974,Artificial Intelligence in Emergency Medicine: Surmountable Barriers With Revolutionary Potential,,True,other,GAN
32049304,Application of Basic Epidemiologic Principles and Electronic Health Records in a Deep Learning Prediction Model,,True,other,GAN
32019699,Beyond Performance Metrics: Automatic Deep Learning Retinal OCT Analysis Reproduces Clinical Trial Outcome,"PURPOSE: To validate the efficacy of a fully automatic, deep learning-based segmentation algorithm beyond conventional performance metrics by measuring the primary outcome of a clinical trial for macular telangiectasia type 2 (MacTel2).
DESIGN: Evaluation of diagnostic test or technology.
PARTICIPANTS: A total of 92 eyes from 62 participants with MacTel2 from a phase 2 clinical trial (NCT01949324) randomized to 1 of 2 treatment groups METHODS: The ellipsoid zone (EZ) defect areas were measured on spectral domain OCT images of each eye at 2 time points (baseline and month 24) by a fully automatic, deep learning-based segmentation algorithm. The change in EZ defect area from baseline to month 24 was calculated and analyzed according to the clinical trial protocol.
MAIN OUTCOME MEASURE: Difference in the change in EZ defect area from baseline to month 24 between the 2 treatment groups.
RESULTS: The difference in the change in EZ defect area from baseline to month 24 between the 2 treatment groups measured by the fully automatic segmentation algorithm was 0.072±0.035 mm2 (P = 0.021). This was comparable to the outcome of the clinical trial using semiautomatic measurements by expert readers, 0.065±0.033 mm2 (P = 0.025).
CONCLUSIONS: The fully automatic segmentation algorithm was as accurate as semiautomatic expert segmentation to assess EZ defect areas and was able to reliably reproduce the statistically significant primary outcome measure of the clinical trial. This approach, to validate the performance of an automatic segmentation algorithm on the primary clinical trial end point, provides a robust gauge of its clinical applicability.",True,both,Not specified
32019148,Geometric Deep Lean Learning: Deep Learning in Industry 4.0 Cyber-Physical Complex Networks,"In the near future, value streams associated with Industry 4.0 will be formed by interconnected cyber-physical elements forming complex networks that generate huge amounts of data in real time. The success or failure of industry leaders interested in the continuous improvement of lean management systems in this context is determined by their ability to recognize behavioral patterns in these big data structured within non-Euclidean domains, such as these dynamic sociotechnical complex networks. We assume that artificial intelligence in general and deep learning in particular may be able to help find useful patterns of behavior in 4.0 industrial environments in the lean management of cyber-physical systems. However, although these technologies have meant a paradigm shift in the resolution of complex problems in the past, the traditional methods of deep learning, focused on image or video analysis, both with regular structures, are not able to help in this specific field. This is why this work focuses on proposing geometric deep lean learning, a mathematical methodology that describes deep-lean-learning operations such as convolution and pooling on cyber-physical Industry 4.0 graphs. Geometric deep lean learning is expected to positively support sustainable organizational growth because customers and suppliers ought to be able to reach new levels of transparency and traceability on the quality and efficiency of processes that generate new business for both, hence generating new products, services, and cooperation opportunities in a cyber-physical environment.",True,other,recurrent neural network
32013791,Development and Validation of a Multitask Deep Learning Model for Severity Grading of Hip Osteoarthritis Features on Radiographs,"Background A multitask deep learning model might be useful in large epidemiologic studies wherein detailed structural assessment of osteoarthritis still relies on expert radiologists' readings. The potential of such a model in clinical routine should be investigated. Purpose To develop a multitask deep learning model for grading radiographic hip osteoarthritis features on radiographs and compare its performance to that of attending-level radiologists. Materials and Methods This retrospective study analyzed hip joints seen on weight-bearing anterior-posterior pelvic radiographs from participants in the Osteoarthritis Initiative (OAI). Participants were recruited from February 2004 to May 2006 for baseline measurements, and follow-up was performed 48 months later. Femoral osteophytes (FOs), acetabular osteophytes (AOs), and joint-space narrowing (JSN) were graded as absent, mild, moderate, or severe according to the Osteoarthritis Research Society International atlas. Subchondral sclerosis and subchondral cysts were graded as present or absent. The participants were split at 80% (n = 3494), 10% (n = 437), and 10% (n = 437) by using split-sample validation into training, validation, and testing sets, respectively. The multitask neural network was based on DenseNet-161, a shared convolutional features extractor trained with multitask loss function. Model performance was evaluated in the internal test set from the OAI and in an external test set by using temporal and geographic validation consisting of routine clinical radiographs. Results A total of 4368 participants (mean age, 61.0 years ± 9.2 [standard deviation]; 2538 women) were evaluated (15 364 hip joints on 7738 weight-bearing anterior-posterior pelvic radiographs). The accuracy of the model for assessing these five features was 86.7% (1333 of 1538) for FOs, 69.9% (1075 of 1538) for AOs, 81.7% (1257 of 1538) for JSN, 95.8% (1473 of 1538) for subchondral sclerosis, and 97.6% (1501 of 1538) for subchondral cysts in the internal test set, and 82.7% (86 of 104) for FOS, 65.4% (68 of 104) for AOs, 80.8% (84 of 104) for JSN, 88.5% (92 of 104) for subchondral sclerosis, and 91.3% (95 of 104) for subchondral cysts in the external test set. Conclusion A multitask deep learning model is a feasible approach to reliably assess radiographic features of hip osteoarthritis. © RSNA, 2020 Online supplemental material is available for this article.",True,other,Not specified
32012148,DeepWAS: Multivariate genotype-phenotype associations by directly integrating regulatory information using deep learning,"Genome-wide association studies (GWAS) identify genetic variants associated with traits or diseases. GWAS never directly link variants to regulatory mechanisms. Instead, the functional annotation of variants is typically inferred by post hoc analyses. A specific class of deep learning-based methods allows for the prediction of regulatory effects per variant on several cell type-specific chromatin features. We here describe ""DeepWAS"", a new approach that integrates these regulatory effect predictions of single variants into a multivariate GWAS setting. Thereby, single variants associated with a trait or disease are directly coupled to their impact on a chromatin feature in a cell type. Up to 61 regulatory SNPs, called dSNPs, were associated with multiple sclerosis (MS, 4,888 cases and 10,395 controls), major depressive disorder (MDD, 1,475 cases and 2,144 controls), and height (5,974 individuals). These variants were mainly non-coding and reached at least nominal significance in classical GWAS. The prediction accuracy was higher for DeepWAS than for classical GWAS models for 91% of the genome-wide significant, MS-specific dSNPs. DSNPs were enriched in public or cohort-matched expression and methylation quantitative trait loci and we demonstrated the potential of DeepWAS to generate testable functional hypotheses based on genotype data alone. DeepWAS is available at https://github.com/cellmapslab/DeepWAS.",True,other,Not specified
32007170,Deep learning for prediction of colorectal cancer outcome: a discovery and validation study,"BACKGROUND: Improved markers of prognosis are needed to stratify patients with early-stage colorectal cancer to refine selection of adjuvant therapy. The aim of the present study was to develop a biomarker of patient outcome after primary colorectal cancer resection by directly analysing scanned conventional haematoxylin and eosin stained sections using deep learning.
METHODS: More than 12 000 000 image tiles from patients with a distinctly good or poor disease outcome from four cohorts were used to train a total of ten convolutional neural networks, purpose-built for classifying supersized heterogeneous images. A prognostic biomarker integrating the ten networks was determined using patients with a non-distinct outcome. The marker was tested on 920 patients with slides prepared in the UK, and then independently validated according to a predefined protocol in 1122 patients treated with single-agent capecitabine using slides prepared in Norway. All cohorts included only patients with resectable tumours, and a formalin-fixed, paraffin-embedded tumour tissue block available for analysis. The primary outcome was cancer-specific survival.
FINDINGS: 828 patients from four cohorts had a distinct outcome and were used as a training cohort to obtain clear ground truth. 1645 patients had a non-distinct outcome and were used for tuning. The biomarker provided a hazard ratio for poor versus good prognosis of 3·84 (95% CI 2·72-5·43; p<0·0001) in the primary analysis of the validation cohort, and 3·04 (2·07-4·47; p<0·0001) after adjusting for established prognostic markers significant in univariable analyses of the same cohort, which were pN stage, pT stage, lymphatic invasion, and venous vascular invasion.
INTERPRETATION: A clinically useful prognostic marker was developed using deep learning allied to digital scanning of conventional haematoxylin and eosin stained tumour tissue sections. The assay has been extensively evaluated in large, independent patient populations, correlates with and outperforms established molecular and morphological prognostic markers, and gives consistent results across tumour and nodal stage. The biomarker stratified stage II and III patients into sufficiently distinct prognostic groups that potentially could be used to guide selection of adjuvant treatment by avoiding therapy in very low risk groups and identifying patients who would benefit from more intensive treatment regimes.
FUNDING: The Research Council of Norway.",True,other,recurrent neural network
31943495,Top 10 Reviewer Critiques of Radiology Artificial Intelligence (AI) Articles: Qualitative Thematic Analysis of Reviewer Critiques of Machine Learning/Deep Learning Manuscripts Submitted to JMRI,"BACKGROUND: Classical machine learning (ML) and deep learning (DL) articles have rapidly captured the attention of the radiology research community and comprise an increasing proportion of articles submitted to JMRI, of variable reporting and methodological quality.
PURPOSE: To identify the most frequent reviewer critiques of classical ML and DL articles submitted to JMRI.
STUDY TYPE: Qualitative thematic analysis.
POPULATION: In all, 1396 manuscript journal articles submitted to JMRI for consideration in 2018, with thematic analysis performed of reviewer critiques of 38 artificial intelligence (AI) articles, comprised of 24 ML and 14 DL articles, from January 9, 2018 to June 2, 2018.
FIELD STRENGTH/SEQUENCE: N/A.
ASSESSMENT: After identifying and sampling ML and DL articles, and collecting all reviews, qualitative thematic analysis was performed to identify major and minor themes of reviewer critiques.
STATISTICAL TESTS: Descriptive statistics provided of article characteristics, and thematic review of major and minor themes.
RESULTS: Thirty-eight articles were sampled for thematic review: 24 (63.2%) focused on classical ML and 14 (36.8%) on DL. The overall acceptance rate of classical ML/DL articles was 28.9%, similar to the overall 2017-2019 acceptance rate of 23.1-28.1%. These articles resulted in 72 reviews analyzed, yielding a total 713 critiques that underwent formal thematic analysis consensus encoding. Ten major themes of critiques were identified, with 1-Lack of Information as the most frequent, comprising 268 (37.6%) of all critiques. Frequent minor themes of critiques concerning ML/DL-specific recommendations included performing basic clinical statistics such as to ensure similarity of training and test groups (N = 26), emphasizing strong clinical Gold Standards for the basis of training labels (N = 19), and ensuring strong radiological relevance of the topic and task performed (N = 16).
DATA CONCLUSION: Standardized reporting of ML and DL methods could help address nearly one-third of all reviewer critiques made.
LEVEL OF EVIDENCE: 4 Technical Efficacy Stage: 1 J. Magn. Reson. Imaging 2020;52:248-254.",True,other,LSTM
31926745,Training and Validation of Deep Neural Networks for the Prediction of 90-Day Post-Liver Transplant Mortality Using UNOS Registry Data,"Prediction models of post-liver transplant mortality are crucial so that donor organs are not allocated to recipients with unreasonably high probabilities of mortality. Machine learning algorithms, particularly deep neural networks (DNNs), can often achieve higher predictive performance than conventional models. In this study, we trained a DNN to predict 90-day post-transplant mortality using preoperative variables and compared the performance to that of the Survival Outcomes Following Liver Transplantation (SOFT) and Balance of Risk (BAR) scores, using United Network of Organ Sharing data on adult patients who received a deceased donor liver transplant between 2005 and 2015 (n = 57,544). The DNN was trained using 202 features, and the best DNN's architecture consisted of 5 hidden layers with 110 neurons each. The area under the receiver operating characteristics curve (AUC) of the best DNN model was 0.703 (95% CI: 0.682-0.726) as compared to 0.655 (95% CI: 0.633-0.678) and 0.688 (95% CI: 0.667-0.711) for the BAR score and SOFT score, respectively. In conclusion, despite the complexity of DNN, it did not achieve a significantly higher discriminative performance than the SOFT score. Future risk models will likely benefit from the inclusion of other data sources, including high-resolution clinical features for which DNNs are particularly apt to outperform conventional statistical methods.",True,other,Not specified
31911545,Multifactorial Deep Learning Reveals Pan-Cancer Genomic Tumor Clusters with Distinct Immunogenomic Landscape and Response to Immunotherapy,"PURPOSE: Tumor genomic features have been of particular interest because of their potential impact on the tumor immune microenvironment and response to immunotherapy. Due to the substantial heterogeneity, an integrative approach incorporating diverse molecular features is needed to characterize immunologic features underlying primary resistance to immunotherapy and for the establishment of novel predictive biomarkers.
EXPERIMENTAL DESIGN: We developed a pan-cancer deep machine learning model integrating tumor mutation burden, microsatellite instability, and somatic copy-number alterations to classify tumors of different types into different genomic clusters, and assessed the immune microenvironment in each genomic cluster and the association of each genomic cluster with response to immunotherapy.
RESULTS: Our model grouped 8,646 tumors of 29 cancer types from The Cancer Genome Atlas into four genomic clusters. Analysis of RNA-sequencing data revealed distinct immune microenvironment in tumors of each genomic class. Furthermore, applying this model to tumors from two melanoma immunotherapy clinical cohorts demonstrated that patients with melanoma of different genomic classes achieved different benefit from immunotherapy. Interestingly, tumors in cluster 4 demonstrated a cold immune microenvironment and lack of benefit from immunotherapy despite high microsatellite instability burden.
CONCLUSIONS: Our study provides a proof for principle that deep learning modeling may have the potential to discover intrinsic statistical cross-modality correlations of multifactorial input data to dissect the molecular mechanisms underlying primary resistance to immunotherapy, which likely involves multiple factors from both the tumor and host at different molecular levels.",True,other,Not specified
31893285,Multi-instance Deep Learning with Graph Convolutional Neural Networks for Diagnosis of Kidney Diseases Using Ultrasound Imaging,"Ultrasound imaging (US) is commonly used in nephrology for diagnostic studies of the kidneys and lower urinary tract. However, it remains challenging to automate the disease diagnosis based on clinical 2D US images since they provide partial anatomic information of the kidney and the 2D images of the same kidney may have heterogeneous appearance. To overcome this challenge, we develop a novel multi-instance deep learning method to build a robust classifier by treating multiple 2D US images of each individual subject as multiple instances of one bag. Particularly, we adopt convolutional neural networks (CNNs) to learn instance-level features from 2D US kidney images and graph convolutional networks (GCNs) to further optimize the instance-level features by exploring potential correlation among instances of the same bag. We also adopt a gated attention-based MIL pooling to learn bag-level features using full-connected neural networks (FCNs). Finally, we integrate both instance-level and bag-level supervision to further improve the bag-level classification accuracy. Ablation studies and comparison results have demonstrated that our method could accurately diagnose kidney diseases using ultrasound imaging, with better performance than alternative state-of-the-art multi-instance deep learning methods.",True,other,convolutional neural network
31879529,Point-of-care cervical cancer screening using deep learning-based microholography,"Most deaths (80%) from cervical cancer occur in regions lacking adequate screening infrastructures or ready access to them. In contrast, most developed countries now embrace human papillomavirus (HPV) analyses as standalone screening; this transition threatens to further widen the resource gap. Methods: We describe the development of a DNA-focused digital microholography platform for point-of-care HPV screening, with automated readouts driven by customized deep-learning algorithms. In the presence of high-risk HPV 16 or 18 DNA, microbeads were designed to bind the DNA targets and form microbead dimers. The resulting holographic signature of the microbeads was recorded and analyzed. Results: The HPV DNA assay showed excellent sensitivity (down to a single cell) and specificity (100% concordance) in detecting HPV 16 and 18 DNA from cell lines. Our deep learning approach was 120-folder faster than the traditional reconstruction method and completed the analysis in &lt; 2 min using a single CPU. In a blinded clinical study using patient cervical brushings, we successfully benchmarked our platform's performance to an FDA-approved HPV assay. Conclusions: Reliable and decentralized HPV testing will facilitate cataloguing the high-risk HPV landscape in underserved populations, revealing HPV coverage gaps in existing vaccination strategies and informing future iterations.",True,other,Not specified
31873197,Artificial intelligence approaches to improve kidney care,"Artificial intelligence is increasingly being used to improve diagnosis and prognostication for acute and chronic kidney diseases. Studies published in 2019 relied on a variety of available data sources towards this objective, including electronic health records, intraoperative physiological signals, kidney ultrasound imaging, and digitized biopsy specimens.",True,other,RNN
31865908,Interpretable deep neural network for cancer survival analysis by integrating genomic and clinical data,"BACKGROUND: Understanding the complex biological mechanisms of cancer patient survival using genomic and clinical data is vital, not only to develop new treatments for patients, but also to improve survival prediction. However, highly nonlinear and high-dimension, low-sample size (HDLSS) data cause computational challenges to applying conventional survival analysis.
RESULTS: We propose a novel biologically interpretable pathway-based sparse deep neural network, named Cox-PASNet, which integrates high-dimensional gene expression data and clinical data on a simple neural network architecture for survival analysis. Cox-PASNet is biologically interpretable where nodes in the neural network correspond to biological genes and pathways, while capturing the nonlinear and hierarchical effects of biological pathways associated with cancer patient survival. We also propose a heuristic optimization solution to train Cox-PASNet with HDLSS data. Cox-PASNet was intensively evaluated by comparing the predictive performance of current state-of-the-art methods on glioblastoma multiforme (GBM) and ovarian serous cystadenocarcinoma (OV) cancer. In the experiments, Cox-PASNet showed out-performance, compared to the benchmarking methods. Moreover, the neural network architecture of Cox-PASNet was biologically interpreted, and several significant prognostic factors of genes and biological pathways were identified.
CONCLUSIONS: Cox-PASNet models biological mechanisms in the neural network by incorporating biological pathway databases and sparse coding. The neural network of Cox-PASNet can identify nonlinear and hierarchical associations of genomic and clinical data to cancer patient survival. The open-source code of Cox-PASNet in PyTorch implemented for training, evaluation, and model interpretation is available at: https://github.com/DataX-JieHao/Cox-PASNet.",True,other,recurrent neural network
31859569,Predicting Influenza A Tropism with End-to-End Learning of Deep Networks,"The type of host that a virus can infect, referred to as host specificity or tropism, influences infectivity and thus is important for disease diagnosis, epidemic response, and prevention. Advances in DNA sequencing technology have enabled rapid metagenomic analyses of viruses, but the prediction of virus phenotype from genome sequences is an active area of research. As such, automatic prediction of host tropism from analysis of genomic information is of considerable utility. Previous research has applied machine learning methods to accomplish this task, although deep learning (particularly deep convolutional neural network, CNN) techniques have not yet been applied. These techniques have the ability to learn how to recognize critical hierarchical structures within the genome in a data-driven manner. We designed deep CNN models to identify host tropism for human and avian influenza A viruses based on protein sequences and performed a detailed analysis of the results. Our findings show that deep CNN techniques work as well as existing approaches (with 99% mean accuracy on the binary prediction task) while performing end-to-end learning of the prediction model (without the need to specify handcrafted features). The findings also show that these models, combined with standard principal component analysis, can be used to quantify and visualize viral strain similarity.",True,other,recurrent neural network
31857325,Deep Transfer Learning and Radiomics Feature Prediction of Survival of Patients with High-Grade Gliomas,"BACKGROUND AND PURPOSE: Patient survival in high-grade glioma remains poor, despite the recent developments in cancer treatment. As new chemo-, targeted molecular, and immune therapies emerge and show promising results in clinical trials, image-based methods for early prediction of treatment response are needed. Deep learning models that incorporate radiomics features promise to extract information from brain MR imaging that correlates with response and prognosis. We report initial production of a combined deep learning and radiomics model to predict overall survival in a clinically heterogeneous cohort of patients with high-grade gliomas.
MATERIALS AND METHODS: Fifty patients with high-grade gliomas from our hospital and 128 patients with high-grade glioma from The Cancer Genome Atlas were included. For each patient, we calculated 348 hand-crafted radiomics features and 8192 deep features generated by a pretrained convolutional neural network. We then applied feature selection and Elastic Net-Cox modeling to differentiate patients into long- and short-term survivors.
RESULTS: In the 50 patients with high-grade gliomas from our institution, the combined feature analysis framework classified the patients into long- and short-term survivor groups with a log-rank test P value &lt; .001. In the 128 patients from The Cancer Genome Atlas, the framework classified patients into long- and short-term survivors with a log-rank test P value of .014. For the mixed cohort of 50 patients from our institution and 58 patients from The Cancer Genome Atlas, it yielded a log-rank test P value of .035.
CONCLUSIONS: A deep learning model combining deep and radiomics features can dichotomize patients with high-grade gliomas into long- and short-term survivors.",True,other,Not specified
31856342,Diagnostic performance of a deep learning convolutional neural network in the differentiation of combined naevi and melanomas,"BACKGROUND: Deep learning convolutional neural networks (CNN) may assist physicians in the diagnosis of melanoma. The capacity of a CNN to differentiate melanomas from combined naevi, the latter representing well-known melanoma simulators, has not been investigated.
OBJECTIVE: To assess the diagnostic performance of a CNN when used to differentiate melanomas from combined naevi in comparison with dermatologists.
METHODS: In this study, a CNN with regulatory approval for the European market (Moleanalyzer-Pro, FotoFinder Systems GmbH, Bad Birnbach, Germany) was used. We attained a dichotomous classification (benign, malignant) in dermoscopic images of 36 combined naevi and 36 melanomas with a mean Breslow thickness of 1.3 mm. Primary outcome measures were the CNN's sensitivity, specificity and the diagnostic odds ratio (DOR) in comparison with 11 dermatologists with different levels of experience.
RESULTS: The CNN revealed a sensitivity, specificity and DOR of 97.1% (95% CI [82.7-99.6]), 78.8% (95% CI [62.8-89.1.3]) and 34 (95% CI [4.8-239]), respectively. Dermatologists showed a lower mean sensitivity, specificity and DOR of 90.6% (95% CI [84.1-94.7]; P = 0.092), 71.0% (95% CI [62.6-78.1]; P = 0.256) and 24 (95% CI [11.6-48.4]; P = 0.1114). Under the assumption that dermatologists use the CNN to verify their (initial) melanoma diagnosis, dermatologists achieve an increased specificity of 90.3% (95% CI [79.8-95.6]) at an almost unchanged sensitivity. The largest benefit was observed in 'beginners', who performed worst without CNN verification (DOR = 12) but best with CNN verification (DOR = 98).
CONCLUSION: The tested CNN more accurately classified combined naevi and melanomas in comparison with trained dermatologists. Their diagnostic performance could be improved if the CNN was used to confirm/overrule an initial melanoma diagnosis. Application of a CNN may therefore be of benefit to clinicians.",True,other,CNN
31856141,Re: A Call for Deep-learning Healthcare,,True,other,GAN
31853543,"Machine learning to predict the long-term risk of myocardial infarction and cardiac death based on clinical risk, coronary calcium, and epicardial adipose tissue: a prospective study","AIMS: Our aim was to evaluate the performance of machine learning (ML), integrating clinical parameters with coronary artery calcium (CAC), and automated epicardial adipose tissue (EAT) quantification, for the prediction of long-term risk of myocardial infarction (MI) and cardiac death in asymptomatic subjects.
METHODS AND RESULTS: Our study included 1912 asymptomatic subjects [1117 (58.4%) male, age: 55.8 ± 9.1 years] from the prospective EISNER trial with long-term follow-up after CAC scoring. EAT volume and density were quantified using a fully automated deep learning method. ML extreme gradient boosting was trained using clinical co-variates, plasma lipid panel measurements, risk factors, CAC, aortic calcium, and automated EAT measures, and validated using repeated 10-fold cross validation. During mean follow-up of 14.5 ± 2 years, 76 events of MI and/or cardiac death occurred. ML obtained a significantly higher AUC than atherosclerotic cardiovascular disease (ASCVD) risk and CAC score for predicting events (ML: 0.82; ASCVD: 0.77; CAC: 0.77, P < 0.05 for all). Subjects with a higher ML score (by Youden's index) had high hazard of suffering events (HR: 10.38, P < 0.001); the relationships persisted in multivariable analysis including ASCVD-risk and CAC measures (HR: 2.94, P = 0.005). Age, ASCVD-risk, and CAC were prognostically important for both genders. Systolic blood pressure was more important than cholesterol in women, and the opposite in men.
CONCLUSIONS: In this prospective study, machine learning used to integrate clinical and quantitative imaging-based variables significantly improves prediction of MI and cardiac death compared with standard clinical risk assessment. Following further validation, such a personalized paradigm could potentially be used to improve cardiovascular risk assessment.",True,other,Not specified
31851954,A novel deep learning model using dosimetric and clinical information for grade 4 radiotherapy-induced lymphopenia prediction,"Radiotherapy-induced lymphopenia has increasingly been shown to reduce cancer survivorship. We developed a novel hybrid deep learning model to efficiently integrate an entire set of dosimetric parameters of a radiation treatment plan with a patient's pre- and mid-treatment information to improve the prediction of grade 4 radiotherapy-induced lymphopenia. We proposed a two-input channel hybrid deep learning model to process dosimetric information using a stacked bi-directional long-short term memory structure and non-dosimetric information using a multilayer perceptron structure independently before integrating the dosimetric and non-dosimetric information for final prediction. The model was trained from 505 patients and tested in 216 patients. We compared our model with other popular predictive models, including logistic regression (with and without elastic-net regularization) random forest, support vector machines, and artificial neural network. Our hybrid deep learning model out-performed other predictive models in various evaluation metrics. It achieved the highest area under the curve at 0.831, accuracy at 0.769, F1 score at 0.631, precision at 0.670, and recall at 0.610. The hybrid deep learning model also demonstrated robustness in exploiting the value of dosimetric parameters in predictive modeling. We demonstrated that our hybrid deep learning model with a two-input channel structure, which addressed the sequential and inter-correlated nature of dosimetric parameters, could potentially improve the prediction of radiotherapy-induced lymphopenia. Our proposed deep learning framework is flexible and transferable to other related radiotherapy-induced toxicities.",True,other,Not specified
31840093,Eliminating biasing signals in lung cancer images for prognosis predictions with deep learning,"Deep learning has shown remarkable results for image analysis and is expected to aid individual treatment decisions in health care. Treatment recommendations are predictions with an inherently causal interpretation. To use deep learning for these applications in the setting of observational data, deep learning methods must be made compatible with the required causal assumptions. We present a scenario with real-world medical images (CT-scans of lung cancer) and simulated outcome data. Through the data simulation scheme, the images contain two distinct factors of variation that are associated with survival, but represent a collider (tumor size) and a prognostic factor (tumor heterogeneity), respectively. When a deep network would use all the information available in the image to predict survival, it would condition on the collider and thereby introduce bias in the estimation of the treatment effect. We show that when this collider can be quantified, unbiased individual prognosis predictions are attainable with deep learning. This is achieved by (1) setting a dual task for the network to predict both the outcome and the collider and (2) enforcing a form of linear independence of the activation distributions of the last layer. Our method provides an example of combining deep learning and structural causal models to achieve unbiased individual prognosis predictions. Extensions of machine learning methods for applications to causal questions are required to attain the long-standing goal of personalized medicine supported by artificial intelligence.",True,other,Not specified
31797610,PAGE-Net: Interpretable and Integrative Deep Learning for Survival Analysis Using Histopathological Images and Genomic Data,"The integration of multi-modal data, such as histopathological images and genomic data, is essential for understanding cancer heterogeneity and complexity for personalized treatments, as well as for enhancing survival predictions in cancer study. Histopathology, as a clinical gold-standard tool for diagnosis and prognosis in cancers, allows clinicians to make precise decisions on therapies, whereas high-throughput genomic data have been investigated to dissect the genetic mechanisms of cancers. We propose a biologically interpretable deep learning model (PAGE-Net) that integrates histopathological images and genomic data, not only to improve survival prediction, but also to identify genetic and histopathological patterns that cause different survival rates in patients. PAGE-Net consists of pathology/genome/demography-specific layers, each of which provides comprehensive biological interpretation. In particular, we propose a novel patch-wise texture-based convolutional neural network, with a patch aggregation strategy, to extract global survival-discriminative features, without manual annotation for the pathology-specific layers. We adapted the pathway-based sparse deep neural network, named Cox-PASNet, for the genome-specific layers. The proposed deep learning model was assessed with the histopathological images and the gene expression data of Glioblastoma Multiforme (GBM) at The Cancer Genome Atlas (TCGA) and The Cancer Imaging Archive (TCIA). PAGE-Net achieved a C-index of 0.702, which is higher than the results achieved with only histopathological images (0.509) and Cox-PASNet (0.640). More importantly, PAGE-Net can simultaneously identify histopathological and genomic prognostic factors associated with patients survivals. The source code of PAGE-Net is publicly available at https://github.com/DataX-JieHao/PAGE-Net.",True,other,Not specified
31793851,Deep Learning Enables Automatic Classification of Emphysema Pattern at CT,"BackgroundPattern of emphysema at chest CT, scored visually by using the Fleischner Society system, is associated with physiologic impairment and mortality risk.PurposeTo determine whether participant-level emphysema pattern could predict impairment and mortality when classified by using a deep learning method.Materials and MethodsThis retrospective analysis of Genetic Epidemiology of COPD (COPDGene) study participants enrolled between 2007 and 2011 included those with baseline CT, visual emphysema scores, and survival data through 2018. Participants were partitioned into nonoverlapping sets of 2407 for algorithm training, 100 for validation and parameter tuning, and 7143 for testing. A deep learning algorithm using convolutional neural network and long short-term memory architectures was trained to classify pattern of emphysema according to Fleischner criteria. Deep learning scores were compared with visual scores and clinical parameters including pulmonary function tests. Cox proportional hazard models were used to evaluate relationships between emphysema scores and survival. The algorithm was also tested by using CT and clinical data in 1962 participants enrolled in the Evaluation of COPD Longitudinally to Identify Predictive Surrogate End-points (ECLIPSE) study.ResultsA total of 7143 COPDGene participants (mean age ± standard deviation, 59.8 years ± 8.9; 3734 men and 3409 women) were evaluated. Deep learning emphysema classifications were associated with impaired pulmonary function tests, 6-minute walk distance, and St George's Respiratory Questionnaire at univariate analysis (P &lt; .001 for each). Testing in the ECLIPSE cohort showed similar associations (P &lt; .001). In the COPDGene test cohort, deep learning emphysema classification improved the fit of linear mixed models in the prediction of these clinical parameters compared with visual scoring (P &lt; .001). Compared with participants without emphysema, mortality was greater in participants classified by the deep learning algorithm as having any grade of emphysema (adjusted hazard ratios were 1.5, 1.7, 2.9, 5.3, and 9.7, respectively, for trace, mild, moderate, confluent, and advanced destructive emphysema; P &lt; .05).ConclusionDeep learning automation of the Fleischner grade of emphysema at chest CT is associated with clinical measures of pulmonary insufficiency and the risk of mortality.© RSNA, 2019Online supplemental material is available for this article.",True,other,Not specified
31752689,Harnessing technology and molecular analysis to understand the development of cardiovascular diseases in Asia: a prospective cohort study (SingHEART),"BACKGROUND: Cardiovascular disease (CVD) imposes much mortality and morbidity worldwide. The use of ""deep learning"", advancements in genomics, metabolomics, proteomics and devices like wearables have the potential to unearth new insights in the field of cardiology. Currently, in Asia, there are no studies that combine the use of conventional clinical information with these advanced technologies. We aim to harness these new technologies to understand the development of cardiovascular disease in Asia.
METHODS: Singapore is a multi-ethnic country in Asia with well-represented diverse ethnicities including Chinese, Malays and Indians. The SingHEART study is the first technology driven multi-ethnic prospective population-based study of healthy Asians. Healthy male and female subjects aged 21-69 years old without any prior cardiovascular disease or diabetes mellitus will be recruited from the general population. All subjects are consented to undergo a detailed on-line questionnaire, basic blood investigations, resting and continuous electrocardiogram and blood pressure monitoring, activity and sleep tracking, calcium score, cardiac magnetic resonance imaging, whole genome sequencing and lipidomic analysis. Outcomes studied will include mortality and cause of mortality, myocardial infarction, stroke, malignancy, heart failure, and the development of co-morbidities.
DISCUSSION: An initial target of 2500 patients has been set. From October 2015 to May 2017, an initial 683 subjects have been recruited and have completed the initial work-up the SingHEART project is the first contemporary population-based study in Asia that will include whole genome sequencing and deep phenotyping: including advanced imaging and wearable data, to better understand the development of cardiovascular disease across different ethnic groups in Asia.",True,other,Not specified
31714429,Deep Learning Analysis of Cerebral Blood Flow to Identify Cognitive Impairment and Frailty in Persons Living With HIV,"BACKGROUND: Deep learning algorithms of cerebral blood flow were used to classify cognitive impairment and frailty in people living with HIV (PLWH). Feature extraction techniques identified brain regions that were the strongest predictors.
SETTING: Virologically suppressed (<50 copies/mL) PLWH (n = 125) on combination antiretroviral therapy were enrolled. Participants averaged 51.4 (11.4) years of age and 13.7 (2.8) years of education. Participants were administered a neuropsychological battery, assessed for frailty, and completed structural neuroimaging.
METHODS: Deep neural network (DNN) models were trained to classify PLWH as cognitively unimpaired or impaired based on neuropsychological tests (Hopkins Verbal Learning Test-Revised and Brief Visuospatial Memory Test-Revised, Trail making, Letter-Number Sequencing, Verbal Fluency, and Color Word Interference), as well as frail, prefrail, or nonfrail based on the Fried phenotype criteria (at least 3 of the following 5: weight loss, physical inactivity, exhaustion, grip strength, walking time).
RESULTS: DNNs classified individuals with cognitive impairment in the learning, memory, and executive domains with 82%-86% accuracy (0.81-0.87 AUC). Our model classified nonfrail, prefrail, and frail PLWH with 75% accuracy. The strongest predictors of cognitive impairment were cortical (parietal, occipital, and temporal) and subcortical (amygdala, caudate, and hippocampus) regions, whereas the strongest predictors of frailty were subcortical (amygdala, caudate, hippocampus, thalamus, pallidum, and cerebellum).
CONCLUSIONS: DNN models achieved high accuracy in classifying cognitive impairment and frailty status in PLWH. Feature selection algorithms identified predictive regions in each domain and identified overlapping regions between cognitive impairment and frailty. Our results suggest frailty in HIV is primarily subcortical, whereas cognitive impairment in HIV involves subcortical and cortical brain regions.",True,other,convolutional neural network
31707199,Data-efficient deep learning of radiological image data for outcome prediction after endovascular treatment of patients with acute ischemic stroke,"Treatment selection is becoming increasingly more important in acute ischemic stroke patient care. Clinical variables and radiological image biomarkers (old age, pre-stroke mRS, NIHSS, occlusion location, ASPECTS, among others) have an important role in treatment selection and prognosis. Radiological biomarkers require expert annotation and are subject to inter-observer variability. Recently, Deep Learning has been introduced to reproduce these radiological image biomarkers. Instead of reproducing these biomarkers, in this work, we investigated Deep Learning techniques for building models to directly predict good reperfusion after endovascular treatment (EVT) and good functional outcome using CT angiography images. These models do not require image annotation and are fast to compute. We compare the Deep Learning models to Machine Learning models using traditional radiological image biomarkers. We explored Residual Neural Network (ResNet) architectures, adapted them with Structured Receptive Fields (RFNN) and auto-encoders (AE) for network weight initialization. We further included model visualization techniques to provide insight into the network's decision-making process. We applied the methods on the MR CLEAN Registry dataset with 1301 patients. The Deep Learning models outperformed the models using traditional radiological image biomarkers in three out of four cross-validation folds for functional outcome (average AUC of 0.71) and for all folds for reperfusion (average AUC of 0.65). Model visualization showed that the arteries were relevant features for functional outcome prediction. The best results were obtained for the ResNet models with RFNN. Auto-encoder initialization often improved the results. We concluded that, in our dataset, automated image analysis with Deep Learning methods outperforms radiological image biomarkers for stroke outcome prediction and has the potential to improve treatment selection.",True,other,Not specified
31693124,Attention-Based Deep Neural Networks for Detection of Cancerous and Precancerous Esophagus Tissue on Histopathological Slides,"IMPORTANCE: Deep learning-based methods, such as the sliding window approach for cropped-image classification and heuristic aggregation for whole-slide inference, for analyzing histological patterns in high-resolution microscopy images have shown promising results. These approaches, however, require a laborious annotation process and are fragmented.
OBJECTIVE: To evaluate a novel deep learning method that uses tissue-level annotations for high-resolution histological image analysis for Barrett esophagus (BE) and esophageal adenocarcinoma detection.
DESIGN, SETTING, AND PARTICIPANTS: This diagnostic study collected deidentified high-resolution histological images (N = 379) for training a new model composed of a convolutional neural network and a grid-based attention network. Histological images of patients who underwent endoscopic esophagus and gastroesophageal junction mucosal biopsy between January 1, 2016, and December 31, 2018, at Dartmouth-Hitchcock Medical Center (Lebanon, New Hampshire) were collected.
MAIN OUTCOMES AND MEASURES: The model was evaluated on an independent testing set of 123 histological images with 4 classes: normal, BE-no-dysplasia, BE-with-dysplasia, and adenocarcinoma. Performance of this model was measured and compared with that of the current state-of-the-art sliding window approach using the following standard machine learning metrics: accuracy, recall, precision, and F1 score.
RESULTS: Of the independent testing set of 123 histological images, 30 (24.4%) were in the BE-no-dysplasia class, 14 (11.4%) in the BE-with-dysplasia class, 21 (17.1%) in the adenocarcinoma class, and 58 (47.2%) in the normal class. Classification accuracies of the proposed model were 0.85 (95% CI, 0.81-0.90) for the BE-no-dysplasia class, 0.89 (95% CI, 0.84-0.92) for the BE-with-dysplasia class, and 0.88 (95% CI, 0.84-0.92) for the adenocarcinoma class. The proposed model achieved a mean accuracy of 0.83 (95% CI, 0.80-0.86) and marginally outperformed the sliding window approach on the same testing set. The F1 scores of the attention-based model were at least 8% higher for each class compared with the sliding window approach: 0.68 (95% CI, 0.61-0.75) vs 0.61 (95% CI, 0.53-0.68) for the normal class, 0.72 (95% CI, 0.63-0.80) vs 0.58 (95% CI, 0.45-0.69) for the BE-no-dysplasia class, 0.30 (95% CI, 0.11-0.48) vs 0.22 (95% CI, 0.11-0.33) for the BE-with-dysplasia class, and 0.67 (95% CI, 0.54-0.77) vs 0.58 (95% CI, 0.44-0.70) for the adenocarcinoma class. However, this outperformance was not statistically significant.
CONCLUSIONS AND RELEVANCE: Results of this study suggest that the proposed attention-based deep neural network framework for BE and esophageal adenocarcinoma detection is important because it is based solely on tissue-level annotations, unlike existing methods that are based on regions of interest. This new model is expected to open avenues for applying deep learning to digital pathology.",True,other,Not specified
31682189,Validation of a Deep Learning Algorithm for Diabetic Retinopathy,"Background:To validate our deep learning algorithm (DLA) to read diabetic retinopathy (DR) retinographies.Introduction:Currently DR detection is made by retinography; due to its increasing diabetes mellitus incidence we need to find systems that help us to screen DR.Materials and Methods:The DLA was built and trained using 88,702 images from EyePACS, 1,748 from Messidor-2, and 19,230 from our own population. For validation a total of 38,339 retinographies from 17,669 patients (obtained from our DR screening databases) were read by a DLA and compared by four senior retina ophthalmologists for detecting any-DR and referable-DR. We determined the values of Cohen's weighted Kappa (CWK) index, sensitivity (S), specificity (SP), positive predictive value (PPV) and negative predictive value (NPV), and errors type I and II.Results:The results of the DLA to detect any-DR were: CWK = 0.886 ± 0.004 (95% confidence interval [CI] 0.879-0.894), S = 0.967%, SP = 0.976%, PPV = 0.836%, and NPV = 0.996%. The error type I = 0.024, and the error type II = 0.004. Likewise, the referable-DR results were: CWK = 0.809 (95% CI 0.798-0.819), S = 0.998, SP = 0.968, PPV = 0.701, NPV = 0.928, error type I = 0.032, and error type II = 0.001.Discussion:Our DLA can be used as a high confidence diagnostic tool to help in DR screening, especially when it might be difficult for ophthalmologists or other professionals to identify. It can identify patients with any-DR and those that should be referred.Conclusions:The DLA can be valid to aid in screening of DR.",True,both,Not specified
31671144,Deep-learning-based risk stratification for mortality of patients with acute myocardial infarction,"OBJECTIVE: Conventional risk stratification models for mortality of acute myocardial infarction (AMI) have potential limitations. This study aimed to develop and validate deep-learning-based risk stratification for the mortality of patients with AMI (DAMI).
METHODS: The data of 22,875 AMI patients from the Korean working group of the myocardial infarction (KorMI) registry were exclusively divided into 12,152 derivation data of 36 hospitals and 10,723 validation data of 23 hospitals. The predictor variables were the initial demographic and laboratory data. The endpoints were in-hospital mortality and 12-months mortality. We compared the DAMI performance with the global registry of acute coronary event (GRACE) score, acute coronary treatment and intervention outcomes network (ACTION) score, and the thrombolysis in myocardial infarction (TIMI) score using the validation data.
RESULTS: In-hospital mortality for the study subjects was 4.4% and 6-month mortality after survival upon discharge was 2.2%. The areas under the receiver operating characteristic curves (AUCs) of the DAMI were 0.905 [95% confidence interval 0.902-0.909] and 0.870 [0.865-0.876] for the ST elevation myocardial infarction (STEMI) and non ST elevation myocardial infarction (NSTEMI) patients, respectively; these results significantly outperformed those of the GRACE (0.851 [0.846-0.856], 0.810 [0.803-0.819]), ACTION (0.852 [0.847-0.857], 0.806 [0.799-0.814] and TIMI score (0.781 [0.775-0.787], 0.593[0.585-0.603]). DAMI predicted 30.9% of patients more accurately than the GRACE score. As secondary outcome, during the 6-month follow-up, the high risk group, defined by the DAMI, has a significantly higher mortality rate than the low risk group (17.1% vs. 0.5%, p < 0.001).
CONCLUSIONS: The DAMI predicted in-hospital mortality and 12-month mortality of AMI patients more accurately than the existing risk scores and other machine-learning methods.",True,computer vision,Not specified
31627032,Extracting comprehensive clinical information for breast cancer using deep learning methods,"OBJECTIVE: Breast cancer is the most common malignant tumor among women. The diagnosis and treatment information of breast cancer patients is abundant in multiple types of clinical fields, including clinicopathological data, genotype and phenotype information, treatment information, and prognosis information. However, current studies are mainly focused on extracting information from one specific type of clinical field. This study defines a comprehensive information model to represent the whole-course clinical information of patients. Furthermore, deep learning approaches are used to extract the concepts and their attributes from clinical breast cancer documents by fine-tuning pretrained Bidirectional Encoder Representations from Transformers (BERT) language models.
MATERIALS AND METHODS: The clinical corpus that was used in this study was from one 3A cancer hospital in China, consisting of the encounter notes, operation records, pathology notes, radiology notes, progress notes and discharge summaries of 100 breast cancer patients. Our system consists of two components: a named entity recognition (NER) component and a relation recognition component. For each component, we implemented deep learning-based approaches by fine-tuning BERT, which outperformed other state-of-the-art methods on multiple natural language processing (NLP) tasks. A clinical language model is first pretrained using BERT on a large-scale unlabeled corpus of Chinese clinical text. For NER, the context embeddings that were pretrained using BERT were used as the input features of the Bi-LSTM-CRF (Bidirectional long-short-memory-conditional random fields) model and were fine-tuned using the annotated breast cancer notes. Furthermore, we proposed an approach to fine-tune BERT for relation extraction. It was considered to be a classification problem in which the two entities that were mentioned in the input sentence were replaced with their semantic types.
RESULTS: Our best-performing system achieved F1 scores of 93.53% for the NER and 96.73% for the relation extraction. Additional evaluations showed that the deep learning-based approaches that fine-tuned BERT did outperform the traditional Bi-LSTM-CRF and CRF machine learning algorithms in NER and the attention-Bi-LSTM and SVM (support vector machines) algorithms in relation recognition.
CONCLUSION: In this study, we developed a deep learning approach that fine-tuned BERT to extract the breast cancer concepts and their attributes. It demonstrated its superior performance compared to traditional machine learning algorithms, thus supporting its uses in broader NER and relation extraction tasks in the medical domain.",True,other,Not specified
31607660,Deep Learning in Quantitative PET Myocardial Perfusion Imaging: A Study on Cardiovascular Event Prediction,,True,other,GAN
31593701,Application of Artificial Intelligence to Gastroenterology and Hepatology,"Since 2010, substantial progress has been made in artificial intelligence (AI) and its application to medicine. AI is explored in gastroenterology for endoscopic analysis of lesions, in detection of cancer, and to facilitate the analysis of inflammatory lesions or gastrointestinal bleeding during wireless capsule endoscopy. AI is also tested to assess liver fibrosis and to differentiate patients with pancreatic cancer from those with pancreatitis. AI might also be used to establish prognoses of patients or predict their response to treatments, based on multiple factors. We review the ways in which AI may help physicians make a diagnosis or establish a prognosis and discuss its limitations, knowing that further randomized controlled studies will be required before the approval of AI techniques by the health authorities.",True,other,Not specified
31583282,Medical device surveillance with electronic health records,"Post-market medical device surveillance is a challenge facing manufacturers, regulatory agencies, and health care providers. Electronic health records are valuable sources of real-world evidence for assessing device safety and tracking device-related patient outcomes over time. However, distilling this evidence remains challenging, as information is fractured across clinical notes and structured records. Modern machine learning methods for machine reading promise to unlock increasingly complex information from text, but face barriers due to their reliance on large and expensive hand-labeled training sets. To address these challenges, we developed and validated state-of-the-art deep learning methods that identify patient outcomes from clinical notes without requiring hand-labeled training data. Using hip replacements-one of the most common implantable devices-as a test case, our methods accurately extracted implant details and reports of complications and pain from electronic health records with up to 96.3% precision, 98.5% recall, and 97.4% F1, improved classification performance by 12.8-53.9% over rule-based methods, and detected over six times as many complication events compared to using structured data alone. Using these additional events to assess complication-free survivorship of different implant systems, we found significant variation between implants, including for risk of revision surgery, which could not be detected using coded data alone. Patients with revision surgeries had more hip pain mentions in the post-hip replacement, pre-revision period compared to patients with no evidence of revision surgery (mean hip pain mentions 4.97 vs. 3.23; t = 5.14; p &lt; 0.001). Some implant models were associated with higher or lower rates of hip pain mentions. Our methods complement existing surveillance mechanisms by requiring orders of magnitude less hand-labeled training data, offering a scalable solution for national medical device surveillance using electronic health records.",True,other,Not specified
31577910,Machine Learning in Epidemiology and Health Outcomes Research,"Machine learning approaches to modeling of epidemiologic data are becoming increasingly more prevalent in the literature. These methods have the potential to improve our understanding of health and opportunities for intervention, far beyond our past capabilities. This article provides a walkthrough for creating supervised machine learning models with current examples from the literature. From identifying an appropriate sample and selecting features through training, testing, and assessing performance, the end-to-end approach to machine learning can be a daunting task. We take the reader through each step in the process and discuss novel concepts in the area of machine learning, including identifying treatment effects and explaining the output from machine learning models.",True,other,Not specified
31562510,Deep neural networks ensemble for detecting medication mentions in tweets,"OBJECTIVE: Twitter posts are now recognized as an important source of patient-generated data, providing unique insights into population health. A fundamental step toward incorporating Twitter data in pharmacoepidemiologic research is to automatically recognize medication mentions in tweets. Given that lexical searches for medication names suffer from low recall due to misspellings or ambiguity with common words, we propose a more advanced method to recognize them.
MATERIALS AND METHODS: We present Kusuri, an Ensemble Learning classifier able to identify tweets mentioning drug products and dietary supplements. Kusuri (, ""medication"" in Japanese) is composed of 2 modules: first, 4 different classifiers (lexicon based, spelling variant based, pattern based, and a weakly trained neural network) are applied in parallel to discover tweets potentially containing medication names; second, an ensemble of deep neural networks encoding morphological, semantic, and long-range dependencies of important words in the tweets makes the final decision.
RESULTS: On a class-balanced (50-50) corpus of 15 005 tweets, Kusuri demonstrated performances close to human annotators with an F1 score of 93.7%, the best score achieved thus far on this corpus. On a corpus made of all tweets posted by 112 Twitter users (98 959 tweets, with only 0.26% mentioning medications), Kusuri obtained an F1 score of 78.8%. To the best of our knowledge, Kusuri is the first system to achieve this score on such an extremely imbalanced dataset.
CONCLUSIONS: The system identifies tweets mentioning drug names with performance high enough to ensure its usefulness, and is ready to be integrated in pharmacovigilance, toxicovigilance, or more generally, public health pipelines that depend on medication name mentions.",True,both,Not specified
31536581,Development and verification of prediction models for preventing cardiovascular diseases,"OBJECTIVES: Cardiovascular disease (CVD) is one of the major causes of death worldwide. For improved accuracy of CVD prediction, risk classification was performed using national time-series health examination data. The data offers an opportunity to access deep learning (RNN-LSTM), which is widely known as an outstanding algorithm for analyzing time-series datasets. The objective of this study was to show the improved accuracy of deep learning by comparing the performance of a Cox hazard regression and RNN-LSTM based on survival analysis.
METHODS AND FINDINGS: We selected 361,239 subjects (age 40 to 79 years) with more than two health examination records from 2002-2006 using the National Health Insurance System-National Health Screening Cohort (NHIS-HEALS). The average number of health screenings (from 2002-2013) used in the analysis was 2.9 ± 1.0. Two CVD prediction models were developed from the NHIS-HEALS data: a Cox hazard regression model and a deep learning model. In an internal validation of the NHIS-HEALS dataset, the Cox regression model showed a highest time-dependent area under the curve (AUC) of 0.79 (95% CI 0.70 to 0.87) for in females and 0.75 (95% CI 0.70 to 0.80) in males at 2 years. The deep learning model showed a highest time-dependent AUC of 0.94 (95% CI 0.91 to 0.97) for in females and 0.96 (95% CI 0.95 to 0.97) in males at 2 years. Layer-wise Relevance Propagation (LRP) revealed that age was the variable that had the greatest effect on CVD, followed by systolic blood pressure (SBP) and diastolic blood pressure (DBP), in that order.
CONCLUSION: The performance of the deep learning model for predicting CVD occurrences was better than that of the Cox regression model. In addition, it was confirmed that the known risk factors shown to be important by previous clinical studies were extracted from the study results using LRP.",True,other,RNN
31488886,Artificial intelligence for diabetic retinopathy screening: a review,"Diabetes is a global eye health issue. Given the rising in diabetes prevalence and ageing population, this poses significant challenge to perform diabetic retinopathy (DR) screening for these patients. Artificial intelligence (AI) using machine learning and deep learning have been adopted by various groups to develop automated DR detection algorithms. This article aims to describe the state-of-art AI DR screening technologies that have been described in the literature, some of which are already commercially available. All these technologies were designed using different training datasets and technical methodologies. Although many groups have published robust diagnostic performance of the AI algorithms for DR screening, future research is required to address several challenges, for examples medicolegal implications, ethics, and clinical deployment model in order to expedite the translation of these novel technologies into the healthcare setting.",True,other,Not specified
31476576,Learning to detect lymphocytes in immunohistochemistry with deep learning,"The immune system is of critical importance in the development of cancer. The evasion of destruction by the immune system is one of the emerging hallmarks of cancer. We have built a dataset of 171,166 manually annotated CD3+ and CD8+ cells, which we used to train deep learning algorithms for automatic detection of lymphocytes in histopathology images to better quantify immune response. Moreover, we investigate the effectiveness of four deep learning based methods when different subcompartments of the whole-slide image are considered: normal tissue areas, areas with immune cell clusters, and areas containing artifacts. We have compared the proposed methods in breast, colon and prostate cancer tissue slides collected from nine different medical centers. Finally, we report the results of an observer study on lymphocyte quantification, which involved four pathologists from different medical centers, and compare their performance with the automatic detection. The results give insights on the applicability of the proposed methods for clinical use. U-Net obtained the highest performance with an F1-score of 0.78 and the highest agreement with manual evaluation (κ=0.72), whereas the average pathologists agreement with reference standard was κ=0.64. The test set and the automatic evaluation procedure are publicly available at lyon19.grand-challenge.org.",True,other,Not specified
31456363,Development and External Validation of a Deep Learning Algorithm for Prognostication of Cardiovascular Outcomes,"BACKGROUND AND OBJECTIVES: We aim to explore the additional discriminative accuracy of a deep learning (DL) algorithm using repeated-measures data for identifying people at high risk for cardiovascular disease (CVD), compared to Cox hazard regression.
METHODS: Two CVD prediction models were developed from National Health Insurance Service-Health Screening Cohort (NHIS-HEALS): a Cox regression model and a DL model. Performance of each model was assessed in the internal and 2 external validation cohorts in Koreans (National Health Insurance Service-National Sample Cohort; NHIS-NSC) and in Europeans (Rotterdam Study). A total of 412,030 adults in the NHIS-HEALS; 178,875 adults in the NHIS-NSC; and the 4,296 adults in Rotterdam Study were included.
RESULTS: Mean ages was 52 years (46% women) and there were 25,777 events (6.3%) in NHIS-HEALS during the follow-up. In internal validation, the DL approach demonstrated a C-statistic of 0.896 (95% confidence interval, 0.886-0.907) in men and 0.921 (0.908-0.934) in women and improved reclassification compared with Cox regression (net reclassification index [NRI], 24.8% in men, 29.0% in women). In external validation with NHIS-NSC, DL demonstrated a C-statistic of 0.868 (0.860-0.876) in men and 0.889 (0.876-0.898) in women, and improved reclassification compared with Cox regression (NRI, 24.9% in men, 26.2% in women). In external validation applied to the Rotterdam Study, DL demonstrated a C-statistic of 0.860 (0.824-0.897) in men and 0.867 (0.830-0.903) in women, and improved reclassification compared with Cox regression (NRI, 36.9% in men, 31.8% in women).
CONCLUSIONS: A DL algorithm exhibited greater discriminative accuracy than Cox model approaches.
TRIAL REGISTRATION: ClinicalTrials.gov Identifier: NCT02931500.",True,other,Not specified
31412949,A deep learning model for real-time mortality prediction in critically ill children,"BACKGROUND: The rapid development in big data analytics and the data-rich environment of intensive care units together provide unprecedented opportunities for medical breakthroughs in the field of critical care. We developed and validated a machine learning-based model, the Pediatric Risk of Mortality Prediction Tool (PROMPT), for real-time prediction of all-cause mortality in pediatric intensive care units.
METHODS: Utilizing two separate retrospective observational cohorts, we conducted model development and validation using a machine learning algorithm with a convolutional neural network. The development cohort comprised 1445 pediatric patients with 1977 medical encounters admitted to intensive care units from January 2011 to December 2017 at Severance Hospital (Seoul, Korea). The validation cohort included 278 patients with 364 medical encounters admitted to the pediatric intensive care unit from January 2016 to November 2017 at Samsung Medical Center.
RESULTS: Using seven vital signs, along with patient age and body weight on intensive care unit admission, PROMPT achieved an area under the receiver operating characteristic curve in the range of 0.89-0.97 for mortality prediction 6 to 60 h prior to death. Our results demonstrated that PROMPT provided high sensitivity with specificity and outperformed the conventional severity scoring system, the Pediatric Index of Mortality, in predictive ability. Model performance was indistinguishable between the development and validation cohorts.
CONCLUSIONS: PROMPT is a deep model-based, data-driven early warning score tool that can predict mortality in critically ill children and may be useful for the timely identification of deteriorating patients.",True,computer vision,RNN
31364559,"Application of a long short-term memory neural network: a burgeoning method of deep learning in forecasting HIV incidence in Guangxi, China","Guangxi, a province in southwestern China, has the second highest reported number of HIV/AIDS cases in China. This study aimed to develop an accurate and effective model to describe the tendency of HIV and to predict its incidence in Guangxi. HIV incidence data of Guangxi from 2005 to 2016 were obtained from the database of the Chinese Center for Disease Control and Prevention. Long short-term memory (LSTM) neural network models, autoregressive integrated moving average (ARIMA) models, generalised regression neural network (GRNN) models and exponential smoothing (ES) were used to fit the incidence data. Data from 2015 and 2016 were used to validate the most suitable models. The model performances were evaluated by evaluating metrics, including mean square error (MSE), root mean square error, mean absolute error and mean absolute percentage error. The LSTM model had the lowest MSE when the N value (time step) was 12. The most appropriate ARIMA models for incidence in 2015 and 2016 were ARIMA (1, 1, 2) (0, 1, 2)12 and ARIMA (2, 1, 0) (1, 1, 2)12, respectively. The accuracy of GRNN and ES models in forecasting HIV incidence in Guangxi was relatively poor. Four performance metrics of the LSTM model were all lower than the ARIMA, GRNN and ES models. The LSTM model was more effective than other time-series models and is important for the monitoring and control of local HIV epidemics.",True,other,Not specified
31357159,Identifying depression in the National Health and Nutrition Examination Survey data using a deep learning algorithm,"BACKGROUND: As depression is the leading cause of disability worldwide, large-scale surveys have been conducted to establish the occurrence and risk factors of depression. However, accurately estimating epidemiological factors leading up to depression has remained challenging. Deep-learning algorithms can be applied to assess the factors leading up to prevalence and clinical manifestations of depression.
METHODS: Customized deep-neural-network and machine-learning classifiers were assessed using survey data from 19,725 participants from the NHANES database (from 1999 through 2014) and 4949 from the South Korea NHANES (K-NHANES) database in 2014.
RESULTS: A deep-learning algorithm showed area under the receiver operating characteristic curve (AUCs) of 0.91 and 0.89 for detecting depression in NHANES and K-NHANES, respectively. The deep-learning algorithm trained with serial datasets (NHANES, from 1999 to 2012), predicted the prevalence of depression in the following two years of data (NHANES, 2013 and 2014) with an AUC of 0.92. Machine learning classifiers trained with NHANES could further predict depression in K-NHANES. There, logistic regression had the highest performance (AUC, 0.77) followed by deep learning algorithm (AUC, 0.74).
CONCLUSIONS: Deep neural-networks managed to identify depression well from other health and demographic factors in both the NHANES and K-NHANES datasets. The deep-learning algorithm was also able to predict depression relatively well on new data set-cross temporally and cross nationally. Further research can delineate the clinical implications of machine learning and deep learning in detecting disease prevalence and progress as well as other risk factors for depression and other mental illnesses.",True,other,recurrent neural network
31322692,Deep Learning to Assess Long-term Mortality From Chest Radiographs,"IMPORTANCE: Chest radiography is the most common diagnostic imaging test in medicine and may also provide information about longevity and prognosis.
OBJECTIVE: To develop and test a convolutional neural network (CNN) (named CXR-risk) to predict long-term mortality, including noncancer death, from chest radiographs.
DESIGN, SETTING, AND PARTICIPANTS: In this prognostic study, CXR-risk CNN development (n = 41 856) and testing (n = 10 464) used data from the screening radiography arm of the Prostate, Lung, Colorectal, and Ovarian Cancer Screening Trial (PLCO) (n = 52 320), a community cohort of asymptomatic nonsmokers and smokers (aged 55-74 years) enrolled at 10 US sites from November 8, 1993, through July 2, 2001. External testing used data from the screening radiography arm of the National Lung Screening Trial (NLST) (n = 5493), a community cohort of heavy smokers (aged 55-74 years) enrolled at 21 US sites from August 2002, through April 2004. Data analysis was performed from January 1, 2018, to May 23, 2019.
EXPOSURE: Deep learning CXR-risk score (very low, low, moderate, high, and very high) based on CNN analysis of the enrollment radiograph.
MAIN OUTCOMES AND MEASURES: All-cause mortality. Prognostic value was assessed in the context of radiologists' diagnostic findings (eg, lung nodule) and standard risk factors (eg, age, sex, and diabetes) and for cause-specific mortality.
RESULTS: Among 10 464 PLCO participants (mean [SD] age, 62.4 [5.4] years; 5405 men [51.6%]; median follow-up, 12.2 years [interquartile range, 10.5-12.9 years]) and 5493 NLST test participants (mean [SD] age, 61.7 [5.0] years; 3037 men [55.3%]; median follow-up, 6.3 years [interquartile range, 6.0-6.7 years]), there was a graded association between CXR-risk score and mortality. The very high-risk group had mortality of 53.0% (PLCO) and 33.9% (NLST), which was higher compared with the very low-risk group (PLCO: unadjusted hazard ratio [HR], 18.3 [95% CI, 14.5-23.2]; NLST: unadjusted HR, 15.2 [95% CI, 9.2-25.3]; both P < .001). This association was robust to adjustment for radiologists' findings and risk factors (PLCO: adjusted HR [aHR], 4.8 [95% CI, 3.6-6.4]; NLST: aHR, 7.0 [95% CI, 4.0-12.1]; both P < .001). Comparable results were seen for lung cancer death (PLCO: aHR, 11.1 [95% CI, 4.4-27.8]; NLST: aHR, 8.4 [95% CI, 2.5-28.0]; both P ≤ .001) and for noncancer cardiovascular death (PLCO: aHR, 3.6 [95% CI, 2.1-6.2]; NLST: aHR, 47.8 [95% CI, 6.1-374.9]; both P < .001) and respiratory death (PLCO: aHR, 27.5 [95% CI, 7.7-97.8]; NLST: aHR, 31.9 [95% CI, 3.9-263.5]; both P ≤ .001).
CONCLUSIONS AND RELEVANCE: In this study, the deep learning CXR-risk score stratified the risk of long-term mortality based on a single chest radiograph. Individuals at high risk of mortality may benefit from prevention, screening, and lifestyle interventions.",True,both,RNN
31319675,Unsupervised Learning Techniques for the Investigation of Chronic Rhinosinusitis,"OBJECTIVES: This article reviews the principles of unsupervised learning, a novel technique which has increasingly been reported as a tool for the investigation of chronic rhinosinusitis (CRS). It represents a paradigm shift from the traditional approach to investigating CRS based upon the clinically recognized phenotypes of ""with polyps"" and ""without polyps"" and instead relies upon the application of complex mathematical models to derive subgroups which can then be further examined. This review article reports on the principles which underlie this investigative technique and some of the published examples in CRS.
METHODS: This review summarizes the different types of unsupervised learning techniques which have been described and briefly expounds upon their useful applications. A literature review of studies which have unsupervised learning is then presented to provide a practical guide to its uses and some of the new directions of investigations suggested by their findings.
RESULTS: The commonest unsupervised learning technique applied to rhinology research is cluster analysis, which can be further subdivided into hierarchical and non-hierarchical approaches. The mathematical principles which underpin these approaches are explained within this article. Studies which have used these techniques can be broadly divided into those which have used clinical data only and that which includes biomarkers. Studies which include biomarkers adhere closely to the established canon of CRS disease phenotypes, while those that use clinical data may diverge from the typical ""polyp versus non-polyp"" phenotypes and reflect subgroups of patients who share common symptom modifiers.
SUMMARY: Artificial intelligence is increasingly influential in health care research and machine learning techniques have been reported in the investigation of CRS, promising several interesting new avenues for research. However, when critically appraising studies which use this technique, the reader needs to be au fait with the limitations and appropriate uses of its application.",True,other,Not specified
31316553,MildInt: Deep Learning-Based Multimodal Longitudinal Data Integration Framework,"As large amounts of heterogeneous biomedical data become available, numerous methods for integrating such datasets have been developed to extract complementary knowledge from multiple domains of sources. Recently, a deep learning approach has shown promising results in a variety of research areas. However, applying the deep learning approach requires expertise for constructing a deep architecture that can take multimodal longitudinal data. Thus, in this paper, a deep learning-based python package for data integration is developed. The python package deep learning-based multimodal longitudinal data integration framework (MildInt) provides the preconstructed deep learning architecture for a classification task. MildInt contains two learning phases: learning feature representation from each modality of data and training a classifier for the final decision. Adopting deep architecture in the first phase leads to learning more task-relevant feature representation than a linear model. In the second phase, linear regression classifier is used for detecting and investigating biomarkers from multimodal data. Thus, by combining the linear model and the deep learning model, higher accuracy and better interpretability can be achieved. We validated the performance of our package using simulation data and real data. For the real data, as a pilot study, we used clinical and multimodal neuroimaging datasets in Alzheimer's disease to predict the disease progression. MildInt is capable of integrating multiple forms of numerical data including time series and non-time series data for extracting complementary features from the multimodal dataset.",True,other,recurrent neural network
31304376,Automation of the kidney function prediction and classification through ultrasound-based kidney imaging using deep learning,"Prediction of kidney function and chronic kidney disease (CKD) through kidney ultrasound imaging has long been considered desirable in clinical practice because of its safety, convenience, and affordability. However, this highly desirable approach is beyond the capability of human vision. We developed a deep learning approach for automatically determining the estimated glomerular filtration rate (eGFR) and CKD status. We exploited the transfer learning technique, integrating the powerful ResNet model pretrained on an ImageNet dataset in our neural network architecture, to predict kidney function based on 4,505 kidney ultrasound images labeled using eGFRs derived from serum creatinine concentrations. To further extract the information from ultrasound images, we leveraged kidney length annotations to remove the peripheral region of the kidneys and applied various data augmentation schemes to produce additional data with variations. Bootstrap aggregation was also applied to avoid overfitting and improve the model's generalization. Moreover, the kidney function features obtained by our deep neural network were used to identify the CKD status defined by an eGFR of &lt;60 ml/min/1.73 m2. A Pearson correlation coefficient of 0.741 indicated the strong relationship between artificial intelligence (AI)- and creatinine-based GFR estimations. Overall CKD status classification accuracy of our model was 85.6% -higher than that of experienced nephrologists (60.3%-80.1%). Our model is the first fundamental step toward realizing the potential of transforming kidney ultrasound imaging into an effective, real-time, distant screening tool. AI-GFR estimation offers the possibility of noninvasive assessment of kidney function, a key goal of AI-powered functional automation in clinical practice.",True,other,RNN
31304371,Deep learning in estimating prevalence and systemic risk factors for diabetic retinopathy: a multi-ethnic study,"In any community, the key to understanding the burden of a specific condition is to conduct an epidemiological study. The deep learning system (DLS) recently showed promising diagnostic performance for diabetic retinopathy (DR). This study aims to use DLS as the grading tool, instead of human assessors, to determine the prevalence and the systemic cardiovascular risk factors for DR on fundus photographs, in patients with diabetes. This is a multi-ethnic (5 races), multi-site (8 datasets from Singapore, USA, Hong Kong, China and Australia), cross-sectional study involving 18,912 patients (n = 93,293 images). We compared these results and the time taken for DR assessment by DLS versus 17 human assessors - 10 retinal specialists/ophthalmologists and 7 professional graders). The estimation of DR prevalence between DLS and human assessors is comparable for any DR, referable DR and vision-threatening DR (VTDR) (Human assessors: 15.9, 6.5% and 4.1%; DLS: 16.1%, 6.4%, 3.7%). Both assessment methods identified similar risk factors (with comparable AUCs), including younger age, longer diabetes duration, increased HbA1c and systolic blood pressure, for any DR, referable DR and VTDR (p &gt; 0.05). The total time taken for DLS to evaluate DR from 93,293 fundus photographs was ~1 month compared to 2 years for human assessors. In conclusion, the prevalence and systemic risk factors for DR in multi-ethnic population could be determined accurately using a DLS, in significantly less time than human assessors. This study highlights the potential use of AI for future epidemiology or clinical trials for DR grading in the global communities.",True,other,Not specified
31298717,Development and Validation of a Deep Learning Algorithm for Mortality Prediction in Selecting Patients With Dementia for Earlier Palliative Care Interventions,"IMPORTANCE: Early palliative care interventions drive high-value care but currently are underused. Health care professionals face challenges in identifying patients who may benefit from palliative care.
OBJECTIVE: To develop a deep learning algorithm using longitudinal electronic health records to predict mortality risk as a proxy indicator for identifying patients with dementia who may benefit from palliative care.
DESIGN, SETTING, AND PARTICIPANTS: In this retrospective cohort study, 6-month, 1-year, and 2-year mortality prediction models with recurrent neural networks used patient demographic information and topics generated from clinical notes within Partners HealthCare System, an integrated health care delivery system in Boston, Massachusetts. This study included 26 921 adult patients with dementia who visited the health care system from January 1, 2011, through December 31, 2017. The models were trained using a data set of 24 229 patients and validated using another data set of 2692 patients. Data were analyzed from September 18, 2018, to May 15, 2019.
MAIN OUTCOMES AND MEASURES: The area under the receiver operating characteristic curve (AUC) for 6-month and 1- and 2-year mortality prediction models and the factors contributing to the predictions.
RESULTS: The study cohort included 26 921 patients (16 263 women [60.4%]; mean [SD] age, 74.6 [13.5] years). For the 24 229 patients in the training data set, mean (SD) age was 74.8 (13.2) years and 14 632 (60.4%) were women. For the 2692 patients in the validation data set, mean (SD) age was 75.0 (12.6) years and 1631 (60.6%) were women. The 6-month model reached an AUC of 0.978 (95% CI, 0.977-0.978); the 1-year model, 0.956 (95% CI, 0.955-0.956); and the 2-year model, 0.943 (95% CI, 0.942-0.944). The top-ranked latent topics associated with 6-month and 1- and 2-year mortality in patients with dementia include palliative and end-of-life care, cognitive function, delirium, testing of cholesterol levels, cancer, pain, use of health care services, arthritis, nutritional status, skin care, family meeting, shock, respiratory failure, and swallowing function.
CONCLUSIONS AND RELEVANCE: A deep learning algorithm based on patient demographic information and longitudinal clinical notes appeared to show promising results in predicting mortality among patients with dementia in different time frames. Further research is necessary to determine the feasibility of applying this algorithm in clinical settings for identifying unmet palliative care needs earlier.",True,other,Not specified
31258997,Approaching neural net feature interpretation using stacked autoencoders: gene expression profiling of systemic lupus erythematosus patients,"Systemic lupus erythematosus (SLE) is a rare, autoimmune disorder known to affect most organ sites. Complicating clinical management is a poorly differentiated, heterogenous SLE disease state. While some small molecule drugs and biologics are available for treatment, additional therapeutic options are needed. Parsing complex biological signatures using powerful, yet human interpretable approaches is critical to advancing our understanding of SLE etiology and identifying therapeutic repositioning opportunities. To approach this goal, we developed a semi-supervised deep neural network pipeline for gene expression profiling of SLE patients and subsequent characterization of individual gene features. Our pipeline performed exemplar multinomial classification of SLE patients in independent balanced validation (F<sub>1</sub>=0.956) and unbalanced, under-powered testing (F<sub>1</sub>=0.944) cohorts. A stacked autoencoder disambiguated individual feature representativeness by regenerating an input-like(A ') feature matrix. A to A' comparisons suggest the top associated features to be key features in gene expression profiling using neural nets.",True,other,Not specified
31201368,Microvascularity detection and quantification in glioma: a novel deep-learning-based framework,"Microvascularity is highly correlated with the grading and subtyping of gliomas, making this one of its most important histological features. Accurate quantitative analysis of microvessels is helpful for the development of a targeted therapy for antiangiogenesis. The deep-learning algorithm is by far the most effective segmentation and detection model and enables location and recognition of complex microvascular networks in large images obtained from hematoxylin and eosin (H&E) stained specimens. We proposed an automated deep-learning-based method to detect and quantify the microvascularity in glioma and applied it to comprehensive clinical analyses. A total of 350 glioma patients were enrolled in our study, for which digitalized imaging of H&E stained slides were reviewed, molecular diagnosis was performed and follow-up was investigated. The microvascular features were compared according to their histologic types, molecular types, and patients' prognosis. The results show that the proposed method can quantify microvascular characteristics automatically and effectively. Significant increases of microvascular density and microvascular area were observed in glioblastomas (95% p < 0.001 in density, 170% p < 0.001 in area) in comparison with other histologic types; increases were also observed in cases with TERT-mut only (68% p < 0.001 in density, 54% p < 0.001 in area) compared with other molecular types. Survival analysis showed that microvascular features can be used to cluster cases into two groups with different survival periods (hazard ratio [HR] 2.843, log-rank <0.001), which indicates the quantified microvascular features may potentially be alternative signatures for revealing patients' prognosis. This deep-learning-based method may be a useful tool in routine clinical practice for precise diagnosis and antiangiogenic treatment.",True,other,Not specified
31160815,Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer,"Microsatellite instability determines whether patients with gastrointestinal cancer respond exceptionally well to immunotherapy. However, in clinical practice, not every patient is tested for MSI, because this requires additional genetic or immunohistochemical tests. Here we show that deep residual learning can predict MSI directly from H&E histology, which is ubiquitously available. This approach has the potential to provide immunotherapy to a much broader subset of patients with gastrointestinal cancer.",True,other,Not specified
31141892,The Use of Deep Learning to Predict Stroke Patient Mortality,"The increase in stroke incidence with the aging of the Korean population will rapidly impose an economic burden on society. Timely treatment can improve stroke prognosis. Awareness of stroke warning signs and appropriate actions in the event of a stroke improve outcomes. Medical service use and health behavior data are easier to collect than medical imaging data. Here, we used a deep neural network to detect stroke using medical service use and health behavior data; we identified 15,099 patients with stroke. Principal component analysis (PCA) featuring quantile scaling was used to extract relevant background features from medical records; we used these to predict stroke. We compared our method (a scaled PCA/deep neural network [DNN] approach) to five other machine-learning methods. The area under the curve (AUC) value of our method was 83.48%; hence; it can be used by both patients and doctors to prescreen for possible stroke.",True,both,Not specified
31128628,Deep learning for supervised classification of spatial epidemics,"In an emerging epidemic, public health officials must move quickly to contain the spread. Information obtained from statistical disease transmission models often informs the development of containment strategies. Inference procedures such as Bayesian Markov chain Monte Carlo allow researchers to estimate parameters of such models, but are computationally expensive. In this work, we explore supervised statistical and machine learning methods for fast inference via supervised classification, with a focus on deep learning. We apply our methods to simulated epidemics through two populations of swine farms in Iowa, and find that the random forest performs well on the denser population, but is outperformed by a deep learning model on the sparser population.",True,other,Not specified
31061433,Deep learning-based survival prediction of oral cancer patients,"The Cox proportional hazards model commonly used to evaluate prognostic variables in survival of cancer patients may be too simplistic to properly predict a cancer patient's outcome since it assumes that the outcome is a linear combination of covariates. In this retrospective study including 255 patients suitable for analysis who underwent surgical treatment in our department from 2000 to 2017, we applied a deep learning-based survival prediction method in oral squamous cell carcinoma (SCC) patients and validated its performance. Survival prediction using DeepSurv, a deep learning based-survival prediction algorithm, was compared with random survival forest (RSF) and the Cox proportional hazard model (CPH). DeepSurv showed the best performance among the three models, the c-index of the training and testing sets reaching 0.810 and 0.781, respectively, followed by RSF (0.770/0.764), and CPH (0.756/0.694). The performance of DeepSurv steadily improved with added features. Thus, deep learning-based survival prediction may improve prediction accuracy and guide clinicians both in choosing treatment options for better survival and in avoiding unnecessary treatments.",True,other,Not specified
31048019,Deep learning in ophthalmology: The technical and clinical considerations,"The advent of computer graphic processing units, improvement in mathematical models and availability of big data has allowed artificial intelligence (AI) using machine learning (ML) and deep learning (DL) techniques to achieve robust performance for broad applications in social-media, the internet of things, the automotive industry and healthcare. DL systems in particular provide improved capability in image, speech and motion recognition as well as in natural language processing. In medicine, significant progress of AI and DL systems has been demonstrated in image-centric specialties such as radiology, dermatology, pathology and ophthalmology. New studies, including pre-registered prospective clinical trials, have shown DL systems are accurate and effective in detecting diabetic retinopathy (DR), glaucoma, age-related macular degeneration (AMD), retinopathy of prematurity, refractive error and in identifying cardiovascular risk factors and diseases, from digital fundus photographs. There is also increasing attention on the use of AI and DL systems in identifying disease features, progression and treatment response for retinal diseases such as neovascular AMD and diabetic macular edema using optical coherence tomography (OCT). Additionally, the application of ML to visual fields may be useful in detecting glaucoma progression. There are limited studies that incorporate clinical data including electronic health records, in AL and DL algorithms, and no prospective studies to demonstrate that AI and DL algorithms can predict the development of clinical eye disease. This article describes global eye disease burden, unmet needs and common conditions of public health importance for which AI and DL systems may be applicable. Technical and clinical aspects to build a DL system to address those needs, and the potential challenges for clinical adoption are discussed. AI, ML and DL will likely play a crucial role in clinical ophthalmology practice, with implications for screening, diagnosis and follow up of the major causes of vision impairment in the setting of ageing populations globally.",True,other,CNN
33323241,Artificial intelligence for diabetic retinopathy screening in Africa,,True,other,GAN
31038007,Predictive analytics and machine learning in stroke and neurovascular medicine,"Advances in predictive analytics and machine learning supported by an ever-increasing wealth of data and processing power are transforming almost every industry. Accuracy and precision of predictive analytics have significantly increased over the past few years and are evolving at an exponential pace. There have been significant breakthroughs in using Predictive Analytics in healthcare where it is held as the foundation of precision medicine. Yet, although the research in the field is expanding with the profuse volume of papers applying machine learning algorithms to medical data, very few have contributed meaningfully to clinical care. This lack of impact stands in stark contrast to the enormous relevance of machine learning to many other industries. Regardless of the status of its current contribution, the field of predictive analytics is expected to fundamentally change the way we diagnose and treat diseases, as well as the conduct of biomedical science research. In this review, we describe the main tools and techniques in predictive analytics and will analyze the trends in application of these techniques over the recent years. We will also provide examples of its application in medicine and more specifically in stroke and neurovascular research and outline current limitations.",True,other,recurrent neural network
31015713,Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning,"Traditionally, medical discoveries are made by observing associations, making hypotheses from them and then designing and running experiments to test the hypotheses. However, with medical images, observing and quantifying associations can often be difficult because of the wide variety of features, patterns, colours, values and shapes that are present in real data. Here, we show that deep learning can extract new knowledge from retinal fundus images. Using deep-learning models trained on data from 284,335 patients and validated on two independent datasets of 12,026 and 999 patients, we predicted cardiovascular risk factors not previously thought to be present or quantifiable in retinal images, such as age (mean absolute error within 3.26 years), gender (area under the receiver operating characteristic curve (AUC) = 0.97), smoking status (AUC = 0.71), systolic blood pressure (mean absolute error within 11.23 mmHg) and major adverse cardiac events (AUC = 0.70). We also show that the trained deep-learning models used anatomical features, such as the optic disc or blood vessels, to generate each prediction.",True,other,recurrent neural network
31014678,Demystifying the Jargon: The Bridge between Ophthalmology and Artificial Intelligence,"Publications related to artificial intelligence (AI) and machine learning have risen exponentially in the past 5 years in the medical literature, including a number of articles involving retinal disease.– The mathematical theories beneath machine learning methods have been around for decades but in most cases were too computationally intense to implement by hand., Recent advances in computer central processing units and graphics processing units have enabled the application of these models to solve real-world problems., This has led to rapid advances in the fields of AI and machine learning, specifically deep learning, and to a growing number of medical and ophthalmic applications.–, As with the rapid evolution of any new technologies, there can be confusion about new terminologies, and AI is no exception. Though they are often used interchangeably, the terms “AI,” “machine learning,” “deep learning,” and “neural networks” are not synonymous and may be confusing for ophthalmologists to distinguish. Below, we attempt to define these terms in a manner accessible to both ophthalmologists and vision researchers (Figure 1).",True,other,recurrent neural network
31005759,Differential diagnosis of multiple system atrophy with predominant parkinsonism and Parkinson's disease using neural networks,"Differential diagnosis between Parkinson's disease (PD) and atypical parkinsonism, such as multiple system atrophy (MSA), can be difficult, especially in the early stages of the disease. Deep learning using neural networks (NNs) makes possible the prediction of the diagnosis using various types of biomarkers, unlike conventional linear statistics. We aimed to differentiate the Parkinson's variant of MSA (MSA-P) from PD both in the early stages by clinical utilization of NN analyses before the hot cross-bun and putaminal rim imaging features of MSA appeared. Analysis by NN involved the data of voxel-based morphometry (VBM) that indicate morphological changes and magnetic resonance spectroscopy (MRS) that indicate qualitative changes. VBM analysis showed that compared with PD patients, MSA-P patients showed atrophy in the superior cerebellar peduncle, middle cerebellar peduncle, cerebellar hemisphere, pons, midbrain, and putamen, but not in the globus pallidus. Proton MRS on the globus pallidus in the diseased hemisphere, lacking atrophy as observed with VBM, revealed decreased neurons and gliosis in both groups. Clinical differentiation of MSA-P from PD using NN analysis, involved measuring the prediction potential using the area under the receiver operator characteristic (ROC) curves (AUC). Using both VBM and MRS data, NNs contributed adequately to the clinical diagnosis.",True,other,RNN
31003081,Novel taxonomy-independent deep learning microbiome approach allows for accurate classification of different forensically relevant human epithelial materials,"Correct identification of different human epithelial materials such as from skin, saliva and vaginal origin is relevant in forensic casework as it provides crucial information for crime reconstruction. However, the overlap in human cell type composition between these three epithelial materials provides challenges for their differentiation and identification when using previously proposed human cell biomarkers, while their microbiota composition largely differs. By using validated 16S rRNA gene massively parallel sequencing data from the Human Microbiome Project of 1636 skin, oral and vaginal samples, 50 taxonomy-independent deep learning networks were trained to classify these three tissues. Validation testing was performed in de-novo generated high-throughput 16S rRNA gene sequencing data using the Ion Torrent™ Personal Genome Machine from 110 test samples: 56 hand skin, 31 saliva and 23 vaginal secretion specimens. Body-site classification accuracy of these test samples was very high as indicated by AUC values of 0.99 for skin, 0.99 for oral, and 1 for vaginal secretion. Misclassifications were limited to 3 (5%) skin samples. Additional forensic validation testing was performed in mock casework samples by de-novo high-throughput sequencing of 19 freshly-prepared samples and 22 samples aged for 1 up to 7.6 years. All of the 19 fresh and 20 (91%) of the 22 aged mock casework samples were correctly tissue-type classified. Moreover, comparing the microbiome results with outcomes from previous human mRNA-based tissue identification testing in the same 16 aged mock casework samples reveals that our microbiome approach performs better in 12 (75%), similarly in 2 (12.5%), and less good in 2 (12.5%) of the samples. Our results demonstrate that this new microbiome approach allows for accurate tissue-type classification of three human epithelial materials of skin, oral and vaginal origin, which is highly relevant for future forensic investigations.",True,both,Not specified
30988951,Deep learning opens new horizons in personalized medicine,"Although the idea of the personalization of patient care dates back to the time of Hippocrates, recent advances in diagnostic medical imaging and molecular medicine are gradually transforming healthcare services, by offering information and diagnostic tools enabling individualized patient management. Facilitating personalized / precision medicine requires taking into account multiple heterogenous parameters, such as sociodemographics, gene variability, environmental and lifestyle factors. Therefore, one of the most critical challenges in personalized medicine is the need to transform large, multi-modal data into decision support tools, capable of bridging the translational gap to the clinical setting. Towards these challenges, deep learning (DL) provides a novel approach, which enables obtaining or developing high-accuracy, multi-modal predictive models, that allow the implementation of the personalized medicine vision in the near future. DL is a highly effective strategy in addressing these challenges, with DL-based models leading to unprecedented results, matching or even improving state-of-the-art prediction/detection rates based on both intuitive and non-intuitive disease descriptors. These results hold promise for significant socio-economic benefits from the application of DL personalized medicine.",True,text mining,Not specified
30984467,Automated Detection of Celiac Disease on Duodenal Biopsy Slides: A Deep Learning Approach,"CONTEXT: Celiac disease (CD) prevalence and diagnosis have increased substantially in recent years. The current gold standard for CD confirmation is visual examination of duodenal mucosal biopsies. An accurate computer-aided biopsy analysis system using deep learning can help pathologists diagnose CD more efficiently.
SUBJECTS AND METHODS: In this study, we trained a deep learning model to detect CD on duodenal biopsy images. Our model uses a state-of-the-art residual convolutional neural network to evaluate patches of duodenal tissue and then aggregates those predictions for whole-slide classification. We tested the model on an independent set of 212 images and evaluated its classification results against reference standards established by pathologists.
RESULTS: Our model identified CD, normal tissue, and nonspecific duodenitis with accuracies of 95.3%, 91.0%, and 89.2%, respectively. The area under the receiver operating characteristic curve was >0.95 for all classes.
CONCLUSIONS: We have developed an automated biopsy analysis system that achieves high performance in detecting CD on biopsy slides. Our system can highlight areas of interest and provide preliminary classification of duodenal biopsies before review by pathologists. This technology has great potential for improving the accuracy and efficiency of CD diagnosis.",True,other,Not specified
30979558,[Can Big Data change our practices?],"The European Medicines Agency has defined Big Data by the ""3 V's"": Volume, Velocity and Variety. These large databases allow access to real life data on patient care. They are particularly suited for studies of adverse events and pharmacoepidemiology. Deep learning is a collection of algorithms used in machine learning, used to model high-level abstractions in data using model architectures, which are composed of multiple nonlinear transformations. This article shows how Big Data and Deep Learning can help in ophthalmology, pointing out their advantages and disadvantages. A literature review is presented in this article illustrating the uses of Deep Learning in ophthalmology.",True,other,convolutional neural network
30951460,Dynamic-DeepHit: A Deep Learning Approach for Dynamic Survival Analysis With Competing Risks Based on Longitudinal Data,"Currently available risk prediction methods are limited in their ability to deal with complex, heterogeneous, and longitudinal data such as that available in primary care records, or in their ability to deal with multiple competing risks. This paper develops a novel deep learning approach that is able to successfully address current limitations of standard statistical approaches such as landmarking and joint modeling. Our approach, which we call Dynamic-DeepHit, flexibly incorporates the available longitudinal data comprising various repeated measurements (rather than only the last available measurements) in order to issue dynamically updated survival predictions for one or multiple competing risk(s). Dynamic-DeepHit learns the time-to-event distributions without the need to make any assumptions about the underlying stochastic models for the longitudinal and the time-to-event processes. Thus, unlike existing works in statistics, our method is able to learn data-driven associations between the longitudinal data and the various associated risks without underlying model specifications. We demonstrate the power of our approach by applying it to a real-world longitudinal dataset from the U.K. Cystic Fibrosis Registry, which includes a heterogeneous cohort of 5883 adult patients with annual follow-ups between 2009 to 2015. The results show that Dynamic-DeepHit provides a drastic improvement in discriminating individual risks of different forms of failures due to cystic fibrosis. Furthermore, our analysis utilizes post-processing statistics that provide clinical insight by measuring the influence of each covariate on risk predictions and the temporal importance of longitudinal measurements, thereby enabling us to identify covariates that are influential for different competing risks.",True,other,recurrent neural network
30929473,"Deep learning for identifying environmental risk factors of acute respiratory diseases in Beijing, China: implications for population with different age and gender","This study focuses on identifying environmental health risk factors related to acute respiratory diseases using deep learning method. Based on respiratory disease data, air pollution data and meteorological environmental data, cross-domain risk factors of acute respiratory diseases were identified in Beijing, China. We conducted age and gender stratified deep neural network models in air pollution epidemiology. We ranked risk factors of respiratory diseases in stratified populations and conducted quantitative comparison. People ≥50 years were more sensitive to PM<sub>2.5</sub> pollution than &lt;50 years people, especially women ≥50 years. Compared with women, both men ≥50 years and &lt;50 years were more susceptible to PM<sub>10</sub>. Young women &lt;50 years were more sensitive to general air pollutants such as SO<sub>2</sub> and NO<sub>2</sub> than &lt;50 years young men. Meteorological factors such as wind speed and precipitation could promote the diffusion of fine particulate matter and general air pollutants (SO<sub>2</sub>, NO<sub>2</sub>, etc.), which could help to reduce the incidence of acute respiratory diseases. This study represents a quantitative analysis of environmental health risk factors identification related to acute respiratory diseases based on deep neural network method. The results of this study could help people to improve their awareness of acute respiratory diseases prevention.",True,other,Not specified
39398279,UNSUPERVISED DOMAIN ADAPTION WITH ADVERSARIAL LEARNING (UDAA) FOR EMPHYSEMA SUBTYPING ON CARDIAC CT SCANS: THE MESA STUDY,"Emphysema quantification and sub-typing is actively studied on cohorts of full-lung high-resolution CT (HRCT) scans, with promising results. Transfer of quantification and classification tools to cardiac CT scans, which involve 70% of the lungs, is challenging due to lower image resolution and degradation of textural patterns. In this study, we propose an original deep-learning domain-adaptation framework to use a pre-existing dictionary of lung texture patterns (LTP), learned on gold-standard full-lung HRCT scans, to label emphysema regions on cardiac CT scans. The method exploits convolutional neural networks (CNNs) trained for: 1) supervised lung texture classification on synthetic cardiac images, and 2) adversarial learning to discriminate between real and synthetic cardiac images. Combination of the classification and adversarial tasks enables to label real cardiac CT scans, and is evaluated on the MESA cohort (N = 15,357 scans). Our results show that image features derived from the adversarial training preserve the labeling accuracy on synthetic scans. LTP histogram signatures generated on 4,315 longitudinal pairs of cardiac CT scans, show high level of consistency over time and scanner generations. The ability to robustly label emphysema texture patterns on cardiac CT scans will enable large-scale longitudinal studies over 10 years of follow-up, for better understanding of the disease progression.",True,other,Not specified
30901858,Group Lasso Regularized Deep Learning for Cancer Prognosis from Multi-Omics and Clinical Features,"Accurate prognosis of patients with cancer is important for the stratification of patients, the optimization of treatment strategies, and the design of clinical trials. Both clinical features and molecular data can be used for this purpose, for instance, to predict the survival of patients censored at specific time points. Multi-omics data, including genome-wide gene expression, methylation, protein expression, copy number alteration, and somatic mutation data, are becoming increasingly common in cancer studies. To harness the rich information in multi-omics data, we developed GDP (Group lass regularized Deep learning for cancer Prognosis), a computational tool for survival prediction using both clinical and multi-omics data. GDP integrated a deep learning framework and Cox proportional hazard model (CPH) together, and applied group lasso regularization to incorporate gene-level group prior knowledge into the model training process. We evaluated its performance in both simulated and real data from The Cancer Genome Atlas (TCGA) project. In simulated data, our results supported the importance of group prior information in the regularization of the model. Compared to the standard lasso regularization, we showed that group lasso achieved higher prediction accuracy when the group prior knowledge was provided. We also found that GDP performed better than CPH for complex survival data. Furthermore, analysis on real data demonstrated that GDP performed favorably against other methods in several cancers with large-scale omics data sets, such as glioblastoma multiforme, kidney renal clear cell carcinoma, and bladder urothelial carcinoma. In summary, we demonstrated that GDP is a powerful tool for prognosis of patients with cancer, especially when large-scale molecular features are available.",True,other,Not specified
30874779,Assessment of a Deep Learning Model Based on Electronic Health Record Data to Forecast Clinical Outcomes in Patients With Rheumatoid Arthritis,"IMPORTANCE: Knowing the future condition of a patient would enable a physician to customize current therapeutic options to prevent disease worsening, but predicting that future condition requires sophisticated modeling and information. If artificial intelligence models were capable of forecasting future patient outcomes, they could be used to aid practitioners and patients in prognosticating outcomes or simulating potential outcomes under different treatment scenarios.
OBJECTIVE: To assess the ability of an artificial intelligence system to prognosticate the state of disease activity of patients with rheumatoid arthritis (RA) at their next clinical visit.
DESIGN, SETTING, AND PARTICIPANTS: This prognostic study included 820 patients with RA from rheumatology clinics at 2 distinct health care systems with different electronic health record platforms: a university hospital (UH) and a public safety-net hospital (SNH). The UH and SNH had substantially different patient populations and treatment patterns. The UH has records on approximately 1 million total patients starting in January 2012. The UH data for this study were accessed on July 1, 2017. The SNH has records on 65 000 unique individuals starting in January 2013. The SNH data for the study were collected on February 27, 2018.
EXPOSURES: Structured data were extracted from the electronic health record, including exposures (medications), patient demographics, laboratories, and prior measures of disease activity. A longitudinal deep learning model was used to predict disease activity for patients with RA at their next rheumatology clinic visit and to evaluate interhospital performance and model interoperability strategies.
MAIN OUTCOMES AND MEASURES: Model performance was quantified using the area under the receiver operating characteristic curve (AUROC). Disease activity in RA was measured using a composite index score.
RESULTS: A total of 578 UH patients (mean [SD] age, 57 [15] years; 477 [82.5%] female; 296 [51.2%] white) and 242 SNH patients (mean [SD] age, 60 [15] years; 195 [80.6%] female; 30 [12.4%] white) were included in the study. Patients at the UH compared with those at the SNH were seen more frequently (median time between visits, 100 vs 180 days) and were more frequently prescribed higher-class medications (biologics) (364 [63.0%] vs 70 [28.9%]). At the UH, the model reached an AUROC of 0.91 (95% CI, 0.86-0.96) in a test cohort of 116 patients. The UH-trained model had an AUROC of 0.74 (95% CI, 0.65-0.83) in the SNH test cohort (n = 117) despite marked differences in the patient populations. In both settings, baseline prediction using each patients' most recent disease activity score had statistically random performance.
CONCLUSIONS AND RELEVANCE: The findings suggest that building accurate models to forecast complex disease outcomes using electronic health record data is possible and these models can be shared across hospitals with diverse patient populations.",True,other,Not specified
30866562,Effects of Food Contamination on Gastrointestinal Morbidity: Comparison of Different Machine-Learning Methods,"Morbidity prediction can be useful in improving the effectiveness and efficiency of medical services, but accurate morbidity prediction is often difficult because of the complex relationships between diseases and their influencing factors. This study investigates the effects of food contamination on gastrointestinal-disease morbidities using eight different machine-learning models, including multiple linear regression, a shallow neural network, and three deep neural networks and their improved versions trained by an evolutionary algorithm. Experiments on the datasets from ten cities/counties in central China demonstrate that deep neural networks achieve significantly higher accuracy than classical linear-regression and shallow neural-network models, and the deep denoising autoencoder model with evolutionary learning exhibits the best prediction performance. The results also indicate that the prediction accuracies on acute gastrointestinal diseases are generally higher than those on other diseases, but the models are difficult to predict the morbidities of gastrointestinal tumors. This study demonstrates that evolutionary deep-learning models can be utilized to accurately predict the morbidities of most gastrointestinal diseases from food contamination, and this approach can be extended for the morbidity prediction of many other diseases.",True,other,recurrent neural network
30842562,Detection of chromosome structural variation by targeted next-generation sequencing and a deep learning application,"Molecular testing is increasingly important in cancer diagnosis. Targeted next generation sequencing (NGS) is widely accepted method but structural variation (SV) detection by targeted NGS remains challenging. In the brain tumor, identification of molecular alterations, including 1p/19q co-deletion, is essential for accurate glial tumor classification. Hence, we used targeted NGS to detect 1p/19q co-deletion using a newly developed deep learning (DL) model in 61 tumors, including 19 oligodendroglial tumors. An ensemble 1-dimentional convolution neural network was developed and used to detect the 1p/19q co-deletion. External validation was performed using 427 low-grade glial tumors from The Cancer Genome Atlas (TCGA). Manual review of the copy number plot from the targeted NGS identified the 1p/19q co-deletion in all 19 oligodendroglial tumors. Our DL model also perfectly detected the 1p/19q co-deletion (area under the curve, AUC = 1) in the testing set, and yielded reproducible results (AUC = 0.9652) in the validation set (n = 427), although the validation data were generated on a completely different platform (SNP Array 6.0 platform). In conclusion, targeted NGS using a cancer gene panel is a promising approach for classifying glial tumors, and DL can be successfully integrated for the SV detection in NGS data.",True,other,Not specified
30815669,Deep learning for cardiovascular medicine: a practical primer,"Deep learning (DL) is a branch of machine learning (ML) showing increasing promise in medicine, to assist in data classification, novel disease phenotyping and complex decision making. Deep learning is a form of ML typically implemented via multi-layered neural networks. Deep learning has accelerated by recent advances in computer hardware and algorithms and is increasingly applied in e-commerce, finance, and voice and image recognition to learn and classify complex datasets. The current medical literature shows both strengths and limitations of DL. Strengths of DL include its ability to automate medical image interpretation, enhance clinical decision-making, identify novel phenotypes, and select better treatment pathways in complex diseases. Deep learning may be well-suited to cardiovascular medicine in which haemodynamic and electrophysiological indices are increasingly captured on a continuous basis by wearable devices as well as image segmentation in cardiac imaging. However, DL also has significant weaknesses including difficulties in interpreting its models (the 'black-box' criticism), its need for extensive adjudicated ('labelled') data in training, lack of standardization in design, lack of data-efficiency in training, limited applicability to clinical trials, and other factors. Thus, the optimal clinical application of DL requires careful formulation of solvable problems, selection of most appropriate DL algorithms and data, and balanced interpretation of results. This review synthesizes the current state of DL for cardiovascular clinicians and investigators, and provides technical context to appreciate the promise, pitfalls, near-term challenges, and opportunities for this exciting new area.",True,other,recurrent neural network
30811548,deepBioWSD: effective deep neural word sense disambiguation of biomedical text data,"OBJECTIVE: In biomedicine, there is a wealth of information hidden in unstructured narratives such as research articles and clinical reports. To exploit these data properly, a word sense disambiguation (WSD) algorithm prevents downstream difficulties in the natural language processing applications pipeline. Supervised WSD algorithms largely outperform un- or semisupervised and knowledge-based methods; however, they train 1 separate classifier for each ambiguous term, necessitating a large number of expert-labeled training data, an unattainable goal in medical informatics. To alleviate this need, a single model that shares statistical strength across all instances and scales well with the vocabulary size is desirable.
MATERIALS AND METHODS: Built on recent advances in deep learning, our deepBioWSD model leverages 1 single bidirectional long short-term memory network that makes sense prediction for any ambiguous term. In the model, first, the Unified Medical Language System sense embeddings will be computed using their text definitions; and then, after initializing the network with these embeddings, it will be trained on all (available) training data collectively. This method also considers a novel technique for automatic collection of training data from PubMed to (pre)train the network in an unsupervised manner.
RESULTS: We use the MSH WSD dataset to compare WSD algorithms, with macro and micro accuracies employed as evaluation metrics. deepBioWSD outperforms existing models in biomedical text WSD by achieving the state-of-the-art performance of 96.82% for macro accuracy.
CONCLUSIONS: Apart from the disambiguation improvement and unsupervised training, deepBioWSD depends on considerably less number of expert-labeled data as it learns the target and the context terms jointly. These merit deepBioWSD to be conveniently deployable in real-time biomedical applications.",True,text mining,autoencoder
30779585,Multiple Machine Learning Comparisons of HIV Cell-based and Reverse Transcriptase Data Sets,"The human immunodeficiency virus (HIV) causes over a million deaths every year and has a huge economic impact in many countries. The first class of drugs approved were nucleoside reverse transcriptase inhibitors. A newer generation of reverse transcriptase inhibitors have become susceptible to drug resistant strains of HIV, and hence, alternatives are urgently needed. We have recently pioneered the use of Bayesian machine learning to generate models with public data to identify new compounds for testing against different disease targets. The current study has used the NIAID ChemDB HIV, Opportunistic Infection and Tuberculosis Therapeutics Database for machine learning studies. We curated and cleaned data from HIV-1 wild-type cell-based and reverse transcriptase (RT) DNA polymerase inhibition assays. Compounds from this database with ≤1 μM HIV-1 RT DNA polymerase activity inhibition and cell-based HIV-1 inhibition are correlated (Pearson r = 0.44, n = 1137, p < 0.0001). Models were trained using multiple machine learning approaches (Bernoulli Naive Bayes, AdaBoost Decision Tree, Random Forest, support vector classification, k-Nearest Neighbors, and deep neural networks as well as consensus approaches) and then their predictive abilities were compared. Our comparison of different machine learning methods demonstrated that support vector classification, deep learning, and a consensus were generally comparable and not significantly different from each other using 5-fold cross validation and using 24 training and test set combinations. This study demonstrates findings in line with our previous studies for various targets that training and testing with multiple data sets does not demonstrate a significant difference between support vector machine and deep neural networks.",True,other,Not specified
30765436,Diagnostic Accuracy of a Device for the Automated Detection of Diabetic Retinopathy in a Primary Care Setting,"OBJECTIVE: To determine the diagnostic accuracy in a real-world primary care setting of a deep learning-enhanced device for automated detection of diabetic retinopathy (DR).
RESEARCH DESIGN AND METHODS: Retinal images of people with type 2 diabetes visiting a primary care screening program were graded by a hybrid deep learning-enhanced device (IDx-DR-EU-2.1; IDx, Amsterdam, the Netherlands), and its classification of retinopathy (vision-threatening [vt]DR, more than mild [mtm]DR, and mild or more [mom]DR) was compared with a reference standard. This reference standard consisted of grading according to the International Clinical Classification of DR by the Rotterdam Study reading center. We determined the diagnostic accuracy of the hybrid deep learning-enhanced device (IDx-DR-EU-2.1) against the reference standard.
RESULTS: A total of 1,616 people with type 2 diabetes were imaged. The hybrid deep learning-enhanced device's sensitivity/specificity against the reference standard was, respectively, for vtDR 100% (95% CI 77.1-100)/97.8% (95% CI 96.8-98.5) and for mtmDR 79.4% (95% CI 66.5-87.9)/93.8% (95% CI 92.1-94.9).
CONCLUSIONS: The hybrid deep learning-enhanced device had high diagnostic accuracy for the detection of both vtDR (although the number of vtDR cases was low) and mtmDR in a primary care setting against an independent reading center. This allows its' safe use in a primary care setting.",True,other,recurrent neural network
30704458,Predicting drug response of tumors from integrated genomic profiles by deep neural networks,"BACKGROUND: The study of high-throughput genomic profiles from a pharmacogenomics viewpoint has provided unprecedented insights into the oncogenic features modulating drug response. A recent study screened for the response of a thousand human cancer cell lines to a wide collection of anti-cancer drugs and illuminated the link between cellular genotypes and vulnerability. However, due to essential differences between cell lines and tumors, to date the translation into predicting drug response in tumors remains challenging. Recently, advances in deep learning have revolutionized bioinformatics and introduced new techniques to the integration of genomic data. Its application on pharmacogenomics may fill the gap between genomics and drug response and improve the prediction of drug response in tumors.
RESULTS: We proposed a deep learning model to predict drug response (DeepDR) based on mutation and expression profiles of a cancer cell or a tumor. The model contains three deep neural networks (DNNs), i) a mutation encoder pre-trained using a large pan-cancer dataset (The Cancer Genome Atlas; TCGA) to abstract core representations of high-dimension mutation data, ii) a pre-trained expression encoder, and iii) a drug response predictor network integrating the first two subnetworks. Given a pair of mutation and expression profiles, the model predicts IC<sub>50</sub> values of 265 drugs. We trained and tested the model on a dataset of 622 cancer cell lines and achieved an overall prediction performance of mean squared error at 1.96 (log-scale IC<sub>50</sub> values). The performance was superior in prediction error or stability than two classical methods (linear regression and support vector machine) and four analog DNN models of DeepDR, including DNNs built without TCGA pre-training, partly replaced by principal components, and built on individual types of input data. We then applied the model to predict drug response of 9059 tumors of 33 cancer types. Using per-cancer and pan-cancer settings, the model predicted both known, including EGFR inhibitors in non-small cell lung cancer and tamoxifen in ER+ breast cancer, and novel drug targets, such as vinorelbine for TTN-mutated tumors. The comprehensive analysis further revealed the molecular mechanisms underlying the resistance to a chemotherapeutic drug docetaxel in a pan-cancer setting and the anti-cancer potential of a novel agent, CX-5461, in treating gliomas and hematopoietic malignancies.
CONCLUSIONS: Here we present, as far as we know, the first DNN model to translate pharmacogenomics features identified from in vitro drug screening to predict the response of tumors. The results covered both well-studied and novel mechanisms of drug resistance and drug targets. Our model and findings improve the prediction of drug response and the identification of novel therapeutic options.",True,other,Not specified
30689691,Reply to the letter to the editor 'Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists' by H. A. Haenssle et al,,True,other,GAN
30684090,Rheumatoid Arthritis: Atherosclerosis Imaging and Cardiovascular Risk Assessment Using Machine and Deep Learning-Based Tissue Characterization,"PURPOSE OF THE REVIEW: Rheumatoid arthritis (RA) is a chronic, autoimmune disease which may result in a higher risk of cardiovascular (CV) events and stroke. Tissue characterization and risk stratification of patients with rheumatoid arthritis are a challenging problem. Risk stratification of RA patients using traditional risk factor-based calculators either underestimates or overestimates the CV risk. Advancements in medical imaging have facilitated early and accurate CV risk stratification compared to conventional cardiovascular risk calculators.
RECENT FINDING: In recent years, a link between carotid atherosclerosis and rheumatoid arthritis has been widely discussed by multiple studies. Imaging the carotid artery using 2-D ultrasound is a noninvasive, economic, and efficient imaging approach that provides an atherosclerotic plaque tissue-specific image. Such images can help to morphologically characterize the plaque type and accurately measure vital phenotypes such as media wall thickness and wall variability. Intelligence-based paradigms such as machine learning- and deep learning-based techniques not only automate the risk characterization process but also provide an accurate CV risk stratification for better management of RA patients. This review provides a brief understanding of the pathogenesis of RA and its association with carotid atherosclerosis imaged using the B-mode ultrasound technique. Lacunas in traditional risk scores and the role of machine learning-based tissue characterization algorithms are discussed and could facilitate cardiovascular risk assessment in RA patients. The key takeaway points from this review are the following: (i) inflammation is a common link between RA and atherosclerotic plaque buildup, (ii) carotid ultrasound is a better choice to characterize the atherosclerotic plaque tissues in RA patients, and (iii) intelligence-based paradigms are useful for accurate tissue characterization and risk stratification of RA patients.",True,both,Not specified
30679510,Learning from Longitudinal Data in Electronic Health Record and Genetic Data to Improve Cardiovascular Event Prediction,"Current approaches to predicting a cardiovascular disease (CVD) event rely on conventional risk factors and cross-sectional data. In this study, we applied machine learning and deep learning models to 10-year CVD event prediction by using longitudinal electronic health record (EHR) and genetic data. Our study cohort included 109, 490 individuals. In the first experiment, we extracted aggregated and longitudinal features from EHR. We applied logistic regression, random forests, gradient boosting trees, convolutional neural networks (CNN) and recurrent neural networks with long short-term memory (LSTM) units. In the second experiment, we applied a late-fusion approach to incorporate genetic features. We compared the performance with approaches currently utilized in routine clinical practice - American College of Cardiology and the American Heart Association (ACC/AHA) Pooled Cohort Risk Equation. Our results indicated that incorporating longitudinal feature lead to better event prediction. Combining genetic features through a late-fusion approach can further improve CVD prediction, underscoring the importance of integrating relevant genetic data whenever available.",True,other,convolutional neural network
30652558,Deep Learning-Based Survival Analysis Identified Associations Between Molecular Subtype and Optimal Adjuvant Treatment of Patients With Gastric Cancer,"PURPOSE: Gastric cancer (GC) is the third-leading cause of cancer-related deaths. Several pivotal clinical trials of adjuvant treatments were performed during the previous decade; however, the optimal regimen for adjuvant treatment of GC remains controversial.
PATIENTS AND METHODS: We developed a novel deep learning-based survival model (survival recurrent network [SRN]) in patients with GC by including all available clinical and pathologic data and treatment regimens. This model uses time-sequential data only in the training step, and upon being trained, it receives the initial data from the first visit and then sequentially predicts the outcome at each time point until it reaches 5 years. In total, 1,190 patients from three cohorts (the Asian Cancer Research Group cohort, n = 300; the fluorouracil, leucovorin, and radiotherapy cohort, n = 432; and the Adjuvant Chemoradiation Therapy in Stomach Cancer cohort, n = 458) were included in the analysis. In addition, we added Asian Cancer Research Group molecular classifications into the prediction model. SRN simulated the sequential learning process of clinicians in the outpatient clinic using a recurrent neural network and time-sequential outcome data.
RESULTS: The mean area under the receiver operating characteristics curve was 0.92 ± 0.049 at the fifth year. The SRN demonstrated that GC with a mesenchymal subtype should elicit a more risk-adapted postoperative treatment strategy as a result of its high recurrence rate. In addition, the SRN found that GCs with microsatellite instability and GCs of the papillary type exhibited significantly more favorable survival outcomes after capecitabine plus cisplatin chemotherapy alone.
CONCLUSION: Our SRN predicted survival at a high rate, reaching 92% at postoperative year 5. Our findings suggest that SRN-based clinical trials or risk-adapted adjuvant trials could be considered for patients with GC to investigate more individualized adjuvant treatments after curative gastrectomy.",True,other,Not specified
32362304,Machine Learning and Deep Learning Approaches in Breast Cancer Survival Prediction Using Clinical Data,"Breast cancer survival prediction can have an extreme effect on selection of best treatment protocols. Many approaches such as statistical or machine learning models have been employed to predict the survival prospects of patients, but newer algorithms such as deep learning can be tested with the aim of improving the models and prediction accuracy. In this study, we used machine learning and deep learning approaches to predict breast cancer survival in 4,902 patient records from the University of Malaya Medical Centre Breast Cancer Registry. The results indicated that the multilayer perceptron (MLP), random forest (RF) and decision tree (DT) classifiers could predict survivorship, respectively, with 88.2 %, 83.3 % and 82.5 % accuracy in the tested samples. Support vector machine (SVM) came out to be lower with 80.5 %. In this study, tumour size turned out to be the most important feature for breast cancer survivability prediction. Both deep learning and machine learning methods produce desirable prediction accuracy, but other factors such as parameter configurations and data transformations affect the accuracy of the predictive model.",True,other,Not specified
30577835,GSAE: an autoencoder with embedded gene-set nodes for genomics functional characterization,"BACKGROUND: Bioinformatics tools have been developed to interpret gene expression data at the gene set level, and these gene set based analyses improve the biologists' capability to discover functional relevance of their experiment design. While elucidating gene set individually, inter-gene sets association is rarely taken into consideration. Deep learning, an emerging machine learning technique in computational biology, can be used to generate an unbiased combination of gene set, and to determine the biological relevance and analysis consistency of these combining gene sets by leveraging large genomic data sets.
RESULTS: In this study, we proposed a gene superset autoencoder (GSAE), a multi-layer autoencoder model with the incorporation of a priori defined gene sets that retain the crucial biological features in the latent layer. We introduced the concept of the gene superset, an unbiased combination of gene sets with weights trained by the autoencoder, where each node in the latent layer is a superset. Trained with genomic data from TCGA and evaluated with their accompanying clinical parameters, we showed gene supersets' ability of discriminating tumor subtypes and their prognostic capability. We further demonstrated the biological relevance of the top component gene sets in the significant supersets.
CONCLUSIONS: Using autoencoder model and gene superset at its latent layer, we demonstrated that gene supersets retain sufficient biological information with respect to tumor subtypes and clinical prognostic significance. Superset also provides high reproducibility on survival analysis and accurate prediction for cancer subtypes.",True,other,convolutional neural network
30573815,Deep learning enables de novo peptide sequencing from data-independent-acquisition mass spectrometry,"We present DeepNovo-DIA, a de novo peptide-sequencing method for data-independent acquisition (DIA) mass spectrometry data. We use neural networks to capture precursor and fragment ions across m/z, retention-time, and intensity dimensions. They are then further integrated with peptide sequence patterns to address the problem of highly multiplexed spectra. DIA coupled with de novo sequencing allowed us to identify novel peptides in human antibodies and antigens.",True,text mining,Not specified
30544648,Artificial Intelligence and Big Data in Public Health,"Artificial intelligence and automation are topics dominating global discussions on the future of professional employment, societal change, and economic performance. In this paper, we describe fundamental concepts underlying AI and Big Data and their significance to public health. We highlight issues involved and describe the potential impacts and challenges to medical professionals and diagnosticians. The possible benefits of advanced data analytics and machine learning are described in the context of recently reported research. Problems are identified and discussed with respect to ethical issues and the future roles of professionals and specialists in the age of artificial intelligence.",True,other,Not specified
30532223,Distillation of the clinical algorithm improves prognosis by multi-task deep learning in high-risk Neuroblastoma,"We introduce the CDRP (Concatenated Diagnostic-Relapse Prognostic) architecture for multi-task deep learning that incorporates a clinical algorithm, e.g., a risk stratification schema to improve prognostic profiling. We present the first application to survival prediction in High-Risk (HR) Neuroblastoma from transcriptomics data, a task that studies from the MAQC consortium have shown to remain the hardest among multiple diagnostic and prognostic endpoints predictable from the same dataset. To obtain a more accurate risk stratification needed for appropriate treatment strategies, CDRP combines a first component (CDRP-A) synthesizing a diagnostic task and a second component (CDRP-N) dedicated to one or more prognostic tasks. The approach leverages the advent of semi-supervised deep learning structures that can flexibly integrate multimodal data or internally create multiple processing paths. CDRP-A is an autoencoder trained on gene expression on the HR/non-HR risk stratification by the Children's Oncology Group, obtaining a 64-node representation in the bottleneck layer. CDRP-N is a multi-task classifier for two prognostic endpoints, i.e., Event-Free Survival (EFS) and Overall Survival (OS). CDRP-A provides the HR embedding input to the CDRP-N shared layer, from which two branches depart to model EFS and OS, respectively. To control for selection bias, CDRP is trained and evaluated using a Data Analysis Protocol (DAP) developed within the MAQC initiative. CDRP was applied on Illumina RNA-Seq of 498 Neuroblastoma patients (HR: 176) from the SEQC study (12,464 Entrez genes) and on Affymetrix Human Exon Array expression profiles (17,450 genes) of 247 primary diagnostic Neuroblastoma of the TARGET NBL cohort. On the SEQC HR patients, CDRP achieves Matthews Correlation Coefficient (MCC) 0.38 for EFS and MCC = 0.19 for OS in external validation, improving over published SEQC models. We show that a CDRP-N embedding is indeed parametrically associated to increasing severity and the embedding can be used to better stratify patients' survival.",True,other,Not specified
30500819,Deep learning for lung cancer prognostication: A retrospective multi-cohort radiomics study,"BACKGROUND: Non-small-cell lung cancer (NSCLC) patients often demonstrate varying clinical courses and outcomes, even within the same tumor stage. This study explores deep learning applications in medical imaging allowing for the automated quantification of radiographic characteristics and potentially improving patient stratification.
METHODS AND FINDINGS: We performed an integrative analysis on 7 independent datasets across 5 institutions totaling 1,194 NSCLC patients (age median = 68.3 years [range 32.5-93.3], survival median = 1.7 years [range 0.0-11.7]). Using external validation in computed tomography (CT) data, we identified prognostic signatures using a 3D convolutional neural network (CNN) for patients treated with radiotherapy (n = 771, age median = 68.0 years [range 32.5-93.3], survival median = 1.3 years [range 0.0-11.7]). We then employed a transfer learning approach to achieve the same for surgery patients (n = 391, age median = 69.1 years [range 37.2-88.0], survival median = 3.1 years [range 0.0-8.8]). We found that the CNN predictions were significantly associated with 2-year overall survival from the start of respective treatment for radiotherapy (area under the receiver operating characteristic curve [AUC] = 0.70 [95% CI 0.63-0.78], p < 0.001) and surgery (AUC = 0.71 [95% CI 0.60-0.82], p < 0.001) patients. The CNN was also able to significantly stratify patients into low and high mortality risk groups in both the radiotherapy (p < 0.001) and surgery (p = 0.03) datasets. Additionally, the CNN was found to significantly outperform random forest models built on clinical parameters-including age, sex, and tumor node metastasis stage-as well as demonstrate high robustness against test-retest (intraclass correlation coefficient = 0.91) and inter-reader (Spearman's rank-order correlation = 0.88) variations. To gain a better understanding of the characteristics captured by the CNN, we identified regions with the most contribution towards predictions and highlighted the importance of tumor-surrounding tissue in patient stratification. We also present preliminary findings on the biological basis of the captured phenotypes as being linked to cell cycle and transcriptional processes. Limitations include the retrospective nature of this study as well as the opaque black box nature of deep learning networks.
CONCLUSIONS: Our results provide evidence that deep learning networks may be used for mortality risk stratification based on standard-of-care CT images from NSCLC patients. This evidence motivates future research into better deciphering the clinical and biological basis of deep learning networks as well as validation in prospective data.",True,other,Not specified
30480079,"Fusion of deep learning models of MRI scans, Mini-Mental State Examination, and logical memory test enhances diagnosis of mild cognitive impairment","INTRODUCTION: Our aim was to investigate if the accuracy of diagnosing mild cognitive impairment (MCI) using the Mini-Mental State Examination (MMSE) and logical memory (LM) test could be enhanced by adding MRI data.
METHODS: Data of individuals with normal cognition and MCI were obtained from the National Alzheimer Coordinating Center database (n = 386). Deep learning models trained on MRI slices were combined to generate a fused MRI model using different voting techniques to predict normal cognition versus MCI. Two multilayer perceptron (MLP) models were developed with MMSE and LM test results. Finally, the fused MRI model and the MLP models were combined using majority voting.
RESULTS: The fusion model was superior to the individual models alone and achieved an overall accuracy of 90.9%.
DISCUSSION: This study is a proof of principle that multimodal fusion of models developed using MRI scans, MMSE, and LM test data is feasible and can better predict MCI.",True,other,recurrent neural network
30470715,Evaluation of a deep learning image assessment system for detecting severe retinopathy of prematurity,"BACKGROUND: Prior work has demonstrated the near-perfect accuracy of a deep learning retinal image analysis system for diagnosing plus disease in retinopathy of prematurity (ROP). Here we assess the screening potential of this scoring system by determining its ability to detect all components of ROP diagnosis.
METHODS: Clinical examination and fundus photography were performed at seven participating centres. A deep learning system was trained to detect plus disease, generating a quantitative assessment of retinal vascular abnormality (the i-ROP plus score) on a 1-9 scale. Overall ROP disease category was established using a consensus reference standard diagnosis combining clinical and image-based diagnosis. Experts then ranked ordered a second data set of 100 posterior images according to overall ROP severity.
RESULTS: 4861 examinations from 870 infants were analysed. 155 examinations (3%) had a reference standard diagnosis of type 1 ROP. The i-ROP deep learning (DL) vascular severity score had an area under the receiver operating curve of 0.960 for detecting type 1 ROP. Establishing a threshold i-ROP DL score of 3 conferred 94% sensitivity, 79% specificity, 13% positive predictive value and 99.7% negative predictive value for type 1 ROP. There was strong correlation between expert rank ordering of overall ROP severity and the i-ROP DL vascular severity score (Spearman correlation coefficient=0.93; p<0.0001).
CONCLUSION: The i-ROP DL system accurately identifies diagnostic categories and overall disease severity in an automated fashion, after being trained only on posterior pole vascular morphology. These data provide proof of concept that a deep learning screening platform could improve objectivity of ROP diagnosis and accessibility of screening.",True,other,recurrent neural network
30410601,"Multiple Machine Learnings Revealed Similar Predictive Accuracy for Prognosis of PNETs from the Surveillance, Epidemiology, and End Result Database","Background: Prognosis prediction is indispensable in clinical practice and machine learning has been proved to be helpful. We expected to predict survival of pancreatic neuroendocrine tumors (PNETs) with machine learning, and compared it with the American Joint Committee on Cancer (AJCC) staging system. Methods: Data of PNETs cases were extracted from The Surveillance, Epidemiology, and End Result (SEER) database. Statistic description, multivariate survival analysis and preprocessing were done before machine learning. Four different algorithms (logistic regression (LR), support vector machines (SVM), random forest (RF) and deep learning (DL)) were used to train the model. We used proper imputations to manage missing data in the database and sensitive analysis was performed to evaluate the imputation. The model with the best predictive accuracy was compared with the AJCC staging system using the SEER cases. Results: The four models had similar predictive accuracy with no significant difference existed (p = 0.664). The DL model showed a slightly better predictive accuracy than others (81.6% (± 1.9%)), thus it was used for further comparison with the AJCC staging system and revealed a better performance for PNETs cases in SEER database (Area under receiver operating characteristic curve: 0.87 vs 0.76). The validity of missing data imputation was supported by sensitivity analysis. Conclusions: The models developed with machine learning performed well in survival prediction of PNETs, and the DL model have a better accuracy and specificity than the AJCC staging system in SEER data. The DL model has potential for clinical application but external validation is needed.",True,other,recurrent neural network
30401843,Machine learning spots natural selection at work in human genome,,True,other,GAN
30381856,Artificial intelligence and amniotic fluid multiomics: prediction of perinatal outcome in asymptomatic women with short cervix,"OBJECTIVE: To evaluate the application of artificial intelligence (AI), i.e. deep learning and other machine-learning techniques, to amniotic fluid (AF) metabolomics and proteomics, alone and in combination with sonographic, clinical and demographic factors, in the prediction of perinatal outcome in asymptomatic pregnant women with short cervical length (CL).
METHODS: AF samples, which had been obtained in the second trimester from asymptomatic women with short CL (< 15 mm) identified on transvaginal ultrasound, were analyzed. CL, funneling and the presence of AF 'sludge' were assessed in all cases close to the time of amniocentesis. A combination of liquid chromatography coupled with mass spectrometry and proton nuclear magnetic resonance spectroscopy-based metabolomics, as well as targeted proteomics analysis, including chemokines, cytokines and growth factors, was performed on the AF samples. To determine the robustness of the markers, we used six different machine-learning techniques, including deep learning, to predict preterm delivery < 34 weeks, latency period prior to delivery < 28 days after amniocentesis and requirement for admission to a neonatal intensive care unit (NICU). Omics biomarkers were evaluated alone and in combination with standard sonographic, clinical and demographic factors to predict outcome. Predictive accuracy was assessed using the area under the receiver-operating characteristics curve (AUC) with 95% CI, sensitivity and specificity.
RESULTS: Of the 32 patients included in the study, complete omics, demographic and clinical data and outcome information were available for 26. Of these, 11 (42.3%) patients delivered ≥ 34 weeks, while 15 (57.7%) delivered < 34 weeks. There was no statistically significant difference in CL between these two groups (mean ± SD, 11.2 ± 4.4 mm vs 8.9 ± 5.3 mm, P = 0.31). Using combined omics, demographic and clinical data, deep learning displayed good to excellent performance, with an AUC (95% CI) of 0.890 (0.810-0.970) for delivery < 34 weeks' gestation, 0.890 (0.790-0.990) for delivery < 28 days post-amniocentesis and 0.792 (0.689-0.894) for NICU admission. These values were higher overall than for the other five machine-learning methods, although each individual machine-learning technique yielded statistically significant prediction of the different perinatal outcomes.
CONCLUSIONS: This is the first study to report use of AI with AF proteomics and metabolomics and ultrasound assessment in pregnancy. Machine learning, particularly deep learning, achieved good to excellent prediction of perinatal outcome in asymptomatic pregnant women with short CL in the second trimester. Copyright © 2018 ISUOG. Published by John Wiley & Sons Ltd.",True,other,Not specified
30356094,Identifying substance use risk based on deep neural networks and Instagram social media data,"Social media may provide new insight into our understanding of substance use and addiction. In this study, we developed a deep-learning method to automatically classify individuals' risk for alcohol, tobacco, and drug use based on the content from their Instagram profiles. In total, 2287 active Instagram users participated in the study. Deep convolutional neural networks for images and long short-term memory (LSTM) for text were used to extract predictive features from these data for risk assessment. The evaluation of our approach on a held-out test set of 228 individuals showed that among the substances we evaluated, our method could estimate the risk of alcohol abuse with statistical significance. These results are the first to suggest that deep-learning approaches applied to social media data can be used to identify potential substance use risk behavior, such as alcohol use. Utilization of automated estimation techniques can provide new insights for the next generation of population-level risk assessment and intervention delivery.",True,other,Not specified
30274956,Machine learning for real-time prediction of complications in critical care: a retrospective study,"BACKGROUND: The large amount of clinical signals in intensive care units can easily overwhelm health-care personnel and can lead to treatment delays, suboptimal care, or clinical errors. The aim of this study was to apply deep machine learning methods to predict severe complications during critical care in real time after cardiothoracic surgery.
METHODS: We used deep learning methods (recurrent neural networks) to predict several severe complications (mortality, renal failure with a need for renal replacement therapy, and postoperative bleeding leading to operative revision) in post cardiosurgical care in real time. Adult patients who underwent major open heart surgery from Jan 1, 2000, to Dec 31, 2016, in a German tertiary care centre for cardiovascular diseases formed the main derivation dataset. We measured the accuracy and timeliness of the deep learning model's forecasts and compared predictive quality to that of established standard-of-care clinical reference tools (clinical rule for postoperative bleeding, Simplified Acute Physiology Score II for mortality, and the Kidney Disease: Improving Global Outcomes staging criteria for acute renal failure) using positive predictive value (PPV), negative predictive value, sensitivity, specificity, area under the curve (AUC), and the F<sub>1</sub> measure (which computes a harmonic mean of sensitivity and PPV). Results were externally retrospectively validated with 5898 cases from the published MIMIC-III dataset.
FINDINGS: Of 47 559 intensive care admissions (corresponding to 42 007 patients), we included 11 492 (corresponding to 9269 patients). The deep learning models yielded accurate predictions with the following PPV and sensitivity scores: PPV 0·90 and sensitivity 0·85 for mortality, 0·87 and 0·94 for renal failure, and 0·84 and 0·74 for bleeding. The predictions significantly outperformed the standard clinical reference tools, improving the absolute complication prediction AUC by 0·29 (95% CI 0·23-0·35) for bleeding, by 0·24 (0·19-0·29) for mortality, and by 0·24 (0·13-0·35) for renal failure (p<0·0001 for all three analyses). The deep learning methods showed accurate predictions immediately after patient admission to the intensive care unit. We also observed an increase in performance in our validation cohort when the machine learning approach was tested against clinical reference tools, with absolute improvements in AUC of 0·09 (95% CI 0·03-0·15; p=0·0026) for bleeding, of 0·18 (0·07-0·29; p=0·0013) for mortality, and of 0·25 (0·18-0·32; p<0·0001) for renal failure.
INTERPRETATION: The observed improvements in prediction for all three investigated clinical outcomes have the potential to improve critical care. These findings are noteworthy in that they use routinely collected clinical data exclusively, without the need for any manual processing. The deep machine learning method showed AUC scores that significantly surpass those of clinical reference tools, especially soon after admission. Taken together, these properties are encouraging for prospective deployment in critical care settings to direct the staff's attention towards patients who are most at risk.
FUNDING: No specific funding.",True,other,Not specified
30261823,Deep learning approach for survival prediction for patients with synovial sarcoma,"Synovial sarcoma is a rare disease with diverse progression characteristics. We developed a novel deep-learning-based prediction algorithm for survival rates of synovial sarcoma patients. The purpose of this study is to evaluate the performance of the proposed prediction model and demonstrate its clinical usage. The study involved 242 patients who were diagnosed with synovial sarcoma in three institutions between March 2001 and February 2013. The patients were randomly divided into a training set (80%) and a testing set (20%). Fivefold cross validation was performed utilizing the training set. The test set was retained for the final testing. A Cox proportional hazard model, simple neural network, and the proposed survival neural network were all trained utilizing the same training set, and fivefold cross validation was performed. The final testing was performed utilizing the isolated test data to determine the best prediction model. The multivariate Cox proportional hazard regression analysis revealed that size, initial metastasis, and margin were independent prognostic factors. In fivefold cross validation, the median value of the receiver-operating characteristic curve (area under the curve) was 0.87 in the survival neural network, which is significantly higher compared to the area under the curve of 0.792 for the simple neural network (p = 0.043). In the final test, survival neural network model showed the better performance (area under the curve: 0.814) compared to the Cox proportional hazard model (area under the curve: 0.629; p = 0.0001). The survival neural network model predicted survival of synovial sarcoma patients more accurately compared to Cox proportional hazard model.",True,other,Not specified
30213980,G2Vec: Distributed gene representations for identification of cancer prognostic genes,"Identification of cancer prognostic genes is important in that it can lead to accurate outcome prediction and better therapeutic trials for cancer patients. Many computational approaches have been proposed to achieve this goal; however, there is room for improvement. Recent developments in deep learning techniques can aid in the identification of better prognostic genes and more accurate outcome prediction, but one of the main problems in the adoption of deep learning for this purpose is that data from cancer patients have too many dimensions, while the number of samples is relatively small. In this study, we propose a novel network-based deep learning method to identify prognostic gene signatures via distributed gene representations generated by G2Vec, which is a modified Word2Vec model originally used for natural language processing. We applied the proposed method to five cancer types including liver cancer and showed that G2Vec outperformed extant feature selection methods, especially for small number of samples. Moreover, biomarkers identified by G2Vec was useful to find significant prognostic gene modules associated with hepatocellular carcinoma.",True,other,convolutional neural network
30171033,Can Deep Learning Improve Genomic Prediction of Complex Human Traits?,"The genetic analysis of complex traits does not escape the current excitement around artificial intelligence, including a renewed interest in ""deep learning"" (DL) techniques such as Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs). However, the performance of DL for genomic prediction of complex human traits has not been comprehensively tested. To provide an evaluation of MLPs and CNNs, we used data from distantly related white Caucasian individuals (n ∼100k individuals, m ∼500k SNPs, and k = 1000) of the interim release of the UK Biobank. We analyzed a total of five phenotypes: height, bone heel mineral density, body mass index, systolic blood pressure, and waist-hip ratio, with genomic heritabilities ranging from ∼0.20 to 0.70. After hyperparameter optimization using a genetic algorithm, we considered several configurations, from shallow to deep learners, and compared the predictive performance of MLPs and CNNs with that of Bayesian linear regressions across sets of SNPs (from 10k to 50k) that were preselected using single-marker regression analyses. For height, a highly heritable phenotype, all methods performed similarly, although CNNs were slightly but consistently worse. For the rest of the phenotypes, the performance of some CNNs was comparable or slightly better than linear methods. Performance of MLPs was highly dependent on SNP set and phenotype. In all, over the range of traits evaluated in this study, CNN performance was competitive to linear models, but we did not find any case where DL outperformed the linear model by a sizable margin. We suggest that more research is needed to adapt CNN methodology, originally motivated by image analysis, to genetic-based problems in order for CNNs to be competitive with linear models.",True,other,recurrent neural network
30104757,Automated Gleason grading of prostate cancer tissue microarrays via deep learning,"The Gleason grading system remains the most powerful prognostic predictor for patients with prostate cancer since the 1960s. Its application requires highly-trained pathologists, is tedious and yet suffers from limited inter-pathologist reproducibility, especially for the intermediate Gleason score 7. Automated annotation procedures constitute a viable solution to remedy these limitations. In this study, we present a deep learning approach for automated Gleason grading of prostate cancer tissue microarrays with Hematoxylin and Eosin (H&E) staining. Our system was trained using detailed Gleason annotations on a discovery cohort of 641 patients and was then evaluated on an independent test cohort of 245 patients annotated by two pathologists. On the test cohort, the inter-annotator agreements between the model and each pathologist, quantified via Cohen's quadratic kappa statistic, were 0.75 and 0.71 respectively, comparable with the inter-pathologist agreement (kappa = 0.71). Furthermore, the model's Gleason score assignments achieved pathology expert-level stratification of patients into prognostically distinct groups, on the basis of disease-specific survival data available for the test cohort. Overall, our study shows promising results regarding the applicability of deep learning-based solutions towards more objective and reproducible prostate cancer grading, especially for cases with heterogeneous Gleason patterns.",True,other,Not specified
30034349,A Deep Learning Approach for Predicting Antidepressant Response in Major Depression Using Clinical and Genetic Biomarkers,"In the wake of recent advances in scientific research, personalized medicine using deep learning techniques represents a new paradigm. In this work, our goal was to establish deep learning models which distinguish responders from non-responders, and also to predict possible antidepressant treatment outcomes in major depressive disorder (MDD). To uncover relationships between the responsiveness of antidepressant treatment and biomarkers, we developed a deep learning prediction approach resulting from the analysis of genetic and clinical factors such as single nucleotide polymorphisms (SNPs), age, sex, baseline Hamilton Rating Scale for Depression score, depressive episodes, marital status, and suicide attempt status of MDD patients. The cohort consisted of 455 patients who were treated with selective serotonin reuptake inhibitors (treatment-response rate = 61.0%; remission rate = 33.0%). By using the SNP dataset that was original to a genome-wide association study, we selected 10 SNPs (including ABCA13 rs4917029, BNIP3 rs9419139, CACNA1E rs704329, EXOC4 rs6978272, GRIN2B rs7954376, LHFPL3 rs4352778, NELL1 rs2139423, NUAK1 rs2956406, PREX1 rs4810894, and SLIT3 rs139863958) which were associated with antidepressant treatment response. Furthermore, we pinpointed 10 SNPs (including ARNTL rs11022778, CAMK1D rs2724812, GABRB3 rs12904459, GRM8 rs35864549, NAALADL2 rs9878985, NCALD rs483986, PLA2G4A rs12046378, PROK2 rs73103153, RBFOX1 rs17134927, and ZNF536 rs77554113) in relation to remission. Then, we employed multilayer feedforward neural networks (MFNNs) containing 1-3 hidden layers and compared MFNN models with logistic regression models. Our analysis results revealed that the MFNN model with 2 hidden layers (area under the receiver operating characteristic curve (AUC) = 0.8228 ± 0.0571; sensitivity = 0.7546 ± 0.0619; specificity = 0.6922 ± 0.0765) performed maximally among predictive models to infer the complex relationship between antidepressant treatment response and biomarkers. In addition, the MFNN model with 3 hidden layers (AUC = 0.8060 ± 0.0722; sensitivity = 0.7732 ± 0.0583; specificity = 0.6623 ± 0.0853) achieved best among predictive models to predict remission. Our study indicates that the deep MFNN framework may provide a suitable method to establish a tool for distinguishing treatment responders from non-responders prior to antidepressant therapy.",True,other,Not specified
29950020,Deep neural networks and distant supervision for geographic location mention extraction,"MOTIVATION: Virus phylogeographers rely on DNA sequences of viruses and the locations of the infected hosts found in public sequence databases like GenBank for modeling virus spread. However, the locations in GenBank records are often only at the country or state level, and may require phylogeographers to scan the journal articles associated with the records to identify more localized geographic areas. To automate this process, we present a named entity recognizer (NER) for detecting locations in biomedical literature. We built the NER using a deep feedforward neural network to determine whether a given token is a toponym or not. To overcome the limited human annotated data available for training, we use distant supervision techniques to generate additional samples to train our NER.
RESULTS: Our NER achieves an F1-score of 0.910 and significantly outperforms the previous state-of-the-art system. Using the additional data generated through distant supervision further boosts the performance of the NER achieving an F1-score of 0.927. The NER presented in this research improves over previous systems significantly. Our experiments also demonstrate the NER's capability to embed external features to further boost the system's performance. We believe that the same methodology can be applied for recognizing similar biomedical entities in scientific literature.",True,text mining,Not specified
29888072,Deep Learning data integration for better risk stratification models of bladder cancer,"We propose an unsupervised multi-omics integration pipeline, using deep-learning autoencoder algorithm, to predict the survival subtypes in bladder cancer (BC). We used TCGA dataset comprising mRNA, miRNA and methylation to infer two survival subtypes. We then constructed a supervised classification model to predict the survival subgroups of any new individual sample. Our training data gave two subgroups with significant survival differences (p-value=8e-4), where high-risk survival subgroup was enriched with KRT6/14 overexpression and PI3K-Akt pathways. We tested the robustness of model by randomly splitting the main dataset into multiple training and test folds, which gave overall significant p-values. Then, we successfully inferred the subtypes for a subset of samples kept as test dataset (p-value=0.03). We further applied our pipeline to predict the survival subgroups from another validation dataset with miRNA data (p-value=0.02). Conclusively, present pipeline is an effective approach to infer the survival subtype of a new sample, exemplified by BC.",True,other,Not specified
29664888,Development and Validation of a Deep Neural Network Model for Prediction of Postoperative In-hospital Mortality,"WHAT WE ALREADY KNOW ABOUT THIS TOPIC: WHAT THIS ARTICLE TELLS US THAT IS NEW: BACKGROUND:: The authors tested the hypothesis that deep neural networks trained on intraoperative features can predict postoperative in-hospital mortality.
METHODS: The data used to train and validate the algorithm consists of 59,985 patients with 87 features extracted at the end of surgery. Feed-forward networks with a logistic output were trained using stochastic gradient descent with momentum. The deep neural networks were trained on 80% of the data, with 20% reserved for testing. The authors assessed improvement of the deep neural network by adding American Society of Anesthesiologists (ASA) Physical Status Classification and robustness of the deep neural network to a reduced feature set. The networks were then compared to ASA Physical Status, logistic regression, and other published clinical scores including the Surgical Apgar, Preoperative Score to Predict Postoperative Mortality, Risk Quantification Index, and the Risk Stratification Index.
RESULTS: In-hospital mortality in the training and test sets were 0.81% and 0.73%. The deep neural network with a reduced feature set and ASA Physical Status classification had the highest area under the receiver operating characteristics curve, 0.91 (95% CI, 0.88 to 0.93). The highest logistic regression area under the curve was found with a reduced feature set and ASA Physical Status (0.90, 95% CI, 0.87 to 0.93). The Risk Stratification Index had the highest area under the receiver operating characteristics curve, at 0.97 (95% CI, 0.94 to 0.99).
CONCLUSIONS: Deep neural networks can predict in-hospital mortality based on automatically extractable intraoperative data, but are not (yet) superior to existing methods.",True,other,recurrent neural network
29594181,Predicting malignant nodules by fusing deep features with classical radiomics features,"Lung cancer has a high incidence and mortality rate. Early detection and diagnosis of lung cancers is best achieved with low-dose computed tomography (CT). Classical radiomics features extracted from lung CT images have been shown as able to predict cancer incidence and prognosis. With the advancement of deep learning and convolutional neural networks (CNNs), deep features can be identified to analyze lung CTs for prognosis prediction and diagnosis. Due to a limited number of available images in the medical field, the transfer learning concept can be helpful. Using subsets of participants from the National Lung Screening Trial (NLST), we utilized a transfer learning approach to differentiate lung cancer nodules versus positive controls. We experimented with three different pretrained CNNs for extracting deep features and used five different classifiers. Experiments were also conducted with deep features from different color channels of a pretrained CNN. Selected deep features were combined with radiomics features. A CNN was designed and trained. Combinations of features from pretrained, CNNs trained on NLST data, and classical radiomics were used to build classifiers. The best accuracy (76.79%) was obtained using feature combinations. An area under the receiver operating characteristic curve of 0.87 was obtained using a CNN trained on an augmented NLST data cohort.",True,other,Not specified
29581968,A Risk Stratification Model for Lung Cancer Based on Gene Coexpression Network and Deep Learning,"Risk stratification model for lung cancer with gene expression profile is of great interest. Instead of previous models based on individual prognostic genes, we aimed to develop a novel system-level risk stratification model for lung adenocarcinoma based on gene coexpression network. Using multiple microarray, gene coexpression network analysis was performed to identify survival-related networks. A deep learning based risk stratification model was constructed with representative genes of these networks. The model was validated in two test sets. Survival analysis was performed using the output of the model to evaluate whether it could predict patients' survival independent of clinicopathological variables. Five networks were significantly associated with patients' survival. Considering prognostic significance and representativeness, genes of the two survival-related networks were selected for input of the model. The output of the model was significantly associated with patients' survival in two test sets and training set (p &lt; 0.00001, p &lt; 0.0001 and p = 0.02 for training and test sets 1 and 2, resp.). In multivariate analyses, the model was associated with patients' prognosis independent of other clinicopathological features. Our study presents a new perspective on incorporating gene coexpression networks into the gene expression signature and clinical application of deep learning in genomic data science for prognosis prediction.",True,other,Not specified
29494731,Detecting Chemotherapeutic Skin Adverse Reactions in Social Health Networks Using Deep Learning,This study reports proof-of-principle early detection of chemotherapeutic-associated skin adverse drug reactions from social health networks using a deep learning–based signal generation pipeline to capture how patients describe cutaneous eruptions.,True,other,Not specified
29486341,Predicting central line-associated bloodstream infections and mortality using supervised machine learning,"PURPOSE: The purpose of this study was to compare machine learning techniques for predicting central line-associated bloodstream infection (CLABSI).
MATERIALS AND METHODS: The Multiparameter Intelligent Monitoring in Intensive Care III database was queried for all ICU admissions. The variables included six different severities of illness scores calculated on the first day of ICU admission with their components and comorbidities. The outcomes of interest were in-hospital mortality, central line placement, and CLABSI. Predictive models were created for these outcomes using classifiers with different algorithms: logistic regression, gradient boosted trees, and deep learning.
RESULTS: There were 57,786 total hospital admissions and the mortality rate was 10.1%. There were 38.4% patients with a central line and the rate of CLABSI was 1.5%. The classifiers using deep learning performed with the highest AUC for mortality, 0.885±0.010 (p<0.01) and central line placement, 0.816±0.006 (p<0.01). The classifier using logistic regression for predicting CLABSI performed with an AUC of 0.722±0.048 (p<0.01).
CONCLUSIONS: This study demonstrates models for identifying patients who will develop CLABSI. Early identification of these patients has implications for quality, cost, and outcome improvements.",True,other,Not specified
29471912,Detection of tuberculosis patterns in digital photographs of chest X-ray images using Deep Learning: feasibility study,"OBJECTIVE: To evaluate the feasibility of Deep Learning-based detection and classification of pathological patterns in a set of digital photographs of chest X-ray (CXR) images of tuberculosis (TB) patients.
MATERIALS AND METHODS: In this prospective, observational study, patients with previously diagnosed TB were enrolled. Photographs of their CXRs were taken using a consumer-grade digital still camera. The images were stratified by pathological patterns into classes: cavity, consolidation, effusion, interstitial changes, miliary pattern or normal examination. Image analysis was performed with commercially available Deep Learning software in two steps. Pathological areas were first localised; detected areas were then classified. Detection was assessed using receiver operating characteristics (ROC) analysis, and classification using a confusion matrix.
RESULTS: The study cohort was 138 patients with human immunodeficiency virus (HIV) and TB co-infection (median age 34 years, IQR 28-40); 54 patients were female. Localisation of pathological areas was excellent (area under the ROC curve 0.82). The software could perfectly distinguish pleural effusions from intraparenchymal changes. The most frequent misclassifications were consolidations as cavitations, and miliary patterns as interstitial patterns (and vice versa).
CONCLUSION: Deep Learning analysis of CXR photographs is a promising tool. Further efforts are needed to build larger, high-quality data sets to achieve better diagnostic performance.",True,other,Not specified
29309734,Methodologic Guide for Evaluating Clinical Performance and Effect of Artificial Intelligence Technology for Medical Diagnosis and Prediction,"The use of artificial intelligence in medicine is currently an issue of great interest, especially with regard to the diagnostic or predictive analysis of medical images. Adoption of an artificial intelligence tool in clinical practice requires careful confirmation of its clinical utility. Herein, the authors explain key methodology points involved in a clinical evaluation of artificial intelligence technology for use in medicine, especially high-dimensional or overparameterized diagnostic or predictive models in which artificial deep neural networks are used, mainly from the standpoints of clinical epidemiology and biostatistics. First, statistical methods for assessing the discrimination and calibration performances of a diagnostic or predictive model are summarized. Next, the effects of disease manifestation spectrum and disease prevalence on the performance results are explained, followed by a discussion of the difference between evaluating the performance with use of internal and external datasets, the importance of using an adequate external dataset obtained from a well-defined clinical cohort to avoid overestimating the clinical performance as a result of overfitting in high-dimensional or overparameterized classification model and spectrum bias, and the essentials for achieving a more robust clinical evaluation. Finally, the authors review the role of clinical trials and observational outcome studies for ultimate clinical verification of diagnostic or predictive artificial intelligence tools through patient outcomes, beyond performance metrics, and how to design such studies. © RSNA, 2018.",True,other,convolutional neural network
29234807,Development and Validation of a Deep Learning System for Diabetic Retinopathy and Related Eye Diseases Using Retinal Images From Multiethnic Populations With Diabetes,"IMPORTANCE: A deep learning system (DLS) is a machine learning technology with potential for screening diabetic retinopathy and related eye diseases.
OBJECTIVE: To evaluate the performance of a DLS in detecting referable diabetic retinopathy, vision-threatening diabetic retinopathy, possible glaucoma, and age-related macular degeneration (AMD) in community and clinic-based multiethnic populations with diabetes.
DESIGN, SETTING, AND PARTICIPANTS: Diagnostic performance of a DLS for diabetic retinopathy and related eye diseases was evaluated using 494 661 retinal images. A DLS was trained for detecting diabetic retinopathy (using 76 370 images), possible glaucoma (125 189 images), and AMD (72 610 images), and performance of DLS was evaluated for detecting diabetic retinopathy (using 112 648 images), possible glaucoma (71 896 images), and AMD (35 948 images). Training of the DLS was completed in May 2016, and validation of the DLS was completed in May 2017 for detection of referable diabetic retinopathy (moderate nonproliferative diabetic retinopathy or worse) and vision-threatening diabetic retinopathy (severe nonproliferative diabetic retinopathy or worse) using a primary validation data set in the Singapore National Diabetic Retinopathy Screening Program and 10 multiethnic cohorts with diabetes.
EXPOSURES: Use of a deep learning system.
MAIN OUTCOMES AND MEASURES: Area under the receiver operating characteristic curve (AUC) and sensitivity and specificity of the DLS with professional graders (retinal specialists, general ophthalmologists, trained graders, or optometrists) as the reference standard.
RESULTS: In the primary validation dataset (n = 14 880 patients; 71 896 images; mean [SD] age, 60.2 [2.2] years; 54.6% men), the prevalence of referable diabetic retinopathy was 3.0%; vision-threatening diabetic retinopathy, 0.6%; possible glaucoma, 0.1%; and AMD, 2.5%. The AUC of the DLS for referable diabetic retinopathy was 0.936 (95% CI, 0.925-0.943), sensitivity was 90.5% (95% CI, 87.3%-93.0%), and specificity was 91.6% (95% CI, 91.0%-92.2%). For vision-threatening diabetic retinopathy, AUC was 0.958 (95% CI, 0.956-0.961), sensitivity was 100% (95% CI, 94.1%-100.0%), and specificity was 91.1% (95% CI, 90.7%-91.4%). For possible glaucoma, AUC was 0.942 (95% CI, 0.929-0.954), sensitivity was 96.4% (95% CI, 81.7%-99.9%), and specificity was 87.2% (95% CI, 86.8%-87.5%). For AMD, AUC was 0.931 (95% CI, 0.928-0.935), sensitivity was 93.2% (95% CI, 91.1%-99.8%), and specificity was 88.7% (95% CI, 88.3%-89.0%). For referable diabetic retinopathy in the 10 additional datasets, AUC range was 0.889 to 0.983 (n = 40 752 images).
CONCLUSIONS AND RELEVANCE: In this evaluation of retinal images from multiethnic cohorts of patients with diabetes, the DLS had high sensitivity and specificity for identifying diabetic retinopathy and related eye diseases. Further research is necessary to evaluate the applicability of the DLS in health care settings and the utility of the DLS to improve vision outcomes.",True,other,Not specified
29179711,A systematic review of data mining and machine learning for air pollution epidemiology,"BACKGROUND: Data measuring airborne pollutants, public health and environmental factors are increasingly being stored and merged. These big datasets offer great potential, but also challenge traditional epidemiological methods. This has motivated the exploration of alternative methods to make predictions, find patterns and extract information. To this end, data mining and machine learning algorithms are increasingly being applied to air pollution epidemiology.
METHODS: We conducted a systematic literature review on the application of data mining and machine learning methods in air pollution epidemiology. We carried out our search process in PubMed, the MEDLINE database and Google Scholar. Research articles applying data mining and machine learning methods to air pollution epidemiology were queried and reviewed.
RESULTS: Our search queries resulted in 400 research articles. Our fine-grained analysis employed our inclusion/exclusion criteria to reduce the results to 47 articles, which we separate into three primary areas of interest: 1) source apportionment; 2) forecasting/prediction of air pollution/quality or exposure; and 3) generating hypotheses. Early applications had a preference for artificial neural networks. In more recent work, decision trees, support vector machines, k-means clustering and the APRIORI algorithm have been widely applied. Our survey shows that the majority of the research has been conducted in Europe, China and the USA, and that data mining is becoming an increasingly common tool in environmental health. For potential new directions, we have identified that deep learning and geo-spacial pattern mining are two burgeoning areas of data mining that have good potential for future applications in air pollution epidemiology.
CONCLUSIONS: We carried out a systematic review identifying the current trends, challenges and new directions to explore in the application of data mining methods to air pollution epidemiology. This work shows that data mining is increasingly being applied in air pollution epidemiology. The potential to support air pollution epidemiology continues to grow with advancements in data mining related to temporal and geo-spacial mining, and deep learning. This is further supported by new sensors and storage mediums that enable larger, better quality data. This suggests that many more fruitful applications can be expected in the future.",True,other,Not specified
29163582,Deep Learning for Image-Based Cassava Disease Detection,"Cassava is the third largest source of carbohydrates for human food in the world but is vulnerable to virus diseases, which threaten to destabilize food security in sub-Saharan Africa. Novel methods of cassava disease detection are needed to support improved control which will prevent this crisis. Image recognition offers both a cost effective and scalable technology for disease detection. New deep learning models offer an avenue for this technology to be easily deployed on mobile devices. Using a dataset of cassava disease images taken in the field in Tanzania, we applied transfer learning to train a deep convolutional neural network to identify three diseases and two types of pest damage (or lack thereof). The best trained model accuracies were 98% for brown leaf spot (BLS), 96% for red mite damage (RMD), 95% for green mite damage (GMD), 98% for cassava brown streak disease (CBSD), and 96% for cassava mosaic disease (CMD). The best model achieved an overall accuracy of 93% for data not used in the training process. Our results show that the transfer learning approach for image recognition of field images offers a fast, affordable, and easily deployable strategy for digital plant disease detection.",True,other,Not specified
29133818,Searching for prostate cancer by fully automated magnetic resonance imaging classification: deep learning versus non-deep learning,"Prostate cancer (PCa) is a major cause of death since ancient time documented in Egyptian Ptolemaic mummy imaging. PCa detection is critical to personalized medicine and varies considerably under an MRI scan. 172 patients with 2,602 morphologic images (axial 2D T2-weighted imaging) of the prostate were obtained. A deep learning with deep convolutional neural network (DCNN) and a non-deep learning with SIFT image feature and bag-of-word (BoW), a representative method for image recognition and analysis, were used to distinguish pathologically confirmed PCa patients from prostate benign conditions (BCs) patients with prostatitis or prostate benign hyperplasia (BPH). In fully automated detection of PCa patients, deep learning had a statistically higher area under the receiver operating characteristics curve (AUC) than non-deep learning (P = 0.0007 < 0.001). The AUCs were 0.84 (95% CI 0.78-0.89) for deep learning method and 0.70 (95% CI 0.63-0.77) for non-deep learning method, respectively. Our results suggest that deep learning with DCNN is superior to non-deep learning with SIFT image feature and BoW model for fully automated PCa patients differentiation from prostate BCs patients. Our deep learning method is extensible to image modalities such as MR imaging, CT and PET of other organs.",True,both,Not specified
29110491,Deep Learning Accurately Predicts Estrogen Receptor Status in Breast Cancer Metabolomics Data,"Metabolomics holds the promise as a new technology to diagnose highly heterogeneous diseases. Conventionally, metabolomics data analysis for diagnosis is done using various statistical and machine learning based classification methods. However, it remains unknown if deep neural network, a class of increasingly popular machine learning methods, is suitable to classify metabolomics data. Here we use a cohort of 271 breast cancer tissues, 204 positive estrogen receptor (ER+), and 67 negative estrogen receptor (ER-) to test the accuracies of feed-forward networks, a deep learning (DL) framework, as well as six widely used machine learning models, namely random forest (RF), support vector machines (SVM), recursive partitioning and regression trees (RPART), linear discriminant analysis (LDA), prediction analysis for microarrays (PAM), and generalized boosted models (GBM). DL framework has the highest area under the curve (AUC) of 0.93 in classifying ER+/ER- patients, compared to the other six machine learning algorithms. Furthermore, the biological interpretation of the first hidden layer reveals eight commonly enriched significant metabolomics pathways (adjusted P-value <0.05) that cannot be discovered by other machine learning methods. Among them, protein digestion and absorption and ATP-binding cassette (ABC) transporters pathways are also confirmed in integrated analysis between metabolomics and gene expression data in these samples. In summary, deep learning method shows advantages for metabolomics based breast cancer ER status classification, with both the highest prediction accuracy (AUC = 0.93) and better revelation of disease biology. We encourage the adoption of feed-forward networks based deep learning method in the metabolomics research community for classification.",True,other,recurrent neural network
28982688,Deep Learning-Based Multi-Omics Integration Robustly Predicts Survival in Liver Cancer,"Identifying robust survival subgroups of hepatocellular carcinoma (HCC) will significantly improve patient care. Currently, endeavor of integrating multi-omics data to explicitly predict HCC survival from multiple patient cohorts is lacking. To fill this gap, we present a deep learning (DL)-based model on HCC that robustly differentiates survival subpopulations of patients in six cohorts. We built the DL-based, survival-sensitive model on 360 HCC patients' data using RNA sequencing (RNA-Seq), miRNA sequencing (miRNA-Seq), and methylation data from The Cancer Genome Atlas (TCGA), which predicts prognosis as good as an alternative model where genomics and clinical data are both considered. This DL-based model provides two optimal subgroups of patients with significant survival differences (P = 7.13e-6) and good model fitness [concordance index (C-index) = 0.68]. More aggressive subtype is associated with frequent TP53 inactivation mutations, higher expression of stemness markers (KRT19 and EPCAM) and tumor marker BIRC5, and activated Wnt and Akt signaling pathways. We validated this multi-omics model on five external datasets of various omics types: LIRI-JP cohort (n = 230, C-index = 0.75), NCI cohort (n = 221, C-index = 0.67), Chinese cohort (n = 166, C-index = 0.69), E-TABM-36 cohort (n = 40, C-index = 0.77), and Hawaiian cohort (n = 27, C-index = 0.82). This is the first study to employ DL to identify multi-omics features linked to the differential survival of patients with HCC. Given its robustness over multiple cohorts, we expect this workflow to be useful at predicting HCC prognosis prediction. Clin Cancer Res; 24(6); 1248-59. ©2017 AACR.",True,other,Not specified
28927314,Survivability prediction of colon cancer patients using neural networks,"We utilize deep neural networks to develop prediction models for patient survival and conditional survival of colon cancer. Our models are trained and validated on data obtained from the Surveillance, Epidemiology, and End Results Program. We provide an online outcome calculator for 1, 2, and 5 years survival periods. We experimented with multiple neural network structures and found that a network with five hidden layers produces the best results for these data. Moreover, the online outcome calculator provides conditional survival of 1, 2, and 5 years after surviving the mentioned survival periods. In this article, we report an approximate 0.87 area under the receiver operating characteristic curve measurements, higher than the 0.85 reported by Stojadinovic et al.",True,other,recurrent neural network
28916782,Predicting clinical outcomes from large scale cancer genomic profiles with deep survival models,"Translating the vast data generated by genomic platforms into accurate predictions of clinical outcomes is a fundamental challenge in genomic medicine. Many prediction methods face limitations in learning from the high-dimensional profiles generated by these platforms, and rely on experts to hand-select a small number of features for training prediction models. In this paper, we demonstrate how deep learning and Bayesian optimization methods that have been remarkably successful in general high-dimensional prediction tasks can be adapted to the problem of predicting cancer outcomes. We perform an extensive comparison of Bayesian optimized deep survival models and other state of the art machine learning methods for survival analysis, and describe a framework for interpreting deep survival models using a risk backpropagation technique. Finally, we illustrate that deep survival models can successfully transfer information across diseases to improve prognostic accuracy. We provide an open-source software implementation of this framework called SurvivalNet that enables automatic training, evaluation and interpretation of deep survival models.",True,other,recurrent neural network
28910352,Deep learning approach to bacterial colony classification,"In microbiology it is diagnostically useful to recognize various genera and species of bacteria. It can be achieved using computer-aided methods, which make the recognition processes more automatic and thus significantly reduce the time necessary for the classification. Moreover, in case of diagnostic uncertainty (the misleading similarity in shape or structure of bacterial cells), such methods can minimize the risk of incorrect recognition. In this article, we apply the state of the art method for texture analysis to classify genera and species of bacteria. This method uses deep Convolutional Neural Networks to obtain image descriptors, which are then encoded and classified with Support Vector Machine or Random Forest. To evaluate this approach and to make it comparable with other approaches, we provide a new dataset of images. DIBaS dataset (Digital Image of Bacterial Species) contains 660 images with 33 different genera and species of bacteria.",True,computer vision,recurrent neural network
28843741,A pilot study in using deep learning to predict limited life expectancy in women with recurrent cervical cancer,,True,other,GAN
28720701,De novo peptide sequencing by deep learning,"De novo peptide sequencing from tandem MS data is the key technology in proteomics for the characterization of proteins, especially for new sequences, such as mAbs. In this study, we propose a deep neural network model, DeepNovo, for de novo peptide sequencing. DeepNovo architecture combines recent advances in convolutional neural networks and recurrent neural networks to learn features of tandem mass spectra, fragment ions, and sequence patterns of peptides. The networks are further integrated with local dynamic programming to solve the complex optimization task of de novo sequencing. We evaluated the method on a wide variety of species and found that DeepNovo considerably outperformed state of the art methods, achieving 7.7-22.9% higher accuracy at the amino acid level and 38.1-64.0% higher accuracy at the peptide level. We further used DeepNovo to automatically reconstruct the complete sequences of antibody light and heavy chains of mouse, achieving 97.5-100% coverage and 97.2-99.5% accuracy, without assisting databases. Moreover, DeepNovo is retrainable to adapt to any sources of data and provides a complete end-to-end training and prediction solution to the de novo sequencing problem. Not only does our study extend the deep learning revolution to a new field, but it also shows an innovative approach in solving optimization problems by using deep learning and dynamic programming.",True,text mining,recurrent neural network
28655145,Partitioned learning of deep Boltzmann machines for SNP data,"MOTIVATION: Learning the joint distributions of measurements, and in particular identification of an appropriate low-dimensional manifold, has been found to be a powerful ingredient of deep leaning approaches. Yet, such approaches have hardly been applied to single nucleotide polymorphism (SNP) data, probably due to the high number of features typically exceeding the number of studied individuals.
RESULTS: After a brief overview of how deep Boltzmann machines (DBMs), a deep learning approach, can be adapted to SNP data in principle, we specifically present a way to alleviate the dimensionality problem by partitioned learning. We propose a sparse regression approach to coarsely screen the joint distribution of SNPs, followed by training several DBMs on SNP partitions that were identified by the screening. Aggregate features representing SNP patterns and the corresponding SNPs are extracted from the DBMs by a combination of statistical tests and sparse regression. In simulated case-control data, we show how this can uncover complex SNP patterns and augment results from univariate approaches, while maintaining type 1 error control. Time-to-event endpoints are considered in an application with acute myeloid leukemia patients, where SNP patterns are modeled after a pre-screening based on gene expression data. The proposed approach identified three SNPs that seem to jointly influence survival in a validation dataset. This indicates the added value of jointly investigating SNPs compared to standard univariate analyses and makes partitioned learning of DBMs an interesting complementary approach when analyzing SNP data.
AVAILABILITY AND IMPLEMENTATION: A Julia package is provided at 'http://github.com/binderh/BoltzmannMachines.jl'.
CONTACT: binderh@imbi.uni-freiburg.de.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.",True,other,recurrent neural network
28070484,Deep learning predictions of survival based on MRI in amyotrophic lateral sclerosis,"Amyotrophic lateral sclerosis (ALS) is a progressive neuromuscular disease, with large variation in survival between patients. Currently, it remains rather difficult to predict survival based on clinical parameters alone. Here, we set out to use clinical characteristics in combination with MRI data to predict survival of ALS patients using deep learning, a machine learning technique highly effective in a broad range of big-data analyses. A group of 135 ALS patients was included from whom high-resolution diffusion-weighted and T1-weighted images were acquired at the first visit to the outpatient clinic. Next, each of the patients was monitored carefully and survival time to death was recorded. Patients were labeled as short, medium or long survivors, based on their recorded time to death as measured from the time of disease onset. In the deep learning procedure, the total group of 135 patients was split into a training set for deep learning (n = 83 patients), a validation set (n = 20) and an independent evaluation set (n = 32) to evaluate the performance of the obtained deep learning networks. Deep learning based on clinical characteristics predicted survival category correctly in 68.8% of the cases. Deep learning based on MRI predicted 62.5% correctly using structural connectivity and 62.5% using brain morphology data. Notably, when we combined the three sources of information, deep learning prediction accuracy increased to 84.4%. Taken together, our findings show the added value of MRI with respect to predicting survival in ALS, demonstrating the advantage of deep learning in disease prognostication.",True,other,recurrent neural network
27453696,SimNest: Social Media Nested Epidemic Simulation via Online Semi-supervised Deep Learning,"Infectious disease epidemics such as influenza and Ebola pose a serious threat to global public health. It is crucial to characterize the disease and the evolution of the ongoing epidemic efficiently and accurately. Computational epidemiology can model the disease progress and underlying contact network, but suffers from the lack of real-time and fine-grained surveillance data. Social media, on the other hand, provides timely and detailed disease surveillance, but is insensible to the underlying contact network and disease model. This paper proposes a novel semi-supervised deep learning framework that integrates the strengths of computational epidemiology and social media mining techniques. Specifically, this framework learns the social media users' health states and intervention actions in real time, which are regularized by the underlying disease model and contact network. Conversely, the learned knowledge from social media can be fed into computational epidemic model to improve the efficiency and accuracy of disease diffusion modeling. We propose an online optimization algorithm to substantialize the above interactive learning process iteratively to achieve a consistent stage of the integration. The extensive experimental results demonstrated that our approach can effectively characterize the spatio-temporal disease diffusion, outperforming competing methods by a substantial margin on multiple metrics.",True,other,CNN
26915120,Unsupervised Deep Learning Applied to Breast Density Segmentation and Mammographic Risk Scoring,"Mammographic risk scoring has commonly been automated by extracting a set of handcrafted features from mammograms, and relating the responses directly or indirectly to breast cancer risk. We present a method that learns a feature hierarchy from unlabeled data. When the learned features are used as the input to a simple classifier, two different tasks can be addressed: i) breast density segmentation, and ii) scoring of mammographic texture. The proposed model learns features at multiple scales. To control the models capacity a novel sparsity regularizer is introduced that incorporates both lifetime and population sparsity. We evaluated our method on three different clinical datasets. Our state-of-the-art results show that the learned breast density scores have a very strong positive relationship with manual ones, and that the learned texture scores are predictive of breast cancer. The model is easy to apply and generalizes to many other segmentation and scoring problems.",True,both,Not specified
26357333,Integrative Data Analysis of Multi-Platform Cancer Data with a Multimodal Deep Learning Approach,"Identification of cancer subtypes plays an important role in revealing useful insights into disease pathogenesis and advancing personalized therapy. The recent development of high-throughput sequencing technologies has enabled the rapid collection of multi-platform genomic data (e.g., gene expression, miRNA expression, and DNA methylation) for the same set of tumor samples. Although numerous integrative clustering approaches have been developed to analyze cancer data, few of them are particularly designed to exploit both deep intrinsic statistical properties of each input modality and complex cross-modality correlations among multi-platform input data. In this paper, we propose a new machine learning model, called multimodal deep belief network (DBN), to cluster cancer patients from multi-platform observation data. In our integrative clustering framework, relationships among inherent features of each single modality are first encoded into multiple layers of hidden variables, and then a joint latent model is employed to fuse common features derived from multiple input modalities. A practical learning algorithm, called contrastive divergence (CD), is applied to infer the parameters of our multimodal DBN model in an unsupervised manner. Tests on two available cancer datasets show that our integrative data analysis approach can effectively extract a unified representation of latent features to capture both intra- and cross-modality correlations, and identify meaningful disease subtypes from multi-platform cancer data. In addition, our approach can identify key genes and miRNAs that may play distinct roles in the pathogenesis of different cancer subtypes. Among those key miRNAs, we found that the expression level of miR-29a is highly correlated with survival time in ovarian cancer patients. These results indicate that our multimodal DBN based data analysis approach may have practical applications in cancer pathogenesis studies and provide useful guidelines for personalized cancer therapy.",True,other,Not specified
39271955,Results and implications for generative AI in a large introductory biomedical and health informatics course,"Generative artificial intelligence (AI) systems have performed well at many biomedical tasks, but few studies have assessed their performance directly compared to students in higher-education courses. We compared student knowledge-assessment scores with prompting of 6 large-language model (LLM) systems as they would be used by typical students in a large online introductory course in biomedical and health informatics that is taken by graduate, continuing education, and medical students. The state-of-the-art LLM systems were prompted to answer multiple-choice questions (MCQs) and final exam questions. We compared the scores for 139 students (30 graduate students, 85 continuing education students, and 24 medical students) to the LLM systems. All of the LLMs scored between the 50th and 75th percentiles of students for MCQ and final exam questions. The performance of LLMs raises questions about student assessment in higher education, especially in courses that are knowledge-based and online.",True,other,convolutional neural network
39228001,The performance of OpenAI ChatGPT-4 and Google Gemini in virology multiple-choice questions: a comparative analysis of English and Arabic responses,"OBJECTIVE: The integration of artificial intelligence (AI) in healthcare education is inevitable. Understanding the proficiency of generative AI in different languages to answer complex questions is crucial for educational purposes. The study objective was to compare the performance ChatGPT-4 and Gemini in answering Virology multiple-choice questions (MCQs) in English and Arabic, while assessing the quality of the generated content. Both AI models' responses to 40 Virology MCQs were assessed for correctness and quality based on the CLEAR tool designed for evaluation of AI-generated content. The MCQs were classified into lower and higher cognitive categories based on the revised Bloom's taxonomy. The study design considered the METRICS checklist for the design and reporting of generative AI-based studies in healthcare.
RESULTS: ChatGPT-4 and Gemini performed better in English compared to Arabic, with ChatGPT-4 consistently surpassing Gemini in correctness and CLEAR scores. ChatGPT-4 led Gemini with 80% vs. 62.5% correctness in English compared to 65% vs. 55% in Arabic. For both AI models, superior performance in lower cognitive domains was reported. Both ChatGPT-4 and Gemini exhibited potential in educational applications; nevertheless, their performance varied across languages highlighting the importance of continued development to ensure the effective AI integration in healthcare education globally.",True,text mining,RNN
39070036,"Generative models of MRI-derived neuroimaging features and associated dataset of 18,000 samples","Availability of large and diverse medical datasets is often challenged by privacy and data sharing restrictions. For successful application of machine learning techniques for disease diagnosis, prognosis, and precision medicine, large amounts of data are necessary for model building and optimization. To help overcome such limitations in the context of brain MRI, we present GenMIND: a collection of generative models of normative regional volumetric features derived from structural brain imaging. GenMIND models are trained on real brain imaging regional volumetric measures from the iSTAGING consortium, which encompasses over 40,000 MRI scans across 13 studies, incorporating covariates such as age, sex, and race. Leveraging GenMIND, we produce and offer 18,000 synthetic samples spanning the adult lifespan (ages 22-90 years), alongside the model's capability to generate unlimited data. Experimental results indicate that samples generated from GenMIND agree with the distributions obtained from real data. Most importantly, the generated normative data significantly enhance the accuracy of downstream machine learning models on tasks such as disease classification. Data and models are available at: https://huggingface.co/spaces/rongguangw/GenMIND.",True,other,recurrent neural network
38354491,Generative artificial intelligence in surgery: balancing innovation with ethical challenges,,True,other,GAN
38333501,Exploring Generative Artificial Intelligence-Assisted Medical Education: Assessing Case-Based Learning for Medical Students,"The recent public release of generative artificial intelligence (GenAI) has brought fresh excitement by making access to GenAI for medical education easier than ever before. It is now incumbent upon both students and faculty to determine the optimal role of GenAI within the medical school curriculum. Given the promise and limitations of GenAI, this study aims to assess the current capabilities of a GenAI (Chat Generative Pre-trained Transformer, ChatGPT), specifically within the framework of a pre-clerkship case-based active learning curriculum. The role of GenAI is explored by evaluating its performance in generating educational materials, creating medical assessment questions, answering medical queries, and engaging in clinical reasoning by prompting it to respond to a problem-based learning scenario. Our results demonstrated that GenAI addressed epidemiology, diagnosis, and treatment questions well. However, there were still instances where it failed to provide comprehensive answers. Responses from GenAI might offer essential information, hint at the need for further inquiry, or sometimes omit critical details. GenAI struggled with generating information on complex topics, raising a significant concern when using it as a 'search engine' for medical student queries. This creates uncertainty for students regarding potentially missed critical information. With the increasing integration of GenAI into medical education, it is imperative for faculty to become well-versed in both its advantages and limitations. This awareness will enable them to educate students on using GenAI effectively in medical education.",True,text mining,RNN
38294157,Prompt Engineering for Generative Artificial Intelligence in Gastroenterology and Hepatology,,True,other,GAN
38287655,Search still matters: information retrieval in the era of generative AI,"OBJECTIVE: Information retrieval (IR, also known as search) systems are ubiquitous in modern times. How does the emergence of generative artificial intelligence (AI), based on large language models (LLMs), fit into the IR process?
PROCESS: This perspective explores the use of generative AI in the context of the motivations, considerations, and outcomes of the IR process with a focus on the academic use of such systems.
CONCLUSIONS: There are many information needs, from simple to complex, that motivate use of IR. Users of such systems, particularly academics, have concerns for authoritativeness, timeliness, and contextualization of search. While LLMs may provide functionality that aids the IR process, the continued need for search systems, and research into their improvement, remains essential.",True,other,convolutional neural network
32381039,Generation and evaluation of synthetic patient data,"BACKGROUND: Machine learning (ML) has made a significant impact in medicine and cancer research; however, its impact in these areas has been undeniably slower and more limited than in other application domains. A major reason for this has been the lack of availability of patient data to the broader ML research community, in large part due to patient privacy protection concerns. High-quality, realistic, synthetic datasets can be leveraged to accelerate methodological developments in medicine. By and large, medical data is high dimensional and often categorical. These characteristics pose multiple modeling challenges.
METHODS: In this paper, we evaluate three classes of synthetic data generation approaches; probabilistic models, classification-based imputation models, and generative adversarial neural networks. Metrics for evaluating the quality of the generated synthetic datasets are presented and discussed.
RESULTS: While the results and discussions are broadly applicable to medical data, for demonstration purposes we generate synthetic datasets for cancer based on the publicly available cancer registry data from the Surveillance Epidemiology and End Results (SEER) program. Specifically, our cohort consists of breast, respiratory, and non-solid cancer cases diagnosed between 2010 and 2015, which includes over 360,000 individual cases.
CONCLUSIONS: We discuss the trade-offs of the different methods and metrics, providing guidance on considerations for the generation and usage of medical synthetic data.",True,other,Not specified
30202918,The impact of different sources of heterogeneity on loss of accuracy from genomic prediction models,"Cross-study validation (CSV) of prediction models is an alternative to traditional cross-validation (CV) in domains where multiple comparable datasets are available. Although many studies have noted potential sources of heterogeneity in genomic studies, to our knowledge none have systematically investigated their intertwined impacts on prediction accuracy across studies. We employ a hybrid parametric/non-parametric bootstrap method to realistically simulate publicly available compendia of microarray, RNA-seq, and whole metagenome shotgun microbiome studies of health outcomes. Three types of heterogeneity between studies are manipulated and studied: (i) imbalances in the prevalence of clinical and pathological covariates, (ii) differences in gene covariance that could be caused by batch, platform, or tumor purity effects, and (iii) differences in the ""true"" model that associates gene expression and clinical factors to outcome. We assess model accuracy, while altering these factors. Lower accuracy is seen in CSV than in CV. Surprisingly, heterogeneity in known clinical covariates and differences in gene covariance structure have very limited contributions in the loss of accuracy when validating in new studies. However, forcing identical generative models greatly reduces the within/across study difference. These results, observed consistently for multiple disease outcomes and omics platforms, suggest that the most easily identifiable sources of study heterogeneity are not necessarily the primary ones that undermine the ability to accurately replicate the accuracy of omics prediction models in new studies. Unidentified heterogeneity, such as could arise from unmeasured confounding, may be more important.",True,other,Not specified
38815316,Automating biomedical literature review for rapid drug discovery: Leveraging GPT-4 to expedite pandemic response,"OBJECTIVE: The rapid expansion of the biomedical literature challenges traditional review methods, especially during outbreaks of emerging infectious diseases when quick action is critical. Our study aims to explore the potential of ChatGPT to automate the biomedical literature review for rapid drug discovery.
MATERIALS AND METHODS: We introduce a novel automated pipeline helping to identify drugs for a given virus in response to a potential future global health threat. Our approach can be used to select PubMed articles identifying a drug target for the given virus. We tested our approach on two known pathogens: SARS-CoV-2, where the literature is vast, and Nipah, where the literature is sparse. Specifically, a panel of three experts reviewed a set of PubMed articles and labeled them as either describing a drug target for the given virus or not. The same task was given to the automated pipeline and its performance was based on whether it labeled the articles similarly to the human experts. We applied a number of prompt engineering techniques to improve the performance of ChatGPT.
RESULTS: Our best configuration used GPT-4 by OpenAI and achieved an out-of-sample validation performance with accuracy/F1-score/sensitivity/specificity of 92.87%/88.43%/83.38%/97.82% for SARS-CoV-2 and 87.40%/73.90%/74.72%/91.36% for Nipah.
CONCLUSION: These results highlight the utility of ChatGPT in drug discovery and development and reveal their potential to enable rapid drug target identification during a pandemic-level health emergency.",True,text mining,Not specified
38035200,Guiding principles and proposed classification system for the responsible adoption of artificial intelligence in scientific writing in medicine,"The integration of large language models (LLMs) and artificial intelligence (AI) into scientific writing, especially in medical literature, presents both unprecedented opportunities and inherent challenges. This manuscript evaluates the transformative potential of LLMs for the synthesis of information, linguistic enhancements, and global knowledge dissemination. At the same time, it raises concerns about unintentional plagiarism, the risk of misinformation, data biases, and an over-reliance on AI. To address these, we propose governing principles for AI adoption that ensure integrity, transparency, validity, and accountability. Additionally, guidelines for reporting AI involvement in manuscript development are delineated, and a classification system to specify the level of AI assistance is introduced. This approach uniquely addresses the challenges of AI in scientific writing, emphasizing transparency in authorship, qualification of AI involvement, and ethical considerations. Concerns regarding access equity, potential biases in AI-generated content, authorship dynamics, and accountability are also explored, emphasizing the human author's continued responsibility. Recommendations are made for fostering collaboration between AI developers, researchers, and journal editors and for emphasizing the importance of AI's responsible use in academic writing. Regular evaluations of AI's impact on the quality and biases of medical manuscripts are also advocated. As we navigate the expanding realm of AI in scientific discourse, it is crucial to maintain the human element of creativity, ethics, and oversight, ensuring that the integrity of scientific literature remains uncompromised.",True,text mining,CNN
37987431,Evaluating the Efficacy of ChatGPT in Navigating the Spanish Medical Residency Entrance Examination (MIR): Promising Horizons for AI in Clinical Medicine,"UNLABELLED: The rapid progress in artificial intelligence, machine learning, and natural language processing has led to increasingly sophisticated large language models (LLMs) for use in healthcare. This study assesses the performance of two LLMs, the GPT-3.5 and GPT-4 models, in passing the MIR medical examination for access to medical specialist training in Spain. Our objectives included gauging the model's overall performance, analyzing discrepancies across different medical specialties, discerning between theoretical and practical questions, estimating error proportions, and assessing the hypothetical severity of errors committed by a physician.
MATERIAL AND METHODS: We studied the 2022 Spanish MIR examination results after excluding those questions requiring image evaluations or having acknowledged errors. The remaining 182 questions were presented to the LLM GPT-4 and GPT-3.5 in Spanish and English. Logistic regression models analyzed the relationships between question length, sequence, and performance. We also analyzed the 23 questions with images, using GPT-4's new image analysis capability.
RESULTS: GPT-4 outperformed GPT-3.5, scoring 86.81% in Spanish (p &lt; 0.001). English translations had a slightly enhanced performance. GPT-4 scored 26.1% of the questions with images in English. The results were worse when the questions were in Spanish, 13.0%, although the differences were not statistically significant (p = 0.250). Among medical specialties, GPT-4 achieved a 100% correct response rate in several areas, and the Pharmacology, Critical Care, and Infectious Diseases specialties showed lower performance. The error analysis revealed that while a 13.2% error rate existed, the gravest categories, such as ""error requiring intervention to sustain life"" and ""error resulting in death"", had a 0% rate.
CONCLUSIONS: GPT-4 performs robustly on the Spanish MIR examination, with varying capabilities to discriminate knowledge across specialties. While the model's high success rate is commendable, understanding the error severity is critical, especially when considering AI's potential role in real-world medical practice and its implications for patient safety.",True,text mining,RNN
38814687,Searching COVID-19 Clinical Research Using Graph Queries: Algorithm Development and Validation,"BACKGROUND: Since the beginning of the COVID-19 pandemic, >1 million studies have been collected within the COVID-19 Open Research Dataset, a corpus of manuscripts created to accelerate research against the disease. Their related abstracts hold a wealth of information that remains largely unexplored and difficult to search due to its unstructured nature. Keyword-based search is the standard approach, which allows users to retrieve the documents of a corpus that contain (all or some of) the words in a target list. This type of search, however, does not provide visual support to the task and is not suited to expressing complex queries or compensating for missing specifications.
OBJECTIVE: This study aims to consider small graphs of concepts and exploit them for expressing graph searches over existing COVID-19-related literature, leveraging the increasing use of graphs to represent and query scientific knowledge and providing a user-friendly search and exploration experience.
METHODS: We considered the COVID-19 Open Research Dataset corpus and summarized its content by annotating the publications' abstracts using terms selected from the Unified Medical Language System and the Ontology of Coronavirus Infectious Disease. Then, we built a co-occurrence network that includes all relevant concepts mentioned in the corpus, establishing connections when their mutual information is relevant. A sophisticated graph query engine was built to allow the identification of the best matches of graph queries on the network. It also supports partial matches and suggests potential query completions using shortest paths.
RESULTS: We built a large co-occurrence network, consisting of 128,249 entities and 47,198,965 relationships; the GRAPH-SEARCH interface allows users to explore the network by formulating or adapting graph queries; it produces a bibliography of publications, which are globally ranked; and each publication is further associated with the specific parts of the query that it explains, thereby allowing the user to understand each aspect of the matching.
CONCLUSIONS: Our approach supports the process of query formulation and evidence search upon a large text corpus; it can be reapplied to any scientific domain where documents corpora and curated ontologies are made available.",True,other,Not specified
38748991,A general framework for developing computable clinical phenotype algorithms,"OBJECTIVE: To present a general framework providing high-level guidance to developers of computable algorithms for identifying patients with specific clinical conditions (phenotypes) through a variety of approaches, including but not limited to machine learning and natural language processing methods to incorporate rich electronic health record data.
MATERIALS AND METHODS: Drawing on extensive prior phenotyping experiences and insights derived from 3 algorithm development projects conducted specifically for this purpose, our team with expertise in clinical medicine, statistics, informatics, pharmacoepidemiology, and healthcare data science methods conceptualized stages of development and corresponding sets of principles, strategies, and practical guidelines for improving the algorithm development process.
RESULTS: We propose 5 stages of algorithm development and corresponding principles, strategies, and guidelines: (1) assessing fitness-for-purpose, (2) creating gold standard data, (3) feature engineering, (4) model development, and (5) model evaluation.
DISCUSSION AND CONCLUSION: This framework is intended to provide practical guidance and serve as a basis for future elaboration and extension.",True,text mining,Not specified
38556036,Calculated Medicine: Seven Decades of Accelerating Growth,"The field of Calculated Medicine has grown substantially over the last 7 decades. Comprised of objective, evidence-based medical decision tools, Calculated Medicine has broad application in medical practice, medical research, and health care management. This article reviews the history and varied methodologies of Calculated Medicine, starting with the 1953 Apgar score and concluding with a look into modern computational tools of the field: machine learning, natural language processing, artificial intelligence, and in silico research techniques. We'll also review and quantify the rapidly accelerating growth of Calculated Medicine in the medical literature. Our database of journal articles referring to the field has accumulated over 1.8 million citations, with more than 460 new citations (on average) posted every day. Using natural language processing, we examine and analyze this burgeoning database. Lastly, we examine an important new direction of Calculated Medicine: self-reflection on its potential effect on racial and ethnic disparities in health care. Our field is making great strides promoting health care egality, and some of the most prominent contributions will be reviewed.",True,other,Not specified
38269692,Machine Learning Model to Extract Malnutrition Data from Nursing Notes,"Malnutrition is a severe health problem that is prevalent in older people residing in residential aged care facilities. Recent advancements in machine learning have made it possible to extract key insight from electronic health records. To date, few researchers applied these techniques to classify nursing notes automatically. Therefore, we propose a model based on ClinicalBioBert to identify malnutrition notes. We evaluated our approach with two mainstream approaches. Our approach had the highest F1-score of 0.90.",True,other,Not specified
38117843,Detecting nuance in conspiracy discourse: Advancing methods in infodemiology and communication science with machine learning and qualitative content coding,"The spread of misinformation and conspiracies has been an ongoing issue since the early stages of the internet era, resulting in the emergence of the field of infodemiology (i.e., information epidemiology), which investigates the transmission of health-related information. Due to the high volume of online misinformation in recent years, there is a need to continue advancing methodologies in order to effectively identify narratives and themes. While machine learning models can be used to detect misinformation and conspiracies, these models are limited in their generalizability to other datasets and misinformation phenomenon, and are often unable to detect implicit meanings in text that require contextual knowledge. To rapidly detect evolving conspiracist narratives within high volume online discourse while identifying nuanced themes requiring the comprehension of subtext, this study describes a hybrid methodology that combines natural language processing (i.e., topic modeling and sentiment analysis) with qualitative content coding approaches to characterize conspiracy discourse related to 5G wireless technology and COVID-19 on Twitter (currently known as 'X'). Discourse that focused on correcting 5G conspiracies was also analyzed for comparison. Sentiment analysis shows that conspiracy-related discourse was more likely to use language that was analytic, combative, past-oriented, referenced social status, and expressed negative emotions. Corrections discourse was more likely to use words reflecting cognitive processes, prosocial relations, health-related consequences, and future-oriented language. Inductive coding characterized conspiracist narratives related to global elites, anti-vax sentiment, medical authorities, religious figures, and false correlations between technology advancements and disease outbreaks. Further, the corrections discourse did not address many of the narratives prevalent in conspiracy conversations. This paper aims to further bridge the gap between computational and qualitative methodologies by demonstrating how both approaches can be used in tandem to emphasize the positive aspects of each methodology while minimizing their respective drawbacks.",True,other,convolutional neural network
38042599,Natural language processing with machine learning methods to analyze unstructured patient-reported outcomes derived from electronic health records: A systematic review,"OBJECTIVE: Natural language processing (NLP) combined with machine learning (ML) techniques are increasingly used to process unstructured/free-text patient-reported outcome (PRO) data available in electronic health records (EHRs). This systematic review summarizes the literature reporting NLP/ML systems/toolkits for analyzing PROs in clinical narratives of EHRs and discusses the future directions for the application of this modality in clinical care.
METHODS: We searched PubMed, Scopus, and Web of Science for studies written in English between 1/1/2000 and 12/31/2020. Seventy-nine studies meeting the eligibility criteria were included. We abstracted and summarized information related to the study purpose, patient population, type/source/amount of unstructured PRO data, linguistic features, and NLP systems/toolkits for processing unstructured PROs in EHRs.
RESULTS: Most of the studies used NLP/ML techniques to extract PROs from clinical narratives (n = 74) and mapped the extracted PROs into specific PRO domains for phenotyping or clustering purposes (n = 26). Some studies used NLP/ML to process PROs for predicting disease progression or onset of adverse events (n = 22) or developing/validating NLP/ML pipelines for analyzing unstructured PROs (n = 19). Studies used different linguistic features, including lexical, syntactic, semantic, and contextual features, to process unstructured PROs. Among the 25 NLP systems/toolkits we identified, 15 used rule-based NLP, 6 used hybrid NLP, and 4 used non-neural ML algorithms embedded in NLP.
CONCLUSIONS: This study supports the potential utility of different NLP/ML techniques in processing unstructured PROs available in EHRs for clinical care. Though using annotation rules for NLP/ML to analyze unstructured PROs is dominant, deploying novel neural ML-based methods is warranted.",True,text mining,RNN
37698203,Development of Electronic Health Record-Based Machine Learning Models to Predict Barrett's Esophagus and Esophageal Adenocarcinoma Risk,"INTRODUCTION: Screening for Barrett's esophagus (BE) is suggested in those with risk factors, but remains underutilized. BE/esophageal adenocarcinoma (EAC) risk prediction tools integrating multiple risk factors have been described. However, accuracy remains modest (area under the receiver-operating curve [AUROC] ≤0.7), and clinical implementation has been challenging. We aimed to develop machine learning (ML) BE/EAC risk prediction models from an electronic health record (EHR) database.
METHODS: The Clinical Data Analytics Platform, a deidentified EHR database of 6 million Mayo Clinic patients, was used to predict BE and EAC risk. BE and EAC cases and controls were identified using International Classification of Diseases codes and augmented curation (natural language processing) techniques applied to clinical, endoscopy, laboratory, and pathology notes. Cases were propensity score matched to 5 independent randomly selected control groups. An ensemble transformer-based ML model architecture was used to develop predictive models.
RESULTS: We identified 8,476 BE cases, 1,539 EAC cases, and 252,276 controls. The BE ML transformer model had an overall sensitivity, specificity, and AUROC of 76%, 76%, and 0.84, respectively. The EAC ML transformer model had an overall sensitivity, specificity, and AUROC of 84%, 70%, and 0.84, respectively. Predictors of BE and EAC included conventional risk factors and additional novel factors, such as coronary artery disease, serum triglycerides, and electrolytes.
DISCUSSION: ML models developed on an EHR database can predict incident BE and EAC risk with improved accuracy compared with conventional risk factor-based risk scores. Such a model may enable effective implementation of a minimally invasive screening technology.",True,other,Not specified
37646719,Machine Learning Applied to Cholesterol-Lowering Pharmacotherapy: Proof-of-Concept in High-Risk Patients Treated in Primary Care,"Objectives: Machine learning has potential to improve the management of lipid disorders. We explored the utility of machine learning in high-risk patients in primary care receiving cholesterol-lowering medications. Methods: Machine learning algorithms were created based on lipid management guidelines for England [National Institute for Health and Care Excellence (NICE) CG181] to reproduce the guidance with &gt;95% accuracy. Natural language processing and therapy identification algorithms were applied to anonymized electronic records from six South London primary care general practices to extract medication information from free text fields. Results: Among a total of 48,226 adult patients, a subset of 5630 (mean ± standard deviation, age = 67 ± 13 years; male:female = 55:45) with a history of lipid-lowering therapy were identified. Additional major cardiometabolic comorbidities included type 2 diabetes in 13% (n = 724) and hypertension in 32% (n = 1791); all three risk factors were present in a further 28% (n = 1552). Of the 5630 patients, 4290 (76%) and 1349 (24%) were in primary and secondary cardiovascular disease prevention cohorts, respectively. Statin monotherapy was the most common current medication (82%, n = 4632). For patients receiving statin monotherapy, 71% (n = 3269) were on high-intensity therapy aligned with NICE guidance with rates being similar for the primary and secondary prevention cohorts. In the combined cohort, only 46% of patients who had been prescribed lipid-lowering therapy in the previous 12 months achieved the NICE treatment goal of &gt;40% reduction in non-high-density lipoprotein cholesterol from baseline pretreatment levels. Based on the most recent data entry for patients not at goal the neural network recommended either increasing the dose of statin, adding complementary cholesterol-lowering medication, or obtaining an expert lipid opinion. Conclusions: Machine learning can be of value in (a) quantifying suboptimal lipid-lowering prescribing patterns, (b) identifying high-risk patients who could benefit from more intensive therapy, and (c) suggesting evidence-based therapeutic options.",True,other,Not specified
37577535,Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,"There are many studies that require researchers to extract specific information from the published literature, such as details about sequence records or about a randomized control trial. While manual extraction is cost efficient for small studies, larger studies such as systematic reviews are much more costly and time-consuming. To avoid exhaustive manual searches and extraction, and their related cost and effort, natural language processing (NLP) methods can be tailored for the more subtle extraction and decision tasks that typically only humans have performed. The need for such studies that use the published literature as a data source became even more evident as the COVID-19 pandemic raged through the world and millions of sequenced samples were deposited in public repositories such as GISAID and GenBank, promising large genomic epidemiology studies, but more often than not lacked many important details that prevented large-scale studies. Thus, granular geographic location or the most basic patient-relevant data such as demographic information, or clinical outcomes were not noted in the sequence record. However, some of these data was indeed published, but in the text, tables, or supplementary material of a corresponding published article. We present here methods to identify relevant journal articles that report having produced and made available in GenBank or GISAID, new SARS-CoV-2 sequences, as those that initially produced and made available the sequences are the most likely articles to include the high-level details about the patients from whom the sequences were obtained. Human annotators validated the approach, creating a gold standard set for training and validation of a machine learning classifier. Identifying these articles is a crucial step to enable future automated informatics pipelines that will apply Machine Learning and Natural Language Processing to identify patient characteristics such as co-morbidities, outcomes, age, gender, and race, enriching SARS-CoV-2 sequence databases with actionable information for defining large genomic epidemiology studies. Thus, enriched patient metadata can enable secondary data analysis, at scale, to uncover associations between the viral genome (including variants of concern and their sublineages), transmission risk, and health outcomes. However, for such enrichment to happen, the right papers need to be found and very detailed data needs to be extracted from them. Further, finding the very specific articles needed for inclusion is a task that also facilitates scoping and systematic reviews, greatly reducing the time needed for full-text analysis and extraction.",True,text mining,Not specified
37575020,Identifying the most important data for research in the field of infectious diseases: thinking on the basis of artificial intelligence,"OBJECTIVE: Clinical data on which artificial intelligence (AI) algorithms are trained and tested provide the basis to improve diagnosis or treatment of infectious diseases (ID). We aimed to identify important data for ID research to prioritise efforts being undertaken in AI programmes.
METHODS: We searched for 1,000 articlesfrom high-impact ID journals on PubMed, selecting 288 of the latest articles from 10 top journals. We classified them into structured or unstructured data. Variables were homogenised and grouped into the following categories: epidemiology, admission, demographics, comorbidities, clinical manifestations, laboratory, microbiology, other diagnoses, treatment, outcomes and other non-categorizable variables.
RESULTS: 4,488 individual variables were collected, from the 288 articles. 3,670 (81.8%) variables were classified as structured data whilst 818 (18.2%) as unstructured data. From the structured data, 2,319 (63.2%) variables were classified as direct-retrievable from electronic health records-whilst 1,351 (36.8%) were indirect. The most frequent unstructured data were related to clinical manifestations and were repeated across articles. Data on demographics, comorbidities and microbiology constituted the most frequent group of variables.
CONCLUSIONS: This article identified that structured variables have comprised the most important data in research to generate knowledge in the field of ID. Extracting these data should be a priority when a medical centre intends to start an AI programme for ID. We also documented that the most important unstructured data in this field are those related to clinical manifestations. Such data could easily undergo some structuring with the use of semi-structured medical records focusing on a few symptoms.",True,computer vision,RNN
37531365,Blending citizen science with natural language processing and machine learning: Understanding the experience of living with multiple sclerosis,"The emergence of new digital technologies has enabled a new way of doing research, including active collaboration with the public ('citizen science'). Innovation in machine learning (ML) and natural language processing (NLP) has made automatic analysis of large-scale text data accessible to study individual perspectives in a convenient and efficient fashion. Here we blend citizen science with innovation in NLP and ML to examine (1) which categories of life events persons with multiple sclerosis (MS) perceived as central for their MS; and (2) associated emotions. We subsequently relate our results to standardized individual-level measures. Participants (n = 1039) took part in the 'My Life with MS' study of the Swiss MS Registry which involved telling their story through self-selected life events using text descriptions and a semi-structured questionnaire. We performed topic modeling ('latent Dirichlet allocation') to identify high-level topics underlying the text descriptions. Using a pre-trained language model, we performed a fine-grained emotion analysis of the text descriptions. A topic modeling analysis of totally 4293 descriptions revealed eight underlying topics. Five topics are common in clinical research: 'diagnosis', 'medication/treatment', 'relapse/child', 'rehabilitation/wheelchair', and 'injection/symptoms'. However, three topics, 'work', 'birth/health', and 'partnership/MS' represent domains that are of great relevance for participants but are generally understudied in MS research. While emotions were predominantly negative (sadness, anxiety), emotions linked to the topics 'birth/health' and 'partnership/MS' was also positive (joy). Designed in close collaboration with persons with MS, the 'My Life with MS' project explores the experience of living with the chronic disease of MS using NLP and ML. Our study thus contributes to the body of research demonstrating the potential of integrating citizen science with ML-driven NLP methods to explore the experience of living with a chronic condition.",True,other,Not specified
37163511,A method for rapid machine learning development for data mining with doctor-in-the-loop,"Classifying free-text from historical databases into research-compatible formats is a barrier for clinicians undertaking audit and research projects. The aim of this study was to (a) develop interactive active machine-learning model training methodology using readily available software that was (b) easily adaptable to a wide range of natural language databases and allowed customised researcher-defined categories, and then (c) evaluate the accuracy and speed of this model for classifying free text from two unique and unrelated clinical notes into coded data. A user interface for medical experts to train and evaluate the algorithm was created. Data requiring coding in the form of two independent databases of free-text clinical notes, each of unique natural language structure. Medical experts defined categories relevant to research projects and performed 'label-train-evaluate' loops on the training data set. A separate dataset was used for validation, with the medical experts blinded to the label given by the algorithm. The first dataset was 32,034 death certificate records from Northern Territory Births Deaths and Marriages, which were coded into 3 categories: haemorrhagic stroke, ischaemic stroke or no stroke. The second dataset was 12,039 recorded episodes of aeromedical retrieval from two prehospital and retrieval services in Northern Territory, Australia, which were coded into 5 categories: medical, surgical, trauma, obstetric or psychiatric. For the first dataset, macro-accuracy of the algorithm was 94.7%. For the second dataset, macro-accuracy was 92.4%. The time taken to develop and train the algorithm was 124 minutes for the death certificate coding, and 144 minutes for the aeromedical retrieval coding. This machine-learning training method was able to classify free-text clinical notes quickly and accurately from two different health datasets into categories of relevance to clinicians undertaking health service research.",True,text mining,autoencoder
36896545,Optimal feature selection using novel flamingo search algorithm for classification of COVID-19 patients from clinical text,"Though several AI-based models have been established for COVID-19 diagnosis, the machine-based diagnostic gap is still ongoing, making further efforts to combat this epidemic imperative. So, we tried to create a new feature selection (FS) method because of the persistent need for a reliable system to choose features and to develop a model to predict the COVID-19 virus from clinical texts. This study employs a newly developed methodology inspired by the flamingo's behavior to find a near-ideal feature subset for accurate diagnosis of COVID-19 patients. The best features are selected using a two-stage. In the first stage, we implemented a term weighting technique, which that is RTF-C-IEF, to quantify the significance of the features extracted. The second stage involves using a newly developed feature selection approach called the improved binary flamingo search algorithm (IBFSA), which chooses the most important and relevant features for COVID-19 patients. The proposed multi-strategy improvement process is at the heart of this study to improve the search algorithm. The primary objective is to broaden the algorithm's capabilities by increasing diversity and support exploring the algorithm search space. Additionally, a binary mechanism was used to improve the performance of traditional FSA to make it appropriate for binary FS issues. Two datasets, totaling 3053 and 1446 cases, were used to evaluate the suggested model based on the Support Vector Machine (SVM) and other classifiers. The results showed that IBFSA has the best performance compared to numerous previous swarm algorithms. It was noted, that the number of feature subsets that were chosen was also drastically reduced by 88% and obtained the best global optimal features.",True,both,recurrent neural network
36530667,An NLP tool for data extraction from electronic health records: COVID-19 mortalities and comorbidities,"BACKGROUND: The high infection rate, severe symptoms, and evolving aspects of the COVID-19 pandemic provide challenges for a variety of medical systems around the world. Automatic information retrieval from unstructured text is greatly aided by Natural Language Processing (NLP), the primary approach taken in this field. This study addresses COVID-19 mortality data from the intensive care unit (ICU) in Kuwait during the first 18 months of the pandemic. A key goal is to extract and classify the primary and intermediate causes of death from electronic health records (EHRs) in a timely way. In addition, comorbid conditions or concurrent diseases were retrieved and analyzed in relation to a variety of causes of mortality.
METHOD: An NLP system using the Python programming language is constructed to automate the process of extracting primary and secondary causes of death, as well as comorbidities. The system is capable of handling inaccurate and messy data, this includes inadequate formats, spelling mistakes and mispositioned information. A machine learning decision trees method is used to classify the causes of death.
RESULTS: For 54.8% of the 1691 ICU patients we studied, septic shock or sepsis-related multiorgan failure was the leading cause of mortality. About three-quarters of patients die from acute respiratory distress syndrome (ARDS), a common intermediate cause of death. An arrhythmia (AF) disorder was determined to be the strongest predictor of intermediate cause of death, whether caused by ARDS or other causes.
CONCLUSION: We created an NLP system to automate the extraction of causes of death and comorbidities from EHRs. Our method processes messy and erroneous data and classifies the primary and intermediate causes of death of COVID-19 patients. We advocate arranging the EHR with well-defined sections and menu-driven options to reduce incorrect forms.",True,text mining,Not specified
36388916,Editorial: Clinical applications of artificial intelligence in retinal and optic nerve disease,,True,other,GAN
36252126,The Real-World Experiences of Persons With Multiple Sclerosis During the First COVID-19 Lockdown: Application of Natural Language Processing,"BACKGROUND: The increasing availability of ""real-world"" data in the form of written text holds promise for deepening our understanding of societal and health-related challenges. Textual data constitute a rich source of information, allowing the capture of lived experiences through a broad range of different sources of information (eg, content and emotional tone). Interviews are the ""gold standard"" for gaining qualitative insights into individual experiences and perspectives. However, conducting interviews on a large scale is not always feasible, and standardized quantitative assessment suitable for large-scale application may miss important information. Surveys that include open-text assessments can combine the advantages of both methods and are well suited for the application of natural language processing (NLP) methods. While innovations in NLP have made large-scale text analysis more accessible, the analysis of real-world textual data is still complex and requires several consecutive steps.
OBJECTIVE: We developed and subsequently examined the utility and scientific value of an NLP pipeline for extracting real-world experiences from textual data to provide guidance for applied researchers.
METHODS: We applied the NLP pipeline to large-scale textual data collected by the Swiss Multiple Sclerosis (MS) registry. Such textual data constitute an ideal use case for the study of real-world text data. Specifically, we examined 639 text reports on the experienced impact of the first COVID-19 lockdown from the perspectives of persons with MS. The pipeline has been implemented in Python and complemented by analyses of the ""Linguistic Inquiry and Word Count"" software. It consists of the following 5 interconnected analysis steps: (1) text preprocessing; (2) sentiment analysis; (3) descriptive text analysis; (4) unsupervised learning-topic modeling; and (5) results interpretation and validation.
RESULTS: A topic modeling analysis identified the following 4 distinct groups based on the topics participants were mainly concerned with: ""contacts/communication;"" ""social environment;"" ""work;"" and ""errands/daily routines."" Notably, the sentiment analysis revealed that the ""contacts/communication"" group was characterized by a pronounced negative emotional tone underlying the text reports. This observed heterogeneity in emotional tonality underlying the reported experiences of the first COVID-19-related lockdown is likely to reflect differences in emotional burden, individual circumstances, and ways of coping with the pandemic, which is in line with previous research on this matter.
CONCLUSIONS: This study illustrates the timely and efficient applicability of an NLP pipeline and thereby serves as a precedent for applied researchers. Our study thereby contributes to both the dissemination of NLP techniques in applied health sciences and the identification of previously unknown experiences and burdens of persons with MS during the pandemic, which may be relevant for future treatment.",True,other,Not specified
36249261,Application of machine learning and natural language processing for predicting stroke-associated pneumonia,"BACKGROUND: Identifying patients at high risk of stroke-associated pneumonia (SAP) may permit targeting potential interventions to reduce its incidence. We aimed to explore the functionality of machine learning (ML) and natural language processing techniques on structured data and unstructured clinical text to predict SAP by comparing it to conventional risk scores.
METHODS: Linked data between a hospital stroke registry and a deidentified research-based database including electronic health records and administrative claims data was used. Natural language processing was applied to extract textual features from clinical notes. The random forest algorithm was used to build ML models. The predictive performance of ML models was compared with the A2DS2, ISAN, PNA, and ACDD4 scores using the area under the receiver operating characteristic curve (AUC).
RESULTS: Among 5,913 acute stroke patients hospitalized between Oct 2010 and Sep 2021, 450 (7.6%) developed SAP within the first 7 days after stroke onset. The ML model based on both textual features and structured variables had the highest AUC [0.840, 95% confidence interval (CI) 0.806-0.875], significantly higher than those of the ML model based on structured variables alone (0.828, 95% CI 0.793-0.863, P = 0.040), ACDD4 (0.807, 95% CI 0.766-0.849, P = 0.041), A2DS2 (0.803, 95% CI 0.762-0.845, P = 0.013), ISAN (0.795, 95% CI 0.752-0.837, P = 0.009), and PNA (0.778, 95% CI 0.735-0.822, P &lt; 0.001). All models demonstrated adequate calibration except for the A2DS2 score.
CONCLUSIONS: The ML model based on both textural features and structured variables performed better than conventional risk scores in predicting SAP. The workflow used to generate ML prediction models can be disseminated for local adaptation by individual healthcare organizations.",True,other,convolutional neural network
36197453,Overview of the COVID-19 text mining tool interactive demonstration track in BioCreative VII,"The coronavirus disease 2019 (COVID-19) pandemic has compelled biomedical researchers to communicate data in real time to establish more effective medical treatments and public health policies. Nontraditional sources such as preprint publications, i.e. articles not yet validated by peer review, have become crucial hubs for the dissemination of scientific results. Natural language processing (NLP) systems have been recently developed to extract and organize COVID-19 data in reasoning systems. Given this scenario, the BioCreative COVID-19 text mining tool interactive demonstration track was created to assess the landscape of the available tools and to gauge user interest, thereby providing a two-way communication channel between NLP system developers and potential end users. The goal was to inform system designers about the performance and usability of their products and to suggest new additional features. Considering the exploratory nature of this track, the call for participation solicited teams to apply for the track, based on their system's ability to perform COVID-19-related tasks and interest in receiving user feedback. We also recruited volunteer users to test systems. Seven teams registered systems for the track, and &gt;30 individuals volunteered as test users; these volunteer users covered a broad range of specialties, including bench scientists, bioinformaticians and biocurators. The users, who had the option to participate anonymously, were provided with written and video documentation to familiarize themselves with the NLP tools and completed a survey to record their evaluation. Additional feedback was also provided by NLP system developers. The track was well received as shown by the overall positive feedback from the participating teams and the users. Database URL: https://biocreative.bioinformatics.udel.edu/tasks/biocreative-vii/track-4/.",True,text mining,CNN
36168546,Natural Language Processing and Machine Learning to Identify People Who Inject Drugs in Electronic Health Records,"BACKGROUND: Improving the identification of people who inject drugs (PWID) in electronic medical records can improve clinical decision making, risk assessment and mitigation, and health service research. Identification of PWID currently consists of heterogeneous, nonspecific International Classification of Diseases (ICD) codes as proxies. Natural language processing (NLP) and machine learning (ML) methods may have better diagnostic metrics than nonspecific ICD codes for identifying PWID.
METHODS: We manually reviewed 1000 records of patients diagnosed with Staphylococcus aureus bacteremia admitted to Veterans Health Administration hospitals from 2003 through 2014. The manual review was the reference standard. We developed and trained NLP/ML algorithms with and without regular expression filters for negation (NegEx) and compared these with 11 proxy combinations of ICD codes to identify PWID. Data were split 70% for training and 30% for testing. We calculated diagnostic metrics and estimated 95% confidence intervals (CIs) by bootstrapping the hold-out test set. Best models were determined by best F-score, a summary of sensitivity and positive predictive value.
RESULTS: Random forest with and without NegEx were the best-performing NLP/ML algorithms in the training set. Random forest with NegEx outperformed all ICD-based algorithms. F-score for the best NLP/ML algorithm was 0.905 (95% CI, .786-.967) and 0.592 (95% CI, .550-.632) for the best ICD-based algorithm. The NLP/ML algorithm had a sensitivity of 92.6% and specificity of 95.4%.
CONCLUSIONS: NLP/ML outperformed ICD-based coding algorithms at identifying PWID in electronic health records. NLP/ML models should be considered in identifying cohorts of PWID to improve clinical decision making, health services research, and administrative surveillance.",True,text mining,Not specified
35938002,MLEE: A method for extracting object-level medical knowledge graph entities from Chinese clinical records,"As a typical knowledge-intensive industry, the medical field uses knowledge graph technology to construct causal inference calculations, such as ""symptom-disease"", ""laboratory examination/imaging examination-disease"", and ""disease-treatment method"". The continuous expansion of large electronic clinical records provides an opportunity to learn medical knowledge by machine learning. In this process, how to extract entities with a medical logic structure and how to make entity extraction more consistent with the logic of the text content in electronic clinical records are two issues that have become key in building a high-quality, medical knowledge graph. In this work, we describe a method for extracting medical entities using real Chinese clinical electronic clinical records. We define a computational architecture named MLEE to extract object-level entities with ""object-attribute"" dependencies. We conducted experiments based on randomly selected electronic clinical records of 1,000 patients from Shengjing Hospital of China Medical University to verify the effectiveness of the method.",True,other,convolutional neural network
35834334,Language-agnostic pharmacovigilant text mining to elicit side effects from clinical notes and hospital medication records,"We sought to craft a drug safety signalling pipeline associating latent information in clinical free text with exposures to single drugs and drug pairs. Data arose from 12 secondary and tertiary public hospitals in two Danish regions, comprising approximately half the Danish population. Notes were operationalised with a fastText embedding, based on which we trained 10 270 neural-network models (one for each distinct single-drug/drug-pair exposure) predicting the risk of exposure given an embedding vector. We included 2 905 251 admissions between May 2008 and June 2016, with 13 740 564 distinct drug prescriptions; the median number of prescriptions was 5 (IQR: 3-9) and in 1 184 340 (41%) admissions patients used ≥5 drugs concomitantly. A total of 10 788 259 clinical notes were included, with 179 441 739 tokens retained after pruning. Of 345 single-drug signals reviewed, 28 (8.1%) represented possibly undescribed relationships; 186 (54%) signals were clinically meaningful. Sixteen (14%) of the 115 drug-pair signals were possible interactions, and two (1.7%) were known. In conclusion, we built a language-agnostic pipeline for mining associations between free-text information and medication exposure without manual curation, predicting not the likely outcome of a range of exposures but also the likely exposures for outcomes of interest. Our approach may help overcome limitations of text mining methods relying on curated data in English and can help leverage non-English free text for pharmacovigilance.",True,both,Not specified
35750878,Preparing for the next pandemic via transfer learning from existing diseases with hierarchical multi-modal BERT: a study on COVID-19 outcome prediction,"Developing prediction models for emerging infectious diseases from relatively small numbers of cases is a critical need for improving pandemic preparedness. Using COVID-19 as an exemplar, we propose a transfer learning methodology for developing predictive models from multi-modal electronic healthcare records by leveraging information from more prevalent diseases with shared clinical characteristics. Our novel hierarchical, multi-modal model ([Formula: see text]) integrates baseline risk factors from the natural language processing of clinical notes at admission, time-series measurements of biomarkers obtained from laboratory tests, and discrete diagnostic, procedure and drug codes. We demonstrate the alignment of [Formula: see text]'s predictions with well-established clinical knowledge about COVID-19 through univariate and multivariate risk factor driven sub-cohort analysis. [Formula: see text]'s superior performance over state-of-the-art methods shows that leveraging patient data across modalities and transferring prior knowledge from similar disorders is critical for accurate prediction of patient outcomes, and this approach may serve as an important tool in the early response to future pandemics.",True,text mining,convolutional neural network
35647478,Developing and optimizing a computable phenotype for incident venous thromboembolism in a longitudinal cohort of patients with cancer,"BACKGROUND: Research on venous thromboembolism (VTE) that relies only on the International Classification of Diseases (ICD) can misclassify outcomes. Our study aims to discover and validate an improved VTE computable phenotype for people with cancer.
METHODS: We used a cancer registry electronic health record (EHR)-linked longitudinal database. We derived three algorithms that were ICD/medication based, natural language processing (NLP) based, or all combined. We then randomly sampled 400 patients from patients with VTE codes (n = 1111) and 400 from those without VTE codes (n = 7396). Weighted sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) were calculated on the entire sample using inverse probability weighting, followed by bootstrapped receiver operating curve analysis to calculate the concordance statistic (c statistic).
RESULTS: Among 800 patients sampled, 280 had a confirmed acute VTE during the first year after cancer diagnosis. The ICD/medication algorithm had a weighted PPV of 95% and a weighted sensitivity of 81%, with a c statistic of 0.90 (95% confidence interval [CI], 0.89-0.91). Adding Current Procedural Terminology codes for inferior vena cava filter removal or early death did not improve the performance. The NLP algorithm had a weighted PPV of 80% and a weighted sensitivity of 90%, with a c statistic of 0.93 (95% CI, 0.92-0.94). The combined algorithm had a weighted PPV of 98% at the higher cutoff and a weighted sensitivity of 96% at the lower cutoff, with a c statistic of 0.98 (95% CI, 0.97-0.98).
CONCLUSIONS: Our ICD/medication-based algorithm can accurately identify VTE phenotype among patients with cancer with a high PPV of 95%. The combined algorithm should be considered in EHR databases that have access to such capabilities.",True,text mining,RNN
35430265,Text mining in mosquito-borne disease: A systematic review,"Mosquito-borne diseases are emerging and re-emerging across the globe, especially after the COVID19 pandemic. The recent advances in text mining in infectious diseases hold the potential of providing timely access to explicit and implicit associations among information in the text. In the past few years, the availability of online text data in the form of unstructured or semi-structured text with rich content of information from this domain enables many studies to provide solutions in this area, e.g., disease-related knowledge discovery, disease surveillance, early detection system, etc. However, a recent review of text mining in the domain of mosquito-borne disease was not available to the best of our knowledge. In this review, we survey the recent works in the text mining techniques used in combating mosquito-borne diseases. We highlight the corpus sources, technologies, applications, and the challenges faced by the studies, followed by the possible future directions that can be taken further in this domain. We present a bibliometric analysis of the 294 scientific articles that have been published in Scopus and PubMed in the domain of text mining in mosquito-borne diseases, from the year 2016 to 2021. The papers were further filtered and reviewed based on the techniques used to analyze the text related to mosquito-borne diseases. Based on the corpus of 158 selected articles, we found 27 of the articles were relevant and used text mining in mosquito-borne diseases. These articles covered the majority of Zika (38.70%), Dengue (32.26%), and Malaria (29.03%), with extremely low numbers or none of the other crucial mosquito-borne diseases like chikungunya, yellow fever, West Nile fever. Twitter was the dominant corpus resource to perform text mining in mosquito-borne diseases, followed by PubMed and LexisNexis databases. Sentiment analysis was the most popular technique of text mining to understand the discourse of the disease and followed by information extraction, which dependency relation and co-occurrence-based approach to extract relations and events. Surveillance was the main usage of most of the reviewed studies and followed by treatment, which focused on the drug-disease or symptom-disease association. The advance in text mining could improve the management of mosquito-borne diseases. However, the technique and application posed many limitations and challenges, including biases like user authentication and language, real-world implementation, etc. We discussed the future direction which can be useful to expand this area and domain. This review paper contributes mainly as a library for text mining in mosquito-borne diseases and could further explore the system for other neglected diseases.",True,both,Not specified
35426190,Predictive models for clinical decision making: Deep dives in practical machine learning,"The deployment of machine learning for tasks relevant to complementing standard of care and advancing tools for precision health has gained much attention in the clinical community, thus meriting further investigations into its broader use. In an introduction to predictive modelling using machine learning, we conducted a review of the recent literature that explains standard taxonomies, terminology and central concepts to a broad clinical readership. Articles aimed at readers with little or no prior experience of commonly used methods or typical workflows were summarised and key references are highlighted. Continual interdisciplinary developments in data science, biostatistics and epidemiology also motivated us to further discuss emerging topics in predictive and data-driven (hypothesis-less) analytics with machine learning. Through two methodological deep dives using examples from precision psychiatry and outcome prediction after lymphoma, we highlight how the use of, for example, natural language processing can outperform established clinical risk scores and aid dynamic prediction and adaptive care strategies. Such realistic and detailed examples allow for critical analysis of the importance of new technological advances in artificial intelligence for clinical decision-making. New clinical decision support systems can assist in prevention and care by leveraging precision medicine.",True,other,RNN
35322668,Information Extraction From Electronic Health Records to Predict Readmission Following Acute Myocardial Infarction: Does Natural Language Processing Using Clinical Notes Improve Prediction of Readmission?,"Background Social risk factors influence rehospitalization rates yet are challenging to incorporate into prediction models. Integration of social risk factors using natural language processing (NLP) and machine learning could improve risk prediction of 30-day readmission following an acute myocardial infarction. Methods and Results Patients were enrolled into derivation and validation cohorts. The derivation cohort included inpatient discharges from Vanderbilt University Medical Center between January 1, 2007, and December 31, 2016, with a primary diagnosis of acute myocardial infarction, who were discharged alive, and not transferred from another facility. The validation cohort included patients from Dartmouth-Hitchcock Health Center between April 2, 2011, and December 31, 2016, meeting the same eligibility criteria described above. Data from both sites were linked to Centers for Medicare & Medicaid Services administrative data to supplement 30-day hospital readmissions. Clinical notes from each cohort were extracted, and an NLP model was deployed, counting mentions of 7 social risk factors. Five machine learning models were run using clinical and NLP-derived variables. Model discrimination and calibration were assessed, and receiver operating characteristic comparison analyses were performed. The 30-day rehospitalization rates among the derivation (n=6165) and validation (n=4024) cohorts were 15.1% (n=934) and 10.2% (n=412), respectively. The derivation models demonstrated no statistical improvement in model performance with the addition of the selected NLP-derived social risk factors. Conclusions Social risk factors extracted using NLP did not significantly improve 30-day readmission prediction among hospitalized patients with acute myocardial infarction. Alternative methods are needed to capture social risk factors.",True,computer vision,RNN
35171725,A scoping review of asthma and machine learning,"OBJECTIVE: The objective of this study was to determine the extent of machine learning (ML) application in asthma research and to identify research gaps while mapping the existing literature.
DATA SOURCES: We conducted a scoping review. PubMed, ProQuest, and Embase Scopus databases were searched with an end date of September 18, 2020.
STUDY SELECTION: DistillerSR was used for data management. Inclusion criteria were an asthma focus, human participants, ML techniques, and written in English. Exclusion criteria were abstract only, simulation-based, not human based, or were reviews or commentaries. Descriptive statistics were presented.
RESULTS: A total of 6,317 potential articles were found. After removing duplicates, and reviewing the titles and abstracts, 102 articles were included for the full text analysis. Asthma episode prediction (24.5%), asthma phenotype classification (16.7%), and genetic profiling of asthma (12.7%) were the top three study topics. Cohort (52.9%), cross-sectional (20.6%), and case-control studies (11.8%) were the study designs most frequently used. Regarding the ML techniques, 34.3% of the studies used more than one technique. Neural networks, clustering, and random forests were the most common ML techniques used where they were used in 20.6%, 18.6%, and 17.6% of studies, respectively. Very few studies considered location of residence (i.e. urban or rural status).
CONCLUSIONS: The use of ML in asthma studies has been increasing with most of this focused on the three major topics (>50%). Future research using ML could focus on gaps such as a broader range of study topics and focus on its use in additional populations (e.g. location of residence).
UNLABELLED: Supplemental data for this article is available online at http://dx.doi.org/ .",True,other,Not specified
35121948,An artificial intelligence framework integrating longitudinal electronic health records with real-world data enables continuous pan-cancer prognostication,"Despite widespread adoption of electronic health records (EHRs), most hospitals are not ready to implement data science research in the clinical pipelines. Here, we develop MEDomics, a continuously learning infrastructure through which multimodal health data are systematically organized and data quality is assessed with the goal of applying artificial intelligence for individual prognosis. Using this framework, currently composed of thousands of individuals with cancer and millions of data points over a decade of data recording, we demonstrate prognostic utility of this framework in oncology. As proof of concept, we report an analysis using this infrastructure, which identified the Framingham risk score to be robustly associated with mortality among individuals with early-stage and advanced-stage cancer, a potentially actionable finding from a real-world cohort of individuals with cancer. Finally, we show how natural language processing (NLP) of medical notes could be used to continuously update estimates of prognosis as a given individual's disease course unfolds.",True,other,RNN
35039533,A machine learning application for raising WASH awareness in the times of COVID-19 pandemic,"The COVID-19 pandemic has revealed the power of internet disinformation in influencing global health. The deluge of information travels faster than the epidemic itself and is a threat to the health of millions across the globe. Health apps need to leverage machine learning for delivering the right information while constantly learning misinformation trends and deliver these effectively in vernacular languages in order to combat the infodemic at the grassroot levels in the general public. Our application, WashKaro, is a multi-pronged intervention that uses conversational Artificial Intelligence (AI), machine translation, and natural language processing to combat misinformation (NLP). WashKaro uses AI to provide accurate information matched against WHO recommendations and delivered in an understandable format in local languages. The primary aim of this study was to assess the use of neural models for text summarization and machine learning for delivering WHO matched COVID-19 information to mitigate the misinfodemic. The secondary aim of this study was to develop a symptom assessment tool and segmentation insights for improving the delivery of information. A total of 5026 people downloaded the app during the study window; among those, 1545 were actively engaged users. Our study shows that 3.4 times more females engaged with the App in Hindi as compared to males, the relevance of AI-filtered news content doubled within 45 days of continuous machine learning, and the prudence of integrated AI chatbot ""Satya"" increased thus proving the usefulness of a mHealth platform to mitigate health misinformation. We conclude that a machine learning application delivering bite-sized vernacular audios and conversational AI is a practical approach to mitigate health misinformation.",True,other,CNN
34837942,A multitask transfer learning framework for the prediction of virus-human protein-protein interactions,"BACKGROUND: Viral infections are causing significant morbidity and mortality worldwide. Understanding the interaction patterns between a particular virus and human proteins plays a crucial role in unveiling the underlying mechanism of viral infection and pathogenesis. This could further help in prevention and treatment of virus-related diseases. However, the task of predicting protein-protein interactions between a new virus and human cells is extremely challenging due to scarce data on virus-human interactions and fast mutation rates of most viruses.
RESULTS: We developed a multitask transfer learning approach that exploits the information of around 24 million protein sequences and the interaction patterns from the human interactome to counter the problem of small training datasets. Instead of using hand-crafted protein features, we utilize statistically rich protein representations learned by a deep language modeling approach from a massive source of protein sequences. Additionally, we employ an additional objective which aims to maximize the probability of observing human protein-protein interactions. This additional task objective acts as a regularizer and also allows to incorporate domain knowledge to inform the virus-human protein-protein interaction prediction model.
CONCLUSIONS: Our approach achieved competitive results on 13 benchmark datasets and the case study for the SARS-COV-2 virus receptor. Experimental results show that our proposed model works effectively for both virus-human and bacteria-human protein-protein interaction prediction tasks. We share our code for reproducibility and future research at https://git.l3s.uni-hannover.de/dong/multitask-transfer .",True,other,Not specified
34623312,Categorizing Vaccine Confidence With a Transformer-Based Machine Learning Model: Analysis of Nuances of Vaccine Sentiment in Twitter Discourse,"BACKGROUND: Social media has become an established platform for individuals to discuss and debate various subjects, including vaccination. With growing conversations on the web and less than desired maternal vaccination uptake rates, these conversations could provide useful insights to inform future interventions. However, owing to the volume of web-based posts, manual annotation and analysis are difficult and time consuming. Automated processes for this type of analysis, such as natural language processing, have faced challenges in extracting complex stances such as attitudes toward vaccination from large amounts of text.
OBJECTIVE: The aim of this study is to build upon recent advances in transposer-based machine learning methods and test whether transformer-based machine learning could be used as a tool to assess the stance expressed in social media posts toward vaccination during pregnancy.
METHODS: A total of 16,604 tweets posted between November 1, 2018, and April 30, 2019, were selected using keyword searches related to maternal vaccination. After excluding irrelevant tweets, the remaining tweets were coded by 3 individual researchers into the categories Promotional, Discouraging, Ambiguous, and Neutral or No Stance. After creating a final data set of 2722 unique tweets, multiple machine learning techniques were trained on a part of this data set and then tested and compared with the human annotators.
RESULTS: We found the accuracy of the machine learning techniques to be 81.8% (F score=0.78) compared with the agreed score among the 3 annotators. For comparison, the accuracies of the individual annotators compared with the final score were 83.3%, 77.9%, and 77.5%.
CONCLUSIONS: This study demonstrates that we are able to achieve close to the same accuracy in categorizing tweets using our machine learning models as could be expected from a single human coder. The potential to use this automated process, which is reliable and accurate, could free valuable time and resources for conducting this analysis, in addition to informing potentially effective and necessary interventions.",True,text mining,Not specified
34588153,Web-based and machine learning approaches for identification of patient-reported outcomes in inflammatory bowel disease,"BACKGROUND: Messages from an Internet forum are raw material that emerges in a natural setting (i.e., non-induced by a research situation).
AIMS: The FLARE-IBD project aimed at using an innovative approach consisting of collecting messages posted by patients in an Internet forum and conducting a machine-learning study (data analysis/language processing) for developing a patient-reported outcome measuring flare in inflammatory bowel disease meeting international requirements.
METHODS: We used web-based and machine learning approaches, in the following steps. 1) Web-scraping to collect all available posts in an Internet forum (23 656 messages) and extracting metadata from the forum. 2) Twenty patients were randomly assigned 50 extracted messages; participants indicated whether the message corresponded or not to the flare phenomenon (labeling). If yes, participants were asked to identify excerpts from the text they considered significant flare markers (annotation). 3) The set of annotated messages underwent a vocabulary analysis.
RESULTS: The phenomenon of flare was circumscribed with the identification of 20 surrogate flare markers classified into five dimensions with their frequency within extracted labeled data: impact on life, symptoms, extra-intestinal manifestations, drugs and environmental factors. Web-based and machine-learning approaches met international recommendations to inform the content and structure for the development of patient-reported outcomes.",True,other,Not specified
34142418,Using machine learning to predict severe hypoglycaemia in hospital,"AIM: To predict the risk of hypoglycaemia using machine-learning techniques in hospitalized patients.
METHODS: We conducted a retrospective cohort study of patients hospitalized under general internal medicine (GIM) and cardiovascular surgery (CV) at a tertiary care teaching hospital in Toronto, Ontario. Three models were generated using supervised machine learning: least absolute shrinkage and selection operator (LASSO) logistic regression; gradient-boosted trees; and a recurrent neural network. Each model included baseline patient data and time-varying data. Natural-language processing was used to incorporate text data from physician and nursing notes.
RESULTS: We included 8492 GIM admissions and 8044 CV admissions. Hypoglycaemia occurred in 16% of GIM admissions and 13% of CV admissions. The area under the curve for the models in the held-out validation set was approximately 0.80 on the GIM ward and 0.82 on the CV ward. When the threshold for hypoglycaemia was lowered to 2.9 mmol/L (52 mg/dL), similar results were observed. Among the patients at the highest decile of risk, the positive predictive value was approximately 50% and the sensitivity was 99%.
CONCLUSION: Machine-learning approaches can accurately identify patients at high risk of hypoglycaemia in hospital. Future work will involve evaluating whether implementing this model with targeted clinical interventions can improve clinical outcomes.",True,other,Not specified
33977022,Using data mining techniques to fight and control epidemics: A scoping review,"The main objective of this survey is to study the published articles to determine the most favorite data mining methods and gap of knowledge. Since the threat of pandemics has raised concerns for public health, data mining techniques were applied by researchers to reveal the hidden knowledge. Web of Science, Scopus, and PubMed databases were selected for systematic searches. Then, all of the retrieved articles were screened in the stepwise process according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses checklist to select appropriate articles. All of the results were analyzed and summarized based on some classifications. Out of 335 citations were retrieved, 50 articles were determined as eligible articles through a scoping review. The review results showed that the most favorite DM belonged to Natural language processing (22%) and the most commonly proposed approach was revealing disease characteristics (22%). Regarding diseases, the most addressed disease was COVID-19. The studies show a predominance of applying supervised learning techniques (90%). Concerning healthcare scopes, we found that infectious disease (36%) to be the most frequent, closely followed by epidemiology discipline. The most common software used in the studies was SPSS (22%) and R (20%). The results revealed that some valuable researches conducted by employing the capabilities of knowledge discovery methods to understand the unknown dimensions of diseases in pandemics. But most researches will need in terms of treatment and disease control.",True,other,Not specified
33950204,LitSuggest: a web-based system for literature recommendation and curation using machine learning,"Searching and reading relevant literature is a routine practice in biomedical research. However, it is challenging for a user to design optimal search queries using all the keywords related to a given topic. As such, existing search systems such as PubMed often return suboptimal results. Several computational methods have been proposed as an effective alternative to keyword-based query methods for literature recommendation. However, those methods require specialized knowledge in machine learning and natural language processing, which can make them difficult for biologists to utilize. In this paper, we propose LitSuggest, a web server that provides an all-in-one literature recommendation and curation service to help biomedical researchers stay up to date with scientific literature. LitSuggest combines advanced machine learning techniques for suggesting relevant PubMed articles with high accuracy. In addition to innovative text-processing methods, LitSuggest offers multiple advantages over existing tools. First, LitSuggest allows users to curate, organize, and download classification results in a single interface. Second, users can easily fine-tune LitSuggest results by updating the training corpus. Third, results can be readily shared, enabling collaborative analysis and curation of scientific literature. Finally, LitSuggest provides an automated personalized weekly digest of newly published articles for each user's project. LitSuggest is publicly available at https://www.ncbi.nlm.nih.gov/research/litsuggest.",True,text mining,Not specified
33886492,Tweet Topics and Sentiments Relating to COVID-19 Vaccination Among Australian Twitter Users: Machine Learning Analysis,"BACKGROUND: COVID-19 is one of the greatest threats to human beings in terms of health care, economy, and society in recent history. Up to this moment, there have been no signs of remission, and there is no proven effective cure. Vaccination is the primary biomedical preventive measure against the novel coronavirus. However, public bias or sentiments, as reflected on social media, may have a significant impact on the progression toward achieving herd immunity.
OBJECTIVE: This study aimed to use machine learning methods to extract topics and sentiments relating to COVID-19 vaccination on Twitter.
METHODS: We collected 31,100 English tweets containing COVID-19 vaccine-related keywords between January and October 2020 from Australian Twitter users. Specifically, we analyzed tweets by visualizing high-frequency word clouds and correlations between word tokens. We built a latent Dirichlet allocation (LDA) topic model to identify commonly discussed topics in a large sample of tweets. We also performed sentiment analysis to understand the overall sentiments and emotions related to COVID-19 vaccination in Australia.
RESULTS: Our analysis identified 3 LDA topics: (1) attitudes toward COVID-19 and its vaccination, (2) advocating infection control measures against COVID-19, and (3) misconceptions and complaints about COVID-19 control. Nearly two-thirds of the sentiments of all tweets expressed a positive public opinion about the COVID-19 vaccine; around one-third were negative. Among the 8 basic emotions, trust and anticipation were the two prominent positive emotions observed in the tweets, while fear was the top negative emotion.
CONCLUSIONS: Our findings indicate that some Twitter users in Australia supported infection control measures against COVID-19 and refuted misinformation. However, those who underestimated the risks and severity of COVID-19 may have rationalized their position on COVID-19 vaccination with conspiracy theories. We also noticed that the level of positive sentiment among the public may not be sufficient to increase vaccination coverage to a level high enough to achieve vaccination-induced herd immunity. Governments should explore public opinion and sentiments toward COVID-19 and COVID-19 vaccination, and implement an effective vaccination promotion scheme in addition to supporting the development and clinical administration of COVID-19 vaccines.",True,both,Not specified
33875160,NewsMeSH: A new classifier designed to annotate health news with MeSH headings,"MOTIVATION: In the age of big data, the amount of scientific information available online dwarfs the ability of current tools to support researchers in locating and securing access to the necessary materials. Well-structured open data and the smart systems that make the appropriate use of it are invaluable and can help health researchers and professionals to find the appropriate information by, e.g., configuring the monitoring of information or refining a specific query on a disease.
METHODS: We present an automated text classifier approach based on the MEDLINE/MeSH thesaurus, trained on the manual annotation of more than 26 million expert-annotated scientific abstracts. The classifier was developed tailor-fit to the public health and health research domain experts, in the light of their specific challenges and needs. We have applied the proposed methodology on three specific health domains: the Coronavirus, Mental Health and Diabetes, considering the pertinence of the first, and the known relations with the other two health topics.
RESULTS: A classifier is trained on the MEDLINE dataset that can automatically annotate text, such as scientific articles, news articles or medical reports with relevant concepts from the MeSH thesaurus.
CONCLUSIONS: The proposed text classifier shows promising results in the evaluation of health-related news. The application of the developed classifier enables the exploration of news and extraction of health-related insights, based on the MeSH thesaurus, through a similar workflow as in the usage of PubMed, with which most health researchers are familiar.",True,other,Not specified
33848833,Machine Learning and Surgical Outcomes Prediction: A Systematic Review,"BACKGROUND: Machine learning (ML) has garnered increasing attention as a means to quantitatively analyze the growing and complex medical data to improve individualized patient care. We herein aim to critically examine the current state of ML in predicting surgical outcomes, evaluate the quality of currently available research, and propose areas of improvement for future uses of ML in surgery.
METHODS: A systematic review was conducted in accordance with the Preferred Reporting Items for a Systematic Review and Meta-Analysis (PRISMA) checklist. PubMed, MEDLINE, and Embase databases were reviewed under search syntax ""machine learning"" and ""surgery"" for papers published between 2015 and 2020.
RESULTS: Of the initial 2677 studies, 45 papers met inclusion and exclusion criteria. Fourteen different subspecialties were represented with neurosurgery being most common. The most frequently used ML algorithms were random forest (n = 19), artificial neural network (n = 17), and logistic regression (n = 17). Common outcomes included postoperative mortality, complications, patient reported quality of life and pain improvement. All studies which compared ML algorithms to conventional studies which used area under the curve (AUC) to measure accuracy found improved outcome prediction with ML models.
CONCLUSIONS: While still in its early stages, ML models offer surgeons an opportunity to capitalize on the myriad of clinical data available and improve individualized patient care. Limitations included heterogeneous outcome and imperfect quality of some of the papers. We therefore urge future research to agree upon methods of outcome reporting and require basic quality standards.",True,other,RNN
33739287,"Revealing Opinions for COVID-19 Questions Using a Context Retriever, Opinion Aggregator, and Question-Answering Model: Model Development Study","BACKGROUND: COVID-19 has challenged global public health because it is highly contagious and can be lethal. Numerous ongoing and recently published studies about the disease have emerged. However, the research regarding COVID-19 is largely ongoing and inconclusive.
OBJECTIVE: A potential way to accelerate COVID-19 research is to use existing information gleaned from research into other viruses that belong to the coronavirus family. Our objective is to develop a natural language processing method for answering factoid questions related to COVID-19 using published articles as knowledge sources.
METHODS: Given a question, first, a BM25-based context retriever model is implemented to select the most relevant passages from previously published articles. Second, for each selected context passage, an answer is obtained using a pretrained bidirectional encoder representations from transformers (BERT) question-answering model. Third, an opinion aggregator, which is a combination of a biterm topic model and k-means clustering, is applied to the task of aggregating all answers into several opinions.
RESULTS: We applied the proposed pipeline to extract answers, opinions, and the most frequent words related to six questions from the COVID-19 Open Research Dataset Challenge. By showing the longitudinal distributions of the opinions, we uncovered the trends of opinions and popular words in the articles published in the five time periods assessed: before 1990, 1990-1999, 2000-2009, 2010-2018, and since 2019. The changes in opinions and popular words agree with several distinct characteristics and challenges of COVID-19, including a higher risk for senior people and people with pre-existing medical conditions; high contagion and rapid transmission; and a more urgent need for screening and testing. The opinions and popular words also provide additional insights for the COVID-19-related questions.
CONCLUSIONS: Compared with other methods of literature retrieval and answer generation, opinion aggregation using our method leads to more interpretable, robust, and comprehensive question-specific literature reviews. The results demonstrate the usefulness of the proposed method in answering COVID-19-related questions with main opinions and capturing the trends of research about COVID-19 and other relevant strains of coronavirus in recent years.",True,other,Not specified
33737920,"Applications of Machine Learning in Human Microbiome Studies: A Review on Feature Selection, Biomarker Identification, Disease Prediction and Treatment","The number of microbiome-related studies has notably increased the availability of data on human microbiome composition and function. These studies provide the essential material to deeply explore host-microbiome associations and their relation to the development and progression of various complex diseases. Improved data-analytical tools are needed to exploit all information from these biological datasets, taking into account the peculiarities of microbiome data, i.e., compositional, heterogeneous and sparse nature of these datasets. The possibility of predicting host-phenotypes based on taxonomy-informed feature selection to establish an association between microbiome and predict disease states is beneficial for personalized medicine. In this regard, machine learning (ML) provides new insights into the development of models that can be used to predict outputs, such as classification and prediction in microbiology, infer host phenotypes to predict diseases and use microbial communities to stratify patients by their characterization of state-specific microbial signatures. Here we review the state-of-the-art ML methods and respective software applied in human microbiome studies, performed as part of the COST Action ML4Microbiome activities. This scoping review focuses on the application of ML in microbiome studies related to association and clinical use for diagnostics, prognostics, and therapeutics. Although the data presented here is more related to the bacterial community, many algorithms could be applied in general, regardless of the feature type. This literature and software review covering this broad topic is aligned with the scoping review methodology. The manual identification of data sources has been complemented with: (1) automated publication search through digital libraries of the three major publishers using natural language processing (NLP) Toolkit, and (2) an automated identification of relevant software repositories on GitHub and ranking of the related research papers relying on learning to rank approach.",True,other,Not specified
33571675,Drug repurposing for COVID-19 via knowledge graph completion,"OBJECTIVE: To discover candidate drugs to repurpose for COVID-19 using literature-derived knowledge and knowledge graph completion methods.
METHODS: We propose a novel, integrative, and neural network-based literature-based discovery (LBD) approach to identify drug candidates from PubMed and other COVID-19-focused research literature. Our approach relies on semantic triples extracted using SemRep (via SemMedDB). We identified an informative and accurate subset of semantic triples using filtering rules and an accuracy classifier developed on a BERT variant. We used this subset to construct a knowledge graph, and applied five state-of-the-art, neural knowledge graph completion algorithms (i.e., TransE, RotatE, DistMult, ComplEx, and STELP) to predict drug repurposing candidates. The models were trained and assessed using a time slicing approach and the predicted drugs were compared with a list of drugs reported in the literature and evaluated in clinical trials. These models were complemented by a discovery pattern-based approach.
RESULTS: Accuracy classifier based on PubMedBERT achieved the best performance (F<sub>1</sub> = 0.854) in identifying accurate semantic predications. Among five knowledge graph completion models, TransE outperformed others (MR = 0.923, Hits@1 = 0.417). Some known drugs linked to COVID-19 in the literature were identified, as well as others that have not yet been studied. Discovery patterns enabled identification of additional candidate drugs and generation of plausible hypotheses regarding the links between the candidate drugs and COVID-19. Among them, five highly ranked and novel drugs (i.e., paclitaxel, SB 203580, alpha 2-antiplasmin, metoclopramide, and oxymatrine) and the mechanistic explanations for their potential use are further discussed.
CONCLUSION: We showed that a LBD approach can be feasible not only for discovering drug candidates for COVID-19, but also for generating mechanistic explanations. Our approach can be generalized to other diseases as well as to other clinical questions. Source code and data are available at https://github.com/kilicogluh/lbd-covid.",True,other,recurrent neural network
33509180,CardioNet: a manually curated database for artificial intelligence-based research on cardiovascular diseases,"BACKGROUND: Cardiovascular diseases (CVDs) are difficult to diagnose early and have risk factors that are easy to overlook. Early prediction and personalization of treatment through the use of artificial intelligence (AI) may help clinicians and patients manage CVDs more effectively. However, to apply AI approaches to CVDs data, it is necessary to establish and curate a specialized database based on electronic health records (EHRs) and include pre-processed unstructured data.
METHODS: To build a suitable database (CardioNet) for CVDs that can utilize AI technology, contributing to the overall care of patients with CVDs. First, we collected the anonymized records of 748,474 patients who had visited the Asan Medical Center (AMC) or Ulsan University Hospital (UUH) because of CVDs. Second, we set clinically plausible criteria to remove errors and duplication. Third, we integrated unstructured data such as readings of medical examinations with structured data sourced from EHRs to create the CardioNet. We subsequently performed natural language processing to structuralize the significant variables associated with CVDs because most results of the principal CVD-related medical examinations are free-text readings. Additionally, to ensure interoperability for convergent multi-center research, we standardized the data using several codes that correspond to the common data model. Finally, we created the descriptive table (i.e., dictionary of the CardioNet) to simplify access and utilization of data for clinicians and engineers and continuously validated the data to ensure reliability.
RESULTS: CardioNet is a comprehensive database that can serve as a training set for AI models and assist in all aspects of clinical management of CVDs. It comprises information extracted from EHRs and results of readings of CVD-related digital tests. It consists of 27 tables, a code-master table, and a descriptive table.
CONCLUSIONS: CardioNet database specialized in CVDs was established, with continuing data collection. We are actively supporting multi-center research, which may require further data processing, depending on the subject of the study. CardioNet will serve as the fundamental database for future CVD-related research projects.",True,other,RNN
33426899,Identifying knowledge gaps in heart failure research among women using unsupervised machine-learning methods,"Aim: To identify knowledge gaps in heart failure (HF) research among women, especially postmenopausal women. Materials &amp; methods: We retrieved HF articles from PubMed. Natural language processing and text mining techniques were used to screen relevant articles and identify study objective(s) from abstracts. After text preprocessing, we performed topic modeling with non-negative matrix factorization to cluster articles based on the primary topic. Clusters were independently validated and labeled by three investigators familiar with HF research. Results: Our model yielded 15 topic clusters from articles on HF among women. Atrial fibrillation was found to be the most understudied topic. From articles specific to postmenopausal women, five clusters were identified. The smallest cluster was about stress-induced cardiomyopathy. Conclusion: Topic modeling can help identify understudied areas in medical research.",True,both,Not specified
33383291,Topic modeling to characterize the natural history of ANCA-Associated vasculitis from clinical notes: A proof of concept study,"OBJECTIVES: Clinical notes from electronic health records (EHR) are important to characterize the natural history, comorbidities, and complications of ANCA-associated vasculitis (AAV) because these details may not be captured by claims and structured data. However, labor-intensive chart review is often required to extract information from notes. We hypothesized that machine learning can automatically discover clinically-relevant themes across longitudinal notes to study AAV.
METHODS: This retrospective study included prevalent PR3- or MPO-ANCA+ AAV cases managed within the Mass General Brigham integrated health care system with providers' notes available between March 1, 1990 and August 23, 2018. We generated clinically-relevant topics mentioned in notes using latent Dirichlet allocation-based topic modeling and conducted trend analyses of those topics over the 2 years prior to and 5 years after the initiation of AAV-specific treatment.
RESULTS: The study cohort included 660 patients with AAV. We generated 90 topics using 113,048 available notes. Topics were related to the AAV diagnosis, treatment, symptoms and manifestations (e.g., glomerulonephritis), and complications (e.g., end-stage renal disease, infection). AAV-related symptoms and psychiatric symptoms were mentioned months before treatment initiation. Topics related to pulmonary and renal diseases, diabetes, and infections were common during the disease course but followed distinct temporal patterns.
CONCLUSIONS: Automated topic modeling can be used to discover clinically-relevant themes and temporal patterns related to the diagnosis, treatment, comorbidities, and complications of AAV from EHR notes. Future research might compare the temporal patterns in a non-AAV cohort and leverage clinical notes to identify possible AAV cases prospectively.",True,other,Not specified
33348764,Automated Classification of Online Sources for Infectious Disease Occurrences Using Machine-Learning-Based Natural Language Processing Approaches,"Collecting valid information from electronic sources to detect the potential outbreak of infectious disease is time-consuming and labor-intensive. The automated identification of relevant information using machine learning is necessary to respond to a potential disease outbreak. A total of 2864 documents were collected from various websites and subsequently manually categorized and labeled by two reviewers. Accurate labels for the training and test data were provided based on a reviewer consensus. Two machine learning algorithms-ConvNet and bidirectional long short-term memory (BiLSTM)-and two classification methods-DocClass and SenClass-were used for classifying the documents. The precision, recall, F1, accuracy, and area under the curve were measured to evaluate the performance of each model. ConvNet yielded higher average, min, and max accuracies (87.6%, 85.2%, and 91.1%, respectively) than BiLSTM with DocClass, while BiLSTM performed better than ConvNet with SenClass with average, min, and max accuracies of 92.8%, 92.6%, and 93.3%, respectively. The performance of BiLSTM with SenClass yielded an overall accuracy of 92.9% in classifying infectious disease occurrences. Machine learning had a compatible performance with a human expert given a particular text extraction system. This study suggests that analyzing information from the website using machine learning can achieve significant accuracies in the presence of abundant articles/documents.",True,other,recurrent neural network
33252349,Machine Learning Electronic Health Record Identification of Patients with Rheumatoid Arthritis: Algorithm Pipeline Development and Validation Study,"BACKGROUND: Financial codes are often used to extract diagnoses from electronic health records. This approach is prone to false positives. Alternatively, queries are constructed, but these are highly center and language specific. A tantalizing alternative is the automatic identification of patients by employing machine learning on format-free text entries.
OBJECTIVE: The aim of this study was to develop an easily implementable workflow that builds a machine learning algorithm capable of accurately identifying patients with rheumatoid arthritis from format-free text fields in electronic health records.
METHODS: Two electronic health record data sets were employed: Leiden (n=3000) and Erlangen (n=4771). Using a portion of the Leiden data (n=2000), we compared 6 different machine learning methods and a naïve word-matching algorithm using 10-fold cross-validation. Performances were compared using the area under the receiver operating characteristic curve (AUROC) and the area under the precision recall curve (AUPRC), and F1 score was used as the primary criterion for selecting the best method to build a classifying algorithm. We selected the optimal threshold of positive predictive value for case identification based on the output of the best method in the training data. This validation workflow was subsequently applied to a portion of the Erlangen data (n=4293). For testing, the best performing methods were applied to remaining data (Leiden n=1000; Erlangen n=478) for an unbiased evaluation.
RESULTS: For the Leiden data set, the word-matching algorithm demonstrated mixed performance (AUROC 0.90; AUPRC 0.33; F1 score 0.55), and 4 methods significantly outperformed word-matching, with support vector machines performing best (AUROC 0.98; AUPRC 0.88; F1 score 0.83). Applying this support vector machine classifier to the test data resulted in a similarly high performance (F1 score 0.81; positive predictive value [PPV] 0.94), and with this method, we could identify 2873 patients with rheumatoid arthritis in less than 7 seconds out of the complete collection of 23,300 patients in the Leiden electronic health record system. For the Erlangen data set, gradient boosting performed best (AUROC 0.94; AUPRC 0.85; F1 score 0.82) in the training set, and applied to the test data, resulted once again in good results (F1 score 0.67; PPV 0.97).
CONCLUSIONS: We demonstrate that machine learning methods can extract the records of patients with rheumatoid arthritis from electronic health record data with high precision, allowing research on very large populations for limited costs. Our approach is language and center independent and could be applied to any type of diagnosis. We have developed our pipeline into a universally applicable and easy-to-implement workflow to equip centers with their own high-performing algorithm. This allows the creation of observational studies of unprecedented size covering different countries for low cost from already available data in electronic health record systems.",True,other,RNN
33197205,Application of Artificial Intelligence Methods to Pharmacy Data for Cancer Surveillance and Epidemiology Research: A Systematic Review,"PURPOSE: The implementation and utilization of electronic health records is generating a large volume and variety of data, which are difficult to process using traditional techniques. However, these data could help answer important questions in cancer surveillance and epidemiology research. Artificial intelligence (AI) data processing methods are capable of evaluating large volumes of data, yet current literature on their use in this context of pharmacy informatics is not well characterized.
METHODS: A systematic literature review was conducted to evaluate relevant publications within four domains (cancer, pharmacy, AI methods, population science) across PubMed, EMBASE, Scopus, and the Cochrane Library and included all publications indexed between July 17, 2008, and December 31, 2018. The search returned 3,271 publications, which were evaluated for inclusion.
RESULTS: There were 36 studies that met criteria for full-text abstraction. Of those, only 45% specifically identified the pharmacy data source, and 55% specified drug agents or drug classes. Multiple AI methods were used; 25% used machine learning (ML), 67% used natural language processing (NLP), and 8% combined ML and NLP.
CONCLUSION: This review demonstrates that the application of AI data methods for pharmacy informatics and cancer epidemiology research is expanding. However, the data sources and representations are often missing, challenging study replicability. In addition, there is no consistent format for reporting results, and one of the preferred metrics, F-score, is often missing. There is a resultant need for greater transparency of original data sources and performance of AI methods with pharmacy data to improve the translation of these results into meaningful outcomes.",True,other,Not specified
32867863,30 years of parasitology research analysed by text mining,"Bibliometric methods were used to analyse the major research trends, themes and topics over the last 30 years in the parasitology discipline. The tools used were SciMAT, VOSviewer and SWIFT-Review in conjunction with the parasitology literature contained in the MEDLINE, Web of Science, Scopus and Dimensions databases. The analyses show that the major research themes are dynamic and continually changing with time, although some themes identified based on keywords such as malaria, nematode, epidemiology and phylogeny are consistently referenced over time. We note the major impact of countries like Brazil has had on the literature of parasitology research. The increase in recent times of research productivity on 'antiparasitics' is discussed, as well as the change in emphasis on different antiparasitic drugs and insecticides over time. In summary, innovation in parasitology is global, extensive, multidisciplinary, constantly evolving and closely aligned with the availability of technology.",True,text mining,Not specified
32463365,Knowledge synthesis of 100 million biomedical documents augments the deep expression profiling of coronavirus receptors,"The COVID-19 pandemic demands assimilation of all biomedical knowledge to decode mechanisms of pathogenesis. Despite the recent renaissance in neural networks, a platform for the real-time synthesis of the exponentially growing biomedical literature and deep omics insights is unavailable. Here, we present the nferX platform for dynamic inference from over 45 quadrillion possible conceptual associations from unstructured text, and triangulation with insights from single-cell RNA-sequencing, bulk RNA-seq and proteomics from diverse tissue types. A hypothesis-free profiling of ACE2 suggests tongue keratinocytes, olfactory epithelial cells, airway club cells and respiratory ciliated cells as potential reservoirs of the SARS-CoV-2 receptor. We find the gut as the putative hotspot of COVID-19, where a maturation correlated transcriptional signature is shared in small intestine enterocytes among coronavirus receptors (ACE2, DPP4, ANPEP). A holistic data science platform triangulating insights from structured and unstructured data holds potential for accelerating the generation of impactful biological insights and hypotheses.",True,other,recurrent neural network
32369038,Use of Machine Learning Techniques for Case-Detection of Varicella Zoster Using Routinely Collected Textual Ambulatory Records: Pilot Observational Study,"BACKGROUND: The detection of infectious diseases through the analysis of free text on electronic health reports (EHRs) can provide prompt and accurate background information for the implementation of preventative measures, such as advertising and monitoring the effectiveness of vaccination campaigns.
OBJECTIVE: The purpose of this paper is to compare machine learning techniques in their application to EHR analysis for disease detection.
METHODS: The Pedianet database was used as a data source for a real-world scenario on the identification of cases of varicella. The models' training and test sets were based on two different Italian regions' (Veneto and Sicilia) data sets of 7631 patients and 1,230,355 records, and 2347 patients and 569,926 records, respectively, for whom a gold standard of varicella diagnosis was available. Elastic-net regularized generalized linear model (GLMNet), maximum entropy (MAXENT), and LogitBoost (boosting) algorithms were implemented in a supervised environment and 5-fold cross-validated. The document-term matrix generated by the training set involves a dictionary of 1,871,532 tokens. The analysis was conducted on a subset of 29,096 tokens, corresponding to a matrix with no more than a 99% sparsity ratio.
RESULTS: The highest predictive values were achieved through boosting (positive predicative value [PPV] 63.1, 95% CI 42.7-83.5 and negative predicative value [NPV] 98.8, 95% CI 98.3-99.3). GLMNet delivered superior predictive capability compared to MAXENT (PPV 24.5% and NPV 98.3% vs PPV 11.0% and NPV 98.0%). MAXENT and GLMNet predictions weakly agree with each other (agreement coefficient 1 [AC1]=0.60, 95% CI 0.58-0.62), as well as with LogitBoost (MAXENT: AC1=0.64, 95% CI 0.63-0.66 and GLMNet: AC1=0.53, 95% CI 0.51-0.55).
CONCLUSIONS: Boosting has demonstrated promising performance in large-scale EHR-based infectious disease identification.",True,text mining,RNN
31810495,Screening PubMed abstracts: is class imbalance always a challenge to machine learning?,"BACKGROUND: The growing number of medical literature and textual data in online repositories led to an exponential increase in the workload of researchers involved in citation screening for systematic reviews. This work aims to combine machine learning techniques and data preprocessing for class imbalance to identify the outperforming strategy to screen articles in PubMed for inclusion in systematic reviews.
METHODS: We trained four binary text classifiers (support vector machines, k-nearest neighbor, random forest, and elastic-net regularized generalized linear models) in combination with four techniques for class imbalance: random undersampling and oversampling with 50:50 and 35:65 positive to negative class ratios and none as a benchmark. We used textual data of 14 systematic reviews as case studies. Difference between cross-validated area under the receiver operating characteristic curve (AUC-ROC) for machine learning techniques with and without preprocessing (delta AUC) was estimated within each systematic review, separately for each classifier. Meta-analytic fixed-effect models were used to pool delta AUCs separately by classifier and strategy.
RESULTS: Cross-validated AUC-ROC for machine learning techniques (excluding k-nearest neighbor) without preprocessing was prevalently above 90%. Except for k-nearest neighbor, machine learning techniques achieved the best improvement in conjunction with random oversampling 50:50 and random undersampling 35:65.
CONCLUSIONS: Resampling techniques slightly improved the performance of the investigated machine learning techniques. From a computational perspective, random undersampling 35:65 may be preferred.",True,other,Not specified
31535693,Incorporating natural language processing to improve classification of axial spondyloarthritis using electronic health records,"OBJECTIVES: To develop classification algorithms that accurately identify axial SpA (axSpA) patients in electronic health records, and compare the performance of algorithms incorporating free-text data against approaches using only International Classification of Diseases (ICD) codes.
METHODS: An enriched cohort of 7853 eligible patients was created from electronic health records of two large hospitals using automated searches (⩾1 ICD codes combined with simple text searches). Key disease concepts from free-text data were extracted using NLP and combined with ICD codes to develop algorithms. We created both supervised regression-based algorithms-on a training set of 127 axSpA cases and 423 non-cases-and unsupervised algorithms to identify patients with high probability of having axSpA from the enriched cohort. Their performance was compared against classifications using ICD codes only.
RESULTS: NLP extracted four disease concepts of high predictive value: ankylosing spondylitis, sacroiliitis, HLA-B27 and spondylitis. The unsupervised algorithm, incorporating both the NLP concept and ICD code for AS, identified the greatest number of patients. By setting the probability threshold to attain 80% positive predictive value, it identified 1509 axSpA patients (mean age 53 years, 71% male). Sensitivity was 0.78, specificity 0.94 and area under the curve 0.93. The two supervised algorithms performed similarly but identified fewer patients. All three outperformed traditional approaches using ICD codes alone (area under the curve 0.80-0.87).
CONCLUSION: Algorithms incorporating free-text data can accurately identify axSpA patients in electronic health records. Large cohorts identified using these novel methods offer exciting opportunities for future clinical research.",True,text mining,RNN
31419837,Artificial Intelligence for Surveillance in Public Health,"OBJECTIVES: To introduce and summarize current research in the field of Public Health and Epidemiology Informatics.
METHODS: The 2018 literature concerning public health and epidemiology informatics was searched in PubMed and Web of Science, and the returned references were reviewed by the two section editors to select 15 candidate best papers. These papers were then peer-reviewed by external reviewers to give the editorial team an enlightened selection of the best papers.
RESULTS: Among the 805 references retrieved from PubMed and Web of Science, three were finally selected as best papers. All three papers are about surveillance using digital tools. One study is about the surveillance of flu, another about emerging animal infectious diseases and the last one is about foodborne illness. The sources of information are Google news, Twitter, and Yelp restaurant reviews. Machine learning approaches are most often used to detect signals.
CONCLUSIONS: Surveillance is a central topic in public health informatics with the growing use of machine learning approaches in regards of the size and complexity of data. The evaluation of the approaches developed remains a serious challenge.",True,both,Not specified
31392844,Comparison of text processing methods in social media-based signal detection,"PURPOSE: Adverse event (AE) identification in social media (SM) can be performed using various types of natural language processing (NLP) and machine learning (ML). These methods can be categorized by complexity and precision level. Co-occurrence-based ML methods are rather basic, as they identify simultaneous appearance of drugs and clinical events in a single post. In contrast, statistical learning methods involve more complex NLP and identify drugs, events, and associations between them. We aimed to compare the ability of co-occurrence and NLP to identify AEs and signals of disproportionate reporting (SDR) in patient-generated SM. We also examined the performance of lift in SM-based signal detection (SD).
METHODS: Our examination was performed in a corpus of SM posts crawled from open online patient forums and communities, using the spontaneously reported VigiBase data as reference data set.
RESULTS: We found that co-occurrence and NLP produce AEs, which are 57% and 93% consistent with VigiBase AEs, respectively. Among the SDRs identified both in SM and in VigiBase, up to 55.3% were identified earlier in co-occurrence, and up to 32.1% were identified earlier in NLP-processed SM. Using lift in SM SD provided performance similar to frequentist methods, both in co-occurrence and in NLP-processed AEs.
CONCLUSION: Our results indicate that using SM as a data source complementary to traditional pharmacovigilance sources should be considered further. Various levels of SM processing may be considered, depending on the preferred policies and tolerance for false-positive to false-negative balance in routine pharmacovigilance processes.",True,text mining,Not specified
31361300,"Development of a global infectious disease activity database using natural language processing, machine learning, and human expertise","OBJECTIVE: We assessed whether machine learning can be utilized to allow efficient extraction of infectious disease activity information from online media reports.
MATERIALS AND METHODS: We curated a data set of labeled media reports (n = 8322) indicating which articles contain updates about disease activity. We trained a classifier on this data set. To validate our system, we used a held out test set and compared our articles to the World Health Organization Disease Outbreak News reports.
RESULTS: Our classifier achieved a recall and precision of 88.8% and 86.1%, respectively. The overall surveillance system detected 94% of the outbreaks identified by the WHO covered by online media (89%) and did so 43.4 (IQR: 9.5-61) days earlier on average.
DISCUSSION: We constructed a global real-time disease activity database surveilling 114 illnesses and syndromes. We must further assess our system for bias, representativeness, granularity, and accuracy.
CONCLUSION: Machine learning, natural language processing, and human expertise can be used to efficiently identify disease activity from digital media reports.",True,other,CNN
30766970,"Design of a generic, open platform for machine learning-assisted indexing and clustering of articles in PubMed, a biomedical bibliographic database","Many investigators have carried out text mining of the biomedical literature for a variety of purposes, ranging from the assignment of indexing terms to the disambiguation of author names. A common approach is to define positive and negative training examples, extract features from article metadata, and employ machine learning algorithms. At present, each research group tackles each problem from scratch, and in isolation of other projects, which causes redundancy and great waste of effort. Here, we propose and describe the design of a generic platform for biomedical text mining, which can serve as a shared resource for machine learning projects, and can serve as a public repository for their outputs. We will initially focus on a specific goal, namely, classifying articles according to Publication Type, and emphasize how feature sets can be made more powerful and robust through the use of multiple, heterogeneous similarity measures as input to machine learning models. We then discuss how the generic platform can be extended to include a wide variety of other machine learning based goals and projects, and can be used as a public platform for disseminating the results of NLP tools to end-users as well.",True,other,Not specified
30616584,A clinical text classification paradigm using weak supervision and deep representation,"BACKGROUND: Automatic clinical text classification is a natural language processing (NLP) technology that unlocks information embedded in clinical narratives. Machine learning approaches have been shown to be effective for clinical text classification tasks. However, a successful machine learning model usually requires extensive human efforts to create labeled training data and conduct feature engineering. In this study, we propose a clinical text classification paradigm using weak supervision and deep representation to reduce these human efforts.
METHODS: We develop a rule-based NLP algorithm to automatically generate labels for the training data, and then use the pre-trained word embeddings as deep representation features for training machine learning models. Since machine learning is trained on labels generated by the automatic NLP algorithm, this training process is called weak supervision. We evaluat the paradigm effectiveness on two institutional case studies at Mayo Clinic: smoking status classification and proximal femur (hip) fracture classification, and one case study using a public dataset: the i2b2 2006 smoking status classification shared task. We test four widely used machine learning models, namely, Support Vector Machine (SVM), Random Forest (RF), Multilayer Perceptron Neural Networks (MLPNN), and Convolutional Neural Networks (CNN), using this paradigm. Precision, recall, and F1 score are used as metrics to evaluate performance.
RESULTS: CNN achieves the best performance in both institutional tasks (F1 score: 0.92 for Mayo Clinic smoking status classification and 0.97 for fracture classification). We show that word embeddings significantly outperform tf-idf and topic modeling features in the paradigm, and that CNN captures additional patterns from the weak supervision compared to the rule-based NLP algorithms. We also observe two drawbacks of the proposed paradigm that CNN is more sensitive to the size of training data, and that the proposed paradigm might not be effective for complex multiclass classification tasks.
CONCLUSION: The proposed clinical text classification paradigm could reduce human efforts of labeled training data creation and feature engineering for applying machine learning to clinical text classification by leveraging weak supervision and deep representation. The experimental experiments have validated the effectiveness of paradigm by two institutional and one shared clinical text classification tasks.",True,other,autoencoder
29981872,Extending PubMed searches to ClinicalTrials.gov through a machine learning approach for systematic reviews,"OBJECTIVES: Despite their essential role in collecting and organizing published medical literature, indexed search engines are unable to cover all relevant knowledge. Hence, current literature recommends the inclusion of clinical trial registries in systematic reviews (SRs). This study aims to provide an automated approach to extend a search on PubMed to the ClinicalTrials.gov database, relying on text mining and machine learning techniques.
STUDY DESIGN AND SETTING: The procedure starts from a literature search on PubMed. Next, it considers the training of a classifier that can identify documents with a comparable word characterization in the ClinicalTrials.gov clinical trial repository. Fourteen SRs, covering a broad range of health conditions, are used as case studies for external validation. A cross-validated support-vector machine (SVM) model was used as the classifier.
RESULTS: The sensitivity was 100% in all SRs except one (87.5%), and the specificity ranged from 97.2% to 99.9%. The ability of the instrument to distinguish on-topic from off-topic articles ranged from an area under the receiver operator characteristic curve of 93.4% to 99.9%.
CONCLUSION: The proposed machine learning instrument has the potential to help researchers identify relevant studies in the SR process by reducing workload, without losing sensitivity and at a small price in terms of specificity.",True,other,Not specified
29907560,Validation of a Natural Language Processing Algorithm for Detecting Infectious Disease Symptoms in Primary Care Electronic Medical Records in Singapore,"BACKGROUND: Free-text clinical records provide a source of information that complements traditional disease surveillance. To electronically harness these records, they need to be transformed into codified fields by natural language processing algorithms.
OBJECTIVE: The aim of this study was to develop, train, and validate Clinical History Extractor for Syndromic Surveillance (CHESS), an natural language processing algorithm to extract clinical information from free-text primary care records.
METHODS: CHESS is a keyword-based natural language processing algorithm to extract 48 signs and symptoms suggesting respiratory infections, gastrointestinal infections, constitutional, as well as other signs and symptoms potentially associated with infectious diseases. The algorithm also captured the assertion status (affirmed, negated, or suspected) and symptom duration. Electronic medical records from the National Healthcare Group Polyclinics, a major public sector primary care provider in Singapore, were randomly extracted and manually reviewed by 2 human reviewers, with a third reviewer as the adjudicator. The algorithm was evaluated based on 1680 notes against the human-coded result as the reference standard, with half of the data used for training and the other half for validation.
RESULTS: The symptoms most commonly present within the 1680 clinical records at the episode level were those typically present in respiratory infections such as cough (744/7703, 9.66%), sore throat (591/7703, 7.67%), rhinorrhea (552/7703, 7.17%), and fever (928/7703, 12.04%). At the episode level, CHESS had an overall performance of 96.7% precision and 97.6% recall on the training dataset and 96.0% precision and 93.1% recall on the validation dataset. Symptoms suggesting respiratory and gastrointestinal infections were all detected with more than 90% precision and recall. CHESS correctly assigned the assertion status in 97.3%, 97.9%, and 89.8% of affirmed, negated, and suspected signs and symptoms, respectively (97.6% overall accuracy). Symptom episode duration was correctly identified in 81.2% of records with known duration status.
CONCLUSIONS: We have developed an natural language processing algorithm dubbed CHESS that achieves good performance in extracting signs and symptoms from primary care free-text clinical records. In addition to the presence of symptoms, our algorithm can also accurately distinguish affirmed, negated, and suspected assertion statuses and extract symptom durations.",True,text mining,RNN
28761061,TEPAPA: a novel in silico feature learning pipeline for mining prognostic and associative factors from text-based electronic medical records,"Vast amounts of clinically relevant text-based variables lie undiscovered and unexploited in electronic medical records (EMR). To exploit this untapped resource, and thus facilitate the discovery of informative covariates from unstructured clinical narratives, we have built a novel computational pipeline termed Text-based Exploratory Pattern Analyser for Prognosticator and Associator discovery (TEPAPA). This pipeline combines semantic-free natural language processing (NLP), regular expression induction, and statistical association testing to identify conserved text patterns associated with outcome variables of clinical interest. When we applied TEPAPA to a cohort of head and neck squamous cell carcinoma patients, plausible concepts known to be correlated with human papilloma virus (HPV) status were identified from the EMR text, including site of primary disease, tumour stage, pathologic characteristics, and treatment modalities. Similarly, correlates of other variables (including gender, nodal status, recurrent disease, smoking and alcohol status) were also reliably recovered. Using highly-associated patterns as covariates, a patient's HPV status was classifiable using a bootstrap analysis with a mean area under the ROC curve of 0.861, suggesting its predictive utility in supporting EMR-based phenotyping tasks. These data support using this integrative approach to efficiently identify disease-associated factors from unstructured EMR narratives, and thus to efficiently generate testable hypotheses.",True,text mining,convolutional neural network
28455150,Evaluation of a rule-based method for epidemiological document classification towards the automation of systematic reviews,"INTRODUCTION: Most data extraction efforts in epidemiology are focused on obtaining targeted information from clinical trials. In contrast, limited research has been conducted on the identification of information from observational studies, a major source for human evidence in many fields, including environmental health. The recognition of key epidemiological information (e.g., exposures) through text mining techniques can assist in the automation of systematic reviews and other evidence summaries.
METHOD: We designed and applied a knowledge-driven, rule-based approach to identify targeted information (study design, participant population, exposure, outcome, confounding factors, and the country where the study was conducted) from abstracts of epidemiological studies included in several systematic reviews of environmental health exposures. The rules were based on common syntactical patterns observed in text and are thus not specific to any systematic review. To validate the general applicability of our approach, we compared the data extracted using our approach versus hand curation for 35 epidemiological study abstracts manually selected for inclusion in two systematic reviews.
RESULTS: The returned F-score, precision, and recall ranged from 70% to 98%, 81% to 100%, and 54% to 97%, respectively. The highest precision was observed for exposure, outcome and population (100%) while recall was best for exposure and study design with 97% and 89%, respectively. The lowest recall was observed for the population (54%), which also had the lowest F-score (70%).
CONCLUSION: The generated performance of our text-mining approach demonstrated encouraging results for the identification of targeted information from observational epidemiological study abstracts related to environmental exposures. We have demonstrated that rules based on generic syntactic patterns in one corpus can be applied to other observational study design by simple interchanging the dictionaries aiming to identify certain characteristics (i.e., outcomes, exposures). At the document level, the recognised information can assist in the selection and categorization of studies included in a systematic review.",True,both,Not specified
27902695,Text Mining Genotype-Phenotype Relationships from Biomedical Literature for Database Curation and Precision Medicine,"The practice of precision medicine will ultimately require databases of genes and mutations for healthcare providers to reference in order to understand the clinical implications of each patient's genetic makeup. Although the highest quality databases require manual curation, text mining tools can facilitate the curation process, increasing accuracy, coverage, and productivity. However, to date there are no available text mining tools that offer high-accuracy performance for extracting such triplets from biomedical literature. In this paper we propose a high-performance machine learning approach to automate the extraction of disease-gene-variant triplets from biomedical literature. Our approach is unique because we identify the genes and protein products associated with each mutation from not just the local text content, but from a global context as well (from the Internet and from all literature in PubMed). Our approach also incorporates protein sequence validation and disease association using a novel text-mining-based machine learning approach. We extract disease-gene-variant triplets from all abstracts in PubMed related to a set of ten important diseases (breast cancer, prostate cancer, pancreatic cancer, lung cancer, acute myeloid leukemia, Alzheimer's disease, hemochromatosis, age-related macular degeneration (AMD), diabetes mellitus, and cystic fibrosis). We then evaluate our approach in two ways: (1) a direct comparison with the state of the art using benchmark datasets; (2) a validation study comparing the results of our approach with entries in a popular human-curated database (UniProt) for each of the previously mentioned diseases. In the benchmark comparison, our full approach achieves a 28% improvement in F1-measure (from 0.62 to 0.79) over the state-of-the-art results. For the validation study with UniProt Knowledgebase (KB), we present a thorough analysis of the results and errors. Across all diseases, our approach returned 272 triplets (disease-gene-variant) that overlapped with entries in UniProt and 5,384 triplets without overlap in UniProt. Analysis of the overlapping triplets and of a stratified sample of the non-overlapping triplets revealed accuracies of 93% and 80% for the respective categories (cumulative accuracy, 77%). We conclude that our process represents an important and broadly applicable improvement to the state of the art for curation of disease-gene-variant relationships.",True,other,RNN
27685652,SparkText: Biomedical Text Mining on Big Data Framework,"BACKGROUND: Many new biomedical research articles are published every day, accumulating rich information, such as genetic variants, genes, diseases, and treatments. Rapid yet accurate text mining on large-scale scientific literature can discover novel knowledge to better understand human diseases and to improve the quality of disease diagnosis, prevention, and treatment.
RESULTS: In this study, we designed and developed an efficient text mining framework called SparkText on a Big Data infrastructure, which is composed of Apache Spark data streaming and machine learning methods, combined with a Cassandra NoSQL database. To demonstrate its performance for classifying cancer types, we extracted information (e.g., breast, prostate, and lung cancers) from tens of thousands of articles downloaded from PubMed, and then employed Naïve Bayes, Support Vector Machine (SVM), and Logistic Regression to build prediction models to mine the articles. The accuracy of predicting a cancer type by SVM using the 29,437 full-text articles was 93.81%. While competing text-mining tools took more than 11 hours, SparkText mined the dataset in approximately 6 minutes.
CONCLUSIONS: This study demonstrates the potential for mining large-scale scientific articles on a Big Data infrastructure, with real-time update from new articles published daily. SparkText can be extended to other areas of biomedical research.",True,other,Not specified
26513245,"Combining Search, Social Media, and Traditional Data Sources to Improve Influenza Surveillance","We present a machine learning-based methodology capable of providing real-time (""nowcast"") and forecast estimates of influenza activity in the US by leveraging data from multiple data sources including: Google searches, Twitter microblogs, nearly real-time hospital visit records, and data from a participatory surveillance system. Our main contribution consists of combining multiple influenza-like illnesses (ILI) activity estimates, generated independently with each data source, into a single prediction of ILI utilizing machine learning ensemble approaches. Our methodology exploits the information in each data source and produces accurate weekly ILI predictions for up to four weeks ahead of the release of CDC's ILI reports. We evaluate the predictive ability of our ensemble approach during the 2013-2014 (retrospective) and 2014-2015 (live) flu seasons for each of the four weekly time horizons. Our ensemble approach demonstrates several advantages: (1) our ensemble method's predictions outperform every prediction using each data source independently, (2) our methodology can produce predictions one week ahead of GFT's real-time estimates with comparable accuracy, and (3) our two and three week forecast estimates have comparable accuracy to real-time predictions using an autoregressive model. Moreover, our results show that considerable insight is gained from incorporating disparate data streams, in the form of social media and crowd sourced data, into influenza predictions in all time horizons.",True,other,convolutional neural network
26262339,Automated Classification of Pathology Reports,"This work develops an automated classifier of pathology reports which infers the topography and the morphology classes of a tumor using codes from the International Classification of Diseases for Oncology (ICD-O). Data from 94,980 patients of the A.C. Camargo Cancer Center was used for training and validation of Naive Bayes classifiers, evaluated by the F1-score. Measures greater than 74% in the topographic group and 61% in the morphologic group are reported. Our work provides a successful baseline for future research for the classification of medical documents written in Portuguese and in other domains.",True,other,Not specified
26241355,A systematic comparison of feature space effects on disease classifier performance for phenotype identification of five diseases,"Automated phenotype identification plays a critical role in cohort selection and bioinformatics data mining. Natural Language Processing (NLP)-informed classification techniques can robustly identify phenotypes in unstructured medical notes. In this paper, we systematically assess the effect of naive, lexically normalized, and semantic feature spaces on classifier performance for obesity, atherosclerotic cardiovascular disease (CAD), hyperlipidemia, hypertension, and diabetes. We train support vector machines (SVMs) using individual feature spaces as well as combinations of these feature spaces on two small training corpora (730 and 790 documents) and a combined (1520 documents) training corpus. We assess the importance of feature spaces and training data size on SVM model performance. We show that inclusion of semantically-informed features does not statistically improve performance for these models. The addition of training data has weak effects of mixed statistical significance across disease classes suggesting larger corpora are not necessary to achieve relatively high performance with these models.",True,text mining,recurrent neural network
26122527,The role of fine-grained annotations in supervised recognition of risk factors for heart disease from EHRs,"This paper describes a supervised machine learning approach for identifying heart disease risk factors in clinical text, and assessing the impact of annotation granularity and quality on the system's ability to recognize these risk factors. We utilize a series of support vector machine models in conjunction with manually built lexicons to classify triggers specific to each risk factor. The features used for classification were quite simple, utilizing only lexical information and ignoring higher-level linguistic information such as syntax and semantics. Instead, we incorporated high-quality data to train the models by annotating additional information on top of a standard corpus. Despite the relative simplicity of the system, it achieves the highest scores (micro- and macro-F1, and micro- and macro-recall) out of the 20 participants in the 2014 i2b2/UTHealth Shared Task. This system obtains a micro- (macro-) precision of 0.8951 (0.8965), recall of 0.9625 (0.9611), and F1-measure of 0.9276 (0.9277). Additionally, we perform a series of experiments to assess the value of the annotated data we created. These experiments show how manually-labeled negative annotations can improve information extraction performance, demonstrating the importance of high-quality, fine-grained natural language annotations.",True,text mining,Not specified
25795924,Machine learning approaches to analysing textual injury surveillance data: a systematic review,"OBJECTIVE: To synthesise recent research on the use of machine learning approaches to mining textual injury surveillance data.
DESIGN: Systematic review.
DATA SOURCES: The electronic databases which were searched included PubMed, Cinahl, Medline, Google Scholar, and Proquest. The bibliography of all relevant articles was examined and associated articles were identified using a snowballing technique.
SELECTION CRITERIA: For inclusion, articles were required to meet the following criteria: (a) used a health-related database, (b) focused on injury-related cases, AND used machine learning approaches to analyse textual data.
METHODS: The papers identified through the search were screened resulting in 16 papers selected for review. Articles were reviewed to describe the databases and methodology used, the strength and limitations of different techniques, and quality assurance approaches used. Due to heterogeneity between studies meta-analysis was not performed.
RESULTS: Occupational injuries were the focus of half of the machine learning studies and the most common methods described were Bayesian probability or Bayesian network based methods to either predict injury categories or extract common injury scenarios. Models were evaluated through either comparison with gold standard data or content expert evaluation or statistical measures of quality. Machine learning was found to provide high precision and accuracy when predicting a small number of categories, was valuable for visualisation of injury patterns and prediction of future outcomes. However, difficulties related to generalizability, source data quality, complexity of models and integration of content and technical knowledge were discussed.
CONCLUSIONS: The use of narrative text for injury surveillance has grown in popularity, complexity and quality over recent years. With advances in data mining techniques, increased capacity for analysis of large databases, and involvement of computer scientists in the injury prevention field, along with more comprehensive use and description of quality assurance methods in text mining approaches, it is likely that we will see a continued growth and advancement in knowledge of text mining in the injury field.",True,both,Not specified
25700665,Efficient and sparse feature selection for biomedical text classification via the elastic net: Application to ICU risk stratification from nursing notes,"BACKGROUND AND SIGNIFICANCE: Sparsity is often a desirable property of statistical models, and various feature selection methods exist so as to yield sparser and interpretable models. However, their application to biomedical text classification, particularly to mortality risk stratification among intensive care unit (ICU) patients, has not been thoroughly studied.
OBJECTIVE: To develop and characterize sparse classifiers based on the free text of nursing notes in order to predict ICU mortality risk and to discover text features most strongly associated with mortality.
METHODS: We selected nursing notes from the first 24h of ICU admission for 25,826 adult ICU patients from the MIMIC-II database. We then developed a pair of stochastic gradient descent-based classifiers with elastic-net regularization. We also studied the performance-sparsity tradeoffs of both classifiers as their regularization parameters were varied.
RESULTS: The best-performing classifier achieved a 10-fold cross-validated AUC of 0.897 under the log loss function and full L2 regularization, while full L1 regularization used just 0.00025% of candidate input features and resulted in an AUC of 0.889. Using the log loss (range of AUCs 0.889-0.897) yielded better performance compared to the hinge loss (0.850-0.876), but the latter yielded even sparser models.
DISCUSSION: Most features selected by both classifiers appear clinically relevant and correspond to predictors already present in existing ICU mortality models. The sparser classifiers were also able to discover a number of informative - albeit nonclinical - features.
CONCLUSION: The elastic-net-regularized classifiers perform reasonably well and are capable of reducing the number of features required by over a thousandfold, with only a modest impact on performance.",True,other,RNN
25656516,Automated confidence ranked classification of randomized controlled trial articles: an aid to evidence-based medicine,"OBJECTIVE: For many literature review tasks, including systematic review (SR) and other aspects of evidence-based medicine, it is important to know whether an article describes a randomized controlled trial (RCT). Current manual annotation is not complete or flexible enough for the SR process. In this work, highly accurate machine learning predictive models were built that include confidence predictions of whether an article is an RCT.
MATERIALS AND METHODS: The LibSVM classifier was used with forward selection of potential feature sets on a large human-related subset of MEDLINE to create a classification model requiring only the citation, abstract, and MeSH terms for each article.
RESULTS: The model achieved an area under the receiver operating characteristic curve of 0.973 and mean squared error of 0.013 on the held out year 2011 data. Accurate confidence estimates were confirmed on a manually reviewed set of test articles. A second model not requiring MeSH terms was also created, and performs almost as well.
DISCUSSION: Both models accurately rank and predict article RCT confidence. Using the model and the manually reviewed samples, it is estimated that about 8000 (3%) additional RCTs can be identified in MEDLINE, and that 5% of articles tagged as RCTs in Medline may not be identified.
CONCLUSION: Retagging human-related studies with a continuously valued RCT confidence is potentially more useful for article ranking and review than a simple yes/no prediction. The automated RCT tagging tool should offer significant savings of time and effort during the process of writing SRs, and is a key component of a multistep text mining pipeline that we are building to streamline SR workflow. In addition, the model may be useful for identifying errors in MEDLINE publication types. The RCT confidence predictions described here have been made available to users as a web service with a user query form front end at: http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/RCT_Tagger.cgi.",True,other,LSTM
25474213,The HIV mutation browser: a resource for human immunodeficiency virus mutagenesis and polymorphism data,"Huge research effort has been invested over many years to determine the phenotypes of natural or artificial mutations in HIV proteins--interpretation of mutation phenotypes is an invaluable source of new knowledge. The results of this research effort are recorded in the scientific literature, but it is difficult for virologists to rapidly find it. Manually locating data on phenotypic variation within the approximately 270,000 available HIV-related research articles, or the further 1,500 articles that are published each month is a daunting task. Accordingly, the HIV research community would benefit from a resource cataloguing the available HIV mutation literature. We have applied computational text-mining techniques to parse and map mutagenesis and polymorphism information from the HIV literature, have enriched the data with ancillary information and have developed a public, web-based interface through which it can be intuitively explored: the HIV mutation browser. The current release of the HIV mutation browser describes the phenotypes of 7,608 unique mutations at 2,520 sites in the HIV proteome, resulting from the analysis of 120,899 papers. The mutation information for each protein is organised in a residue-centric manner and each residue is linked to the relevant experimental literature. The importance of HIV as a global health burden advocates extensive effort to maximise the efficiency of HIV research. The HIV mutation browser provides a valuable new resource for the research community. The HIV mutation browser is available at: http://hivmut.org.",True,other,Not specified
24551329,Semantic MEDLINE for discovery browsing: using semantic predications and the literature-based discovery paradigm to elucidate a mechanism for the obesity paradox,"Applying the principles of literature-based discovery (LBD), we elucidate the paradox that obesity is beneficial in critical care despite contributing to disease generally. Our approach enhances a previous extension to LBD, called ""discovery browsing,"" and is implemented using Semantic MEDLINE, which summarizes the results of a PubMed search into an interactive graph of semantic predications. The methodology allows a user to construct argumentation underpinning an answer to a biomedical question by engaging the user in an iterative process between system output and user knowledge. Components of the Semantic MEDLINE output graph identified as ""interesting"" by the user both contribute to subsequent searches and are constructed into a logical chain of relationships constituting an explanatory network in answer to the initial question. Based on this methodology we suggest that phthalates leached from plastic in critical care interventions activate PPAR gamma, which is anti-inflammatory and abundant in obese patients.",True,other,LSTM
24399964,Virk: an active learning-based system for bootstrapping knowledge base development in the neurosciences,"The frequency and volume of newly-published scientific literature is quickly making manual maintenance of publicly-available databases of primary data unrealistic and costly. Although machine learning (ML) can be useful for developing automated approaches to identifying scientific publications containing relevant information for a database, developing such tools necessitates manually annotating an unrealistic number of documents. One approach to this problem, active learning (AL), builds classification models by iteratively identifying documents that provide the most information to a classifier. Although this approach has been shown to be effective for related problems, in the context of scientific databases curation, it falls short. We present Virk, an AL system that, while being trained, simultaneously learns a classification model and identifies documents having information of interest for a knowledge base. Our approach uses a support vector machine (SVM) classifier with input features derived from neuroscience-related publications from the primary literature. Using our approach, we were able to increase the size of the Neuron Registry, a knowledge base of neuron-related information, by a factor of 90%, a knowledge base of neuron-related information, in 3 months. Using standard biocuration methods, it would have taken between 1 and 2 years to make the same number of contributions to the Neuron Registry. Here, we describe the system pipeline in detail, and evaluate its performance against other approaches to sampling in AL.",True,other,recurrent neural network
18974807,The role of the medical librarian in the basic biological sciences: a case study in virology and evolution,,True,other,GAN
17996092,"An open source infrastructure for managing knowledge and finding potential collaborators in a domain-specific subset of PubMed, with an example from human genome epidemiology","BACKGROUND: Identifying relevant research in an ever-growing body of published literature is becoming increasingly difficult. Establishing domain-specific knowledge bases may be a more effective and efficient way to manage and query information within specific biomedical fields. Adopting controlled vocabulary is a critical step toward data integration and interoperability in any information system. We present an open source infrastructure that provides a powerful capacity for managing and mining data within a domain-specific knowledge base. As a practical application of our infrastructure, we presented two applications - Literature Finder and Investigator Browser - as well as a tool set for automating the data curating process for the human genome published literature database. The design of this infrastructure makes the system potentially extensible to other data sources.
RESULTS: Information retrieval and usability tests demonstrated that the system had high rates of recall and precision, 90% and 93% respectively. The system was easy to learn, easy to use, reasonably speedy and effective.
CONCLUSION: The open source system infrastructure presented in this paper provides a novel approach to managing and querying information and knowledge from domain-specific PubMed data. Using the controlled vocabulary UMLS enhanced data integration and interoperability and the extensibility of the system. In addition, by using MVC-based design and Java as a platform-independent programming language, this system provides a potential infrastructure for any domain-specific knowledge base in the biomedical field.",True,text mining,Not specified
16799127,Enhancing text categorization with semantic-enriched representation and training data augmentation,"OBJECTIVE: Acquiring and representing biomedical knowledge is an increasingly important component of contemporary bioinformatics. A critical step of the process is to identify and retrieve relevant documents among the vast volume of modern biomedical literature efficiently. In the real world, many information retrieval tasks are difficult because of high data dimensionality and the lack of annotated examples to train a retrieval algorithm. Under such a scenario, the performance of information retrieval algorithms is often unsatisfactory, therefore improvements are needed.
DESIGN: We studied two approaches that enhance the text categorization performance on sparse and high data dimensionality: (1) semantic-preserving dimension reduction by representing text with semantic-enriched features; and (2) augmenting training data with semi-supervised learning. A probabilistic topic model was applied to extract major semantic topics from a corpus of text of interest. The representation of documents was projected from the high-dimensional vocabulary space onto a semantic topic space with reduced dimensionality. A semi-supervised learning algorithm based on graph theory was applied to identify potential positive training cases, which were further used to augment training data. The effects of data transformation and augmentation on text categorization by support vector machine (SVM) were evaluated.
RESULTS AND CONCLUSION: Semantic-enriched data transformation and the pseudo-positive-cases augmented training data enhance the efficiency and performance of text categorization by SVM.",True,other,Not specified
16447994,Investigation into biomedical literature classification using support vector machines,"Specific topic search in the PubMed Database, one of the most important information resources for scientific community, presents a big challenge to the users. The researcher typically formulates boolean queries followed by scanning the retrieved records for relevance, which is very time consuming and error prone. We applied Support Vector Machines (SVM) for automatic retrieval of PubMed articles related to Human genome epidemiological research at CDC (Center for disease Control and Prevention). In this paper, we discuss various investigations into biomedical literature classification and analyze the effect of various issues related to the choice of keywords, training sets, kernel functions and parameters for the SVM technique. We report on the various factors above to show that SVM is a viable technique for automatic classification of biomedical literature into topics of interest such as epidemiology, cancer, birth defects etc. In all our experiments, we achieved high values of PPV, sensitivity and specificity.",True,text mining,RNN
16159926,Markov model recognition and classification of DNA/protein sequences within large text databases,"MOTIVATION: Short sequence patterns frequently define regions of biological interest (binding sites, immune epitopes, primers, etc.), yet a large fraction of this information exists only within the scientific literature and is thus difficult to locate via conventional means (e.g. keyword queries or manual searches). We describe herein a system to accurately identify and classify sequence patterns from within large corpora using an n-gram Markov model (MM).
RESULTS: As expected, on test sets we found that identification of sequences with limited alphabets and/or regular structures such as nucleic acids (non-ambiguous) and peptide abbreviations (3-letter) was highly accurate, whereas classification of symbolic (1-letter) peptide strings with more complex alphabets was more problematic. The MM was used to analyze two very large, sequence-containing corpora: over 7.75 million Medline abstracts and 9000 full-text articles from Journal of Virology. Performance was benchmarked by comparing the results with Journal of Virology entries in two existing manually curated databases: VirOligo and the HLA Ligand Database. Performance estimates were 98 +/- 2% precision/84% recall for primer identification and classification and 67 +/- 6% precision/85% recall for peptide epitopes. We also find a dramatic difference between the amounts of sequence-related data reported in abstracts versus full text. Our results suggest that automated extraction and classification of sequence elements is a promising, low-cost means of sequence database curation and annotation.
AVAILABILITY: MM routine and datasets are available upon request.",True,text mining,Not specified
39418246,Neural parameter calibration and uncertainty quantification for epidemic forecasting,"The recent COVID-19 pandemic has thrown the importance of accurately forecasting contagion dynamics and learning infection parameters into sharp focus. At the same time, effective policy-making requires knowledge of the uncertainty on such predictions, in order, for instance, to be able to ready hospitals and intensive care units for a worst-case scenario without needlessly wasting resources. In this work, we apply a novel and powerful computational method to the problem of learning probability densities on contagion parameters and providing uncertainty quantification for pandemic projections. Using a neural network, we calibrate an ODE model to data of the spread of COVID-19 in Berlin in 2020, achieving both a significantly more accurate calibration and prediction than Markov-Chain Monte Carlo (MCMC)-based sampling schemes. The uncertainties on our predictions provide meaningful confidence intervals e.g. on infection figures and hospitalisation rates, while training and running the neural scheme takes minutes where MCMC takes hours. We show convergence of our method to the true posterior on a simplified SIR model of epidemics, and also demonstrate our method's learning capabilities on a reduced dataset, where a complex model is learned from a small number of compartments for which data is available.",True,other,convolutional neural network
39415343,Risk-stratified management of cervical high-grade squamous intraepithelial lesion based on machine learning,"The concordance rate between conization and colposcopy-directed biopsy (CDB) proven cervical high-grade squamous intraepithelial lesion (HSIL) were 64-85%. We aimed to identify the risk factors associated with pathological upgrading or downgrading after conization in patients with cervical HSIL and to provide risk-stratified management based on a machine learning predictive model. This retrospective study included patients who visited the Obstetrics and Gynecology Hospital of Fudan University from January 1 to December 31, 2019, were diagnosed with cervical HSIL by CDB, and subsequently underwent conization. A wide variety of data were collected from the medical records, including demographic data, laboratory findings, colposcopy descriptions, and pathological results. The patients were categorized into three groups according to their postconization pathological results: low-grade squamous intraepithelial lesion (LSIL) or below (downgrading group), HSIL (HSIL group), and cervical cancer (upgrading group). Univariate and multivariate analyses were performed to identify the independent risk factors for pathological changes in patients with cervical HSIL. Machine learning prediction models were established, evaluated, and subsequently verified using external testing data. In total, 1585 patients were included, of whom 65 (4.1%) were upgraded to cervical cancer after conization, 1147 (72.4%) remained having HSIL, and 373 (23.5%) were downgraded to LSIL or below. Multivariate analysis showed a 2% decrease in the incidence of pathological downgrade for each additional year of age and a 1% increase in lesion size. Patients with cytology > LSIL (odds ratio [OR] = 0.33; 95% confidence interval [CI], 0.21-0.52), human papillomavirus (HPV) infection (OR = 0.33; 95% CI, 0.14-0.81), HPV 33 infection (OR = 0.37; 95% CI, 0.18-0.78), coarse punctate vessels on colposcopy examination (OR = 0.14; 95% CI, 0.06-0.32), HSIL lesions in the endocervical canal (OR = 0.48; 95% CI, 0.30-0.76), and HSIL impression (OR = 0.02; 95% CI, 0.01-0.03) were less likely to experience pathological downgrading after conization than their counterparts. The independent risk factors for pathological upgrading to cervical cancer after conization included the following: age (OR = 1.08; 95% CI, 1.04-1.12), HPV 16 infection (OR = 4.07; 95% CI, 1.70-9.78), the presence of coarse punctate vessels during colposcopy examination (OR = 2.21; 95% CI, 1.08-4.50), atypical vessels (OR = 6.87; 95% CI, 2.81-16.83), and HSIL lesions in the endocervical canal (OR = 2.91; 95% CI, 1.46-5.77). Among the six machine learning prediction models, the back propagation (BP) neural network model demonstrated the highest and most uniform predictive performance in the downgrading, HSIL, and upgrading groups, with areas under the curve (AUCs) of 0.90, 0.84, and 0.69; sensitivities of 0.74, 0.84, and 0.42; specificities of 0.90, 0.71, and 0.95; and accuracies of 0.74, 0.84, and 0.95, respectively. In the external testing set, the BP neural network model showed a higher predictive performance than the logistic regression model, with an overall AUC of 0.91. Therefore, a web-based prediction tool was developed in this study. BP neural network prediction model has excellent predictive performance and can be used for the risk stratification of patients with CDB-diagnosed HSIL.",True,text mining,Not specified
39379851,"Machine learning-based prognostic prediction for hospitalized HIV/AIDS patients with cryptococcus infection in Guangxi, China","OBJECTIVE: To develop and validate a machine learning model for predicting mortality-associated prognostic factors in order to reduce in-hospital mortality rates among HIV/AIDS patients with Cryptococcus infection in Guangxi, China.
METHODS: This retrospective prognostic study included HIV/AIDS patients with cryptococcosis in the Fourth People's Hospital of Nanning from October 2011 to June 2019. Clinical features were extracted and used to train ten machine learning models, including Logistic Regression, KNN, DT, RF, Adaboost, Xgboost, LightGBM, Catboost, SVM, and NBM, to predict the outcome of HIV patients with cryptococcosis infection. The sensitivity, specificity, AUC, and F1 value were applied to assess model performance in both the testing and training sets. The optimal model was selected and interpreted.
RESULTS: A total of 396 patients were included in the study. The average in-hospital mortality of HIV/AIDS patients with cryptococcosis was 12.9% from 2012 to 2019. After feature screening, 20 clinical features were selected for model construction, accounting for 93.8%, including ART, Electrolyte disorder, Anemia, and 17 laboratory tests. The RF model (AUC 0.9787, Sensitivity 0.9535, Specificity 0.8889, F1 0.7455) and the SVM model (AUC 0.9286, Sensitivity 0.7907, Specificity 0.9786, F1 0.8293) had excellent performance. The SHAP analysis showed that the primary risk factors for prognosis prediction were identified as BUN/CREA, Electrolyte disorder, NEUT%, Urea, and IBIL.
CONCLUSIONS: RF and SVM machine learning models have shown promising predictive abilities for the prognosis of hospitalized HIV/AIDS patients with cryptococcosis, which can aid clinical assessment and treatment decisions for patient prognosis.",True,other,RNN
39375360,Author Correction: Pretrainable geometric graph neural network for antibody affinity maturation,,True,other,GAN
39326409,Development and validation of a machine learning model to predict myocardial blood flow and clinical outcomes from patients' electrocardiograms,"We develop a machine learning (ML) model using electrocardiography (ECG) to predict myocardial blood flow reserve (MFR) and assess its prognostic value for major adverse cardiovascular events (MACEs). Using 3,639 ECG-positron emission tomography (PET) and 17,649 ECG-single-photon emission computed tomography (SPECT) data pairs, the ML model is trained with a swarm intelligence approach and support vector regression (SVR). The model achieves a receiver-operator curve (ROC) area under the curve (AUC) of 0.83, with a sensitivity and specificity of 0.75. An ECG-MFR value below 2 is significantly associated with MACE, with hazard ratios (HRs) of 3.85 and 3.70 in the discovery and validation phases, respectively. The model's C-statistic is 0.76, with a net reclassification improvement (NRI) of 0.35. Validated in an independent cohort, the ML model using ECG data offers superior MACE prediction compared to baseline clinical models, highlighting its potential for risk stratification in patients with coronary artery disease (CAD) using the accessible 12-lead ECG.",True,other,Not specified
39283330,Use machine learning to predict pulmonary metastasis of esophageal cancer: a population-based study,"BACKGROUND: This study aims to establish a predictive model for assessing the risk of esophageal cancer lung metastasis using machine learning techniques.
METHODS: Data on esophageal cancer patients from 2010 to 2020 were extracted from the surveillance, epidemiology, and end results (SEER) database. Through univariate and multivariate logistic regression analyses, eight indicators related to the risk of lung metastasis were selected. These indicators were incorporated into six machine learning classifiers to develop corresponding predictive models. The performance of these models was evaluated and compared using metrics such as The area under curve (AUC), accuracy, sensitivity, specificity, and F1 score.
RESULTS: A total of 20,249 confirmed cases of esophageal cancer were included in this study. Among them, 14,174 cases (70%) were assigned to the training set while 6075 cases (30%) constituted the internal test set. Primary site location, tumor histology, tumor grade classification system T staging criteria N staging criteria brain metastasis bone metastasis liver metastasis emerged as independent risk factors for esophageal cancer with lung metastasis. Amongst the six constructed models, the GBM algorithm-based machine learning model demonstrated superior performance during internal dataset validation. AUC, accuracy, sensitivity, and specificity values achieved by this model stood at respectively at 0.803, 0.849, 0.604, and 0.867.
CONCLUSION: We have developed an online calculator based on the GBM model ( https://lvgrkyxcgdvo7ugoyxyywe.streamlit.app/)to aid clinical decision-making and treatment planning.",True,other,Not specified
39279135,Applying a community-engaged participatory machine learning model,"Although predictive algorithms have been described as the definitive solution to bias in health care, machine learning techniques may also propagate existing health inequities within the community context. However, there may be ways in which machine learning techniques can help community psychologists, public health researchers and practitioners identify patterns in data in a way that empowers improved outcomes. Incorporating community insight in all stages of machine learning research mitigates bias by positioning members of underrepresented communities as the experts of their lived experiences. As community psychologists already prioritize community-based participatory practices, we propose three core guiding principles for a community-engaged participatory model for research using machine learning techniques: shared decision-making, reflexivity and structural humility, and flexibility and adaptability. Guided by these three principles, we emphasize grounding priority setting, problem formation, model assumptions, and interpretation of the resulting algorithmic patterns in the truths born from the lived experiences of people closest to the problem. We also suggest opportunities for bidirectional and mutually empowering partnerships between algorithmic scientists and the communities to which their algorithms will be applied. Inclusion of community stakeholders in all stages of machine learning for health research provides an opportunity to develop algorithms that are both highly effective and ethically grounded in the lived experiences of target populations.",True,other,convolutional neural network
39245968,The utility of a machine learning model in identifying people at high risk of type 2 diabetes mellitus,"BACKGROUND: According to previous reports, very high percentages of individuals in Saudi Arabia are undiagnosed for type 2 diabetes mellitus (T2DM). Despite conducting several screening and awareness campaigns, these efforts lacked full accessibility and consumed extensive human and material resources. Thus, developing machine learning (ML) models could enhance the population-based screening process. The study aims to compare a newly developed ML model's outcomes with the validated American Diabetes Association's (ADA) risk assessment regarding predicting people with high risk for T2DM.
RESEARCH DESIGN AND METHODS: Patients' age, gender, and risk factors that were obtained from the National Health Information Center's dataset were used to build and train the ML model. To evaluate the developed ML model, an external validation study was conducted in three primary health care centers. A random sample (N = 3400) was selected from the non-diabetic individuals.
RESULTS: The results showed the plotted data of sensitivity/100-specificity represented in the Receiver Operating Characteristic (ROC) curve with an AROC value of 0.803, 95% CI: 0.779-0.826.
CONCLUSIONS: The current study reveals a new ML model proposed for population-level classification that can be an adequate tool for identifying those at high risk of T2DM or who already have T2DM but have not been diagnosed.",True,other,Not specified
39236067,A Physics-Informed Neural Network approach for compartmental epidemiological models,"Compartmental models provide simple and efficient tools to analyze the relevant transmission processes during an outbreak, to produce short-term forecasts or transmission scenarios, and to assess the impact of vaccination campaigns. However, their calibration is not straightforward, since many factors contribute to the rapid change of the transmission dynamics. For example, there might be changes in the individual awareness, the imposition of non-pharmacological interventions and the emergence of new variants. As a consequence, model parameters such as the transmission rate are doomed to vary in time, making their assessment more challenging. Here, we propose to use Physics-Informed Neural Networks (PINNs) to track the temporal changes in the model parameters and the state variables. PINNs recently gained attention in many engineering applications thanks to their ability to consider both the information from data (typically uncertain) and the governing equations of the system. The ability of PINNs to identify unknown model parameters makes them particularly suitable to solve ill-posed inverse problems, such as those arising in the application of epidemiological models. Here, we develop a reduced-split approach for the implementation of PINNs to estimate the temporal changes in the state variables and transmission rate of an epidemic based on the SIR model equation and infectious data. The main idea is to split the training first on the epidemiological data, and then on the residual of the system equations. The proposed method is applied to five synthetic test cases and two real scenarios reproducing the first months of the Italian COVID-19 pandemic. Our results show that the split implementation of PINNs outperforms the joint approach in terms of accuracy (up to one order of magnitude) and computational times (speed up of 20%). Finally, we illustrate that the proposed PINN-method can also be adopted to produced short-term forecasts of the dynamics of an epidemic.",True,text mining,Not specified
39195936,Development and multinational validation of an algorithmic strategy for high Lp(a) screening,"Elevated lipoprotein (a) (Lp(a)) is associated with premature atherosclerotic cardiovascular disease. However, fewer than 0.5% of individuals undergo Lp(a) testing, limiting the evaluation and use of novel targeted therapeutics currently under development. Here we describe the development of a machine learning model for targeted screening for elevated Lp(a) (≥150 nmol l-1) in the UK Biobank (N = 456,815), the largest cohort with protocolized Lp(a) testing. We externally validated the model in 3 large cohort studies, ARIC (N = 14,484), CARDIA (N = 4,124) and MESA (N = 4,672). The model, Algorithmic Risk Inspection for Screening Elevated Lp(a) (ARISE), reduced the number needed to test to find one individual with elevated Lp(a) by up to 67.3%, based on the probability threshold, with consistent performance across external validation cohorts. ARISE could be used to optimize screening for elevated Lp(a) using commonly available clinical features, with the potential for its deployment in electronic health records to enhance the yield of Lp(a) testing in real-world settings.",True,other,Not specified
39152423,Prediction of sepsis mortality in ICU patients using machine learning methods,"PROBLEM: Sepsis, a life-threatening condition, accounts for the deaths of millions of people worldwide. Accurate prediction of sepsis outcomes is crucial for effective treatment and management. Previous studies have utilized machine learning for prognosis, but have limitations in feature sets and model interpretability.
AIM: This study aims to develop a machine learning model that enhances prediction accuracy for sepsis outcomes using a reduced set of features, thereby addressing the limitations of previous studies and enhancing model interpretability.
METHODS: This study analyzes intensive care patient outcomes using the MIMIC-IV database, focusing on adult sepsis cases. Employing the latest data extraction tools, such as Google BigQuery, and following stringent selection criteria, we selected 38 features in this study. This selection is also informed by a comprehensive literature review and clinical expertise. Data preprocessing included handling missing values, regrouping categorical variables, and using the Synthetic Minority Over-sampling Technique (SMOTE) to balance the data. We evaluated several machine learning models: Decision Trees, Gradient Boosting, XGBoost, LightGBM, Multilayer Perceptrons (MLP), Support Vector Machines (SVM), and Random Forest. The Sequential Halving and Classification (SHAC) algorithm was used for hyperparameter tuning, and both train-test split and cross-validation methodologies were employed for performance and computational efficiency.
RESULTS: The Random Forest model was the most effective, achieving an area under the receiver operating characteristic curve (AUROC) of 0.94 with a confidence interval of ±0.01. This significantly outperformed other models and set a new benchmark in the literature. The model also provided detailed insights into the importance of various clinical features, with the Sequential Organ Failure Assessment (SOFA) score and average urine output being highly predictive. SHAP (Shapley Additive Explanations) analysis further enhanced the model's interpretability, offering a clearer understanding of feature impacts.
CONCLUSION: This study demonstrates significant improvements in predicting sepsis outcomes using a Random Forest model, supported by advanced machine learning techniques and thorough data preprocessing. Our approach provided detailed insights into the key clinical features impacting sepsis mortality, making the model both highly accurate and interpretable. By enhancing the model's practical utility in clinical settings, we offer a valuable tool for healthcare professionals to make data-driven decisions, ultimately aiming to minimize sepsis-induced fatalities.",True,other,recurrent neural network
39129362,MetaFluAD: meta-learning for predicting antigenic distances among influenza viruses,"Influenza viruses rapidly evolve to evade previously acquired human immunity. Maintaining vaccine efficacy necessitates continuous monitoring of antigenic differences among strains. Traditional serological methods for assessing these differences are labor-intensive and time-consuming, highlighting the need for efficient computational approaches. This paper proposes MetaFluAD, a meta-learning-based method designed to predict quantitative antigenic distances among strains. This method models antigenic relationships between strains, represented by their hemagglutinin (HA) sequences, as a weighted attributed network. Employing a graph neural network (GNN)-based encoder combined with a robust meta-learning framework, MetaFluAD learns comprehensive strain representations within a unified space encompassing both antigenic and genetic features. Furthermore, the meta-learning framework enables knowledge transfer across different influenza subtypes, allowing MetaFluAD to achieve remarkable performance with limited data. MetaFluAD demonstrates excellent performance and overall robustness across various influenza subtypes, including A/H3N2, A/H1N1, A/H5N1, B/Victoria, and B/Yamagata. MetaFluAD synthesizes the strengths of GNN-based encoding and meta-learning to offer a promising approach for accurate antigenic distance prediction. Additionally, MetaFluAD can effectively identify dominant antigenic clusters within seasonal influenza viruses, aiding in the development of effective vaccines and efficient monitoring of viral evolution.",True,other,Not specified
39123113,Admission blood tests predicting survival of SARS-CoV-2 infected patients: a practical implementation of graph convolution network in imbalance dataset,"BACKGROUND: Predicting an individual's risk of death from COVID-19 is essential for planning and optimising resources. However, since the real-world mortality rate is relatively low, particularly in places like Hong Kong, this makes building an accurate prediction model difficult due to the imbalanced nature of the dataset. This study introduces an innovative application of graph convolutional networks (GCNs) to predict COVID-19 patient survival using a highly imbalanced dataset. Unlike traditional models, GCNs leverage structural relationships within the data, enhancing predictive accuracy and robustness. By integrating demographic and laboratory data into a GCN framework, our approach addresses class imbalance and demonstrates significant improvements in prediction accuracy.
METHODS: The cohort included all consecutive positive COVID-19 patients fulfilling study criteria admitted to 42 public hospitals in Hong Kong between January 23 and December 31, 2020 (n = 7,606). We proposed the population-based graph convolutional neural network (GCN) model which took blood test results, age and sex as inputs to predict the survival outcomes. Furthermore, we compared our proposed model to the Cox Proportional Hazard (CPH) model, conventional machine learning models, and oversampling machine learning models. Additionally, a subgroup analysis was performed on the test set in order to acquire a deeper understanding of the relationship between each patient node and its neighbours, revealing possible underlying causes of the inaccurate predictions.
RESULTS: The GCN model was the top-performing model, with an AUC of 0.944, considerably outperforming all other models (p < 0.05), including the oversampled CPH model (0.708), linear regression (0.877), Linear Discriminant Analysis (0.860), K-nearest neighbours (0.834), Gaussian predictor (0.745) and support vector machine (0.847). With Kaplan-Meier estimates, the GCN model demonstrated good discriminability between low- and high-risk individuals (p < 0.0001). Based on subanalysis using the weighted-in score, although the GCN model was able to discriminate well between different predicted groups, the separation was inadequate between false negative (FN) and true negative (TN) groups.
CONCLUSION: The GCN model considerably outperformed all other machine learning methods and baseline CPH models. Thus, when applied to this imbalanced COVID survival dataset, adopting a population graph representation may be an approach to achieving good prediction.",True,other,convolutional neural network
39116330,Using Machine Learning to Identify Patients at Risk of Acquiring HIV in an Urban Health System,"BACKGROUND: Effective measures exist to prevent the spread of HIV. However, the identification of patients who are candidates for these measures can be a challenge. A machine learning model to predict risk for HIV may enhance patient selection for proactive outreach.
SETTING: Using data from the electronic health record at Parkland Health, 1 of the largest public healthcare systems in the country, a machine learning model is created to predict incident HIV cases. The study cohort includes any patient aged 16 or older from 2015 to 2019 (n = 458,893).
METHODS: Implementing a 70:30 ratio random split of the data into training and validation sets with an incident rate <0.08% and stratified by incidence of HIV, the model is evaluated using a k-fold cross-validated (k = 5) area under the receiver operating characteristic curve leveraging Light Gradient Boosting Machine Algorithm, an ensemble classifier.
RESULTS: The light gradient boosting machine produces the strongest predictive power to identify good candidates for HIV PrEP. A gradient boosting classifier produced the best result with an AUC of 0.88 (95% confidence interval: 0.86 to 0.89) on the training set and 0.85 (95% confidence interval: 0.81 to 0.89) on the validation set for a sensitivity of 77.8% and specificity of 75.1%.
CONCLUSIONS: A gradient boosting model using electronic health record data can be used to identify patients at risk of acquiring HIV and implemented in the clinical setting to build outreach for preventative interventions.",True,other,Not specified
39079111,A Machine Learning Model for Predicting In-Hospital Mortality in Chinese Patients With ST-Segment Elevation Myocardial Infarction: Findings From the China Myocardial Infarction Registry,"BACKGROUND: Machine learning (ML) risk prediction models, although much more accurate than traditional statistical methods, are inconvenient to use in clinical practice due to their nontransparency and requirement of a large number of input variables.
OBJECTIVE: We aimed to develop a precise, explainable, and flexible ML model to predict the risk of in-hospital mortality in patients with ST-segment elevation myocardial infarction (STEMI).
METHODS: This study recruited 18,744 patients enrolled in the 2013 China Acute Myocardial Infarction (CAMI) registry and 12,018 patients from the China Patient-Centered Evaluative Assessment of Cardiac Events (PEACE)-Retrospective Acute Myocardial Infarction Study. The Extreme Gradient Boosting (XGBoost) model was derived from 9616 patients in the CAMI registry (2014, 89 variables) with 5-fold cross-validation and validated on both the 9125 patients in the CAMI registry (89 variables) and the independent China PEACE cohort (10 variables). The Shapley Additive Explanations (SHAP) approach was employed to interpret the complex relationships embedded in the proposed model.
RESULTS: In the XGBoost model for predicting all-cause in-hospital mortality, the variables with the top 8 most important scores were age, left ventricular ejection fraction, Killip class, heart rate, creatinine, blood glucose, white blood cell count, and use of angiotensin-converting enzyme inhibitors (ACEIs) and angiotensin II receptor blockers (ARBs). The area under the curve (AUC) on the CAMI validation set was 0.896 (95% CI 0.884-0.909), significantly higher than the previous models. The AUC for the Global Registry of Acute Coronary Events (GRACE) model was 0.809 (95% CI 0.790-0.828), and for the TIMI model, it was 0.782 (95% CI 0.763-0.800). Despite the China PEACE validation set only having 10 available variables, the AUC reached 0.840 (0.829-0.852), showing a substantial improvement to the GRACE (0.762, 95% CI 0.748-0.776) and TIMI (0.789, 95% CI 0.776-0.803) scores. Several novel and nonlinear relationships were discovered between patients' characteristics and in-hospital mortality, including a U-shape pattern of high-density lipoprotein cholesterol (HDL-C).
CONCLUSIONS: The proposed ML risk prediction model was highly accurate in predicting in-hospital mortality. Its flexible and explainable characteristics make the model convenient to use in clinical practice and could help guide patient management.
TRIAL REGISTRATION: ClinicalTrials.gov NCT01874691; https://clinicaltrials.gov/study/NCT01874691.",True,other,Not specified
39027393,Recurrent neural network for the dynamics of Zika virus spreading,"Recurrent Neural Networks (RNNs), a type of machine learning technique, have recently drawn a lot of interest in numerous fields, including epidemiology. Implementing public health interventions in the field of epidemiology depends on efficient modeling and outbreak prediction. Because RNNs can capture sequential dependencies in data, they have become highly effective tools in this field. In this paper, the use of RNNs in epidemic modeling is examined, with a focus on the extent to which they can handle the inherent temporal dynamics in the spread of diseases. The mathematical representation of epidemics requires taking time-dependent variables into account, such as the rate at which infections spread and the long-term effects of interventions. The goal of this study is to use an intelligent computing solution based on RNNs to provide numerical performances and interpretations for the SEIR nonlinear system based on the propagation of the Zika virus (SEIRS-PZV) model. The four patient dynamics, namely susceptible patients S(y), exposed patients admitted in a hospital E(y), the fraction of infective individuals I(y), and recovered patients R(y), are represented by the epidemic version of the nonlinear system, or the SEIR model. SEIRS-PZV is represented by ordinary differential equations (ODEs), which are then solved by the Adams method using the Mathematica software to generate a dataset. The dataset was used as an output for the RNN to train the model and examine results such as regressions, correlations, error histograms, etc. For RNN, we used 100% to train the model with 15 hidden layers and a delay of 2 seconds. The input for the RNN is a time series sequence from 0 to 5, with a step size of 0.05. In the end, we compared the approximated solution with the exact solution by plotting them on the same graph and generating the absolute error plot for each of the 4 cases of SEIRS-PZV. Predictions made by the model appeared to be become more accurate when the mean squared error (MSE) decreased. An increased fit to the observed data was suggested by this decrease in the MSE, which suggested that the variance between the model's predicted values and the actual values was dropping. A minimal absolute error almost equal to zero was obtained, which further supports the usefulness of the suggested strategy. A small absolute error shows the degree to which the model's predictions matches the ground truth values, thus indicating the level of accuracy and precision for the model's output.",True,other,RNN
39018880,"Machine learning models predict triage levels, massive transfusion protocol activation, and mortality in trauma utilizing patients hemodynamics on admission","BACKGROUND: The effective management of trauma patients necessitates efficient triaging, timely activation of Massive Blood Transfusion Protocols (MTP), and accurate prediction of in-hospital outcomes. Machine learning (ML) algorithms have emerged as up-and-coming tools in the domains of optimizing triage decisions, improving intervention strategies, and predicting clinical outcomes, consistently outperforming traditional methodologies. This study aimed to develop, assess, and compare several ML models for the triaging processes, activation of MTP, and mortality prediction.
METHODS: In a 10-year retrospective study, the predictive capabilities of seven ML models for trauma patients were systematically assessed using on-admission patients' hemodynamic data. All patient's data were randomly divided into training (80 %) and test (20 %) sets. Employing Python for data preprocessing, feature scaling, and model development, we evaluated K-Nearest Neighbors (KNN), Logistic Regression (LR), Decision Tree (DT), Support Vector Machines (SVM) with RBF kernels, Random Forest (RF), Extreme Gradient Boosting (XGBoost), and Artificial Neural Network (ANN). We employed various imputation techniques and addressed data imbalance through down-sampling, up-sampling, and synthetic minority for the over-sampling technique (SMOTE). Hyperparameter tuning, coupled with 5-fold cross-validation, was performed. The evaluation included essential metrics like sensitivity, specificity, F1 score, accuracy, Area Under the Receiver Operating Curve (AUC ROC), and Area Under the Precision recall Curve (AUC PR), ensuring robust predictive capability.
RESULT: This study included 17,390 adult trauma patients; of them, 19.5 % (3385) were triaged at a critical level, 3.8 % (664) required MTP, and 7.7 % (1335) died in the hospital. The model's performance improved using imputation and balancing techniques. The overall models demonstrated notable performance metrics for predicting triage, MTP activation, and mortality with F1 scores of 0.75, 0.42, and 0.79, sensitivities of 0.73, 0.82, and 0.9, and AUC ROC values of 0.89, 0.95 and 0.99 respectively.
CONCLUSION: Machine learning, especially RF models, effectively predicted trauma triage, MTP activation, and mortality. Featured critical hemodynamic variables include shock indices, systolic blood pressure, and mean arterial pressure. Therefore, models can do better than individual parameters for the early management and disposition of patients in the ED. Future research should focus on creating sensitive and interpretable models to enhance trauma care.",True,other,Not specified
38971198,Validation of an Electronic Health Record-Based Machine Learning Model Compared With Clinical Risk Scores for Gastrointestinal Bleeding,"BACKGROUND & AIMS: Guidelines recommend use of risk stratification scores for patients presenting with gastrointestinal bleeding (GIB) to identify very-low-risk patients eligible for discharge from emergency departments. Machine learning models may outperform existing scores and can be integrated within the electronic health record (EHR) to provide real-time risk assessment without manual data entry. We present the first EHR-based machine learning model for GIB.
METHODS: The training cohort comprised 2546 patients and internal validation of 850 patients presenting with overt GIB (ie, hematemesis, melena, and hematochezia) to emergency departments of 2 hospitals from 2014 to 2019. External validation was performed on 926 patients presenting to a different hospital with the same EHR from 2014 to 2019. The primary outcome was a composite of red blood cell transfusion, hemostatic intervention (ie, endoscopic, interventional radiologic, or surgical), and 30-day all-cause mortality. We used structured data fields in the EHR, available within 4 hours of presentation, and compared the performance of machine learning models with current guideline-recommended risk scores, Glasgow-Blatchford Score, and Oakland Score. Primary analysis was area under the receiver operating characteristic curve. Secondary analysis was specificity at 99% sensitivity to assess the proportion of patients correctly identified as very low risk.
RESULTS: The machine learning model outperformed the Glasgow-Blatchford Score (area under the receiver operating characteristic curve, 0.92 vs 0.89; P < .001) and Oakland Score (area under the receiver operating characteristic curve, 0.92 vs 0.89; P < .001). At the very-low-risk threshold of 99% sensitivity, the machine learning model identified more very-low-risk patients: 37.9% vs 18.5% for Glasgow-Blatchford Score and 11.7% for Oakland Score (P < .001 for both comparisons).
CONCLUSIONS: An EHR-based machine learning model performs better than currently recommended clinical risk scores and identifies more very-low-risk patients eligible for discharge from the emergency department.",True,other,Not specified
38963925,Bayesian Networks for Prescreening in Depression: Algorithm Development and Validation,"BACKGROUND: Identifying individuals with depressive symptomatology (DS) promptly and effectively is of paramount importance for providing timely treatment. Machine learning models have shown promise in this area; however, studies often fall short in demonstrating the practical benefits of using these models and fail to provide tangible real-world applications.
OBJECTIVE: This study aims to establish a novel methodology for identifying individuals likely to exhibit DS, identify the most influential features in a more explainable way via probabilistic measures, and propose tools that can be used in real-world applications.
METHODS: The study used 3 data sets: PROACTIVE, the Brazilian National Health Survey (Pesquisa Nacional de Saúde [PNS]) 2013, and PNS 2019, comprising sociodemographic and health-related features. A Bayesian network was used for feature selection. Selected features were then used to train machine learning models to predict DS, operationalized as a score of ≥10 on the 9-item Patient Health Questionnaire. The study also analyzed the impact of varying sensitivity rates on the reduction of screening interviews compared to a random approach.
RESULTS: The methodology allows the users to make an informed trade-off among sensitivity, specificity, and a reduction in the number of interviews. At the thresholds of 0.444, 0.412, and 0.472, determined by maximizing the Youden index, the models achieved sensitivities of 0.717, 0.741, and 0.718, and specificities of 0.644, 0.737, and 0.766 for PROACTIVE, PNS 2013, and PNS 2019, respectively. The area under the receiver operating characteristic curve was 0.736, 0.801, and 0.809 for these 3 data sets, respectively. For the PROACTIVE data set, the most influential features identified were postural balance, shortness of breath, and how old people feel they are. In the PNS 2013 data set, the features were the ability to do usual activities, chest pain, sleep problems, and chronic back problems. The PNS 2019 data set shared 3 of the most influential features with the PNS 2013 data set. However, the difference was the replacement of chronic back problems with verbal abuse. It is important to note that the features contained in the PNS data sets differ from those found in the PROACTIVE data set. An empirical analysis demonstrated that using the proposed model led to a potential reduction in screening interviews of up to 52% while maintaining a sensitivity of 0.80.
CONCLUSIONS: This study developed a novel methodology for identifying individuals with DS, demonstrating the utility of using Bayesian networks to identify the most significant features. Moreover, this approach has the potential to substantially reduce the number of screening interviews while maintaining high sensitivity, thereby facilitating improved early identification and intervention strategies for individuals experiencing DS.",True,other,Not specified
38888985,A Paper-Based Multiplexed Serological Test to Monitor Immunity against SARS-COV-2 Using Machine Learning,"The rapid spread of SARS-CoV-2 caused the COVID-19 pandemic and accelerated vaccine development to prevent the spread of the virus and control the disease. Given the sustained high infectivity and evolution of SARS-CoV-2, there is an ongoing interest in developing COVID-19 serology tests to monitor population-level immunity. To address this critical need, we designed a paper-based multiplexed vertical flow assay (xVFA) using five structural proteins of SARS-CoV-2, detecting IgG and IgM antibodies to monitor changes in COVID-19 immunity levels. Our platform not only tracked longitudinal immunity levels but also categorized COVID-19 immunity into three groups: protected, unprotected, and infected, based on the levels of IgG and IgM antibodies. We operated two xVFAs in parallel to detect IgG and IgM antibodies using a total of 40 μL of human serum sample in <20 min per test. After the assay, images of the paper-based sensor panel were captured using a mobile phone-based custom-designed optical reader and then processed by a neural network-based serodiagnostic algorithm. The serodiagnostic algorithm was trained with 120 measurements/tests and 30 serum samples from 7 randomly selected individuals and was blindly tested with 31 serum samples from 8 different individuals, collected before vaccination as well as after vaccination or infection, achieving an accuracy of 89.5%. The competitive performance of the xVFA, along with its portability, cost-effectiveness, and rapid operation, makes it a promising computational point-of-care (POC) serology test for monitoring COVID-19 immunity, aiding in timely decisions on the administration of booster vaccines and general public health policies to protect vulnerable populations.",True,other,Not specified
38879641,A versatile automated pipeline for quantifying virus infectivity by label-free light microscopy and artificial intelligence,"Virus infectivity is traditionally determined by endpoint titration in cell cultures, and requires complex processing steps and human annotation. Here we developed an artificial intelligence (AI)-powered automated framework for ready detection of virus-induced cytopathic effect (DVICE). DVICE uses the convolutional neural network EfficientNet-B0 and transmitted light microscopy images of infected cell cultures, including coronavirus, influenza virus, rhinovirus, herpes simplex virus, vaccinia virus, and adenovirus. DVICE robustly measures virus-induced cytopathic effects (CPE), as shown by class activation mapping. Leave-one-out cross-validation in different cell types demonstrates high accuracy for different viruses, including SARS-CoV-2 in human saliva. Strikingly, DVICE exhibits virus class specificity, as shown with adenovirus, herpesvirus, rhinovirus, vaccinia virus, and SARS-CoV-2. In sum, DVICE provides unbiased infectivity scores of infectious agents causing CPE, and can be adapted to laboratory diagnostics, drug screening, serum neutralization or clinical samples.",True,other,autoencoder
38863928,Machine learning model for cardiovascular disease prediction in patients with chronic kidney disease,"INTRODUCTION: Cardiovascular disease (CVD) is the leading cause of death in patients with chronic kidney disease (CKD). This study aimed to develop CVD risk prediction models using machine learning to support clinical decision making and improve patient prognosis.
METHODS: Electronic medical records from patients with CKD at a single center from 2015 to 2020 were used to develop machine learning models for the prediction of CVD. Least absolute shrinkage and selection operator (LASSO) regression was used to select important features predicting the risk of developing CVD. Seven machine learning classification algorithms were used to build models, which were evaluated by receiver operating characteristic curves, accuracy, sensitivity, specificity, and F1-score, and Shapley Additive explanations was used to interpret the model results. CVD was defined as composite cardiovascular events including coronary heart disease (coronary artery disease, myocardial infarction, angina pectoris, and coronary artery revascularization), cerebrovascular disease (hemorrhagic stroke and ischemic stroke), deaths from all causes (cardiovascular deaths, non-cardiovascular deaths, unknown cause of death), congestive heart failure, and peripheral artery disease (aortic aneurysm, aortic or other peripheral arterial revascularization). A cardiovascular event was a composite outcome of multiple cardiovascular events, as determined by reviewing medical records.
RESULTS: This study included 8,894 patients with CKD, with a composite CVD event incidence of 25.9%; a total of 2,304 patients reached this outcome. LASSO regression identified eight important features for predicting the risk of CKD developing into CVD: age, history of hypertension, sex, antiplatelet drugs, high-density lipoprotein, sodium ions, 24-h urinary protein, and estimated glomerular filtration rate. The model developed using Extreme Gradient Boosting in the test set had an area under the curve of 0.89, outperforming the other models, indicating that it had the best CVD predictive performance.
CONCLUSION: This study established a CVD risk prediction model for patients with CKD, based on routine clinical diagnostic and treatment data, with good predictive accuracy. This model is expected to provide a scientific basis for the management and treatment of patients with CKD.",True,other,RNN
38851393,Interpretable machine learning predicts postpartum hemorrhage with severe maternal morbidity in a lower-risk laboring obstetric population,"BACKGROUND: Early identification of patients at increased risk for postpartum hemorrhage (PPH) associated with severe maternal morbidity (SMM) is critical for preparation and preventative intervention. However, prediction is challenging in patients without obvious risk factors for postpartum hemorrhage with severe maternal morbidity. Current tools for hemorrhage risk assessment use lists of risk factors rather than predictive models.
OBJECTIVE: To develop, validate (internally and externally), and compare a machine learning model for predicting PPH associated with SMM against a standard hemorrhage risk assessment tool in a lower risk laboring obstetric population.
STUDY DESIGN: This retrospective cross-sectional study included clinical data from singleton, term births (>=37 weeks' gestation) at 19 US hospitals (2016-2021) using data from 58,023 births at 11 hospitals to train a generalized additive model (GAM) and 27,743 births at 8 held-out hospitals to externally validate the model. The outcome of interest was PPH with severe maternal morbidity (blood transfusion, hysterectomy, vascular embolization, intrauterine balloon tamponade, uterine artery ligation suture, uterine compression suture, or admission to intensive care). Cesarean birth without a trial of vaginal birth and patients with a history of cesarean were excluded. We compared the model performance to that of the California Maternal Quality Care Collaborative (CMQCC) Obstetric Hemorrhage Risk Factor Assessment Screen.
RESULTS: The GAM predicted PPH with an area under the receiver-operating characteristic curve (AUROC) of 0.67 (95% CI 0.64-0.68) on external validation, significantly outperforming the CMQCC risk screen AUROC of 0.52 (95% CI 0.50-0.53). Additionally, the GAM had better sensitivity of 36.9% (95% CI 33.01-41.02) than the CMQCC screen sensitivity of 20.30% (95% CI 17.40-22.52) at the CMQCC screen positive rate of 16.8%. The GAM identified in-vitro fertilization as a risk factor (adjusted OR 1.5; 95% CI 1.2-1.8) and nulliparous births as the highest PPH risk factor (adjusted OR 1.5; 95% CI 1.4-1.6).
CONCLUSION: Our model identified almost twice as many cases of PPH as the CMQCC rules-based approach for the same screen positive rate and identified in-vitro fertilization and first-time births as risk factors for PPH. Adopting predictive models over traditional screens can enhance PPH prediction.",True,other,Not specified
38835075,Optimizing clinico-genomic disease prediction across ancestries: a machine learning strategy with Pareto improvement,"BACKGROUND: Accurate prediction of an individual's predisposition to diseases is vital for preventive medicine and early intervention. Various statistical and machine learning models have been developed for disease prediction using clinico-genomic data. However, the accuracy of clinico-genomic prediction of diseases may vary significantly across ancestry groups due to their unequal representation in clinical genomic datasets.
METHODS: We introduced a deep transfer learning approach to improve the performance of clinico-genomic prediction models for data-disadvantaged ancestry groups. We conducted machine learning experiments on multi-ancestral genomic datasets of lung cancer, prostate cancer, and Alzheimer's disease, as well as on synthetic datasets with built-in data inequality and distribution shifts across ancestry groups.
RESULTS: Deep transfer learning significantly improved disease prediction accuracy for data-disadvantaged populations in our multi-ancestral machine learning experiments. In contrast, transfer learning based on linear frameworks did not achieve comparable improvements for these data-disadvantaged populations.
CONCLUSIONS: This study shows that deep transfer learning can enhance fairness in multi-ancestral machine learning by improving prediction accuracy for data-disadvantaged populations without compromising prediction accuracy for other populations, thus providing a Pareto improvement towards equitable clinico-genomic prediction of diseases.",True,other,recurrent neural network
38832222,Integrating gated recurrent unit in graph neural network to improve infectious disease prediction: an attempt,"OBJECTIVE: This study focuses on enhancing the precision of epidemic time series data prediction by integrating Gated Recurrent Unit (GRU) into a Graph Neural Network (GNN), forming the GRGNN. The accuracy of the GNN (Graph Neural Network) network with introduced GRU (Gated Recurrent Units) is validated by comparing it with seven commonly used prediction methods.
METHOD: The GRGNN methodology involves multivariate time series prediction using a GNN (Graph Neural Network) network improved by the integration of GRU (Gated Recurrent Units). Additionally, Graphical Fourier Transform (GFT) and Discrete Fourier Transform (DFT) are introduced. GFT captures inter-sequence correlations in the spectral domain, while DFT transforms data from the time domain to the frequency domain, revealing temporal node correlations. Following GFT and DFT, outbreak data are predicted through one-dimensional convolution and gated linear regression in the frequency domain, graph convolution in the spectral domain, and GRU (Gated Recurrent Units) in the time domain. The inverse transformation of GFT and DFT is employed, and final predictions are obtained after passing through a fully connected layer. Evaluation is conducted on three datasets: the COVID-19 datasets of 38 African countries and 42 European countries from worldometers, and the chickenpox dataset of 20 Hungarian regions from Kaggle. Metrics include Average Root Mean Square Error (ARMSE) and Average Mean Absolute Error (AMAE).
RESULT: For African COVID-19 dataset and Hungarian Chickenpox dataset, GRGNN consistently outperforms other methods in ARMSE and AMAE across various prediction step lengths. Optimal results are achieved even at extended prediction steps, highlighting the model's robustness.
CONCLUSION: GRGNN proves effective in predicting epidemic time series data with high accuracy, demonstrating its potential in epidemic surveillance and early warning applications. However, further discussions and studies are warranted to refine its application and judgment methods, emphasizing the ongoing need for exploration and research in this domain.",True,other,recurrent neural network
38822285,Interpretable machine learning model for predicting acute kidney injury in critically ill patients,"BACKGROUND: This study aimed to create a method for promptly predicting acute kidney injury (AKI) in intensive care patients by applying interpretable, explainable artificial intelligence techniques.
METHODS: Population data regarding intensive care patients were derived from the Medical Information Mart for Intensive Care IV database from 2008 to 2019. Machine learning (ML) techniques with six methods were created to construct the predicted models for AKI. The performance of each ML model was evaluated by comparing the areas under the curve (AUC). Local Interpretable Model-Agnostic Explanations (LIME) method and Shapley Additive exPlanation values were used to decipher the best model.
RESULTS: According to inclusion and exclusion criteria, 53,150 severely sick individuals were included in the present study, of which 42,520 (80%) were assigned to the training group, and 10,630 (20%) were allocated to the validation group. Compared to the other five ML models, the eXtreme Gradient Boosting (XGBoost) model greatly predicted AKI following ICU admission, with an AUC of 0.816. The top four contributing variables of the XGBoost model were SOFA score, weight, mechanical ventilation, and the Simplified Acute Physiology Score II. An AKI and Non-AKI cases were predicted separately using the LIME algorithm.
CONCLUSION: Overall, the constructed clinical feature-based ML models are excellent in predicting AKI in intensive care patients. It would be constructive for physicians to provide early support and timely intervention measures to intensive care patients at risk of AKI.",True,computer vision,Not specified
38792496,Using Machine Learning to Evaluate the Value of Genetic Liabilities in the Classification of Hypertension within the UK Biobank,"Background and Objective: Hypertension increases the risk of cardiovascular diseases (CVD) such as stroke, heart attack, heart failure, and kidney disease, contributing to global disease burden and premature mortality. Previous studies have utilized statistical and machine learning techniques to develop hypertension prediction models. Only a few have included genetic liabilities and evaluated their predictive values. This study aimed to develop an effective hypertension classification model and investigate the potential influence of genetic liability for multiple risk factors linked to CVD on hypertension risk using the random forest and the neural network. Materials and Methods: The study involved 244,718 European participants, who were divided into training and testing sets. Genetic liabilities were constructed using genetic variants associated with CVD risk factors obtained from genome-wide association studies (GWAS). Various combinations of machine learning models before and after feature selection were tested to develop the best classification model. The models were evaluated using area under the curve (AUC), calibration, and net reclassification improvement in the testing set. Results: The models without genetic liabilities achieved AUCs of 0.70 and 0.72 using the random forest and the neural network methods, respectively. Adding genetic liabilities improved the AUC for the random forest but not for the neural network. The best classification model was achieved when feature selection and classification were performed using random forest (AUC = 0.71, Spiegelhalter z score = 0.10, p-value = 0.92, calibration slope = 0.99). This model included genetic liabilities for total cholesterol and low-density lipoprotein (LDL). Conclusions: The study highlighted that incorporating genetic liabilities for lipids in a machine learning model may provide incremental value for hypertension classification beyond baseline characteristics.",True,other,Not specified
38769564,Towards proactive palliative care in oncology: developing an explainable EHR-based machine learning model for mortality risk prediction,"BACKGROUND: Ex-ante identification of the last year in life facilitates a proactive palliative approach. Machine learning models trained on electronic health records (EHR) demonstrate promising performance in cancer prognostication. However, gaps in literature include incomplete reporting of model performance, inadequate alignment of model formulation with implementation use-case, and insufficient explainability hindering trust and adoption in clinical settings. Hence, we aim to develop an explainable machine learning EHR-based model that prompts palliative care processes by predicting for 365-day mortality risk among patients with advanced cancer within an outpatient setting.
METHODS: Our cohort consisted of 5,926 adults diagnosed with Stage 3 or 4 solid organ cancer between July 1, 2017, and June 30, 2020 and receiving ambulatory cancer care within a tertiary center. The classification problem was modelled using Extreme Gradient Boosting (XGBoost) and aligned to our envisioned use-case: ""Given a prediction point that corresponds to an outpatient cancer encounter, predict for mortality within 365-days from prediction point, using EHR data up to 365-days prior."" The model was trained with 75% of the dataset (n = 39,416 outpatient encounters) and validated on a 25% hold-out dataset (n = 13,122 outpatient encounters). To explain model outputs, we used Shapley Additive Explanations (SHAP) values. Clinical characteristics, laboratory tests and treatment data were used to train the model. Performance was evaluated using area under the receiver operating characteristic curve (AUROC) and area under the precision-recall curve (AUPRC), while model calibration was assessed using the Brier score.
RESULTS: In total, 17,149 of the 52,538 prediction points (32.6%) had a mortality event within the 365-day prediction window. The model demonstrated an AUROC of 0.861 (95% CI 0.856-0.867) and AUPRC of 0.771. The Brier score was 0.147, indicating slight overestimations of mortality risk. Explanatory diagrams utilizing SHAP values allowed visualization of feature impacts on predictions at both the global and individual levels.
CONCLUSION: Our machine learning model demonstrated good discrimination and precision-recall in predicting 365-day mortality risk among individuals with advanced cancer. It has the potential to provide personalized mortality predictions and facilitate earlier integration of palliative care.",True,other,Not specified
38769334,Development of a long noncoding RNA-based machine learning model to predict COVID-19 in-hospital mortality,"Tools for predicting COVID-19 outcomes enable personalized healthcare, potentially easing the disease burden. This collaborative study by 15 institutions across Europe aimed to develop a machine learning model for predicting the risk of in-hospital mortality post-SARS-CoV-2 infection. Blood samples and clinical data from 1286 COVID-19 patients collected from 2020 to 2023 across four cohorts in Europe and Canada were analyzed, with 2906 long non-coding RNAs profiled using targeted sequencing. From a discovery cohort combining three European cohorts and 804 patients, age and the long non-coding RNA LEF1-AS1 were identified as predictive features, yielding an AUC of 0.83 (95% CI 0.82-0.84) and a balanced accuracy of 0.78 (95% CI 0.77-0.79) with a feedforward neural network classifier. Validation in an independent Canadian cohort of 482 patients showed consistent performance. Cox regression analysis indicated that higher levels of LEF1-AS1 correlated with reduced mortality risk (age-adjusted hazard ratio 0.54, 95% CI 0.40-0.74). Quantitative PCR validated LEF1-AS1's adaptability to be measured in hospital settings. Here, we demonstrate a promising predictive model for enhancing COVID-19 patient management.",True,other,Not specified
38759719,Development and preliminary assessment of a machine learning model to predict myocardial infarction and cardiac arrest after major operations,"INTRODUCTION: Accurate prediction of complications often informs shared decision-making. Derived over 10 years ago to enhance prediction of intra/post-operative myocardial infarction and cardiac arrest (MI/CA), the Gupta score has been criticized for unreliable calibration and inclusion of a wide spectrum of unrelated operations. In the present study, we developed a novel machine learning (ML) model to estimate perioperative risk of MI/CA and compared it to the Gupta score.
METHODS: Patients undergoing major operations were identified from the 2016-2020 ACS-NSQIP. The Gupta score was calculated for each patient, and a novel ML model was developed to predict MI/CA using ACS NSQIP-provided data fields as covariates. Discrimination (C-statistic) and calibration (Brier score) of the ML model were compared to the existing Gupta score within the entire cohort and across operative subgroups.
RESULTS: Of 2,473,487 patients included for analysis, 25,177 (1.0%) experienced MI/CA (55.2% MI, 39.1% CA, 5.6% MI and CA). The ML model, which was fit using a randomly selected training cohort, exhibited higher discrimination within the testing dataset compared to the Gupta score (C-statistic 0.84 vs 0.80, p < 0.001). Furthermore, the ML model had significantly better calibration in the entire cohort (Brier score 0.0097 vs 0.0100). Model performance was markedly improved among patients undergoing thoracic, aortic, peripheral vascular and foregut surgery.
CONCLUSIONS: The present ML model outperformed the Gupta score in the prognostication of MI/CA across a heterogenous range of operations. Given the growing integration of ML into healthcare, such models may be readily incorporated into clinical practice and guide benchmarking efforts.",True,other,Not specified
38710164,Development and Validation of a Novel Machine Learning Model to Predict the Survival of Patients with Gastrointestinal Neuroendocrine Neoplasms,"INTRODUCTION: Well-calibrated models for personalized prognostication of patients with gastrointestinal neuroendocrine neoplasms (GINENs) are limited. This study aimed to develop and validate a machine-learning model to predict the survival of patients with GINENs.
METHODS: Oblique random survival forest (ORSF) model, Cox proportional hazard risk model, Cox model with least absolute shrinkage and selection operator penalization, CoxBoost, Survival Gradient Boosting Machine, Extreme Gradient Boosting survival regression, DeepHit, DeepSurv, DNNSurv, logistic-hazard model, and PC-hazard model were compared. We further tuned hyperparameters and selected variables for the best-performing ORSF. Then, the final ORSF model was validated.
RESULTS: A total of 43,444 patients with GINENs were included. The median (interquartile range) survival time was 53 (19-102) months. The ORSF model performed best, in which age, histology, M stage, tumor size, primary tumor site, sex, tumor number, surgery, lymph nodes removed, N stage, race, and grade were ranked as important variables. However, chemotherapy and radiotherapy were not necessary for the ORSF model. The ORSF model had an overall C index of 0.86 (95% confidence interval, 0.85-0.87). The area under the receiver operation curves at 1, 3, 5, and 10 years were 0.91, 0.89, 0.87, and 0.80, respectively. The decision curve analysis showed superior clinical usefulness of the ORSF model than the American Joint Committee on Cancer Stage. A nomogram and an online tool were given.
CONCLUSION: The machine learning ORSF model could precisely predict the survival of patients with GINENs, with the ability to identify patients at high risk for death and probably guide clinical practice.",True,other,Not specified
38700699,-A machine learning model to predict surgical site infection after surgery of lower extremity fractures,"PURPOSE: This study aimed to develop machine learning algorithms for identifying predictive factors associated with the risk of postoperative surgical site infection in patients with lower extremity fractures.
METHODS: A machine learning analysis was conducted on a dataset comprising 1,579 patients who underwent surgical fixation for lower extremity fractures to create a predictive model for risk stratification of postoperative surgical site infection. We evaluated different clinical and demographic variables to train four machine learning models (neural networks, boosted generalised linear model, naïve bayes, and penalised discriminant analysis). Performance was measured by the area under the curve score, Youdon's index and Brier score. A multivariate adaptive regression splines (MARS) was used to optimise predictor selection.
RESULTS: The final model consisted of five predictors. (1) Operating room time, (2) ankle region, (3) open injury, (4) body mass index, and (5) age. The best-performing machine learning algorithm demonstrated a promising predictive performance, with an area under the ROC curve, Youdon's index, and Brier score of 77.8%, 62.5%, and 5.1%-5.6%, respectively.
CONCLUSION: The proposed predictive model not only assists surgeons in determining high-risk factors for surgical site infections but also empowers patients to closely monitor these factors and take proactive measures to prevent complications. Furthermore, by considering the identified predictors, this model can serve as a reference for implementing preventive measures and reducing postoperative complications, ultimately enhancing patient outcomes. However, further investigations involving larger datasets and external validations are required to confirm the reliability and applicability of our model.",True,other,recurrent neural network
38674742,Machine Learning to Identify Critical Biomarker Profiles in New SARS-CoV-2 Variants,"The global dissemination of SARS-CoV-2 resulted in the emergence of several variants, including Alpha, Alpha + E484K, Beta, and Omicron. Our research integrated the study of eukaryotic translation factors and fundamental components in general protein synthesis with the analysis of SARS-CoV-2 variants and vaccination status. Utilizing statistical methods, we successfully differentiated between variants in infected individuals and, to a lesser extent, between vaccinated and non-vaccinated infected individuals, relying on the expression profiles of translation factors. Additionally, our investigation identified common causal relationships among the translation factors, shedding light on the interplay between SARS-CoV-2 variants and the host's translation machinery.",True,text mining,Not specified
38673408,A New Auto-Regressive Multi-Variable Modified Auto-Encoder for Multivariate Time-Series Prediction: A Case Study with Application to COVID-19 Pandemics,"The SARS-CoV-2 global pandemic prompted governments, institutions, and researchers to investigate its impact, developing strategies based on general indicators to make the most precise predictions possible. Approaches based on epidemiological models were used but the outcomes demonstrated forecasting with uncertainty due to insufficient or missing data. Besides the lack of data, machine-learning models including random forest, support vector regression, LSTM, Auto-encoders, and traditional time-series models such as Prophet and ARIMA were employed in the task, achieving remarkable results with limited effectiveness. Some of these methodologies have precision constraints in dealing with multi-variable inputs, which are important for problems like pandemics that require short and long-term forecasting. Given the under-supply in this scenario, we propose a novel approach for time-series prediction based on stacking auto-encoder structures using three variations of the same model for the training step and weight adjustment to evaluate its forecasting performance. We conducted comparison experiments with previously published data on COVID-19 cases, deaths, temperature, humidity, and air quality index (AQI) in São Paulo City, Brazil. Additionally, we used the percentage of COVID-19 cases from the top ten affected countries worldwide until May 4th, 2020. The results show 80.7% and 10.3% decrease in RMSE to entire and test data over the distribution of 50 trial-trained models, respectively, compared to the first experiment comparison. Also, model type#3 achieved 4th better overall ranking performance, overcoming the NBEATS, Prophet, and Glounts time-series models in the second experiment comparison. This model shows promising forecast capacity and versatility across different input dataset lengths, making it a prominent forecasting model for time-series tasks.",True,other,Not specified
38648576,Explainable Machine Learning Model to Preoperatively Predict Postoperative Complications in Inpatients With Cancer Undergoing Major Operations,"PURPOSE: Preoperative prediction of postoperative complications (PCs) in inpatients with cancer is challenging. We developed an explainable machine learning (ML) model to predict PCs in a heterogenous population of inpatients with cancer undergoing same-hospitalization major operations.
METHODS: Consecutive inpatients who underwent same-hospitalization operations from December 2017 to June 2021 at a single institution were retrospectively reviewed. The ML model was developed and tested using electronic health record (EHR) data to predict 30-day PCs for patients with Clavien-Dindo grade 3 or higher (CD 3+) per the CD classification system. Model performance was assessed using area under the receiver operating characteristic curve (AUROC), area under the precision recall curve (AUPRC), and calibration plots. Model explanation was performed using the Shapley additive explanations (SHAP) method at cohort and individual operation levels.
RESULTS: A total of 988 operations in 827 inpatients were included. The ML model was trained using 788 operations and tested using a holdout set of 200 operations. The CD 3+ complication rates were 28.6% and 27.5% in the training and holdout test sets, respectively. Training and holdout test sets' model performance in predicting CD 3+ complications yielded an AUROC of 0.77 and 0.73 and an AUPRC of 0.56 and 0.52, respectively. Calibration plots demonstrated good reliability. The SHAP method identified features and the contributions of the features to the risk of PCs.
CONCLUSION: We trained and tested an explainable ML model to predict the risk of developing PCs in patients with cancer. Using patient-specific EHR data, the ML model accurately discriminated the risk of developing CD 3+ complications and displayed top features at the individual operation and cohort level.",True,other,Not specified
38621172,Progression from Prediabetes to Diabetes in a Diverse U.S. Population: A Machine Learning Model,"Objective: To date, there are no widely implemented machine learning (ML) models that predict progression from prediabetes to diabetes. Addressing this knowledge gap would aid in identifying at-risk patients within this heterogeneous population who may benefit from targeted treatment and management in order to preserve glucose metabolism and prevent adverse outcomes. The objective of this study was to utilize readily available laboratory data to train and test the performance of ML-based predictive risk models for progression from prediabetes to diabetes. Methods: The study population was composed of laboratory information services data procured from a large U.S. outpatient laboratory network. The retrospective dataset was composed of 15,029 adults over a 5-year period with initial hemoglobin A1C (A1C) values between 5.0% and 6.4%. ML models were developed using random forest survival methods. The ground truth outcome was progression to A1C values indicative of diabetes (i.e., ≥6.5%) within 5 years. Results: The prediabetes risk classifier model accurately predicted A1C ≥6.5% within 5 years and achieved an area under the receiver-operator characteristic curve of 0.87. The most important predictors of progression from prediabetes to diabetes were initial A1C, initial serum glucose, A1C slope, serum glucose slope, initial HDL, HDL slope, age, and sex. Conclusions: Leveraging readily obtainable laboratory data, our ML risk classifier accurately predicts elevation in A1C associated with progression from prediabetes to diabetes. Although prospective studies are warranted, the results support the clinical utility of the model to improve timely recognition, risk stratification, and optimal management for patients with prediabetes.",True,other,Not specified
38615137,An explainable machine learning model for prediction of high-risk nonalcoholic steatohepatitis,"Early identification of high-risk metabolic dysfunction-associated steatohepatitis (MASH) can offer patients access to novel therapeutic options and potentially decrease the risk of progression to cirrhosis. This study aimed to develop an explainable machine learning model for high-risk MASH prediction and compare its performance with well-established biomarkers. Data were derived from the National Health and Nutrition Examination Surveys (NHANES) 2017-March 2020, which included a total of 5281 adults with valid elastography measurements. We used a FAST score ≥ 0.35, calculated using liver stiffness measurement and controlled attenuation parameter values and aspartate aminotransferase levels, to identify individuals with high-risk MASH. We developed an ensemble-based machine learning XGBoost model to detect high-risk MASH and explored the model's interpretability using an explainable artificial intelligence SHAP method. The prevalence of high-risk MASH was 6.9%. Our XGBoost model achieved a high level of sensitivity (0.82), specificity (0.91), accuracy (0.90), and AUC (0.95) for identifying high-risk MASH. Our model demonstrated a superior ability to predict high-risk MASH vs. FIB-4, APRI, BARD, and MASLD fibrosis scores (AUC of 0.95 vs. 0.50, 0.50, 0.49 and 0.50, respectively). To explain the high performance of our model, we found that the top 5 predictors of high-risk MASH were ALT, GGT, platelet count, waist circumference, and age. We used an explainable ML approach to develop a clinically applicable model that outperforms commonly used clinical risk indices and could increase the identification of high-risk MASH patients in resource-limited settings.",True,other,Not specified
38594078,Predicting pressure injury risk in hospitalised patients using machine learning with electronic health records: a US multilevel cohort study,"OBJECTIVE: To predict the risk of hospital-acquired pressure injury using machine learning compared with standard care.
DESIGN: We obtained electronic health records (EHRs) to structure a multilevel cohort of hospitalised patients at risk for pressure injury and then calibrate a machine learning model to predict future pressure injury risk. Optimisation methods combined with multilevel logistic regression were used to develop a predictive algorithm of patient-specific shifts in risk over time. Machine learning methods were tested, including random forests, to identify predictive features for the algorithm. We reported the results of the regression approach as well as the area under the receiver operating characteristics (ROC) curve for predictive models.
SETTING: Hospitalised inpatients.
PARTICIPANTS: EHRs of 35 001 hospitalisations over 5 years across 2 academic hospitals.
MAIN OUTCOME MEASURE: Longitudinal shifts in pressure injury risk.
RESULTS: The predictive algorithm with features generated by machine learning achieved significantly improved prediction of pressure injury risk (p<0.001) with an area under the ROC curve of 0.72; whereas standard care only achieved an area under the ROC curve of 0.52. At a specificity of 0.50, the predictive algorithm achieved a sensitivity of 0.75.
CONCLUSIONS: These data could help hospitals conserve resources within a critical period of patient vulnerability of hospital-acquired pressure injury which is not reimbursed by US Medicare; thus, conserving between 30 000 and 90 000 labour-hours per year in an average 500-bed hospital. Hospitals can use this predictive algorithm to initiate a quality improvement programme for pressure injury prevention and further customise the algorithm to patient-specific variation by facility.",True,other,convolutional neural network
38589865,Utilization of machine learning models in predicting caries risk groups and oral health-related risk factors in adults,"BACKGROUND: The aim of this study was to analyse the risk factors that affect oral health in adults and to evaluate the success of different machine learning algorithms in predicting these risk factors.
METHODS: This study included 2000 patients aged 18 years and older who were admitted to the Department of Oral and Maxillofacial Radiology, Faculty of Dentistry, Gaziantep University, between September and December 2023. In this study, patients completed a 30-item questionnaire designed to assess the factors that affect the decayed, missing, and filled teeth (DMFT). Clinical and radiological examinations were performed, and DMFT scores were calculated after completion of the questionnaire. The obtained data were randomly divided into a 75% training group and a 25% test group. The preprocessed dataset was analysed using various machine learning algorithms, including naive Bayes, logistic regression, support vector machine, decision tree, random forest and Multilayer Perceptron algorithms. Pearson's correlation test was also conducted to assess the correlation between participants' DMFT scores and oral health risk factors. The performance of each algorithm was evaluated to determine the most appropriate algorithm, and model performance was assessed using accuracy, precision, recall and F1 score on the test dataset.
RESULTS: A statistically significant difference was found between various factors and DMFT-based risk groups (p < 0.05), including age, sex, body mass index, tooth brushing frequency, socioeconomic status, employment status, education level, marital status, hypertension, diabetes status, renal disease status, consumption of sugary snacks, dry mouth status and screen time. When considering machine learning algorithms for risk group assessments, the Multilayer Perceptron model demonstrated the highest level of success, achieving an accuracy of 95.8%, an F1-score of 96%, and precision and recall rates of 96%.
CONCLUSIONS: Caries risk assessment using a simple questionnaire can identify individuals at risk of dental caries, determine the key risk factors, provide information to help reduce the risk of dental caries over time and ensure follow-up. In addition, it is extremely important to apply effective preventive treatments and to prevent the general health problems that are caused by the deterioration of oral health. The results of this study show the potential of machine learning algorithms for predicting caries risk groups, and these algorithms are promising for future studies.",True,text mining,Not specified
38531255,On relevant features for the recurrence prediction of urothelial carcinoma of the bladder,"BACKGROUND: Urothelial bladder cancer (UBC) is characterized by a high recurrence rate, which is predicted by scoring systems. However, recent studies show the superiority of Machine Learning (ML) models. Nevertheless, these ML approaches are rarely used in medical practice because most of them are black-box models, that cannot adequately explain how a prediction is made.
OBJECTIVE: We investigate the global feature importance of different ML models. By providing information on the most relevant features, we can facilitate the use of ML in everyday medical practice.
DESIGN, SETTING, AND PARTICIPANTS: The data is provided by the cancer registry Rhineland-Palatinate gGmbH, Germany. It consists of numerical and categorical features of 1,944 patients with UBC. We retrospectively predict 2-year recurrence through ML models using Support Vector Machine, Gradient Boosting, and Artificial Neural Network. We then determine the global feature importance using performance-based Permutation Feature Importance (PFI) and variance-based Feature Importance Ranking Measure (FIRM).
RESULTS: We show reliable recurrence prediction of UBC with 82.02% to 83.89% F1-Score, 83.95% to 84.49% Precision, and an overall performance of 69.20% to 70.82% AUC on testing data, depending on the model. Gradient Boosting performs best among all black-box models with an average F1-Score (83.89%), AUC (70.82%), and Precision (83.95%). Furthermore, we show consistency across PFI and FIRM by identifying the same features as relevant across the different models. These features are exclusively therapeutic measures and are consistent with findings from both medical research and clinical trials.
CONCLUSIONS: We confirm the superiority of ML black-box models in predicting UBC recurrence compared to more traditional logistic regression. In addition, we present an approach that increases the explanatory power of black-box models by identifying the underlying influence of input features, thus facilitating the use of ML in clinical practice and therefore providing improved recurrence prediction through the application of black-box models.",True,other,Not specified
38494197,Machine learning model and nomogram to predict the risk of heart failure hospitalization in peritoneal dialysis patients,"INTRODUCTION: The study presented here aimed to establish a predictive model for heart failure (HF) and all-cause mortality in peritoneal dialysis (PD) patients with machine learning (ML) algorithm.
METHODS: We retrospectively included 1006 patients who initiated PD from 2010 to 2016. XGBoost, random forest (RF), and AdaBoost were used to train models for assessing risk for 1-year and 5-year HF hospitalization and mortality. The performance was validated using fivefold cross-validation. The optimal ML algorithm was used to construct the models to predictive the risk of the HF and all-cause mortality. The prediction performance of ML methods and Cox regression was compared.
RESULTS: Over a median follow-up of 49 months. Two hundred and ninety-eight patients developed HF required hospitalization; 199 patients died during the follow-up. The RF model (AUC = 0.853) was the best performing model for predicting HF, and the XGBoost model (AUC = 0.871) was the best model for predicting mortality. Baseline moderate or severe renal disease, systolic blood pressure (SBP), body mass index (BMI), age, Charlson Comorbidity Index (CCI) score were strongly associated with HF hospitalization, whereas age, CCI score, creatinine, age, high-density lipoprotein cholesterol (HDL-C), total cholesterol, baseline estimated glomerular filtration rate (eGFR) were the most significant predictors of mortality. For all the above endpoints, the ML models demonstrated better discrimination than Cox regression.
CONCLUSIONS: We developed and validated a novel method to predict the risk factors of HF and all-cause mortality that integrates readily available clinical, laboratory, and electrocardiographic variables to predict the risk of HF among PD patients.",True,other,RNN
38452934,Clinical features-based machine learning models to separate sexually transmitted infections from other skin diagnoses,"INTRODUCTION: Many sexual health services are overwhelmed and cannot cater for all the individuals who present with sexually transmitted infections (STIs). Digital health software that separates STIs from non-STIs could improve the efficiency of clinical services. We developed and evaluated a machine learning model that predicts whether patients have an STI based on their clinical features.
METHODS: We manually extracted 25 demographic features and clinical features from 1315 clinical records in the electronic health record system at Melbourne Sexual Health Center. We examined 16 machine learning models to predict a binary outcome of an STI or a non-STI diagnosis. We evaluated the models' performance with the area under the ROC curve (AUC), accuracy and F1-scores.
RESULTS: Our study included 1315 consultations, of which 36.8% (484/1315) were diagnosed with STIs and 63.2% (831/1315) had non-STI conditions. The study population predominantly consisted of heterosexual men (49.5%, 651/1315), followed by gay, bisexual and other men who have sex with men (GBMSM) (25.7%), women (21.6%) and unknown gender (3.2%). The median age was 31 years (intra-quartile range (IQR) 26-39). The top 5 performing models were CatBoost (AUC 0.912), Random Forest (AUC 0.917), LightGBM (AUC 0.907), Gradient Boosting (AUC 0.905) and XGBoost (AUC 0.900). The best model, CatBoost, achieved an accuracy of 0.837, sensitivity of 0.776, specificity of 0.831, precision of 0.782 and F1-score of 0.778. The key important features were lesion duration, type of skin lesions, age, gender, history of skin disorders, number of lesions, dysuria duration, anorectal pain and itchiness.
CONCLUSIONS: Our best model demonstrates a reasonable performance in distinguishing STIs from non-STIs. However, to be clinically useful, more detailed information such as clinical images, may be required to reach sufficient accuracy.",True,other,recurrent neural network
38445402,Development of a Web Application based on Machine Learning for screening esophageal varices in cirrhosis,"INTRODUCTION: Esophageal varices (EV) are a common manifestation of portal hypertension in cirrhotic patients. Upper gastrointestinal endoscopy (UGE) is the gold standard for diagnosing EV. However, it is an invasive examination with a relatively high cost.
AIM: To develop a machine learning model for the prediction of EV in cirrhotic patients.
METHODS: This is a cross-sectional observational study including all cirrhotic patients, for whom an UGE was performed, between January 2010 and December 2019. We adopted a structured methodical approach with reference to CRISP-DM (Cross-Industry Standard Process for Data Mining). The different steps carried out were: data collection and preparation, modelization, and deployment of the predictive models in a web application.
RESULTS: We included 166 patients, 92 women (55.4%) and 74 men (44.6%). The mean age was 57.2 years. In UGE, 16 patients (9.6%) did not have EV. Other patients had EV grade 1 in 41 cases (24.7%), grade 2 in 81 cases (24.7%) and grade 3 in 28 cases (16.9%). After the selection phase, among the 36 initial variables, 19 were retained. Three machine learning models have been developed with a performance of 90%.
CONCLUSIONS: We developed a machine learning model combining several clinical and para-clinical variables for the prediction of EV in cirrhotic patients.",True,text mining,LSTM
38439210,Performance of different machine learning algorithms in identifying undiagnosed diabetes based on nonlaboratory parameters and the influence of muscle strength: A cross-sectional study,"AIMS/INTRODUCTION: Machine learning algorithms based on the artificial neural network (ANN), support vector machine, naive Bayesian or logistic regression model are commonly used to identify diabetes. This study investigated which approach performed the best and whether muscle strength provided any incremental benefit in identifying undiagnosed diabetes in Chinese adults.
METHODS: This cross-sectional study enrolled 4,482 eligible participants from eight provinces in China, who were randomly divided into the training dataset (n = 3,586) and the testing dataset (n = 896). Muscle strength was assessed by handgrip strength and the number of chair stands in the 30-s chair stand test. An oral glucose tolerance test was used to ascertain undiagnosed diabetes. The areas under the curve (AUCs) were calculated accordingly and compared with each other.
RESULTS: Of the included participants, 233 had newly diagnosed diabetes. All the four machine learning algorithms, which were developed based on nonlaboratory parameters, showed acceptable discriminative ability in identifying undiagnosed diabetes (all AUCs &gt;0.70), with the ANN approach performing the best (AUC 0.806). Adding handgrip strength or the 30-s chair stand test to this approach did not increase the AUC further (P = 0.39 and 0.26, respectively). Furthermore, compared with the New Chinese Diabetes Risk Score, the ANN approach showed a larger AUC in identifying undiagnosed diabetes (P<sub>comparison</sub> &lt; 0.01), regardless of the addition of handgrip strength or the 30-s chair stand test.
CONCLUSIONS: The ANN approach performed the best in identifying undiagnosed diabetes in Chinese adults; however, the addition of muscle strength might not improve its efficacy.",True,other,Not specified
38404544,Machine learning algorithms being an auxiliary tool to predict the overall survival of patients with renal cell carcinoma using the SEER database,"BACKGROUND: The clinical prognosis assessment of renal cell carcinoma (RCC) still relies on nuclear grading and nuclear score by naked eye with microscope, which has defects long time, low efficiency, and uneven evaluation level criteria. There are few machine learning (ML) studies investigating the prognosis in the RCC literature which could also quantify the risk of postoperative recurrence of RCC patients and guide cancer patients to conduct individualized postoperative clinical management. This study evaluated the suitability of ML algorithms for survival prediction in patients with RCC.
METHODS: A total of 192,912 RCC patients from the Surveillance, Epidemiology, and End Results (SEER) were obtained from 2004 to 2015. Six ML algorithms including support vector machine (SVM), Bayesian method, decision tree, random forest, neural network, and Extreme Gradient Boosting (XGBoost) were applied to predict overall survival (OS) of RCC.
RESULTS: Patients from the SEER with a median age of 62 years and the pathological types were clear cell RCC (47.6%), papillary RCC (9.5%), chromophobe RCC (4.0%) and others (4.1%) were collected. In the deleting patients with missing data, the highest accurate model was XGBoost [area under the curve (AUC) 67.0%]. In the deleting patients with missing data and survival time <5 years, the accuracy of random forest, neural network and XGBoost were high, with AUC of 80.8%, 81.5% and 81.8%, respectively. In the only deleting the missing tumor diameter and filling the missing dataset with missForest, the highest accurate model was random forest (AUC: 71.9%). In this study, the overall accuracy of the SVM model was not high, apart from in the population of patients with deleting the missing tumor diameter and survival time <5 years, and filling the missing data with missForest. Random forest, neural network and XGBoost had high accuracy, with AUC of 84.1%, 84.7% and 84.8%, respectively.
CONCLUSIONS: ML algorithms could be used to predict the prognosis of RCC. It could quantify the recurrence possibility of patients and help more individualized postoperative clinical management. Given the limitations and complexity of datasets, ML may be used as an auxiliary tool to analyze and process larger datasets and complex data.",True,other,Not specified
38369456,The prediction of influenza-like illness using national influenza surveillance data and Baidu query data,"BACKGROUND: Seasonal influenza and other respiratory tract infections are serious public health problems that need to be further addressed and investigated. Internet search data are recognized as a valuable source for forecasting influenza or other respiratory tract infection epidemics. However, the selection of internet search data and the application of forecasting methods are important for improving forecasting accuracy. The aim of the present study was to forecast influenza epidemics based on the long short-term memory neural network (LSTM) method, Baidu search index data, and the influenza-like-illness (ILI) rate.
METHODS: The official weekly ILI% data for northern and southern mainland China were obtained from the Chinese Influenza Center from 2018 to 2021. Based on the Baidu Index, search indices related to influenza infection over the corresponding time period were obtained. Pearson correlation analysis was performed to explore the association between influenza-related search queries and the ILI% of southern and northern mainland China. The LSTM model was used to forecast the influenza epidemic within the same week and at lags of 1-4 weeks. The model performance was assessed by evaluation metrics, including the mean square error (MSE), root mean square error (RMSE) and mean absolute error (MAE).
RESULTS: In total, 24 search queries in northern mainland China and 7 search queries in southern mainland China were found to be correlated and were used to construct the LSTM model, which included the same week and a lag of 1-4 weeks. The LSTM model showed that ILI% + mask with one lag week and ILI% + influenza name were good prediction modules, with reduced RMSE predictions of 16.75% and 4.20%, respectively, compared with the estimated ILI% for northern and southern mainland China.
CONCLUSIONS: The results illuminate the feasibility of using an internet search index as a complementary data source for influenza forecasting and the efficiency of using the LSTM model to forecast influenza epidemics.",True,other,CNN
38360080,Temporal attention networks for biomedical hypothesis generation,"OBJECTIVES: Hypothesis Generation (HG) is a task that aims to uncover hidden associations between disjoint scientific terms, which influences innovations in prevention, treatment, and overall public health. Several recent studies strive to use Recurrent Neural Network (RNN) to learn evolutional embeddings for HG. However, the complex spatiotemporal dependencies of term-pair relations will be difficult to depict due to the inherent recurrent structure. This paper aims to accurately model the temporal evolution of term-pair relations using only attention mechanisms, for capturing crucial information on inferring the future connectivities.
METHODS: This paper proposes a Temporal Attention Networks (TAN) to produce powerful spatiotemporal embeddings for Biomedical Hypothesis Generation. Specifically, we formulate HG problem as a future connectivity prediction task in a temporal attributed graph. Our TAN develops a Temporal Spatial Attention Module (TSAM) to establish temporal dependencies of node-pair (term-pair) embeddings between any two time-steps for smoothing spatiotemporal node-pair embeddings. Meanwhile, a Temporal Difference Attention Module (TDAM) is proposed to sharpen temporal differences of spatiotemporal embeddings for highlighting the historical changes of node-pair relations. As such, TAN can adaptively calibrate spatiotemporal embeddings by considering both continuity and difference of node-pair embeddings.
RESULTS: Three real-world biomedical term relationship datasets are constructed from PubMed papers. TAN significantly outperforms the best baseline with 12.03%, 4.59 and 2.34% Micro-F<sub>1</sub> Score improvement in Immunotherapy, Virology and Neurology, respectively. Extensive experiments demonstrate that TAN can model complex spatiotemporal dependencies of term-pairs for explicitly capturing the temporal evolution of relation, significantly outperforming existing state-of-the-art methods.
CONCLUSION: We proposed a novel TAN to learn spatiotemporal embeddings based on pure attention mechanisms for HG. TAN learns the evolution of relationships by modeling both the continuity and difference of temporal term-pair embeddings. The important spatiotemporal dependencies of term-pair relations are extracted based solely on attention mechanism for generating hypotheses.",True,text mining,recurrent neural network
38329973,"Comparison of predicting cardiovascular disease hospitalization using individual, ZIP code-derived, and machine learning model-predicted educational attainment in New York City","BACKGROUND: Area-level social determinants of health (SDOH) based on patients' ZIP codes or census tracts have been commonly used in research instead of individual SDOHs. To our knowledge, whether machine learning (ML) could be used to derive individual SDOH measures, specifically individual educational attainment, is unknown.
METHODS: This is a retrospective study using data from the Mount Sinai BioMe Biobank. We included participants that completed a validated questionnaire on educational attainment and had home addresses in New York City. ZIP code-level education was derived from the American Community Survey matched for the participant's gender and race/ethnicity. We tested several algorithms to predict individual educational attainment from routinely collected clinical and demographic data. To evaluate how using different measures of educational attainment will impact model performance, we developed three distinct models for predicting cardiovascular (CVD) hospitalization. Educational attainment was imputed into models as either survey-derived, ZIP code-derived, or ML-predicted educational attainment.
RESULTS: A total of 20,805 participants met inclusion criteria. Concordance between survey and ZIP code-derived education was 47%, while the concordance between survey and ML model-predicted education was 67%. A total of 13,715 patients from the cohort were included into our CVD hospitalization prediction models, of which 1,538 (11.2%) had a history of CVD hospitalization. The AUROC of the model predicting CVD hospitalization using survey-derived education was significantly higher than the model using ZIP code-level education (0.77 versus 0.72; p < 0.001) and the model using ML model-predicted education (0.77 versus 0.75; p < 0.001). The AUROC for the model using ML model-predicted education was also significantly higher than that using ZIP code-level education (p = 0.003).
CONCLUSION: The concordance of survey and ZIP code-level educational attainment in NYC was low. As expected, the model utilizing survey-derived education achieved the highest performance. The model incorporating our ML model-predicted education outperformed the model relying on ZIP code-derived education. Implementing ML techniques can improve the accuracy of SDOH data and consequently increase the predictive performance of outcome models.",True,other,Not specified
38319746,Predicting Colonic Neoplasia Surgical Complications: A Machine Learning Approach,"BACKGROUND: A range of statistical approaches have been used to help predict outcomes associated with colectomy. The multifactorial nature of complications suggests that machine learning algorithms may be more accurate in determining postoperative outcomes by detecting nonlinear associations, which are not readily measured by traditional statistics.
OBJECTIVE: The aim of this study was to investigate the utility of machine learning algorithms to predict complications in patients undergoing colectomy for colonic neoplasia.
DESIGN: Retrospective analysis using decision tree, random forest, and artificial neural network classifiers to predict postoperative outcomes.
SETTINGS: National Inpatient Sample database (2003-2017).
PATIENTS: Adult patients who underwent elective colectomy with anastomosis for neoplasia.
MAIN OUTCOME MEASURES: Performance was quantified using sensitivity, specificity, accuracy, and area under the receiver operating characteristic curve to predict the incidence of anastomotic leak, prolonged length of stay, and inpatient mortality.
RESULTS: A total of 14,935 patients (4731 laparoscopic, 10,204 open) were included. They had an average age of 67 ± 12.2 years, and 53% of patients were women. The 3 machine learning models successfully identified patients who developed the measured complications. Although differences between model performances were largely insignificant, the neural network scored highest for most outcomes: predicting anastomotic leak, area under the receiver operating characteristic curve 0.88/0.93 (open/laparoscopic, 95% CI, 0.73-0.92/0.80-0.96); prolonged length of stay, area under the receiver operating characteristic curve 0.84/0.88 (open/laparoscopic, 95% CI, 0.82-0.85/0.85-0.91); and inpatient mortality, area under the receiver operating characteristic curve 0.90/0.92 (open/laparoscopic, 95% CI, 0.85-0.96/0.86-0.98).
LIMITATIONS: The patients from the National Inpatient Sample database may not be an accurate sample of the population of all patients undergoing colectomy for colonic neoplasia and does not account for specific institutional and patient factors.
CONCLUSIONS: Machine learning predicted postoperative complications in patients with colonic neoplasia undergoing colectomy with good performance. Although validation using external data and optimization of data quality will be required, these machine learning tools show great promise in assisting surgeons with risk-stratification of perioperative care to improve postoperative outcomes. See Video Abstract .
PREDICCIN DE LAS COMPLICACIONES QUIRRGICAS DE LA NEOPLASIA DE COLON UN ENFOQUE DE MODELO DE APRENDIZAJE AUTOMTICO: ANTECEDENTES:Se han utilizado una variedad de enfoques estadísticos para ayudar a predecir los resultados asociados con la colectomía. La naturaleza multifactorial de las complicaciones sugiere que los algoritmos de aprendizaje automático pueden ser más precisos en determinar los resultados posoperatorios al detectar asociaciones no lineales, que generalmente no se miden en las estadísticas tradicionales.OBJETIVO:El objetivo de este estudio fue investigar la utilidad de los algoritmos de aprendizaje automático para predecir complicaciones en pacientes sometidos a colectomía por neoplasia de colon.DISEÑO:Análisis retrospectivo utilizando clasificadores de árboles de decisión, bosques aleatorios y redes neuronales artificiales para predecir los resultados posoperatorios.AJUSTE:Base de datos de la Muestra Nacional de Pacientes Hospitalizados (2003-2017).PACIENTES:Pacientes adultos sometidos a colectomía electiva con anastomosis por neoplasia.INTERVENCIONES:N/A.PRINCIPALES MEDIDAS DE RESULTADO:El rendimiento se cuantificó utilizando la sensibilidad, especificidad, precisión y la característica operativa del receptor del área bajo la curva para predecir la incidencia de fuga anastomótica, duración prolongada de la estancia hospitalaria y mortalidad de los pacientes hospitalizados.RESULTADOS:Se incluyeron un total de 14.935 pacientes (4.731 laparoscópicos, 10.204 abiertos). Presentaron una edad promedio de 67 ± 12,2 años y el 53% eran mujeres. Los tres modelos de aprendizaje automático identificaron con éxito a los pacientes que desarrollaron las complicaciones medidas. Aunque las diferencias entre el rendimiento del modelo fueron en gran medida insignificantes, la red neuronal obtuvo la puntuación más alta para la mayoría de los resultados: predicción de fuga anastomótica, característica operativa del receptor del área bajo la curva 0,88/0,93 (abierta/laparoscópica, IC del 95%: 0,73-0,92/0,80-0,96); duración prolongada de la estancia hospitalaria, característica operativa del receptor del área bajo la curva 0,84/0,88 (abierta/laparoscópica, IC del 95%: 0,82-0,85/0,85-0,91); y mortalidad de pacientes hospitalizados, característica operativa del receptor del área bajo la curva 0,90/0,92 (abierto/laparoscópico, IC del 95%: 0,85-0,96/0,86-0,98).LIMITACIONES:Los pacientes de la base de datos de la Muestra Nacional de Pacientes Hospitalizados pueden no ser una muestra precisa de la población de todos los pacientes sometidos a colectomía por neoplasia de colon y no tienen en cuenta factores institucionales y específicos del paciente.CONCLUSIONES:El aprendizaje automático predijo con buen rendimiento las complicaciones postoperatorias en pacientes con neoplasia de colon sometidos a colectomía. Aunque será necesaria la validación mediante datos externos y la optimización de la calidad de los datos, estas herramientas de aprendizaje automático son muy prometedoras para ayudar a los cirujanos con la estratificación de riesgos de la atención perioperatoria para mejorar los resultados posoperatorios. (Traducción-Dr. Fidel Ruiz Healy ).",True,other,Not specified
38316188,Interpretable prediction model for assessing diabetes complication risks in Chinese sufferers,"AIMS: With growing concerns over complications in diabetes sufferers, this study sought to develop an interpretable machine learning model to offer enhanced diagnostic and treatment recommendations.
METHODS: We assessed coronary heart disease, diabetic nephropathy, diabetic retinopathy, and fatty liver disease using logistic regression, decision tree, random forest, and CatBoost algorithms. The SHAP algorithm was employed to elucidate the model's predictions, offering a more in-depth understanding of influential features.
RESULTS: The CatBoost model notably outperformed other algorithms in AUC, achieving an average AUC of 90.47 % for the four complications. Through SHAP analysis and visualization, we provided clear and actionable insights into risk factors, enabling better complication risk assessment.
CONCLUSIONS: We introduced an innovative, interpretable complication risk model for people with diabetes. This not only offers a potent tool for healthcare professionals but also empowers sufferers with clearer self-assessment capabilities, encouraging earlier preventive actions. Further studies will underscore the model's clinical applicability.",True,other,Not specified
38307805,Use of Temporally Validated Machine Learning Models To Predict Outcomes of Percutaneous Nephrolithotomy Using Data from the British Association of Urological Surgeons Percutaneous Nephrolithotomy Audit,"BACKGROUND AND OBJECTIVE: Machine learning (ML) is a subset of artificial intelligence that uses data to build algorithms to predict specific outcomes. Few ML studies have examined percutaneous nephrolithotomy (PCNL) outcomes. Our objective was to build, streamline, temporally validate, and use ML models for prediction of PCNL outcomes (intensive care admission, postoperative infection, transfusion, adjuvant treatment, postoperative complications, visceral injury, and stone-free status at follow-up) using a comprehensive national database (British Association of Urological Surgeons PCNL).
METHODS: This was an ML study using data from a prospective national database. Extreme gradient boosting (XGB), deep neural network (DNN), and logistic regression (LR) models were built for each outcome of interest using complete cases only, imputed, and oversampled and imputed/oversampled data sets. All validation was performed with complete cases only. Temporal validation was performed with 2019 data only. A second round used a composite of the most important 11 variables in each model to build the final model for inclusion in the shiny application. We report statistics for prognostic accuracy.
KEY FINDINGS AND LIMITATIONS: The database contains 12 810 patients. The final variables included were age, Charlson comorbidity index, preoperative haemoglobin, Guy's stone score, stone location, size of outer sheath, preoperative midstream urine result, primary puncture site, preoperative dimercapto-succinic acid scan, stone size, and image guidance (https://endourology.shinyapps.io/PCNL_Demographics/). The areas under the receiver operating characteristic curve was >0.6 in all cases.
CONCLUSIONS AND CLINICAL IMPLICATIONS: This is the largest ML study on PCNL outcomes to date. The models are temporally valid and therefore can be implemented in clinical practice for patient-specific risk profiling. Further work will be conducted to externally validate the models.
PATIENT SUMMARY: We applied artificial intelligence to data for patients who underwent a keyhole surgery to remove kidney stones and developed a model to predict outcomes for this procedure. Doctors could use this tool to advise patients about their risk of complications and the outcomes they can expect after this surgery.",True,other,RNN
38200512,Using meta-learning to recommend an appropriate time-series forecasting model,"BACKGROUND: There are various forecasting algorithms available for univariate time series, ranging from simple to sophisticated and computational. In practice, selecting the most appropriate algorithm can be difficult, because there are too many algorithms. Although expert knowledge is required to make an informed decision, sometimes it is not feasible due to the lack of such resources as time, money, and manpower.
METHODS: In this study, we used coronavirus disease 2019 (COVID-19) data, including the absolute numbers of confirmed, death and recovered cases per day in 187 countries from February 20, 2020, to May 25, 2021. Two popular forecasting models, including Auto-Regressive Integrated Moving Average (ARIMA) and exponential smoothing state-space model with Trigonometric seasonality, Box-Cox transformation, ARMA errors, Trend, and Seasonal components (TBATS) were used to forecast the data. Moreover, the data were evaluated by the root mean squared error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), and symmetric mean absolute percentage error (SMAPE) criteria to label time series. The various characteristics of each time series based on the univariate time series structure were extracted as meta-features. After that, three machine-learning classification algorithms, including support vector machine (SVM), decision tree (DT), random forest (RF), and artificial neural network (ANN) were used as meta-learners to recommend an appropriate forecasting model.
RESULTS: The finding of the study showed that the DT model had a better performance in the classification of time series. The accuracy of DT in the training and testing phases was 87.50% and 82.50%, respectively. The sensitivity of the DT algorithm in the training phase was 86.58% and its specificity was 88.46%. Moreover, the sensitivity and specificity of the DT algorithm in the testing phase were 73.33% and 88%, respectively.
CONCLUSION: In general, the meta-learning approach was able to predict the appropriate forecasting model (ARIMA and TBATS) based on some time series features. Considering some characteristics of the desired COVID-19 time series, the ARIMA or TBATS forecasting model might be recommended to forecast the death, confirmed, and recovered trend cases of COVID-19 by the DT model.",True,other,Not specified
38199224,An Artificial Neural Network Model Combined with Dietary Retinol Intake from Different Sources to Predict the Risk of Nonalcoholic Fatty Liver Disease,"OBJECTIVE: This study aimed to develop an artificial neural network (ANN) model combined with dietary retinol intake from different sources to predict the risk of non-alcoholic fatty liver disease (NAFLD) in American adults.
METHODS: Data from the 2007 to 2014 National Health and Nutrition Examination Survey (NHANES) 2007-2014 were analyzed. Eligible subjects ( n = 6,613) were randomly divided into a training set ( n <sub>1</sub> = 4,609) and a validation set ( n <sub>2</sub> = 2,004) at a ratio of 7:3. The training set was used to identify predictors of NAFLD risk using logistic regression analysis. An ANN was established to predict the NAFLD risk using a training set. Receiver operating characteristic (ROC) curve analysis was performed to evaluate the accuracy of the model using the training and validation sets.
RESULTS: Our study found that the odds ratios ( ORs) and 95% confidence intervals ( CIs) of NAFLD for the highest quartile of plant-derived dietary retinol intake (i.e., provitamin A carotenoids, such as β-carotene) ( OR = 0.75, 95% CI: 0.57 to 0.99) were inversely associated with NAFLD risk, compared to the lowest quartile of intake, after adjusting for potential confounders. The areas under the ROC curves were 0.874 and 0.883 for the training and validation sets, respectively. NAFLD occurs when its incidence probability is greater than 0.388.
CONCLUSION: The ANN model combined with plant-derived dietary retinol intake showed a significant effect on NAFLD. This could be applied to predict NAFLD risk in the American adult population when government departments formulate future health plans.",True,text mining,Not specified
38152308,"Informed Random Forest to Model Associations of Epidemiological Priors, Government Policies, and Public Mobility","UNLABELLED: Background. Infectious diseases constitute a significant concern worldwide due to their increasing prevalence, associated health risks, and the socioeconomic costs. Machine learning (ML) models and epidemic models formulated using deterministic differential equations are the most dominant tools for analyzing and modeling the transmission of infectious diseases. However, ML models can be inconsistent in extracting the dynamics of a disease in the presence of data drifts. Likewise, the capability of epidemic models is constrained to parameter dimensions and estimation. We aimed at creating a framework of informed ML that integrates a random forest (RF) with an adapted susceptible infectious recovered (SIR) model to account for accuracy and consistency in stochasticity within the dynamics of coronavirus disease 2019 (COVID-19). Methods. An adapted SIR model was used to inform a default RF on predicting new COVID-19 cases (NCCs) at given intervals. We validated the performance of the informed RF (IRF) using real data. We used Botswana's pharmaceutical interventions (PIs) and non-PIs (NPIs) adopted between February 2020 and August 2022. The discrepancy between predictions and observations is modeled using loss functions, which are minimized, interpreted, and used to assess the IRF. Results. The findings on the real data have revealed the effectiveness of the default RF in modeling and predicting NCCs. The use of the effective reproductive rate to inform the RF yielded an excellent predictive power (84%) compared with 75% by the default RF. Conclusion. This research has potential to inform policy and decision makers in developing systems to evaluate interventions for infectious diseases.
HIGHLIGHTS: This framework is initiated by incorporating model outputs from an epidemic model to a machine learning model.An informed random forest (RF) is instantiated to model government and public responses to the COVID-19 pandemic.This framework does not require data transformations, and the epidemic model is shown to boost the RF's performance.This is a baseline knowledge-informed learning framework for assessing public health interventions in Botswana.",True,other,Not specified
38105323,Building a predictive model for hypertension related to environmental chemicals using machine learning,"Hypertension is a chronic cardiovascular disease characterized by elevated blood pressure that can lead to a number of complications. There is evidence that the numerous environmental substances to which humans are exposed facilitate the emergence of diseases. In this work, we sought to investigate the relationship between exposure to environmental contaminants and hypertension as well as the predictive value of such exposures. The National Health and Nutrition Survey (NHANES) provided us with the information we needed (2005-2012). A total of 4492 participants were included in our study, and we incorporated more common environmental chemicals and covariates by feature selection followed by regularized network analysis. Then, we applied various machine learning (ML) methods, such as extreme gradient boosting (XGBoost), random forest classifier (RF), logistic regression (LR), multilayer perceptron (MLP), and support vector machine (SVM), to predict hypertension by chemical exposure. Finally, SHapley Additive exPlanations (SHAP) were further applied to interpret the features. After the initial feature screening, we included a total of 29 variables (including 21 chemicals) for ML. The areas under the curve (AUCs) of the five ML models XGBoost, RF, LR, MLP, and SVM were 0.729, 0.723, 0.721, 0.730, and 0.731, respectively. Butylparaben (BUP), propylparaben (PPB), and 9-hydroxyfluorene (P17) were the three factors in the prediction model with the highest SHAP values. Comparing five ML models, we found that environmental exposure may play an important role in hypertension. The assessment of important chemical exposure parameters lays the groundwork for more targeted therapies, and the optimized ML models are likely to predict hypertension.",True,other,Not specified
38091881,Predicting the risk of diabetic retinopathy using explainable machine learning algorithms,"BACKGROUND AND OBJECTIVE: Diabetic retinopathy (DR) is a global health concern among diabetic patients. The objective of this study was to propose an explainable machine learning (ML)-based system for predicting the risk of DR.
MATERIALS AND METHODS: This study utilized publicly available cross-sectional data in a Chinese cohort of 6374 respondents. We employed boruta and least absolute shrinkage and selection operator (LASSO) based feature selection methods to identify the common predictors of DR. Using the identified predictors, we trained and optimized four widly applicable models (artificial neural network, support vector machine, random forest, and extreme gradient boosting (XGBoost) to predict patients with DR. Moreover, shapely additive explanation (SHAP) was adopted to show the contribution of each predictor of DR in the prediction.
RESULTS: Combining Boruta and LASSO method revealed that community, TCTG, HDLC, BUN, FPG, HbAlc, weight, and duration were the most important predictors of DR. The XGBoost-based model outperformed the other models, with an accuracy of 90.01%, precision of 91.80%, recall of 97.91%, F1 score of 94.86%, and AUC of 0.850. Moreover, SHAP method showed that HbA1c, community, FPG, TCTG, duration, and UA1b were the influencing predictors of DR.
CONCLUSION: The proposed integrating system will be helpful as a tool for selecting significant predictors, which can predict patients who are at high risk of DR at an early stage in China.",True,computer vision,recurrent neural network
38088426,"Application of deep neural survival networks to the development of risk prediction models for diabetes mellitus, hypertension, and dyslipidemia","OBJECTIVES: : Although numerous risk prediction models have been proposed, few such models have been developed using neural network-based survival analysis. We developed risk prediction models for three cardiovascular disease risk factors (diabetes mellitus, hypertension, and dyslipidemia) among a working-age population in Japan using DeepSurv, a deep feed-forward neural network.
METHODS: : Data were obtained from the Japan Epidemiology Collaboration on Occupational Health Study. A total of 51 258, 44 197, and 31 452 individuals were included in the development of risk models for diabetes mellitus, hypertension, and dyslipidemia, respectively; two-thirds of whom were used to develop prediction models, and the rest were used to validate the models. We compared the performances of DeepSurv-based models with those of prediction models based on the Cox proportional hazards model.
RESULTS: : The area under the receiver-operating characteristic curve was 0.878 [95% confidence interval (CI) = 0.864-0.892] for diabetes mellitus, 0.835 (95% CI = 0.826-0.845) for hypertension, and 0.826 (95% CI = 0.817-0.835) for dyslipidemia. Compared with the Cox proportional hazards-based models, the DeepSurv-based models had better reclassification performance [diabetes mellitus: net reclassification improvement (NRI) = 0.474, P  ≤ 0.001; hypertension: NRI = 0.194, P  ≤ 0.001; dyslipidemia: NRI = 0.397, P  ≤ 0.001] and discrimination performance [diabetes mellitus: integrated discrimination improvement (IDI) = 0.013, P  ≤ 0.001; hypertension: IDI = 0.007, P  ≤ 0.001; and dyslipidemia: IDI = 0.043, P  ≤ 0.001].
CONCLUSION: : This study suggests that DeepSurv has the potential to improve the performance of risk prediction models for cardiovascular disease risk factors.",True,other,recurrent neural network
38061023,Use of a machine learning model to predict retention in care in an urban HIV clinic,"Identifying barriers to retention in care (RIC) is critical to ending the HIV epidemic in the United States. Therefore, we developed a machine learning model (MLM) to identify predictive factors for RIC in an urban HIV clinic. Our MLM yielded a positive predictive value of 84%, higher than previously reported MLMs. We found that MLM can be used to develop interventional strategies to enhance RIC in HIV care.",True,other,Not specified
37971610,Shapely additive values can effectively visualize pertinent covariates in machine learning when predicting hypertension,"Machine learning methods are widely used within the medical field to enhance prediction. However, little is known about the reliability and efficacy of these models to predict long-term medical outcomes such as blood pressure using lifestyle factors, such as diet. The authors assessed whether machine-learning techniques could accurately predict hypertension risk using nutritional information. A cross-sectional study using data from the National Health and Nutrition Examination Survey (NHANES) between January 2017 and March 2020. XGBoost was used as the machine-learning model of choice in this study due to its increased performance relative to other common methods within medical studies. Model prediction metrics (e.g., AUROC, Balanced Accuracy) were used to measure overall model efficacy, covariate Gain statistics (percentage each covariate contributes to the overall prediction) and SHapely Additive exPlanations (SHAP, method to visualize each covariate) were used to provide explanations to machine-learning output and increase the transparency of this otherwise cryptic method. Of a total of 9650 eligible patients, the mean age was 41.02 (SD = 22.16), 4792 (50%) males, 4858 (50%) female, 3407 (35%) White patients, 2567 (27%) Black patients, 2108 (22%) Hispanic patients, and 981 (10%) Asian patients. From evaluation of model gain statistics, age was found to be the single strongest predictor of hypertension, with a gain of 53.1%. Additionally, demographic factors such as poverty and Black race were also strong predictors of hypertension, with gain of 4.33% and 4.18%, respectively. Nutritional Covariates contributed 37% to the overall prediction: Sodium, Caffeine, Potassium, and Alcohol intake being significantly represented within the model. Machine Learning can be used to predict hypertension.",True,other,Not specified
37947154,Machine Learning-based Prediction of Postoperative Pancreatic Fistula Following Pancreaticoduodenectomy,"OBJECTIVE: The aim of this study was to develop a novel machine learning model to predict clinically relevant postoperative pancreatic fistula (CR-POPF) following pancreaticoduodenectomy (PD).
BACKGROUND: Accurate prognostication of CR-POPF may allow for risk stratification and adaptive treatment strategies for potential PD candidates. However, antecedent models, such as the modified Fistula Risk Score (mFRS), are limited by poor discrimination and calibration.
METHODS: All records entailing PD within the 2014 to 2018 American College of Surgeons National Surgical Quality Improvement Program (ACS NSQIP) were identified. In addition, patients undergoing PD at our institution between 2013 and 2021 were queried from our local data repository. An eXtreme Gradient Boosting (XGBoost) model was developed to estimate the risk of CR-POPF using data from the ACS NSQIP and evaluated using institutional data. Model discrimination was estimated using the area under the receiver operating characteristic (AUROC) and area under the precision recall curve (AUPRC).
RESULTS: Overall, 12,281 and 445 patients undergoing PD were identified within the 2014 to 2018 ACS NSQIP and our institutional registry, respectively. Application of the XGBoost and mFRS scores to the internal validation dataset revealed that the former model had significantly greater AUROC (0.72 vs 0.68, P <0.001) and AUPRC (0.22 vs 0.18, P <0.001). Within the external validation dataset, the XGBoost model remained superior to the mFRS with an AUROC of 0.79 (95% CI: 0.74-0.84) versus 0.75 (95% CI: 0.70-0.80, P <0.001). In addition, AUPRC was higher for the XGBoost model, compared with the mFRS.
CONCLUSION: Our novel machine learning model consistently outperformed the previously validated mFRS within internal and external validation cohorts, thereby demonstrating its generalizability and utility for enhancing prediction of CR-POPF.",True,other,Not specified
37936960,Detecting the most critical clinical variables of COVID-19 breakthrough infection in vaccinated persons using machine learning,"BACKGROUND: COVID-19 vaccines offer different levels of immune protection but do not provide 100% protection. Vaccinated persons with pre-existing comorbidities may be at an increased risk of SARS-CoV-2 breakthrough infection or reinfection. The aim of this study is to identify the critical variables associated with a higher probability of SARS-CoV-2 breakthrough infection using machine learning.
METHODS: A dataset comprising symptoms and feedback from 257 persons, of whom 203 were vaccinated and 54 unvaccinated, was used for the investigation. Three machine learning algorithms - Deep Multilayer Perceptron (Deep MLP), XGBoost, and Logistic Regression - were trained with the original (imbalanced) dataset and the balanced dataset created by using the Random Oversampling Technique (ROT), and the Synthetic Minority Oversampling Technique (SMOTE). We compared the performance of the classification algorithms when the features highly correlated with breakthrough infection were used and when all features in the dataset were used.
RESULT: The results show that when highly correlated features were considered as predictors, with Random Oversampling to address data imbalance, the XGBoost classifier has the best performance (F1 = 0.96; accuracy = 0.96; AUC = 0.98; G-Mean = 0.98; MCC = 0.88). The Deep MLP had the second best performance (F1 = 0.94; accuracy = 0.94; AUC = 0.92; G-Mean = 0.70; MCC = 0.42), while Logistic Regression had less accurate performance (F1 = 0.89; accuracy = 0.88; AUC = 0.89; G-Mean = 0.89; MCC = 0.68). We also used Shapley Additive Explanations (SHAP) to investigate the interpretability of the models. We found that body temperature, total cholesterol, glucose level, blood pressure, waist circumference, body weight, body mass index (BMI), haemoglobin level, and physical activity per week are the most critical variables indicating a higher risk of breakthrough infection.
CONCLUSION: These results, evident from our unique data source derived from apparently healthy volunteers with cardiovascular risk factors, follow the expected pattern of positive or negative correlations previously reported in the literature. This information strengthens the body of knowledge currently applied in public health guidelines and may also be used by medical practitioners in the future to reduce the risk of SARS-CoV-2 breakthrough infection.",True,other,Not specified
37920035,Neural-SEIR: A flexible data-driven framework for precise prediction of epidemic disease,"Accurately modeling and predicting epidemic diseases is crucial to prevent disease transmission and reduce mortality. Due to various unpredictable factors, including population migration, vaccination, control efforts, and seasonal fluctuations, traditional epidemic models that rely on prior knowledge of virus transmission mechanisms may not be sufficient to forecast complex epidemics like coronavirus disease 2019(COVID-19). The application of traditional epidemiological models such as susceptible-exposed-infectious-recovered (SEIR) may face difficulties in accurately predicting such complex epidemics. Data-driven prediction approaches lack the ability to generalize and exhibit low accuracy on small datasets due to their reliance on large amounts of data without incorporating prior knowledge. To overcome this limitation, we introduce a flexible ensemble data-driven framework (Neural-SEIR) that ""neuralizes"" the SEIR model by approximating the core parameters through neural networks while preserving the propagation structure of SEIR. Neural-SEIR employs long short-term memory (LSTM) neural network to capture complex correlation features, exponential smoothing (ES) to model seasonal information, and prior knowledge from SEIR. By incorporating SEIR parameters into the neural network structure, Neural-SEIR leverages prior knowledge while updating parameters with real-world data. Our experimental results demonstrate that Neural-SEIR outperforms traditional machine learning and epidemiological models, achieving high prediction accuracy and efficiency in forecasting epidemic diseases.",True,other,Not specified
37906980,Machine Learning Predicts Acute Kidney Injury in Hospitalized Patients with Sickle Cell Disease,"INTRODUCTION: Acute kidney injury (AKI) is common among hospitalized patients with sickle cell disease (SCD) and contributes to increased morbidity and mortality. Early identification and management of AKI is essential to preventing poor outcomes. We aimed to predict AKI earlier in patients with SCD using a machine-learning model that utilized continuous minute-by-minute physiological data.
METHODS: A total of6,278 adult SCD patient encounters were admitted to inpatient units across five regional hospitals in Memphis, TN, over 3 years, from July 2017 to December 2020. From these, 1,178 patients were selected after filtering for data availability. AKI was identified in 82 (7%) patient encounters, using the 2012 Kidney Disease Improving Global Outcomes (KDIGO) criteria. The remaining 1,096 encounters served as controls. Features derived from five physiological data streams, heart rate, respiratory rate, and blood pressure (systolic, diastolic, and mean), captured every minute from bedside monitors were used. An XGBoost classifier was used for classification.
RESULTS: Our model accurately predicted AKI up to 12 h before onset with an area under the receiver operator curve (AUROC) of 0.91 (95% CI [0.89-0.93]) and up to 48 h before AKI with an AUROC of 0.82 (95% CI [0.80-0.83]). Patients with AKI were more likely to be female (64.6%) and have history of hypertension, pulmonary hypertension, chronic kidney disease, and pneumonia than the control group.
CONCLUSION: XGBoost accurately predicted AKI as early as 12 h before onset in hospitalized SCD patients and may enable the development of innovative prevention strategies.",True,computer vision,Not specified
37870482,Leveraging artificial intelligence to identify high-risk patients for postoperative sore throat: An observational study,"Postoperative sore throat (POST) is a prevalent complication after general anesthesia and targeting high-risk patients helps in its prevention. This study developed and validated a machine learning model to predict POST. A total number of 834 patients who underwent general anesthesia with endotracheal intubation were included in this study. Data from a cohort of 685 patients was used for model development and validation, while a cohort of 149 patients served for external validation. The prediction performance of random forest (RF), neural network (NN), and extreme gradient boosting (XGBoost) models was compared using comprehensive performance metrics. The Local Interpretable Model-Agnostic Explanations (LIME) methods elucidated the best-performing model. POST incidences across training, validation, and testing cohorts were 41.7%, 38.4%, and 36.2%, respectively. Five predictors were age, sex, endotracheal tube cuff pressure, endotracheal tube insertion depth, and the time interval between extubation and the first drinking of water after extubation. After incorporating these variables, the NN model demonstrated superior generalization capabilities in predicting POST when compared to the XGBoost and RF models in external validation, achieving an area under the receiver operating characteristic curve (AUROC) of 0.81 (95% CI 0.74-0.89) and a precision-recall curve (AUPRC) of 0.77 (95% CI 0.66-0.86). The model also showed good calibration and clinical usage values. The NN model outperforms the XGBoost and RF models in predicting POST, with potential applications in the healthcare industry for reducing the incidence of this common postoperative complication.",True,other,Not specified
37799774,Machine Learning for Detecting Virus Infection Hotspots Via Wastewater-Based Epidemiology: The Case of SARS-CoV-2 RNA,"Wastewater-based epidemiology (WBE) has been proven to be a useful tool in monitoring public health-related issues such as drug use, and disease. By sampling wastewater and applying WBE methods, wastewater-detectable pathogens such as viruses can be cheaply and effectively monitored, tracking people who might be missed or under-represented in traditional disease surveillance. There is a gap in current knowledge in combining hydraulic modeling with WBE. Recent literature has also identified a gap in combining machine learning with WBE for the detection of viral outbreaks. In this study, we loosely coupled a physically-based hydraulic model of pathogen introduction and transport with a machine learning model to track and trace the source of a pathogen within a sewer network and to evaluate its usefulness under various conditions. The methodology developed was applied to a hypothetical sewer network for the rapid detection of disease hotspots of the disease caused by the SARS-CoV-2 virus. Results showed that the machine learning model's ability to recognize hotspots is promising, but requires a high time-resolution of monitoring data and is highly sensitive to the sewer system's physical layout and properties such as flow velocity, the pathogen sampling procedure, and the model's boundary conditions. The methodology proposed and developed in this paper opens new possibilities for WBE, suggesting a rapid back-tracing of human-excreted biomarkers based on only sampling at the outlet or other key points, but would require high-frequency, contaminant-specific sensor systems that are not available currently.",True,other,Not specified
37710241,LSTM-based recurrent neural network provides effective short term flu forecasting,"BACKGROUND: Influenza virus is responsible for a yearly epidemic in much of the world. To better predict short-term, seasonal variations in flu infection rates and possible mechanisms of yearly infection variation, we trained a Long Short-Term Memory (LSTM)-based deep neural network on historical Influenza-Like-Illness (ILI), climate, and population data.
METHODS: Data were collected from the Centers for Disease Control and Prevention (CDC), the National Center for Environmental Information (NCEI), and the United States Census Bureau. The model was initially built in Python using the Keras API and tuned manually. We explored the roles of temperature, precipitation, local wind speed, population size, vaccination rate, and vaccination efficacy. The model was validated using K-fold cross validation as well as forward chaining cross validation and compared to several standard algorithms. Finally, simulation data was generated in R and used for further exploration of the model.
RESULTS: We found that temperature is the strongest predictor of ILI rates, but also found that precipitation increased the predictive power of the network. Additionally, the proposed model achieved a +1 week prediction mean absolute error (MAE) of 0.1973. This is less than half of the MAE achieved by the next best performing algorithm. Additionally, the model accurately predicted simulation data. To test the role of temperature in the network, we phase-shifted temperature in time and found a predictable reduction in prediction accuracy.
CONCLUSIONS: The results of this study suggest that short term flu forecasting may be effectively accomplished using architectures traditionally reserved for time series analysis. The proposed LSTM-based model was able to outperform comparison models at the +1 week time point. Additionally, this model provided insight into the week-to-week effects of climatic and biotic factors and revealed potential patterns in data series. Specifically, we found that temperature is the strongest predictor of seasonal flu infection rates. This information may prove to be especially important for flu forecasting given the uncertain long-term impact of the SARS-CoV-2 pandemic on seasonal influenza.",True,other,recurrent neural network
37704073,Development of a Novel Clinical Risk Score for COVID-19 Infections,"OBJECTIVE: The ongoing emergence of novel severe acute respiratory syndrome coronavirus 2 strains such as the Omicron variant amplifies the need for precision in predicting severe COVID-19 outcomes. This study presents a machine learning model, tailored to the evolving COVID-19 landscape, emphasizing novel risk factors and refining the definition of severe outcomes to predict the risk of a patient experiencing severe disease more accurately.
METHODS: Utilizing electronic health records from the Healthjump database, this retrospective study examined over 1 million US COVID-19 diagnoses from March 2020 to September 2022. Our model predicts severe outcomes, including acute respiratory failure, intensive care unit admission, or ventilator use, circumventing biases associated with hospitalization, which exhibited ∼4× geographical variance of the new outcome.
RESULTS: The model exceeded similar predictors with an area under the curve of 0.83 without lab data to predict patient risk. It identifies new risk factors, including acute care history, health care encounters, and distinct medication use. An increase in severe outcomes, typically 2-3× higher than subsequent months, was observed at the onset of each new strain era, followed by a plateau phase, but the risk factors remain consistent across strain eras.
CONCLUSION: We offer an improved machine learning model and risk score for predicting severe outcomes during changing COVID-19 strain eras. By emphasizing a more clinically precise definition of severe outcomes, the study provides insights for resource allocation and intervention strategies, aiming to better patient outcomes and reduce health care strain. The necessity for regular model updates is highlighted to maintain relevance amidst the rapidly evolving COVID-19 epidemic.",True,other,Not specified
37672928,An optimized machine learning model for predicting hospitalization for COVID-19 infection in the maintenance dialysis population,"COVID-19 has a high rate of infection in dialysis patients and poses a serious risk to human health. Currently, there are no dialysis centers in China that have analyzed the prevalence of COVID-19 infection in dialysis patients and the mortality rate. Although machine learning-based disease prediction methods have proven to be effective, redundant attributes in the data and the interpretability of the predictive models are still worth investigating. Therefore, this paper proposed a wrapper feature selection classification model to achieve the prediction of the risk of COVID-19 infection in dialysis patients. The method was used to optimize the feature set of the sample through an enhanced JAYA optimization algorithm based on the dispersed foraging strategy and the greedy levy mutation strategy. Then, the proposed method combines fuzzy K-nearest neighbor for classification prediction. IEEE CEC2014 benchmark function experiments as well as prediction experiments on the uremia dataset are used to validate the proposed model. The experimental results showed that the proposed method has a high prediction accuracy of 95.61% for the prevalence risk of COVID-19 infection in dialysis patients. Furthermore, it was shown that proalbumin, CRP, direct bilirubin, hemoglobin, albumin, and phosphorus are of great value for clinical diagnosis. Therefore, the proposed method can be considered as a promising method.",True,other,recurrent neural network
37627817,Development of a Machine Learning Model of Postoperative Acute Kidney Injury Using Non-Invasive Time-Sensitive Intraoperative Predictors,"Acute kidney injury (AKI) is a major postoperative complication that lacks established intraoperative predictors. Our objective was to develop a prediction model using preoperative and high-frequency intraoperative data for postoperative AKI. In this retrospective cohort study, we evaluated 77,428 operative cases at a single academic center between 2016 and 2022. A total of 11,212 cases with serum creatinine (sCr) data were included in the analysis. Then, 8519 cases were randomly assigned to the training set and the remainder to the validation set. Fourteen preoperative and twenty intraoperative variables were evaluated using elastic net followed by hierarchical group least absolute shrinkage and selection operator (LASSO) regression. The training set was 56% male and had a median [IQR] age of 62 (51-72) and a 6% AKI rate. Retained model variables were preoperative sCr values, the number of minutes meeting cutoffs for urine output, heart rate, perfusion index intraoperatively, and the total estimated blood loss. The area under the receiver operator characteristic curve was 0.81 (95% CI, 0.77-0.85). At a score threshold of 0.767, specificity was 77% and sensitivity was 74%. A web application that calculates the model score is available online. Our findings demonstrate the utility of intraoperative time series data for prediction problems, including a new potential use of the perfusion index. Further research is needed to evaluate the model in clinical settings.",True,computer vision,Not specified
37625260,Predicting lung cancer survival based on clinical data using machine learning: A review,"Machine learning has gained popularity in predicting survival time in the medical field. This review examines studies utilizing machine learning and data-mining techniques to predict lung cancer survival using clinical data. A systematic literature review searched MEDLINE, Scopus, and Google Scholar databases, following reporting guidelines and using the COVIDENCE system. Studies published from 2000 to 2023 employing machine learning for lung cancer survival prediction were included. Risk of bias assessment used the prediction model risk of bias assessment tool. Thirty studies were reviewed, with 13 (43.3%) using the surveillance, epidemiology, and end results database. Missing data handling was addressed in 12 (40%) studies, primarily through data transformation and conversion. Feature selection algorithms were used in 19 (63.3%) studies, with age, sex, and N stage being the most chosen features. Random forest was the predominant machine learning model, used in 17 (56.6%) studies. While the number of lung cancer survival prediction studies is limited, the use of machine learning models based on clinical data has grown since 2012. Consideration of diverse patient cohorts and data pre-processing are crucial. Notably, most studies did not account for missing data, normalization, scaling, or standardized data, potentially introducing bias. Therefore, a comprehensive study on lung cancer survival prediction using clinical data is needed, addressing these challenges.",True,other,Not specified
37624075,Identifying Cardiovascular Disease Risk Factors in Adults with Explainable Artificial Intelligence,"BACKGROUND: The aim of this study was to evaluate the relationship between risk factors causing cardiovascular diseases and their importance with explainable machine learning models.
METHODS: In this retrospective study, multiple databases were searched, and data on 11 risk factors of 70 000 patients were obtained. Data included risk factors highly associated with cardiovascular disease and having/not having any cardiovascular disease. The explainable prediction model was constructed using 7 machine learning algorithms: Random Forest Classifier, Extreme Gradient Boost Classifier, Decision Tree Classifier, KNeighbors Classifier, Support Vector Machine Classifier, and GaussianNB. Receiver operating characteristic curve, Brier scores, and mean accuracy were used to assess the model's performance. The interpretability of the predicted results was examined using Shapley additive description values.
RESULTS: The accuracy, area under the curve values, and Brier scores of the Extreme Gradient Boost model (the best prediction model for cardiovascular disease risk factors) were calculated as 0.739, 0.803, and 0.260, respectively. The most important risk factors in the permutation feature importance method and explainable artificial intelligence-Shapley's explanations method are systolic blood pressure (ap_hi) [0.1335 ± 0.0045 w (weight)], cholesterol (0.0341 ± 0.0022 w), and age (0.0211 ± 0.0036 w).
CONCLUSION: The created explainable machine learning model has become a successful clinical model that can predict cardiovascular patients and explain the impact of risk factors. Especially in the clinical setting, this model, which has an accurate, explainable, and transparent algorithm, will help encourage early diagnosis of patients with cardiovascular diseases, risk factors, and possible treatment options.",True,other,recurrent neural network
37575113,Prediction of the risk of cytopenia in hospitalized HIV/AIDS patients using machine learning methods based on electronic medical records,"BACKGROUND: Cytopenia is a frequent complication among HIV-infected patients who require hospitalization. It can have a negative impact on the treatment outcomes for these patients. However, by leveraging machine learning techniques and electronic medical records, a predictive model can be developed to evaluate the risk of cytopenia during hospitalization in HIV patients. Such a model is crucial for designing a more individualized and evidence-based treatment strategy for HIV patients.
METHOD: The present study was conducted on HIV patients who were admitted to Guangxi Chest Hospital between June 2016 and October 2021. We extracted a total of 66 clinical features from the electronic medical records and employed them to train five machine learning prediction models (artificial neural network [ANN], adaptive boosting [AdaBoost], k-nearest neighbour [KNN] and support vector machine [SVM], decision tree [DT]). The models were tested using 20% of the data. The performance of the models was evaluated using indicators such as the area under the receiver operating characteristic curve (AUC). The best predictive models were interpreted using the shapley additive explanation (SHAP).
RESULT: The ANN models have better predictive power. According to the SHAP interpretation of the ANN model, hypoproteinemia and cancer were the most important predictive features of cytopenia in HIV hospitalized patients. Meanwhile, the lower hemoglobin-to-RDW ratio (HGB/RDW), low-density lipoprotein cholesterol (LDL-C) levels, CD4+ T cell counts, and creatinine clearance (Ccr) levels increase the risk of cytopenia in HIV hospitalized patients.
CONCLUSION: The present study constructed a risk prediction model for cytopenia in HIV patients during hospitalization with machine learning and electronic medical record information. The prediction model is important for the rational management of HIV hospitalized patients and the personalized treatment plan setting.",True,computer vision,Not specified
37522752,Machine Learning Predicts Patients With New-onset Diabetes at Risk of Pancreatic Cancer,"BACKGROUND: New-onset diabetes represent a high-risk cohort to screen for pancreatic cancer.
GOALS: Develop a machine model to predict pancreatic cancer among patients with new-onset diabetes.
STUDY: A retrospective cohort of patients with new-onset diabetes was assembled from multiple health care networks in the United States. An XGBoost machine learning model was designed from a portion of this cohort (the training set) and tested on the remaining part of the cohort (the test set). Shapley values were used to explain the XGBoost's model features. Model performance was compared with 2 contemporary models designed to predict pancreatic cancer among patients with new-onset diabetes.
RESULTS: In the test set, the XGBoost model had an area under the curve of 0.80 (0.76 to 0.85) compared with 0.63 and 0.68 for other models. Using cutoffs based on the Youden index, the sensitivity of the XGBoost model was 75%, the specificity was 70%, the accuracy was 70%, the positive predictive value was 1.2%, and the negative predictive value was >99%. The XGBoost model obtained a positive predictive value of at least 2.5% with a sensitivity of 38%. The XGBoost model was the only model that detected at least 50% of patients with cancer one year after the onset of diabetes. All 3 models had similar features that predicted pancreatic cancer, including older age, weight loss, and the rapid destabilization of glucose homeostasis.
CONCLUSION: Machine learning models isolate a high-risk cohort from those with new-onset diabetes at risk for pancreatic cancer.",True,other,Not specified
37467217,Historical visit attendance as predictor of treatment interruption in South African HIV patients: Extension of a validated machine learning model,"Retention of antiretroviral (ART) patients is a priority for achieving HIV epidemic control in South Africa. While machine-learning methods are being increasingly utilised to identify high risk populations for suboptimal HIV service utilisation, they are limited in terms of explaining relationships between predictors. To further understand these relationships, we implemented machine learning methods optimised for predictive power and traditional statistical methods. We used routinely collected electronic medical record (EMR) data to evaluate longitudinal predictors of lost-to-follow up (LTFU) and temporal interruptions in treatment (IIT) in the first two years of treatment for ART patients in the Gauteng and North West provinces of South Africa. Of the 191,162 ART patients and 1,833,248 visits analysed, 49% experienced at least one IIT and 85% of those returned for a subsequent clinical visit. Patients iteratively transition in and out of treatment indicating that ART retention in South Africa is likely underestimated. Historical visit attendance is shown to be predictive of IIT using machine learning, log binomial regression and survival analyses. Using a previously developed categorical boosting (CatBoost) algorithm, we demonstrate that historical visit attendance alone is able to predict almost half of next missed visits. With the addition of baseline demographic and clinical features, this model is able to predict up to 60% of next missed ART visits with a sensitivity of 61.9% (95% CI: 61.5-62.3%), specificity of 66.5% (95% CI: 66.4-66.7%), and positive predictive value of 19.7% (95% CI: 19.5-19.9%). While the full usage of this model is relevant for settings where infrastructure exists to extract EMR data and run computations in real-time, historical visits attendance alone can be used to identify those at risk of disengaging from HIV care in the absence of other behavioural or observable risk factors.",True,other,Not specified
37452503,A machine learning model for predicting hepatocellular carcinoma risk in patients with chronic hepatitis B,"BACKGROUND: Machine learning (ML) algorithms can be used to overcome the prognostic performance limitations of conventional hepatocellular carcinoma (HCC) risk models. We established and validated an ML-based HCC predictive model optimized for patients with chronic hepatitis B (CHB) infections receiving antiviral therapy (AVT).
METHODS: Treatment-naïve CHB patients who were started entecavir (ETV) or tenofovir disoproxil fumarate (TDF) were enrolled. We used a training cohort (n = 960) to develop a novel ML model that predicted HCC development within 5 years and validated the model using an independent external cohort (n = 1937). ML algorithms consider all potential interactions and do not use predefined hypotheses.
RESULTS: The mean age of the patients in the training cohort was 48 years, and most patients (68.9%) were men. During the median 59.3 (interquartile range 45.8-72.3) months of follow-up, 69 (7.2%) patients developed HCC. Our ML-based HCC risk prediction model had an area under the receiver-operating characteristic curve (AUC) of 0.900, which was better than the AUCs of CAMD (0.778) and REAL B (0.772) (both p < .05). The better performance of our model was maintained (AUC = 0.872 vs. 0.788 for CAMD and 0.801 for REAL B) in the validation cohort. Using cut-off probabilities of 0.3 and 0.5, the cumulative incidence of HCC development differed significantly among the three risk groups (p < .001).
CONCLUSIONS: Our new ML model performed better than models in terms of predicting the risk of HCC development in CHB patients receiving AVT.",True,other,Not specified
37451651,"A rapid, high-throughput, viral infectivity assay using automated brightfield microscopy with machine learning","Infectivity assays are essential for the development of viral vaccines, antiviral therapies, and the manufacture of biologicals. Traditionally, these assays take 2-7 days and require several manual processing steps after infection. We describe an automated viral infectivity assay (AVIATM), using convolutional neural networks (CNNs) and high-throughput brightfield microscopy on 96-well plates that can quantify infection phenotypes within hours, before they are manually visible, and without sample preparation. CNN models were trained on HIV, influenza A virus, coronavirus 229E, vaccinia viruses, poliovirus, and adenoviruses, which together span the four major categories of virus (DNA, RNA, enveloped, and non-enveloped). A sigmoidal function, fit between virus dilution curves and CNN predictions, results in sensitivity ranges comparable to or better than conventional plaque or TCID<sub>50</sub> assays, and a precision of ∼10%, which is considerably better than conventional infectivity assays. Because this technology is based on sensitizing CNNs to specific phenotypes of infection, it has potential as a rapid, broad-spectrum tool for virus characterization, and potentially identification.",True,other,CNN
37410747,Using Artificial Intelligence in Predicting Ischemic Stroke Events After Percutaneous Coronary Intervention,"BACKGROUND: Ischemic stroke (IS) is an uncommon but severe complication in patients undergoing percutaneous coronary intervention (PCI). Despite significant morbidity and economic cost associated with post PCI IS, a validated risk prediction model is not currently available.
AIMS: We aim to develop a machine learning model that predicts IS after PCI.
METHODS: We analyzed data from Mayo Clinic CathPCI registry from 2003 to 2018. Baseline clinical and demographic data, electrocardiography (ECG), intra/post-procedural data, and echocardiographic variables were abstracted. A random forest (RF) machine learning model and a logistic regression (LR) model were developed. The receiver operator characteristic (ROC) analysis was used to assess model performance in predicting IS at 6-month, 1-, 2-, and 5-years post-PCI.
RESULTS: A total of 17,356 patients were included in the final analysis. The mean age of this cohort was 66.9 ± 12.5 years, and 70.7% were male. Post-PCI IS was noted in 109 patients (.6%) at 6 months, 132 patients (.8%) at 1 year, 175 patients (1%) at 2 years, and 264 patients (1.5%) at 5 years. The area under the curve of the RF model was superior to the LR model in predicting ischemic stroke at 6 months, 1-, 2-, and 5-years. Periprocedural stroke was the strongest predictor of IS post discharge.
CONCLUSIONS: The RF model accurately predicts short- and long-term risk of IS and outperforms logistic regression analysis in patients undergoing PCI. Patients with periprocedural stroke may benefit from aggressive management to reduce the future risk of IS.",True,other,Not specified
37387168,DeepCoVDR: deep transfer learning with graph transformer and cross-attention for predicting COVID-19 drug response,"MOTIVATION: The coronavirus disease 2019 (COVID-19) remains a global public health emergency. Although people, especially those with underlying health conditions, could benefit from several approved COVID-19 therapeutics, the development of effective antiviral COVID-19 drugs is still a very urgent problem. Accurate and robust drug response prediction to a new chemical compound is critical for discovering safe and effective COVID-19 therapeutics.
RESULTS: In this study, we propose DeepCoVDR, a novel COVID-19 drug response prediction method based on deep transfer learning with graph transformer and cross-attention. First, we adopt a graph transformer and feed-forward neural network to mine the drug and cell line information. Then, we use a cross-attention module that calculates the interaction between the drug and cell line. After that, DeepCoVDR combines drug and cell line representation and their interaction features to predict drug response. To solve the problem of SARS-CoV-2 data scarcity, we apply transfer learning and use the SARS-CoV-2 dataset to fine-tune the model pretrained on the cancer dataset. The experiments of regression and classification show that DeepCoVDR outperforms baseline methods. We also evaluate DeepCoVDR on the cancer dataset, and the results indicate that our approach has high performance compared with other state-of-the-art methods. Moreover, we use DeepCoVDR to predict COVID-19 drugs from FDA-approved drugs and demonstrate the effectiveness of DeepCoVDR in identifying novel COVID-19 drugs.
AVAILABILITY AND IMPLEMENTATION: https://github.com/Hhhzj-7/DeepCoVDR.",True,other,Not specified
37224663,Predictive analysis for pathogenicity classification of H5Nx avian influenza strains using machine learning techniques,"Over the past decades, avian influenza (AI) outbreaks have been reported across different parts of the globe, resulting in large-scale economic and livestock loss and, in some cases raising concerns about their zoonotic potential. The virulence and pathogenicity of H5Nx (e.g., H5N1, H5N2) AI strains for poultry could be inferred through various approaches, and it has been frequently performed by detecting certain pathogenicity markers in their haemagglutinin (HA) gene. The utilization of predictive modeling methods represents a possible approach to exploring this genotypic-phenotypic relationship for assisting experts in determining the pathogenicity of circulating AI viruses. Therefore, the main objective of this study was to evaluate the predictive performance of different machine learning (ML) techniques for in-silico prediction of pathogenicity of H5Nx viruses in poultry, using complete genetic sequences of the HA gene. We annotated 2137 H5Nx HA gene sequences based on the presence of the polybasic HA cleavage site (HACS) with 46.33% and 53.67% of sequences previously identified as highly pathogenic (HP) and low pathogenic (LP), respectively. We compared the performance of different ML classifiers (e.g., logistic regression (LR) with the lasso and ridge regularization, random forest (RF), K-nearest neighbor (KNN), Naïve Bayes (NB), support vector machine (SVM), and convolutional neural network (CNN)) for pathogenicity classification of raw H5Nx nucleotide and protein sequences using a 10-fold cross-validation technique. We found that different ML techniques can be successfully used for the pathogenicity classification of H5 sequences with ∼99% classification accuracy. Our results indicate that for pathogenicity classification of (1) aligned deoxyribonucleic acid (DNA) and protein sequences, with NB classifier had the lowest accuracies of 98.41% (+/-0.89) and 98.31% (+/-1.06), respectively; (2) aligned DNA and protein sequences, with LR (L1/L2), KNN, SVM (radial basis function (RBF)) and CNN classifiers had the highest accuracies of 99.20% (+/-0.54) and 99.20% (+/-0.38), respectively; (3) unaligned DNA and protein sequences, with CNN's achieved accuracies of 98.54% (+/-0.68) and 99.20% (+/-0.50), respectively. ML methods show potential for regular classification of H5Nx virus pathogenicity for poultry species, particularly when sequences containing regular markers were frequently present in the training dataset.",True,other,Not specified
37221360,Detection of systemic cardiovascular illnesses and cardiometabolic risk factors with machine learning and optical coherence tomography angiography: a pilot study,"BACKGROUND/OBJECTIVES: Optical coherence tomography angiography (OCTA) has been found to identify changes in the retinal microvasculature of people with various cardiometabolic factors. Machine learning has previously been applied within ophthalmic imaging but has not yet been applied to these risk factors. The study aims to assess the feasibility of predicting the presence or absence of cardiovascular conditions and their associated risk factors using machine learning and OCTA.
METHODS: Cross-sectional study. Demographic and co-morbidity data was collected for each participant undergoing 3 × 3 mm, 6 × 6 mm and 8 × 8 mm OCTA scanning using the Carl Zeiss CIRRUS HD-OCT model 5000. The data was then pre-processed and randomly split into training and testing datasets (75%/25% split) before being applied to two models (Convolutional Neural Network and MoblieNetV2). Once developed on the training dataset, their performance was assessed on the unseen test dataset.
RESULTS: Two hundred forty-seven participants were included. Both models performed best in predicting the presence of hyperlipidaemia in 3 × 3 mm scans with an AUC of 0.74 and 0.81, and accuracy of 0.79 for CNN and MobileNetV2 respectively. Modest performance was achieved in the identification of diabetes mellitus, hypertension and congestive heart failure in 3 × 3 mm scans (all with AUC and accuracy >0.5). There was no significant recognition for 6 × 6 and 8 × 8 mm for any cardiometabolic risk factor.
CONCLUSION: This study demonstrates the strength of ML to identify the presence cardiometabolic factors, in particular hyperlipidaemia, in high-resolution 3 × 3 mm OCTA scans. Early detection of risk factors prior to a clinically significant event, will assist in preventing adverse outcomes for people.",True,other,Not specified
37211050,Using machine learning to predict cardiovascular risk using self-reported questionnaires: Findings from the 45 and Up Study,"BACKGROUND: Machine learning has been shown to outperform traditional statistical methods for risk prediction model development. We aimed to develop machine learning-based risk prediction models for cardiovascular mortality and hospitalisation for ischemic heart disease (IHD) using self-reported questionnaire data.
METHODS: The 45 and Up Study was a retrospective population-based study in New South Wales, Australia (2005-2009). Self-reported healthcare survey data on 187,268 participants without a history of cardiovascular disease was linked to hospitalisation and mortality data. We compared different machine learning algorithms, including traditional classification methods (support vector machine (SVM), neural network, random forest and logistic regression) and survival methods (fast survival SVM, Cox regression and random survival forest).
RESULTS: A total of 3687 participants experienced cardiovascular mortality and 12,841 participants had IHD-related hospitalisation over a median follow-up of 10.4 years and 11.6 years respectively. The best model for cardiovascular mortality was a Cox survival regression with L1 penalty at a re-sampled case/non-case ratio of 0.3 achieved by under-sampling of the non-cases. This model had the Uno's and Harrel's concordance indexes of 0.898 and 0.900 respectively. The best model for IHD hospitalisation was a Cox survival regression with L1 penalty at a re-sampled case/non-case ratio of 1.0 with Uno's and Harrel's concordance indexes of 0.711 and 0.718 respectively.
CONCLUSION: Machine learning-based risk prediction models developed using self-reported questionnaire data had good prediction performance. These models may have the potential to be used in initial screening tests to identify high-risk individuals before undergoing costly investigation.",True,other,recurrent neural network
37082820,Machine Learning Model for Assessment of Risk Factors and Postoperative Day for Superficial vs Deep/Organ-Space Surgical Site Infections,"Background. Deep and organ space surgical site infections (SSI) require more intensive treatment, may result in more severe clinical disease and may have different risk factors when compared to superficial SSIs. Machine learning (ML) algorithms provide the opportunity to analyze multiple factors to predict of the type and time of development of SSI. Therefore, we developed a ML model to predict type and postoperative week of SSI. Methodology. A case-control study was conducted among patients who developed a SSI after undergoing general surgery procedures at a tertiary care hospital between 2019 to 2020. Patients were followed for 30 days. Six ML algorithms were trained as predictors of type of infection (superficial vs deep/organ space) and time of infection, and tested using area under the receiver operating characteristic curve (AUC-ROC). Results. Data for 113 patients with SSIs was available. Of these 62 (54.8%) had superficial and 51 had (45.2%) deep/organ space infections. Compared with other ML algorithms, the XG boost univariate model had highest AUC-ROC (.84) for prediction of type of SSI and Stochastic gradient boosting univariate, logistic regression univariate, XG boost univariate, and random forest classification univariate model had the highest AUC-ROC (.74) for prediction of week of infection. Conclusions. ML models offer reasonable accuracy in prediction of superficial vs deep SSI and time of developing infection. Follow-up duration and allocation of treatment strategies can be informed by ML predictions.",True,other,RNN
37059871,A machine learning approach to predict self-protecting behaviors during the early wave of the COVID-19 pandemic,"Using a unique harmonized real-time data set from the COME-HERE longitudinal survey that covers five European countries (France, Germany, Italy, Spain, and Sweden) and applying a non-parametric machine learning model, this paper identifies the main individual and macro-level predictors of self-protecting behaviors against the coronavirus disease 2019 (COVID-19) during the first wave of the pandemic. Exploiting the interpretability of a Random Forest algorithm via Shapely values, we find that a higher regional incidence of COVID-19 triggers higher levels of self-protective behavior, as does a stricter government policy response. The level of individual knowledge about the pandemic, confidence in institutions, and population density also ranks high among the factors that predict self-protecting behaviors. We also identify a steep socioeconomic gradient with lower levels of self-protecting behaviors being associated with lower income and poor housing conditions. Among socio-demographic factors, gender, marital status, age, and region of residence are the main determinants of self-protective measures.",True,other,Not specified
37058460,Use of machine learning to identify risk factors for coronary artery disease,"Coronary artery disease (CAD) is the leading cause of death in both developed and developing nations. The objective of this study was to identify risk factors for coronary artery disease through machine-learning and assess this methodology. A retrospective, cross-sectional cohort study using the publicly available National Health and Nutrition Examination Survey (NHANES) was conducted in patients who completed the demographic, dietary, exercise, and mental health questionnaire and had laboratory and physical exam data. Univariate logistic models, with CAD as the outcome, were used to identify covariates that were associated with CAD. Covariates that had a p<0.0001 on univariate analysis were included within the final machine-learning model. The machine learning model XGBoost was used due to its prevalence within the literature as well as its increased predictive accuracy in healthcare prediction. Model covariates were ranked according to the Cover statistic to identify risk factors for CAD. Shapely Additive Explanations (SHAP) explanations were utilized to visualize the relationship between these potential risk factors and CAD. Of the 7,929 patients that met the inclusion criteria in this study, 4,055 (51%) were female, 2,874 (49%) were male. The mean age was 49.2 (SD = 18.4), with 2,885 (36%) White patients, 2,144 (27%) Black patients, 1,639 (21%) Hispanic patients, and 1,261 (16%) patients of other race. A total of 338 (4.5%) of patients had coronary artery disease. These were fitted into the XGBoost model and an AUROC = 0.89, Sensitivity = 0.85, Specificity = 0.87 were observed (Fig 1). The top four highest ranked features by cover, a measure of the percentage contribution of the covariate to the overall model prediction, were age (Cover = 21.1%), Platelet count (Cover = 5.1%), family history of heart disease (Cover = 4.8%), and Total Cholesterol (Cover = 4.1%). Machine learning models can effectively predict coronary artery disease using demographic, laboratory, physical exam, and lifestyle covariates and identify key risk factors.",True,both,Not specified
37046069,Machine learning-based analytics of the impact of the Covid-19 pandemic on alcohol consumption habit changes among United States healthcare workers,"The COVID-19 pandemic is a global health concern that has spread around the globe. Machine Learning is promising in the fight against the COVID-19 pandemic. Machine learning and artificial intelligence have been employed by various healthcare providers, scientists, and clinicians in medical industries in the fight against COVID-19 disease. In this paper, we discuss the impact of the Covid-19 pandemic on alcohol consumption habit changes among healthcare workers in the United States during the first wave of the Covid-19 pandemic. We utilize multiple supervised and unsupervised machine learning methods and models such as decision trees, logistic regression, support vector machines, multilayer perceptron, XGBoost, CatBoost, LightGBM, AdaBoost, Chi-Squared Test, mutual information, KModes clustering and the synthetic minority oversampling technique on a mental health survey data obtained from the University of Michigan Inter-University Consortium for Political and Social Research to investigate the links between COVID-19-related deleterious effects and changes in alcohol consumption habits among healthcare workers. Through the interpretation of the supervised and unsupervised methods, we have concluded that healthcare workers whose children stayed home during the first wave in the US consumed more alcohol. We also found that the work schedule changes due to the Covid-19 pandemic led to a change in alcohol use habits. Changes in food consumption, age, gender, geographical characteristics, changes in sleep habits, the amount of news consumption, and screen time are also important predictors of an increase in alcohol use among healthcare workers in the United States.",True,other,CNN
37027837,Machine-learning enhancement of urine dipstick tests for chronic kidney disease detection,"OBJECTIVE: Screening for chronic kidney disease (CKD) requires an estimated glomerular filtration rate (eGFR, mL/min/1.73 m2) from a blood sample and a proteinuria level from a urinalysis. We developed machine-learning models to detect CKD without blood collection, predicting an eGFR less than 60 (eGFR60 model) or 45 (eGFR45 model) using a urine dipstick test.
MATERIALS AND METHODS: The electronic health record data (n = 220 018) obtained from university hospitals were used for XGBoost-derived model construction. The model variables were age, sex, and 10 measurements from the urine dipstick test. The models were validated using health checkup center data (n = 74 380) and nationwide public data (KNHANES data, n = 62 945) for the general population in Korea.
RESULTS: The models comprised 7 features, including age, sex, and 5 urine dipstick measurements (protein, blood, glucose, pH, and specific gravity). The internal and external areas under the curve (AUCs) of the eGFR60 model were 0.90 or higher, and a higher AUC for the eGFR45 model was obtained. For the eGFR60 model on KNHANES data, the sensitivity was 0.93 or 0.80, and the specificity was 0.86 or 0.85 in ages less than 65 with proteinuria (nondiabetes or diabetes, respectively). Nonproteinuric CKD could be detected in nondiabetic patients under the age of 65 with a sensitivity of 0.88 and specificity of 0.71.
DISCUSSION AND CONCLUSIONS: The model performance differed across subgroups by age, proteinuria, and diabetes. The CKD progression risk can be assessed with the eGFR models using the levels of eGFR decrease and proteinuria. The machine-learning-enhanced urine-dipstick test can become a point-of-care test to promote public health by screening CKD and ranking its risk of progression.",True,other,Not specified
37024922,Explainable prediction of daily hospitalizations for cerebrovascular disease using stacked ensemble learning,"BACKGROUND: With the prevalence of cerebrovascular disease (CD) and the increasing strain on healthcare resources, forecasting the healthcare demands of cerebrovascular patients has significant implications for optimizing medical resources.
METHODS: In this study, a stacking ensemble model comprised of four base learners (ridge regression, random forest, gradient boosting decision tree, and artificial neural network) and a meta learner (elastic net) was proposed for predicting the daily number of hospital admissions (HAs) for CD using the historical HAs data, air quality data, and meteorological data in Chengdu, China from 2015 to 2018. To solve the label imbalance problem, a re-weighting method based on label distribution smoothing was integrated into the meta learner. We trained the model using the data from 2015 to 2017 and evaluated its predictive ability using the data in 2018 based on four metrics, including mean absolute error (MAE), root mean square error (RMSE), mean absolute percentage error (MAPE), and coefficient of determination (R2). In addition, the SHapley Additive exPlanations (SHAP) framework was applied to provide explanation for the prediction of our stacking model.
RESULTS: Our proposed model outperformed all the base learners and long short-term memory (LSTM) on two datasets. Particularly, compared with the optimal results obtained by individual models, the MAE, RMSE, and MAPE of the stacking model decreased by 13.9%, 12.7%, and 5.8%, respectively, and the R2 improved by 6.8% on CD dataset. The model explanation demonstrated that environmental features played a role in further improving the model performance and identified that high temperature and high concentrations of gaseous air pollutants might strongly associate with an increased risk of CD.
CONCLUSIONS: Our stacking model considering environmental exposure is efficient in predicting daily HAs for CD and has practical value in early warning and healthcare resource allocation.",True,text mining,Not specified
36972530,Explainable Machine Learning Model to Predict COVID-19 Severity Among Older Adults in the Province of Quebec,"Context: Patients over the age of 65 years are more likely to experience higher severity and mortality rates than other populations from COVID-19. Clinicians need assistance in supporting their decisions regarding the management of these patients. Artificial Intelligence (AI) can help with this regard. However, the lack of explainability-defined as ""the ability to understand and evaluate the internal mechanism of the algorithm/computational process in human terms""-of AI is one of the major challenges to its application in health care. We know little about application of explainable AI (XAI) in health care. Objective: In this study, we aimed to evaluate the feasibility of the development of explainable machine learning models to predict COVID-19 severity among older adults. Design: Quantitative machine learning methods. Setting: Long-term care facilities within the province of Quebec. Participants: Patients 65 years and older presented to the hospitals who had a positive polymerase chain reaction test for COVID-19. Intervention: We used XAI-specific methods (e.g., EBM), machine learning methods (i.e., random forest, deep forest, and XGBoost), as well as explainable approaches such as LIME, SHAP, PIMP, and anchor with the mentioned machine learning methods. Outcome measures: Classification accuracy and area under the receiver operating characteristic curve (AUC). Results: The age distribution of the patients (n=986, 54.6% male) was 84.5□19.5 years. The best-performing models (and their performance) were as follows. Deep forest using XAI agnostic methods LIME (97.36% AUC, 91.65 ACC), Anchor (97.36% AUC, 91.65 ACC), and PIMP (96.93% AUC, 91.65 ACC). We found alignment with the identified reasoning of our models' predictions and clinical studies' findings-about the correlation of different variables such as diabetes and dementia, and the severity of COVID-19 in this population. Conclusions: The use of explainable machine learning models, to predict the severity of COVID-19 among older adults is feasible. We obtained a high-performance level as well as explainability in the prediction of COVID-19 severity in this population. Further studies are required to integrate these models into a decision support system to facilitate the management of diseases such as COVID-19 for (primary) health care providers and evaluate their usability among them.",True,computer vision,Not specified
36959459,Prediction of cardiovascular disease risk based on major contributing features,"The risk of cardiovascular disease (CVD) is a serious health threat to human society worldwide. The use of machine learning methods to predict the risk of CVD is of great relevance to identify high-risk patients and take timely interventions. In this study, we propose the XGBH machine learning model, which is a CVD risk prediction model based on key contributing features. In this paper, the generalisation of the model was enhanced by adding retrospective data of 14,832 Chinese Shanxi CVD patients to the kaggle dataset. The XGBH risk prediction model proposed in this paper was validated to be highly accurate (AUC = 0.81) compared to the baseline risk score (AUC = 0.65), and the accuracy of the model for CVD risk prediction was improved with the inclusion of the conventional biometric BMI variable. To increase the clinical application of the model, a simpler diagnostic model was designed in this paper, which requires only three characteristics from the patient (age, value of systolic blood pressure and whether cholesterol is normal or not) to enable early intervention in the treatment of high-risk patients with a slight reduction in accuracy (AUC = 0.79). Ultimately, a CVD risk score model with few features and high accuracy will be established based on the main contributing features. Of course, further prospective studies, as well as studies with other populations, are needed to assess the actual clinical effectiveness of the XGBH risk prediction model.",True,other,Not specified
36881437,Personalized Antiviral Drug Selection in Patients With Chronic Hepatitis B Using a Machine Learning Model: A Multinational Study,"INTRODUCTION: Tenofovir disoproxil fumarate (TDF) is reportedly superior or at least comparable to entecavir (ETV) for the prevention of hepatocellular carcinoma (HCC) in patients with chronic hepatitis B; however, it has distinct long-term renal and bone toxicities. This study aimed to develop and validate a machine learning model (designated as Prediction of Liver cancer using Artificial intelligence-driven model for Network-antiviral Selection for hepatitis B [PLAN-S]) to predict an individualized risk of HCC during ETV or TDF therapy.
METHODS: This multinational study included 13,970 patients with chronic hepatitis B. The derivation (n = 6,790), Korean validation (n = 4,543), and Hong Kong-Taiwan validation cohorts (n = 2,637) were established. Patients were classified as the TDF-superior group when a PLAN-S-predicted HCC risk under ETV treatment is greater than under TDF treatment, and the others were defined as the TDF-nonsuperior group.
RESULTS: The PLAN-S model was derived using 8 variables and generated a c-index between 0.67 and 0.78 for each cohort. The TDF-superior group included a higher proportion of male patients and patients with cirrhosis than the TDF-nonsuperior group. In the derivation, Korean validation, and Hong Kong-Taiwan validation cohorts, 65.3%, 63.5%, and 76.4% of patients were classified as the TDF-superior group, respectively. In the TDF-superior group of each cohort, TDF was associated with a significantly lower risk of HCC than ETV (hazard ratio = 0.60-0.73, all P < 0.05). In the TDF-nonsuperior group, however, there was no significant difference between the 2 drugs (hazard ratio = 1.16-1.29, all P > 0.1).
DISCUSSION: Considering the individual HCC risk predicted by PLAN-S and the potential TDF-related toxicities, TDF and ETV treatment may be recommended for the TDF-superior and TDF-nonsuperior groups, respectively.",True,other,Not specified
36823660,Machine learning-based model for predicting the esophagogastric variceal bleeding risk in liver cirrhosis patients,"BACKGROUND: Liver cirrhosis patients are at risk for esophagogastric variceal bleeding (EGVB). Herein, we aimed to estimate the EGVB risk in patients with liver cirrhosis using an artificial neural network (ANN).
METHODS: We included 999 liver cirrhosis patients hospitalized at the Beijing Ditan Hospital, Capital Medical University in the training cohort and 101 patients from Shuguang Hospital in the validation cohort. The factors independently affecting EGVB occurrence were determined via univariate analysis and used to develop an ANN model.
RESULTS: The 1-year cumulative EGVB incidence rates were 11.9 and 11.9% in the training and validation groups, respectively. A total of 12 independent risk factors, including gender, drinking and smoking history, decompensation, ascites, location and size of varices, alanine aminotransferase (ALT), γ-glutamyl transferase (GGT), hematocrit (HCT) and neutrophil-lymphocyte ratio (NLR) levels as well as red blood cell (RBC) count were evaluated and used to establish the ANN model, which estimated the 1-year EGVB risk. The ANN model had an area under the curve (AUC) of 0.959, which was significantly higher than the AUC for the North Italian Endoscopic Club (NIEC) (0.669) and revised North Italian Endoscopic Club (Rev-NIEC) indices (0.725) (all P <  0.001). Decision curve analyses revealed improved net benefits of the ANN compared to the NIEC and Rev-NIEC indices.
CONCLUSIONS: The ANN model accurately predicted the 1-year risk for EGVB in liver cirrhosis patients and might be used as a basis for risk-based EGVB surveillance strategies.",True,both,Not specified
36765157,Generalizable machine learning approach for COVID-19 mortality risk prediction using on-admission clinical and laboratory features,"We aimed to propose a mortality risk prediction model using on-admission clinical and laboratory predictors. We used a dataset of confirmed COVID-19 patients admitted to three general hospitals in Tehran. Clinical and laboratory values were gathered on admission. Six different machine learning models and two feature selection methods were used to assess the risk of in-hospital mortality. The proposed model was selected using the area under the receiver operator curve (AUC). Furthermore, a dataset from an additional hospital was used for external validation. 5320 hospitalized COVID-19 patients were enrolled in the study, with a mortality rate of 17.24% (N = 917). Among 82 features, ten laboratories and 27 clinical features were selected by LASSO. All methods showed acceptable performance (AUC > 80%), except for K-nearest neighbor. Our proposed deep neural network on features selected by LASSO showed AUC scores of 83.4% and 82.8% in internal and external validation, respectively. Furthermore, our imputer worked efficiently when two out of ten laboratory parameters were missing (AUC = 81.8%). We worked intimately with healthcare professionals to provide a tool that can solve real-world needs. Our model confirmed the potential of machine learning methods for use in clinical practice as a decision-support system.",True,computer vision,Not specified
36714611,Fairness in the prediction of acute postoperative pain using machine learning models,"INTRODUCTION: Overall performance of machine learning-based prediction models is promising; however, their generalizability and fairness must be vigorously investigated to ensure they perform sufficiently well for all patients.
OBJECTIVE: This study aimed to evaluate prediction bias in machine learning models used for predicting acute postoperative pain.
METHOD: We conducted a retrospective review of electronic health records for patients undergoing orthopedic surgery from June 1, 2011, to June 30, 2019, at the University of Florida Health system/Shands Hospital. CatBoost machine learning models were trained for predicting the binary outcome of low (≤4) and high pain (>4). Model biases were assessed against seven protected attributes of age, sex, race, area deprivation index (ADI), speaking language, health literacy, and insurance type. Reweighing of protected attributes was investigated for reducing model bias compared with base models. Fairness metrics of equal opportunity, predictive parity, predictive equality, statistical parity, and overall accuracy equality were examined.
RESULTS: The final dataset included 14,263 patients [age: 60.72 (16.03) years, 53.87% female, 39.13% low acute postoperative pain]. The machine learning model (area under the curve, 0.71) was biased in terms of age, race, ADI, and insurance type, but not in terms of sex, language, and health literacy. Despite promising overall performance in predicting acute postoperative pain, machine learning-based prediction models may be biased with respect to protected attributes.
CONCLUSION: These findings show the need to evaluate fairness in machine learning models involved in perioperative pain before they are implemented as clinical decision support tools.",True,other,Not specified
36684185,Establishment of prognostic models of adrenocortical carcinoma using machine learning and big data,"BACKGROUND: Adrenocortical carcinoma (ACC) is a rare malignant tumor with a short life expectancy. It is important to identify patients at high risk so that doctors can adopt more aggressive regimens to treat their condition. Machine learning has the advantage of processing complicated data. To date, there is no research that tries to use machine learning algorithms and big data to construct prognostic models for ACC patients.
METHODS: Clinical data of patients with ACC were obtained from the Surveillance, Epidemiology, and End Results (SEER) database. These records were screened according to preset inclusion and exclusion criteria. The remaining data were applied to univariate survival analysis to select meaningful outcome-related candidates. Backpropagation artificial neural network (BP-ANN), random forest (RF), support vector machine (SVM), and naive Bayes classifier (NBC) were chosen as alternative algorithms. The acquired cases were grouped into a training set and a test set at a ratio of 8:2, and a 10-fold cross-validation method repeated 10 times was performed. Area under the receiver operating characteristic (AUROC) curves were used as indices of efficiency.
RESULTS: The calculated 1-, 3-, 5-, and 10-year overall survival rates were 62.3%, 42.0%, 34.9%, and 26.1%, respectively. A total of 825 patients were included in the study. In the training set, the AUCs of BP-ANN, RF, SVM, and NBC for predicting 1-year survival status were 0.921, 0.885, 0.865, and 0.854; those for predicting 3-year survival status were 0.859, 0.865, 0.837, and 0.831; and those for 5-year survival status were 0.888, 0.872, 0.852, and 0.841, respectively. In the test set, AUCs of these four models for 1-year survival status were 0.899, 0.875, 0.886, and 0.862; those for 3-year survival status were 0.871, 0.858, 0.853, and 0.869; and those for 5-year survival status were 0.841, 0.783, 0.836, and 0.867, respectively. The consequences of the 10-fold cross-validation method repeated 10 times indicated that the mean values of 1-, 3-, and 5-year AUROCs of BP-ANN were 0.890, 0.847, and 0.854, respectively, which were better than those of other classifiers (P &lt; 0.008).
CONCLUSION: The model combined with BP-ANN and big data can precisely predict the survival status of ACC patients and has the potential for clinical application.",True,other,Not specified
36658644,Cardiovascular complications in a diabetes prediction model using machine learning: a systematic review,"Prediction model has been the focus of studies since the last century in the diagnosis and prognosis of various diseases. With the advancement in computational technology, machine learning (ML) has become the widely used tool to develop a prediction model. This review is to investigate the current development of prediction model for the risk of cardiovascular disease (CVD) among type 2 diabetes (T2DM) patients using machine learning. A systematic search on Scopus and Web of Science (WoS) was conducted to look for relevant articles based on the research question. The risk of bias (ROB) for all articles were assessed based on the Prediction model Risk of Bias Assessment Tool (PROBAST) statement. Neural network with 76.6% precision, 88.06% sensitivity, and area under the curve (AUC) of 0.91 was found to be the most reliable algorithm in developing prediction model for cardiovascular disease among type 2 diabetes patients. The overall concern of applicability of all included studies is low. While two out of 10 studies were shown to have high ROB, another studies ROB are unknown due to the lack of information. The adherence to reporting standards was conducted based on the Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD) standard where the overall score is 53.75%. It is highly recommended that future model development should adhere to the PROBAST and TRIPOD assessment to reduce the risk of bias and ensure its applicability in clinical settings. Potential lipid peroxidation marker is also recommended in future cardiovascular disease prediction model to improve overall model applicability.",True,other,recurrent neural network
36642513,Machine Learning-based Models for Outpatient Prescription of Kampo Formulations: An Analysis of a Health Insurance Claims Database,"BACKGROUND: Despite the widespread practice of Japanese traditional Kampo medicine, the characteristics of patients receiving various Kampo formulations have not been documented in detail. We applied a machine learning model to a health insurance claims database to identify the factors associated with the use of Kampo formulations.
METHODS: A 10% sample of enrollees of the JMDC Claims Database in 2018 and 2019 was used to create the training and testing sets, respectively. Logistic regression analyses with lasso regularization were performed in the training set to construct models with prescriptions of 10 commonly used Kampo formulations in 1 year as the dependent variable and data of the preceding year as independent variables. Models were applied to the testing set to calculate the C-statistics. Additionally, the performance of simplified scores using 10 or 5 variables were evaluated.
RESULTS: There were 338,924 and 399,174 enrollees in the training and testing sets, respectively. The commonly prescribed Kampo formulations included kakkonto, bakumondoto, and shoseityuto. Based on the lasso models, the C-statistics ranged from 0.643 (maoto) to 0.888 (tokishakuyakusan). The models identified both the common determinants of different Kampo formulations and the specific characteristics associated with particular Kampo formulations. The simplified scores were slightly inferior to full models.
CONCLUSION: Lasso regression models showed good performance for explaining various Kampo prescriptions from claims data. The models identified the characteristics associated with Kampo formulation use.",True,other,Not specified
36618315,"Explanation of COVID-19 Mortality Using Artificial Neural Network Based on Underlying and Laboratory Risk Factors in Ilam, Iran","The spread of new waves of coronavirus outbreaks, high mortality rates, and time-consuming and numerous challenges in achieving collective safety through vaccination and the need to prioritize the allocation of vaccines to the general population have led to the continued identification of risk factors associated with mortality in patients through innovative strategies and new statistical models. In this study, an artificial neural network (ANN) model was used to predict morbidity in patients with coronavirus disease 2019 (COVID-19). Data of 2,206 patients were extracted from the registry program of Shahid Mostafa Khomeini Hospital in Ilam, Iran, and were randomly analyzed in two training (1,544) and testing (662) groups. By fitting different models of a three-layer neural network, 12 variables could explain more than 77% of the mortality variance in COVID-19 patients. These findings could be used to better mortality management, vaccination prioritization, public education, and quarantine, and allocation of intensive care beds to reduce COVID-19 mortality. The results also confirmed the power of a better explanation of ANN models to predict the mortality of patients.",True,computer vision,Not specified
36588391,Machine learning-based prediction of 1-year mortality in hypertensive patients undergoing coronary revascularization surgery,"BACKGROUND: Machine learning (ML) has shown promising results in all fields of medicine, including preventive cardiology. Hypertensive patients are at higher risk of mortality after coronary artery bypass graft (CABG) surgery; thus, we aimed to design and evaluate five ML models to predict 1-year mortality among hypertensive patients who underwent CABG.
HYOTHESIS: ML algorithms can significantly improve mortality prediction after CABG.
METHODS: Tehran Heart Center's CABG data registry was used to extract several baseline and peri-procedural characteristics and mortality data. The best features were chosen using random forest (RF) feature selection algorithm. Five ML models were developed to predict 1-year mortality: logistic regression (LR), RF, artificial neural network (ANN), extreme gradient boosting (XGB), and naïve Bayes (NB). The area under the curve (AUC), sensitivity, and specificity were used to evaluate the models.
RESULTS: Among the 8,493 hypertensive patients who underwent CABG (mean age of 68.27 ± 9.27 years), 303 died in the first year. Eleven features were selected as the best predictors, among which total ventilation hours and ejection fraction were the leading ones. LR showed the best prediction ability with an AUC of 0.82, while the least AUC was for the NB model (0.79). Among the subgroups, the highest AUC for LR model was for two age range groups (50-59 and 80-89 years), overweight, diabetic, and smoker subgroups of hypertensive patients.
CONCLUSIONS: All ML models had excellent performance in predicting 1-year mortality among CABG hypertension patients, while LR was the best regarding AUC. These models can help clinicians assess the risk of mortality in specific subgroups at higher risk (such as hypertensive ones).",True,other,Not specified
36563696,Machine learning-based marker for coronary artery disease: derivation and validation in two longitudinal cohorts,"BACKGROUND: Binary diagnosis of coronary artery disease does not preserve the complexity of disease or quantify its severity or its associated risk with death; hence, a quantitative marker of coronary artery disease is warranted. We evaluated a quantitative marker of coronary artery disease derived from probabilities of a machine learning model.
METHODS: In this cohort study, we developed and validated a coronary artery disease-predictive machine learning model using 95 935 electronic health records and assessed its probabilities as in-silico scores for coronary artery disease (ISCAD; range 0 [lowest probability] to 1 [highest probability]) in participants in two longitudinal biobank cohorts. We measured the association of ISCAD with clinical outcomes-namely, coronary artery stenosis, obstructive coronary artery disease, multivessel coronary artery disease, all-cause death, and coronary artery disease sequelae.
FINDINGS: Among 95 935 participants, 35 749 were from the BioMe Biobank (median age 61 years [IQR 18]; 14 599 [41%] were male and 21 150 [59%] were female; 5130 [14%] were with diagnosed coronary artery disease) and 60 186 were from the UK Biobank (median age 62 [15] years; 25 031 [42%] male and 35 155 [58%] female; 8128 [14%] with diagnosed coronary artery disease). The model predicted coronary artery disease with an area under the receiver operating characteristic curve of 0·95 (95% CI 0·94-0·95; sensitivity of 0·94 [0·94-0·95] and specificity of 0·82 [0·81-0·83]) and 0·93 (0·92-0·93; sensitivity of 0·90 [0·89-0·90] and specificity of 0·88 [0·87-0·88]) in the BioMe validation and holdout sets, respectively, and 0·91 (0·91-0·91; sensitivity of 0·84 [0·83-0·84] and specificity of 0·83 [0·82-0·83]) in the UK Biobank external test set. ISCAD captured coronary artery disease risk from known risk factors, pooled cohort equations, and polygenic risk scores. Coronary artery stenosis increased quantitatively with ascending ISCAD quartiles (increase per quartile of 12 percentage points), including risk of obstructive coronary artery disease, multivessel coronary artery disease, and stenosis of major coronary arteries. Hazard ratios (HRs) and prevalence of all-cause death increased stepwise over ISCAD deciles (decile 1: HR 1·0 [95% CI 1·0-1·0], 0·2% prevalence; decile 6: 11 [3·9-31], 3·1% prevalence; and decile 10: 56 [20-158], 11% prevalence). A similar trend was observed for recurrent myocardial infarction. 12 (46%) undiagnosed individuals with high ISCAD (≥0·9) had clinical evidence of coronary artery disease according to the 2014 American College of Cardiology/American Heart Association Task Force guidelines.
INTERPRETATION: Electronic health record-based machine learning was used to generate an in-silico marker for coronary artery disease that can non-invasively quantify atherosclerosis and risk of death on a continuous spectrum, and identify underdiagnosed individuals.
FUNDING: National Institutes of Health.",True,other,Not specified
36512364,Real-time online monitoring of insect cell proliferation and baculovirus infection using digital differential holographic microscopy and machine learning,"Real-time, detailed online information on cell cultures is essential for understanding modern biopharmaceutical production processes. The determination of key parameters, such as cell density and viability, is usually based on the offline sampling of bioreactors. Gathering offline samples is invasive, has a low time resolution, and risks altering or contaminating the production process. In contrast, measuring process parameters online provides more safety for the process, has a high time resolution, and thus can aid in timely process control actions. We used online double differential digital holographic microscopy (D3HM) and machine learning to perform non-invasive online cell concentration and viability monitoring of insect cell cultures in bioreactors. The performance of D3HM and the machine learning model was tested for a selected variety of baculovirus constructs, products, and multiplicities of infection (MOI). The results show that with online holographic microscopy insect cell proliferation and baculovirus infection can be monitored effectively in real time with high resolution for a broad range of process parameters and baculovirus constructs. The high-resolution data generated by D3HM showed the exact moment of peak cell densities and temporary events caused by feeding. Furthermore, D3HM allowed us to obtain information on the state of the cell culture at the individual cell level. Combining this detailed, real-time information about cell cultures with methodical machine learning models can increase process understanding, aid in decision-making, and allow for timely process control actions during bioreactor production of recombinant proteins.",True,text mining,Not specified
36477923,Building a better machine learning model of extubation for neurocritical care patients. Author's reply,,True,other,GAN
36429751,Machine Learning Models for Data-Driven Prediction of Diabetes by Lifestyle Type,"The prevalence of diabetes has been increasing in recent years, and previous research has found that machine-learning models are good diabetes prediction tools. The purpose of this study was to compare the efficacy of five different machine-learning models for diabetes prediction using lifestyle data from the National Health and Nutrition Examination Survey (NHANES) database. The 1999-2020 NHANES database yielded data on 17,833 individuals data based on demographic characteristics and lifestyle-related variables. To screen training data for machine models, the Akaike Information Criterion (AIC) forward propagation algorithm was utilized. For predicting diabetes, five machine-learning models (CATBoost, XGBoost, Random Forest (RF), Logistic Regression (LR), and Support Vector Machine (SVM)) were developed. Model performance was evaluated using accuracy, sensitivity, specificity, precision, F1 score, and receiver operating characteristic (ROC) curve. Among the five machine-learning models, the dietary intake levels of energy, carbohydrate, and fat, contributed the most to the prediction of diabetes patients. In terms of model performance, CATBoost ranks higher than RF, LG, XGBoost, and SVM. The best-performing machine-learning model among the five is CATBoost, which achieves an accuracy of 82.1% and an AUC of 0.83. Machine-learning models based on NHANES data can assist medical institutions in identifying diabetes patients.",True,other,recurrent neural network
36383630,Early detection of norovirus outbreak using machine learning methods in South Korea,"BACKGROUND: The norovirus is a major cause of acute gastroenteritis at all ages but particularly has a high chance of affecting children under the age of five. Given that the outbreak of norovirus in Korea is seasonal, it is important to try and predict the start and end of norovirus outbreaks.
METHODS: We predicted weekly norovirus warnings using six machine learning algorithms using test data from 2017 to 2018 and training data from 2009 to 2016. In addition, we proposed a novel method for the early detection of norovirus using a calculated norovirus risk index. Further, feature importance was calculated to evaluate the contribution of the estimated weekly norovirus warnings.
RESULTS: The long short-term memory machine learning (LSTM) algorithm proved to be the best algorithm for predicting weekly norovirus warnings, with 97.2% and 92.5% accuracy in the training and test data, respectively. The LSTM algorithm predicted the observed start and end weeks of the early detection of norovirus within a 3-week range.
CONCLUSIONS: The results of this study show that early detection can provide important insights for the preparation and control of norovirus outbreaks by the government. Our method provides indicators of high-risk weeks. In particular, last norovirus detection rate, minimum temperature, and day length, play critical roles in estimating weekly norovirus warnings.",True,other,Not specified
36366562,A Modified PINN Approach for Identifiable Compartmental Models in Epidemiology with Application to COVID-19,"Many approaches using compartmental models have been used to study the COVID-19 pandemic, with machine learning methods applied to these models having particularly notable success. We consider the Susceptible-Infected-Confirmed-Recovered-Deceased (SICRD) compartmental model, with the goal of estimating the unknown infected compartment I, and several unknown parameters. We apply a variation of a ""Physics Informed Neural Network"" (PINN), which uses knowledge of the system to aid learning. First, we ensure estimation is possible by verifying the model's identifiability. Then, we propose a wavelet transform to process data for the network training. Finally, our central result is a novel modification of the PINN's loss function to reduce the number of simultaneously considered unknowns. We find that our modified network is capable of stable, efficient, and accurate estimation, while the unmodified network consistently yields incorrect values. The modified network is also shown to be efficient enough to be applied to a model with time-varying parameters. We present an application of our model results for ranking states by their estimated relative testing efficiency. Our findings suggest the effectiveness of our modified PINN network, especially in the case of multiple unknown variables.",True,other,recurrent neural network
36362822,Improvement of Mucosal Lesion Diagnosis with Machine Learning Based on Medical and Semiological Data: An Observational Study,"Despite artificial intelligence used in skin dermatology diagnosis is booming, application in oral pathology remains to be developed. Early diagnosis and therefore early management, remain key points in the successful management of oral mucosa cancers. The objective was to develop and evaluate a machine learning algorithm that allows the prediction of oral mucosa lesions diagnosis. This cohort study included patients followed between January 2015 and December 2020 in the oral mucosal pathology consultation of the Toulouse University Hospital. Photographs and demographic and medical data were collected from each patient to constitute clinical cases. A machine learning model was then developed and optimized and compared to 5 models classically used in the field. A total of 299 patients representing 1242 records of oral mucosa lesions were used to train and evaluate machine learning models. Our model reached a mean accuracy of 0.84 for diagnostic prediction. The specificity and sensitivity range from 0.89 to 1.00 and 0.72 to 0.92, respectively. The other models were proven to be less efficient in performing this task. These results suggest the utility of machine learning-based tools in diagnosing oral mucosal lesions with high accuracy. Moreover, the results of this study confirm that the consideration of clinical data and medical history, in addition to the lesion itself, appears to play an important role.",True,other,Not specified
36350808,Ensemble learning-based feature engineering to analyze maternal health during pregnancy and health risk prediction,"Maternal health is an important aspect of women's health during pregnancy, childbirth, and the postpartum period. Specifically, during pregnancy, different health factors like age, blood disorders, heart rate, etc. can lead to pregnancy complications. Detecting such health factors can alleviate the risk of pregnancy-related complications. This study aims to develop an artificial neural network-based system for predicting maternal health risks using health data records. A novel deep neural network architecture, DT-BiLTCN is proposed that uses decision trees, a bidirectional long short-term memory network, and a temporal convolutional network. Experiments involve using a dataset of 1218 samples collected from maternal health care, hospitals, and community clinics using the IoT-based risk monitoring system. Class imbalance is resolved using the synthetic minority oversampling technique. DT-BiLTCN provides a feature set to obtain high accuracy results which in this case are provided by the support vector machine with a 98% accuracy. Maternal health exploratory data analysis reveals that the health conditions which are the strongest indications of health risk during pregnancy are diastolic and systolic blood pressure, heart rate, and age of pregnant women. Using the proposed model, timely prediction of health risks associated with pregnant women can be made thus mitigating the risk of health complications which helps to save lives.",True,other,Not specified
36339144,Individualized prediction of chronic kidney disease for the elderly in longevity areas in China: Machine learning approaches,"BACKGROUND: Chronic kidney disease (CKD) has become a major public health problem worldwide and has caused a huge social and economic burden, especially in developing countries. No previous study has used machine learning (ML) methods combined with longitudinal data to predict the risk of CKD development in 2 years amongst the elderly in China.
METHODS: This study was based on the panel data of 925 elderly individuals in the 2012 baseline survey and 2014 follow-up survey of the Healthy Aging and Biomarkers Cohort Study (HABCS) database. Six ML models, logistic regression (LR), lasso regression, random forests (RF), gradient-boosted decision tree (GBDT), support vector machine (SVM), and deep neural network (DNN), were developed to predict the probability of CKD amongst the elderly in 2 years (the year of 2014). The decision curve analysis (DCA) provided a range of threshold probability of the outcome and the net benefit of each ML model.
RESULTS: Amongst the 925 elderly in the HABCS 2014 survey, 289 (18.8%) had CKD. Compared with the other models, LR, lasso regression, RF, GBDT, and DNN had no statistical significance of the area under the receiver operating curve (AUC) value (&gt;0.7), and SVM exhibited the lowest predictive performance (AUC = 0.633, p-value = 0.057). DNN had the highest positive predictive value (PPV) (0.328), whereas LR had the lowest (0.287). DCA results indicated that within the threshold ranges of ~0-0.03 and 0.37-0.40, the net benefit of GBDT was the largest. Within the threshold ranges of ~0.03-0.10 and 0.26-0.30, the net benefit of RF was the largest. Age was the most important predictor variable in the RF and GBDT models. Blood urea nitrogen, serum albumin, uric acid, body mass index (BMI), marital status, activities of daily living (ADL)/instrumental activities of daily living (IADL) and gender were crucial in predicting CKD in the elderly.
CONCLUSION: The ML model could successfully capture the linear and nonlinear relationships of risk factors for CKD in the elderly. The decision support system based on the predictive model in this research can help medical staff detect and intervene in the health of the elderly early.",True,other,Not specified
36320680,A physics-informed neural network to model COVID-19 infection and hospitalization scenarios,"In this paper, we replace the standard numerical approach of estimating parameters in a mathematical model using numerical solvers for differential equations with a physics-informed neural network (PINN). This neural network requires a sequence of time instances as direct input of the network and the numbers of susceptibles, vaccinated, infected, hospitalized, and recovered individuals per time instance to learn certain parameters of the underlying model, which are used for the loss calculations. The established model is an extended susceptible-infected-recovered (SIR) model in which the transitions between disease-related population groups, called compartments, and the physical laws of epidemic transmission dynamics are expressed by a system of ordinary differential equations (ODEs). The system of ODEs and its time derivative are included in the residual loss function of the PINN in addition to the data error between the current network output and the time series data of the compartment sizes. Further, we illustrate how this PINN approach can also be used for differential equation-based models such as the proposed extended SIR model, called SVIHR model. In a validation process, we compare the performance of the PINN with results obtained with the numerical technique of non-standard finite differences (NSFD) in generating future COVID-19 scenarios based on the parameters identified by the PINN. The used training data set covers the time between the outbreak of the pandemic in Germany and the last week of the year 2021. We obtain a two-step or hybrid approach, as the PINN is then used to generate a future COVID-19 outbreak scenario describing a possibly next pandemic wave. The week at which the prediction starts is chosen in mid-April 2022.",True,text mining,recurrent neural network
36304749,Efficient Model for Coronary Artery Disease Diagnosis: A Comparative Study of Several Machine Learning Algorithms,"BACKGROUND: In today's industrialized world, coronary artery disease (CAD) is one of the leading causes of death, and early detection and timely intervention can prevent many of its complications and eliminate or reduce the resulting mortality. Machine learning (ML) methods as one of the cutting-edge technologies can be used as a suitable solution in diagnosing this disease.
METHODS: In this study, different ML algorithms' performances were compared for their effectiveness in developing a model for early CAD diagnosis based on clinical examination features. This applied descriptive study was conducted on 303 records and overall 26 features, of which 26 were selected as the target features with the advice of several clinical experts. In order to provide a diagnostic model for CAD, we ran most of the most critical classification algorithms, including Multilayer Perceptron (MLP), Support Vector Machine (SVM), Logistic Regression (LR), J48, Random Forest (RF), K-Nearest Neighborhood (KNN), and Naive Bayes (NB). Seven different classification algorithms with 26 predictive features were tested to cover all feature space and reduce model error, and the most efficient algorithms were identified by comparison of the results.
RESULTS: Based on the compared performance metrics, SVM (AUC = 0.88, F-measure = 0.88, ROC = 0.85), and RF (AUC = 0.87, F-measure = 0.87, ROC = 0.91) were the most effective ML algorithms. Among the algorithms, the KNN algorithm had the lowest efficiency (AUC = 0.81, F-measure = 0.81, ROC = 0.77). In the diagnosis of coronary artery disease, machine learning algorithms have played an important role. Proposed ML models can provide practical, cost-effective, and valuable support to doctors in making decisions according to a good prediction. Discussion. It can become the basis for developing clinical decision support systems. SVM and RF algorithms had the highest efficiency and could diagnose CAD based on patient examination data. It is suggested that further studies be performed using these algorithms to diagnose coronary artery disease to obtain more accurate results.",True,other,Not specified
36226692,Machine learning model-based risk prediction of severe complications after off-pump coronary artery bypass grafting,"BACKGROUND: Compared with coronary artery bypass grafting (CABG) under cardiopulmonary bypass, off-pump coronary artery bypass (OPCAB) is minimally invasive and reduces the risk of intraoperative blood transfusion and acute kidney injury. Nonetheless, OPCAB-related complications still pose a threat. Machine learning technology can analyze a large number of clinical data, establish risk prediction models and help clinicians make early and correct clinical decisions.
OBJECTIVES: Risk prediction models are available for mortality and morbidity after cardiac surgery, but they are not specific to OPCAB. This study aimed to develop a predictive model of severe complications after OPCAB, based on machine learning.
MATERIAL AND METHODS: Anesthesia records of OPCAB from the General Hospital of the Northern Theater Command (Shenyang, China) collected between January 1, 2019, and June 15, 2020, were analyzed. The endpoint of the study was the occurrence of serious complications after OPCAB (postoperative unplanned intra-aortic balloon pump, secondary surgery and death). The features entered into the models were as follows: intraoperative ventricular fibrillation, number of saphenous vein grafts, nerve block (NeB), venous oxygen saturation (SvO2), skin incision-bypass time, and hypertension. A total of 8 machine learning algorithms were tested: logistic regression analysis (LRA), k-nearest neighbor (KNN), naïve Bayes (NB), support vector machine (SVM), random forest (RF), extreme gradient boosting (XGBoost), light gradient boosting machine (LightGBM), and categorical features gradient boosting (CatBoost).
RESULTS: Among the 506 patients found in the records, 27 met the endpoint. The highest area under the curve (AUC) value was achieved with the XGBoost model (AUC = 0.94), and the lowest with the SVM model (AUC = 0.75). The highest and lowest accuracy were observed with the XGBoost and NB models, respectively, while the highest and lowest precision were achieved using the SVM and NB models, respectively. Based on the receiver operating characteristic (ROC) curves, the XGBoost model was selected as the most useful in this study.
CONCLUSIONS: This study suggests using the XGBoost model to predict the risk of complications after OPCAB.",True,other,Not specified
36224328,Opinion analysis and aspect understanding during covid-19 pandemic using BERT-Bi-LSTM ensemble method,"Social media platforms significantly increase general information about disease severity and inform preventive measures among community members. To identify public opinion through tweets on the subject of Covid-19 and investigate public sentiment in the country over the period. This article proposed a novel method for sentiment analysis of coronavirus-related tweets using bidirectional encoder representations from transformers (BERT) bi-directional long short-term memory (Bi-LSTM) ensemble learning model. The proposed approach consists of two stages. In the first stage, the BERT model gains the domain knowledge with Covid-19 data and fine-tunes with sentiment word dictionary. The second stage is the Bi-LSTM model, which is used to process the data in a bi-directional way with context sequence dependency preserving to process the data and classify the sentiment. Finally, the ensemble technique combines both models to classify the sentiment into positive and negative categories. The result obtained by the proposed method is better than the state-of-the-art methods. Moreover, the proposed model efficiently understands the public opinion on the Twitter platform, which can aid in formulating, monitoring and regulating public health policies during a pandemic.",True,other,convolutional neural network
36207680,Estimation of myocardial infarction death in Iran: artificial neural network,"BACKGROUND: Examining past trends and predicting the future helps policymakers to design effective interventions to deal with myocardial infarction (MI) with a clear understanding of the current and future situation. The aim of this study was to estimate the death rate due to MI in Iran by artificial neural network (ANN).
METHODS: In this ecological study, the prevalence of diabetes, hypercholesterolemia over 200, hypertension, overweight and obesity were estimated for the years 2017-2025. ANN and Linear regression model were used. Also, Specialists were also asked to predict the death rate due to MI by considering the conditions of 3 conditions (optimistic, pessimistic, and probable), and the predicted process was compared with the modeling process.
RESULTS: Death rate due to MI in Iran is expected to decrease on average, while there will be a significant decrease in the prevalence of hypercholesterolemia 1.031 (- 24.81, 26.88). Also, the trend of diabetes 10.48 (111.45, - 132.42), blood pressure - 110.48 (- 174.04, - 46.91) and obesity and overweight - 35.84 (- 18.66, - 5.02) are slowly increasing. MI death rate in Iran is higher in men but is decreasing on average. Experts' forecasts are different and have predicted a completely upward trend.
CONCLUSION: The trend predicted by the modeling shows that the death rate due to MI will decrease in the future with a low slope. Improving the infrastructure for providing preventive services to reduce the risk factors for cardiovascular disease in the community is one of the priority measures in the current situation.",True,both,Not specified
36194993,Decision support system and outcome prediction in a cohort of patients with necrotizing soft-tissue infections,"INTRODUCTION: Necrotizing Soft Tissue Infections (NSTI) are severe infections with high mortality affecting a heterogeneous patient population. There is a need for a clinical decision support system which predicts outcomes and provides treatment recommendations early in the disease course.
METHODS: To identify relevant clinical needs, interviews with eight medical professionals (surgeons, intensivists, general practitioner, emergency department physician) were conducted. This resulted in 24 unique questions. Mortality was selected as first endpoint to develop a machine learning (Random Forest) based prediction model. For this purpose, data from the prospective, international INFECT cohort (N = 409) was used.
RESULTS: Applying a feature selection procedure based on an unsupervised algorithm (Boruta) to the  > 1000 variables available in INFECT, including baseline, and both NSTI specific and NSTI non-specific clinical data yielded sixteen predictive parameters available on or prior to the first day on the intensive care unit (ICU). Using these sixteen variables 30-day mortality could be accurately predicted (AUC = 0.91, 95% CI 0.88-0.96). Except for age, all variables were related to sepsis (e.g. lactate, urine production, systole). No NSTI-specific variables were identified. Predictions significantly outperformed the SOFA score(p < 0.001, AUC = 0.77, 95% CI 0.69-0.84) and exceeded but did not significantly differ from the SAPS II score (p = 0.07, AUC = 0.88, 95% CI 0.83-0.92). The developed model proved to be stable with AUC  > 0.8 in case of high rates of missing data (50% missing) or when only using very early (<1 h) available variables.
CONCLUSIONS: This study shows that mortality can be accurately predicted using a machine learning model. It lays the foundation for a more extensive, multi-endpoint clinical decision support system in which ultimately other outcomes and clinical questions (risk for septic shock, AKI, causative microbe) will be included.",True,other,RNN
36194900,Validation and Improvement of a Machine Learning Model to Predict Interruptions in Antiretroviral Treatment in South Africa,"INTRODUCTION: Machine learning algorithms are increasingly being used to inform HIV prevention and detection strategies. We validated and extended a previously developed machine learning model for patient retention on antiretroviral therapy in a new geographic catchment area in South Africa.
METHODS: We compared the ability of an adaptive boosting algorithm to predict interruption in treatment (IIT) in 2 South African cohorts from the Free State and Mpumalanga and Gauteng and North West (GA/NW) provinces. We developed a novel set of predictive features for the GA/NW cohort using a categorical boosting model. We evaluated the ability of the model to predict IIT over all visits and across different periods within a patient's treatment trajectory.
RESULTS: When predicting IIT, the GA/NW and Free State and Mpumalanga models demonstrated a sensitivity of 60% and 61%, respectively, able to correctly predict nearly two-thirds of all missed visits with a positive predictive value of 18% and 19%. Using predictive features generated from the GA/NW cohort, the categorical boosting model correctly predicted 22,119 of a total of 35,985 missed next visits, yielding a sensitivity of 62%, specificity of 67%, and positive predictive value of 20%. Model performance was highest when tested on visits within the first 6 months.
CONCLUSIONS: Machine learning algorithms may be useful in informing tools to increase antiretroviral therapy patient retention and efficiency of HIV care interventions. This is particularly relevant in developing countries where health data systems are being strengthened to collect data on a scale that is large enough to apply novel analytical methods.",True,other,convolutional neural network
36088288,Machine learning prediction of postoperative major adverse cardiovascular events in geriatric patients: a prospective cohort study,"BACKGROUND: Postoperative major adverse cardiovascular events (MACEs) account for more than one-third of perioperative deaths. Geriatric patients are more vulnerable to postoperative MACEs than younger patients. Identifying high-risk patients in advance can help with clinical decision making and improve prognosis. This study aimed to develop a machine learning model for the preoperative prediction of postoperative MACEs in geriatric patients.
METHODS: We collected patients' clinical data and laboratory tests prospectively. All patients over 65 years who underwent surgeries in West China Hospital of Sichuan University from June 25, 2019 to June 29, 2020 were included. Models based on extreme gradient boosting (XGB), gradient boosting machine, random forest, support vector machine, and Elastic Net logistic regression were trained. The models' performance was compared according to area under the precision-recall curve (AUPRC), area under the receiver operating characteristic curve (AUROC) and Brier score. To minimize the influence of clinical intervention, we trained the model based on undersampling set. Variables with little contribution were excluded to simplify the model for ensuring the ease of use in clinical settings.
RESULTS: We enrolled 5705 geriatric patients into the final dataset. Of those patients, 171 (3.0%) developed postoperative MACEs within 30 days after surgery. The XGB model outperformed other machine learning models with AUPRC of 0.404(95% confidence interval [CI]: 0.219-0.589), AUROC of 0.870(95%CI: 0.786-0.938) and Brier score of 0.024(95% CI: 0.016-0.032). Model trained on undersampling set showed improved performance with AUPRC of 0.511(95% CI: 0.344-0.667, p < 0.001), AUROC of 0.912(95% CI: 0.847-0.962, p < 0.001) and Brier score of 0.020 (95% CI: 0.013-0.028, p < 0.001). After removing variables with little contribution, the undersampling model showed comparable predictive accuracy with AUPRC of 0.507(95% CI: 0.338-0.669, p = 0.36), AUROC of 0.896(95%CI: 0.826-0.953, p < 0.001) and Brier score of 0.020(95% CI: 0.013-0.028, p = 0.20).
CONCLUSIONS: In this prospective study, we developed machine learning models for preoperative prediction of postoperative MACEs in geriatric patients. The XGB model showed the best performance. Undersampling method achieved further improvement of model performance.
TRIAL REGISTRATION: The protocol of this study was registered at www.chictr.org.cn (15/08/2019, ChiCTR1900025160).",True,computer vision,Not specified
36088224,Comparison of machine learning classification techniques to predict implantation success in an IVF treatment cycle,"RESEARCH QUESTION: Which machine learning model predicts the implantation outcome better in an IVF cycle? What is the importance of each variable in predicting the implantation outcome in an IVF cycle?
DESIGN: Retrospective cohort study comprising 939 transferred embryos between 2014 and 2018 in an IVF centre in Turkey with 17 selected features. The algorithms were Logistic Regression (LR), Decision Tree (DT), Naïve Bayes (NB), Random Forest (RF), Support Vector Machine (SVM), Neural Network (Nnet), Gradient Boost Decision Tree (GBDT), eXtreme Gradient Boosting (XGBoost) and Super Learner (SL). The results were evaluated with performance metrics (F1 score, specificity, accuracy and area under the receiver operating characteristic curve [AUROC]) with 10-fold cross-validation repeated ten times.
RESULTS: RF and SL models achieved the highest performance and showed F1 scores of 74% and 73%, specificity of 94%, an accuracy of 89%, and AUROC of 83%. In addition, the model identified the top features as maternal age, embryo transfer day, total gonadotrophin dose and oestradiol concentration.
CONCLUSIONS: The present study revealed that machine learning algorithms successfully predicted implantation rates in an IVF attempt. In addition, maternal age is by far the most important predictor of IVF success when compared with other variables.",True,other,recurrent neural network
36002080,Machine-learning models for predicting surgical site infections using patient pre-operative risk and surgical procedure factors,"BACKGROUND: Surgical site infections (SSIs) are a significant health care problem as they can cause increased medical costs and increased morbidity and mortality. Assessing a patient's preoperative risk factors can improve risk stratification and help guide the surgical decision-making process. Previous efforts to use preoperative risk factors to predict the occurrence of SSIs have relied upon traditional statistical modeling approaches. The aim of this paper is to develop and validate, using state-of-the-art machine learning (ML) approaches, classification models for the occurrence of SSI to improve upon previous models.
METHODS: In this work, using the American College of Surgeons' National Surgical Quality Improvement Program (ACS NSQIP) database, the performances (eg prediction accuracy) of 7 different ML approaches (Logistic Regression (LR), Naïve Bayesian (NB), Random Forest (RF), Decision Tree (DT), Support Vector Machine (SVM), Artificial Neural Network (ANN), and Deep Neural Network (DNN)) were compared. The performance of these models was evaluated using the area under the curve, accuracy, precision, sensitivity, and F1-score metrics.
RESULTS: Overall, 2,882,526 surgical procedures were identified in the study for the SSI predictive models' development. The results indicate that the DNN model offers the best predictive performance with 10-fold compared to the other 6 approaches considered (area under the curve = 0.8518, accuracy = 0.8518, precision = 0.8517, sensitivity = 0.8527, F1-score = 0.8518). Emergency case surgeries, American Society of Anesthesiologists (ASA) Index of 4 (ASA_4), BMI, Vascular surgeries, and general surgeries were most significant influencing features towards developing an SSI.
CONCLUSIONS: Equally important is that the commonly used LR approach for SSI prediction displayed mediocre performance. The results are encouraging as they suggest that the prediction performance for SSIs can be improved using modern ML approaches.",True,computer vision,Not specified
35996627,A user-friendly tool for cloud-based whole slide image segmentation with examples from renal histopathology,"BACKGROUND: Image-based machine learning tools hold great promise for clinical applications in pathology research. However, the ideal end-users of these computational tools (e.g., pathologists and biological scientists) often lack the programming experience required for the setup and use of these tools which often rely on the use of command line interfaces.
METHODS: We have developed Histo-Cloud, a tool for segmentation of whole slide images (WSIs) that has an easy-to-use graphical user interface. This tool runs a state-of-the-art convolutional neural network (CNN) for segmentation of WSIs in the cloud and allows the extraction of features from segmented regions for further analysis.
RESULTS: By segmenting glomeruli, interstitial fibrosis and tubular atrophy, and vascular structures from renal and non-renal WSIs, we demonstrate the scalability, best practices for transfer learning, and effects of dataset variability. Finally, we demonstrate an application for animal model research, analyzing glomerular features in three murine models.
CONCLUSIONS: Histo-Cloud is open source, accessible over the internet, and adaptable for segmentation of any histological structure regardless of stain.",True,other,convolutional neural network
35934714,Risk score prediction model based on single nucleotide polymorphism for predicting malaria: a machine learning approach,"BACKGROUND: The malaria risk prediction is currently limited to using advanced statistical methods, such as time series and cluster analysis on epidemiological data. Nevertheless, machine learning models have been explored to study the complexity of malaria through blood smear images and environmental data. However, to the best of our knowledge, no study analyses the contribution of Single Nucleotide Polymorphisms (SNPs) to malaria using a machine learning model. More specifically, this study aims to quantify an individual's susceptibility to the development of malaria by using risk scores obtained from the cumulative effects of SNPs, known as weighted genetic risk scores (wGRS).
RESULTS: We proposed an SNP-based feature extraction algorithm that incorporates the susceptibility information of an individual to malaria to generate the feature set. However, it can become computationally expensive for a machine learning model to learn from many SNPs. Therefore, we reduced the feature set by employing the Logistic Regression and Recursive Feature Elimination (LR-RFE) method to select SNPs that improve the efficacy of our model. Next, we calculated the wGRS of the selected feature set, which is used as the model's target variables. Moreover, to compare the performance of the wGRS-only model, we calculated and evaluated the combination of wGRS with genotype frequency (wGRS + GF). Finally, Light Gradient Boosting Machine (LightGBM), eXtreme Gradient Boosting (XGBoost), and Ridge regression algorithms are utilized to establish the machine learning models for malaria risk prediction.
CONCLUSIONS: Our proposed approach identified SNP rs334 as the most contributing feature with an importance score of 6.224 compared to the baseline, with an importance score of 1.1314. This is an important result as prior studies have proven that rs334 is a major genetic risk factor for malaria. The analysis and comparison of the three machine learning models demonstrated that LightGBM achieves the highest model performance with a Mean Absolute Error (MAE) score of 0.0373. Furthermore, based on wGRS + GF, all models performed significantly better than wGRS alone, in which LightGBM obtained the best performance (0.0033 MAE score).",True,other,Not specified
35931671,Interpretable machine learning-derived nomogram model for early detection of diabetic retinopathy in type 2 diabetes mellitus: a widely targeted metabolomics study,"OBJECTIVE: Early identification of diabetic retinopathy (DR) is key to prioritizing therapy and preventing permanent blindness. This study aims to propose a machine learning model for DR early diagnosis using metabolomics and clinical indicators.
METHODS: From 2017 to 2018, 950 participants were enrolled from two affiliated hospitals of Wenzhou Medical University and Anhui Medical University. A total of 69 matched blocks including healthy volunteers, type 2 diabetes, and DR patients were obtained from a propensity score matching-based metabolomics study. UPLC-ESI-MS/MS system was utilized for serum metabolic fingerprint data. CART decision trees (DT) were used to identify the potential biomarkers. Finally, the nomogram model was developed using the multivariable conditional logistic regression models. The calibration curve, Hosmer-Lemeshow test, receiver operating characteristic curve, and decision curve analysis were applied to evaluate the performance of this predictive model.
RESULTS: The mean age of enrolled subjects was 56.7 years with a standard deviation of 9.2, and 61.4% were males. Based on the DT model, 2-pyrrolidone completely separated healthy controls from diabetic patients, and thiamine triphosphate (ThTP) might be a principal metabolite for DR detection. The developed nomogram model (including diabetes duration, systolic blood pressure and ThTP) shows an excellent quality of classification, with AUCs (95% CI) of 0.99 (0.97-1.00) and 0.99 (0.95-1.00) in training and testing sets, respectively. Furthermore, the predictive model also has a reasonable degree of calibration.
CONCLUSIONS: The nomogram presents an accurate and favorable prediction for DR detection. Further research with larger study populations is needed to confirm our findings.",True,both,RNN
35917942,Development of a Machine Learning Model to Predict Outcomes and Cost After Cardiac Surgery,"BACKGROUND: Machine learning (ML) algorithms may enhance outcomes prediction and help guide clinical decision making. This study aimed to develop and validate a ML model that predicts postoperative outcomes and costs after cardiac surgery.
METHODS: The Society of Thoracic Surgeons registry data from 4874 patients who underwent cardiac surgery (56% coronary artery bypass grafting, 42% valve surgery, 19% aortic surgery) at our institution were divided into training (80%) and testing (20%) datasets. The Extreme Gradient Boosting decision-tree ML algorithms were trained to predict three outcomes: operative mortality, major morbidity or mortality, and Medicare outlier high hospitalization cost. Algorithm performance was determined using accuracy, F1 score, and area under the precision-recall curve (AUC-PR). The ML algorithms were validated in index surgery cases with The Society of Thoracic Surgeons risk scores for mortality and major morbidities and with logistic regression and were then applied to nonindex cases.
RESULTS: The ML algorithms with 25 input parameters predicted operative mortality (accuracy 95%; F1 0.31; AUC-PR 0.21), major morbidity or mortality (accuracy 71%, F1 0.47; AUC-PR 0.47), and high cost (accuracy 84%; F1 0.62; AUC-PR 0.65). Preoperative creatinine, complete blood count, patient height and weight, ventricular function, and liver dysfunction were important predictors for all outcomes. For patients undergoing nonindex cardiac operations, the ML model achieved an AUC-PR of 0.15 (95% CI, 0.05-0.32) for mortality and 0.59 (95% CI, 0.51-0.68) for major morbidity or mortality.
CONCLUSIONS: The extreme gradient boosting ML algorithms can predict mortality, major morbidity, and high cost after cardiac surgery, including operations without established risk models. These ML algorithms may refine risk prediction after cardiac surgery for a wide range of procedures.",True,other,Not specified
35892186,Individualized Prospective Prediction of Opioid Use Disorder,"OBJECTIVE: Opioid use disorder (OUD) is a chronic relapsing disorder with a problematic pattern of opioid use, affecting nearly 27 million people worldwide. Machine learning (ML)-based prediction of OUD may lead to early detection and intervention. However, most ML prediction studies were not based on representative data sources and prospective validations, limiting their potential to predict future new cases. In the current study, we aimed to develop and prospectively validate an ML model that could predict individual OUD cases based on representative large-scale health data.
METHOD: We present an ensemble machine-learning model trained on a cross-linked Canadian administrative health data set from 2014 to 2018 (n  =  699,164), with validation of model-predicted OUD cases on a hold-out sample from 2014 to 2018 (n  =  174,791) and prospective prediction of OUD cases on a non-overlapping sample from 2019 (n  =  316,039). We used administrative records of OUD diagnosis for each subject based on International Classification of Diseases (ICD) codes.
RESULTS: With 6409 OUD cases in 2019 (mean [SD], 45.34 [14.28], 3400 males), our model prospectively predicted OUD cases at a high accuracy (balanced accuracy, 86%, sensitivity, 93%; specificity 79%). In accord with prior findings, the top risk factors for OUD in this model were opioid use indicators and a history of other substance use disorders.
CONCLUSION: Our study presents an individualized prospective prediction of OUD cases by applying ML to large administrative health datasets. Such prospective predictions based on ML would be essential for potential future clinical applications in the early detection of OUD.",True,other,recurrent neural network
35882300,Development of a machine learning-based risk prediction model for cerebral infarction and comparison with nomogram model,"BACKGROUND: Development of a cerebral infarction (CI) risk prediction model by mining routine test big data with machine learning algorithms.
METHODS: Cohort 1 included 2017 CI patients and health checkers, and the optimal machine learning algorithms in Extreme gradient Boosting (XgBoost), Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF) were selected to mine all routine test data of the enrolled subjects for screening CI model features. Cohort 2 included patients with CI and Non-CI from 2018 to 2020 to develop an early warning model for CI and was analyzed in subgroups with a cutoff of 50 years. Cohort 3 included CI patients versus Non-CI patients in 2021, and a nomogram models was developed for comparison with the machine learning model.
RESULTS: The optimal algorithm XgBoost was used to develop a CI risk prediction model CI-Lab8 containing eight characteristics of fibrinogen, age, glucose, mean erythrocyte hemoglobin concentration, albumin, neutrophil absolute value, activated partial thromboplastin time, and triglycerides. The model had an AUC of 0.823 in cohort 2, significantly higher than the FIB (AUC = 0.737), which ranked first in feature importance. CI-Lab8 also had higher diagnostic accuracy in CI patients <50 years of age (AUC = 0.800), slightly lower than in CI patients ≥50 years of age (AUC = 0.856). Receiver operating characteristic curve, calibration curve, and decision curve analysis in cohort 3 showed CI-Lab8 to be superior to nomogram.
CONCLUSION: In this study, the CI risk prediction model developed by XgBoost algorithm outperformed the nomogram model and had higher diagnostic accuracy for CI patients in both <50 and ≥50 years old, which may assist clinical assessment for CI.",True,other,convolutional neural network
35783073,Clinical study applying machine learning to detect a rare disease: results and lessons learned,"Machine learning has the potential to improve identification of patients for appropriate diagnostic testing and treatment, including those who have rare diseases for which effective treatments are available, such as acute hepatic porphyria (AHP). We trained a machine learning model on 205 571 complete electronic health records from a single medical center based on 30 known cases to identify 22 patients with classic symptoms of AHP that had neither been diagnosed nor tested for AHP. We offered urine porphobilinogen testing to these patients via their clinicians. Of the 7 who agreed to testing, none were positive for AHP. We explore the reasons for this and provide lessons learned for further work evaluating machine learning to detect AHP and other rare diseases.",True,other,Not specified
35752818,Early prediction of ventilator-associated pneumonia in critical care patients: a machine learning model,"BACKGROUND: This study was performed to develop and validate machine learning models for early detection of ventilator-associated pneumonia (VAP) 24 h before diagnosis, so that VAP patients can receive early intervention and reduce the occurrence of complications.
PATIENTS AND METHODS: This study was based on the MIMIC-III dataset, which was a retrospective cohort. The random forest algorithm was applied to construct a base classifier, and the area under the receiver operating characteristic curve (AUC), sensitivity and specificity of the prediction model were evaluated. Furthermore, We also compare the performance of Clinical Pulmonary Infection Score (CPIS)-based model (threshold value ≥ 3) using the same training and test data sets.
RESULTS: In total, 38,515 ventilation sessions occurred in 61,532 ICU admissions. VAP occurred in 212 of these sessions. We incorporated 42 VAP risk factors at admission and routinely measured the vital characteristics and laboratory results. Five-fold cross-validation was performed to evaluate the model performance, and the model achieved an AUC of 84% in the validation, 74% sensitivity and 71% specificity 24 h after intubation. The AUC of our VAP machine learning model is nearly 25% higher than the CPIS model, and the sensitivity and specificity were also improved by almost 14% and 15%, respectively.
CONCLUSIONS: We developed and internally validated an automated model for VAP prediction using the MIMIC-III cohort. The VAP prediction model achieved high performance based on its AUC, sensitivity and specificity, and its performance was superior to that of the CPIS model. External validation and prospective interventional or outcome studies using this prediction model are envisioned as future work.",True,other,RNN
35687925,Integrated COVID-19 Predictor: Differential expression analysis to reveal potential biomarkers and prediction of coronavirus using RNA-Seq profile data,"BACKGROUND: The world has been battling the continuous COVID-19 pandemic spread by the SARS-CoV-2 virus for last two years. The issue of viral disease prediction is constantly a matter of interest in virology and the study of disease transmission over the long years.
OBJECTIVE: In this study, we aimed to implement genome association studies using RNA-Seq of COVID-19 and reveal highly expressed gene biomarkers and prediction based on the machine learning model of COVID-19 analysis to combat this pandemic.
METHOD: We collected RNA-Seq gene count data for both healthy (Control) and non-healthy (Treated) COVID-19 cases. In this experiment, a sequence of bioinformatics strategies and statistical techniques, such as fold-change and adjusted p-value, were processed to identify differentially expressed genes (DEGs). We filtered biomarker sets of high DEGs, moderate DEGs, and low DEGs using DESeq2, Limma Trend, and Limma Voom methods based on intersection and union operations and applied machine learning techniques to predict COVID-19.
RESULT: Through experimental analysis, 67 potential biomarkers were extracted, comprising 49 up-regulated and 18 down-regulated genes, using statistical techniques and a set-theory consensus strategy. We trained the machine learning models on 12 different biomarker sets and found that the SVM model performed better than the other classifiers with 99.07% classification accuracy for moderate DEGs.
CONCLUSION: Our study revealed that identified differentially expressed genes of the moderate DEGs biomarker set, |log2FC| ≥ 2 with adjusted p-value < 0.05, work significantly as input features to implement a machine learning model using a kernel-based SVM technique to predict COVID-19.",True,other,recurrent neural network
35671415,Analytical Validation of a Deep Neural Network Algorithm for the Detection of Ovarian Cancer,"PURPOSE: Early detection of ovarian cancer, the deadliest gynecologic cancer, is crucial for reducing mortality. Current noninvasive risk assessment measures include protein biomarkers in combination with other clinical factors, which vary in their accuracy. Machine learning can be applied to optimizing the combination of these features, leading to more accurate assessment of malignancy. However, the low prevalence of the disease can make rigorous validation of these tests challenging and can result in unbalanced performance.
METHODS: MIA3G is a deep feedforward neural network for ovarian cancer risk assessment, using seven protein biomarkers along with age and menopausal status as input features. The algorithm was developed on a heterogenous data set of 1,067 serum specimens from women with adnexal masses (prevalence = 31.8%). It was subsequently validated on a cohort almost twice that size (N = 2,000).
RESULTS: In the analytical validation data set (prevalence = 4.9%), MIA3G demonstrated a sensitivity of 89.8% and a specificity of 84.02%. The positive predictive value was 22.45%, and the negative predictive value was 99.38%. When stratified by cancer type and stage, MIA3G achieved sensitivities of 94.94% for epithelial ovarian cancer, 76.92% for early-stage cancer, and 98.04% for late-stage cancer.
CONCLUSION: The balanced performance of MIA3G leads to a high sensitivity and high specificity, a combination that may be clinically useful for providers in evaluating the appropriate management strategy for their patients. Limitations of this work include the largely retrospective nature of the data set and the unequal, albeit random, assignment of histologic subtypes between the training and validation data sets. Future directions may include the addition of new biomarkers or other modalities to strengthen the performance of the algorithm.",True,other,Not specified
35665309,A goodness-of-fit test based on neural network sieve estimators,"Neural networks have become increasingly popular in the field of machine learning and have been successfully used in many applied fields (e.g., imaging recognition). With more and more research has been conducted on neural networks, we have a better understanding of the statistical proprieties of neural networks. While many studies focus on bounding the prediction error of neural network estimators, limited research has been done on the statistical inference of neural networks. From a statistical point of view, it is of great interest to investigate the statistical inference of neural networks as it could facilitate hypothesis testing in many fields (e.g., genetics, epidemiology, and medical science). In this paper, we propose a goodness-of-fit test statistic based on neural network sieve estimators. The test statistic follows an asymptotic distribution, which makes it easy to use in practice. We have also verified the theoretical asymptotic results via simulation studies and a real data application.",True,other,recurrent neural network
35663114,A machine learning approach to identifying delirium from electronic health records,"The identification of delirium in electronic health records (EHRs) remains difficult due to inadequate assessment or under-documentation. The purpose of this research is to present a classification model that identifies delirium using retrospective EHR data. Delirium was confirmed with the Confusion Assessment Method for the Intensive Care Unit. Age, sex, Elixhauser comorbidity index, drug exposures, and diagnoses were used as features. The model was developed based on the Columbia University Irving Medical Center EHR data and further validated with the Medical Information Mart for Intensive Care III dataset. Seventy-six patients from Surgical/Cardiothoracic ICU were included in the model. The logistic regression model achieved the best performance in identifying delirium; mean AUC of 0.874 ± 0.033. The mean positive predictive value of the logistic regression model was 0.80. The model promises to identify delirium cases with EHR data, thereby enable a sustainable infrastructure to build a retrospective cohort of delirium.",True,computer vision,Not specified
35634443,Risk Assessment of Liver Metastasis in Pancreatic Cancer Patients Using Multiple Models Based on Machine Learning: A Large Population-Based Study,"BACKGROUND: A more accurate prediction of liver metastasis (LM) in pancreatic cancer (PC) would help improve clinical therapeutic effects and follow-up strategies for the management of this disease. This study was to assess various prediction models to evaluate the risk of LM based on machine learning algorithms.
METHODS: We retrospectively reviewed clinicopathological characteristics of PC patients from the Surveillance, Epidemiology, and End Results database from 2010 to 2018. The logistic regression, extreme gradient boosting, support vector, random forest (RF), and deep neural network machine algorithms were used to establish models to predict the risk of LM in PC patients. Specificity, sensitivity, and receiver operating characteristic (ROC) curves were used to determine the discriminatory capacity of the prediction models.
RESULTS: A total of 47,919 PC patients were identified; 15,909 (33.2%) of which developed LM. After iterative filtering, a total of nine features were included to establish the risk model for LM based on machine learning. The RF showed the most promising results in the prediction of complications among the models (ROC 0.871 for training and 0.832 for test sets). In risk stratification analysis, the LM rate and 5-year cancer-specific survival (CSS) in the high-risk group were worse than those in the intermediate- and low-risk groups. Surgery, radiotherapy, and chemotherapy were found to significantly improve the CSS in the high- and intermediate-risk groups.
CONCLUSION: In this study, the RF model constructed could accurately predict the risk of LM in PC patients, which has the potential to provide clinicians with more personalized clinical decision-making recommendations.",True,other,LSTM
35603393,A new hybrid ensemble machine-learning model for severity risk assessment and post-COVID prediction system,"Starting from December 2019, the COVID-19 pandemic has globally strained medical resources and caused significant mortality. It is commonly recognized that the severity of SARS-CoV-2 disease depends on both the comorbidity and the state of the patient's immune system, which is reflected in several biomarkers. The development of early diagnosis and disease severity prediction methods can reduce the burden on the health care system and increase the effectiveness of treatment and rehabilitation of patients with severe cases. This study aims to develop and validate an ensemble machine-learning model based on clinical and immunological features for severity risk assessment and post-COVID rehabilitation duration for SARS-CoV-2 patients. The dataset consisting of 35 features and 122 instances was collected from Lviv regional rehabilitation center. The dataset contains age, gender, weight, height, BMI, CAT, 6-minute walking test, pulse, external respiration function, oxygen saturation, and 15 immunological markers used to predict the relationship between disease duration and biomarkers using the machine learning approach. The predictions are assessed through an area under the receiver-operating curve, classification accuracy, precision, recall, and F1 score performance metrics. A new hybrid ensemble feature selection model for a post-COVID prediction system is proposed as an automatic feature cut-off rank identifier. A three-layer high accuracy stacking ensemble classification model for intelligent analysis of short medical datasets is presented. Together with weak predictors, the associative rules allowed improving the classification quality. The proposed ensemble allows using a random forest model as an aggregator for weak repressors' results generalization. The performance of the three-layer stacking ensemble classification model (AUC 0.978; CA 0.920; F1 score 0.921; precision 0.924; recall 0.920) was higher than five machine learning models, viz. tree algorithm with forward pruning; Naïve Bayes classifier; support vector machine with RBF kernel; logistic regression, and a calibrated learner with sigmoid function and decision threshold optimization. Aging-related biomarkers, viz. CD3+, CD4+, CD8+, CD22+ were examined to predict post-COVID rehabilitation duration. The best accuracy was reached in the case of the support vector machine with the linear kernel (MAPE = 0.0787) and random forest classifier (RMSE = 1.822). The proposed three-layer stacking ensemble classification model predicted SARS-CoV-2 disease severity based on the cytokines and physiological biomarkers. The results point out that changes in studied biomarkers associated with the severity of the disease can be used to monitor the severity and forecast the rehabilitation duration.",True,other,Not specified
35603380,A machine learning approach to differentiate between COVID-19 and influenza infection using synthetic infection and immune response data,"Data analysis is widely used to generate new insights into human disease mechanisms and provide better treatment methods. In this work, we used the mechanistic models of viral infection to generate synthetic data of influenza and COVID-19 patients. We then developed and validated a supervised machine learning model that can distinguish between the two infections. Influenza and COVID-19 are contagious respiratory illnesses that are caused by different pathogenic viruses but appeared with similar initial presentations. While having the same primary signs COVID-19 can produce more severe symptoms, illnesses, and higher mortality. The predictive model performance was externally evaluated by the ROC AUC metric (area under the receiver operating characteristic curve) on 100 virtual patients from each cohort and was able to achieve at least AUC = 91% using our multiclass classifier. The current investigation highlighted the ability of machine learning models to accurately identify two different diseases based on major components of viral infection and immune response. The model predicted a dominant role for viral load and productively infected cells through the feature selection process.",True,computer vision,recurrent neural network
35530324,A Translational Model to Improve Early Detection of Epithelial Ovarian Cancers,"Neural network analyses of circulating miRNAs have shown potential as non-invasive screening tests for ovarian cancer. A clinically useful test would detect occult disease when complete cytoreduction is most feasible. Here we used murine xenografts to sensitize a neural network model to detect low volume disease and applied the model to sera from 75 early-stage ovarian cancer cases age-matched to 200 benign adnexal masses or healthy controls. The 14-miRNA model efficiently discriminated tumor bearing animals from controls with 100% sensitivity down to tumor inoculums of 50,000 cells. Among early-stage patient samples, the model performed well with 73% sensitivity at 91% specificity. Applied to a population with 1% disease prevalence, we hypothesize the model would detect most early-stage ovarian cancers while maintaining a negative predictive value of 99.97% (95% CI 99.95%-99.98%). Overall, this supports the concept that miRNAs may be useful as screening markers for early-stage disease.",True,other,Not specified
35466079,Recurrent neural network models (CovRNN) for predicting outcomes of patients with COVID-19 on admission to hospital: model development and validation using electronic health record data,"BACKGROUND: Predicting outcomes of patients with COVID-19 at an early stage is crucial for optimised clinical care and resource management, especially during a pandemic. Although multiple machine learning models have been proposed to address this issue, because of their requirements for extensive data preprocessing and feature engineering, they have not been validated or implemented outside of their original study site. Therefore, we aimed to develop accurate and transferrable predictive models of outcomes on hospital admission for patients with COVID-19.
METHODS: In this study, we developed recurrent neural network-based models (CovRNN) to predict the outcomes of patients with COVID-19 by use of available electronic health record data on admission to hospital, without the need for specific feature selection or missing data imputation. CovRNN was designed to predict three outcomes: in-hospital mortality, need for mechanical ventilation, and prolonged hospital stay (>7 days). For in-hospital mortality and mechanical ventilation, CovRNN produced time-to-event risk scores (survival prediction; evaluated by the concordance index) and all-time risk scores (binary prediction; area under the receiver operating characteristic curve [AUROC] was the main metric); we only trained a binary classification model for prolonged hospital stay. For binary classification tasks, we compared CovRNN against traditional machine learning algorithms: logistic regression and light gradient boost machine. Our models were trained and validated on the heterogeneous, deidentified data of 247 960 patients with COVID-19 from 87 US health-care systems derived from the Cerner Real-World COVID-19 Q3 Dataset up to September 2020. We held out the data of 4175 patients from two hospitals for external validation. The remaining 243 785 patients from the 85 health systems were grouped into training (n=170 626), validation (n=24 378), and multi-hospital test (n=48 781) sets. Model performance was evaluated in the multi-hospital test set. The transferability of CovRNN was externally validated by use of deidentified data from 36 140 patients derived from the US-based Optum deidentified COVID-19 electronic health record dataset (version 1015; from January, 2007, to Oct 15, 2020). Exact dates of data extraction were masked by the databases to ensure patient data safety.
FINDINGS: CovRNN binary models achieved AUROCs of 93·0% (95% CI 92·6-93·4) for the prediction of in-hospital mortality, 92·9% (92·6-93·2) for the prediction of mechanical ventilation, and 86·5% (86·2-86·9) for the prediction of a prolonged hospital stay, outperforming light gradient boost machine and logistic regression algorithms. External validation confirmed AUROCs in similar ranges (91·3-97·0% for in-hospital mortality prediction, 91·5-96·0% for the prediction of mechanical ventilation, and 81·0-88·3% for the prediction of prolonged hospital stay). For survival prediction, CovRNN achieved a concordance index of 86·0% (95% CI 85·1-86·9) for in-hospital mortality and 92·6% (92·2-93·0) for mechanical ventilation.
INTERPRETATION: Trained on a large, heterogeneous, real-world dataset, our CovRNN models showed high prediction accuracy and transferability through consistently good performances on multiple external datasets. Our results show the feasibility of a COVID-19 predictive model that delivers high accuracy without the need for complex feature engineering.
FUNDING: Cancer Prevention and Research Institute of Texas.",True,other,recurrent neural network
35388055,Machine learning model from a Spanish cohort for prediction of SARS-COV-2 mortality risk and critical patients,"Patients affected by SARS-COV-2 have collapsed healthcare systems around the world. Consequently, different challenges arise regarding the prediction of hospital needs, optimization of resources, diagnostic triage tools and patient evolution, as well as tools that allow us to analyze which are the factors that determine the severity of patients. Currently, it is widely accepted that one of the problems since the pandemic appeared was to detect (i) who patients were about to need Intensive Care Unit (ICU) and (ii) who ones were about not overcome the disease. These critical patients collapsed Hospitals to the point that many surgeries around the world had to be cancelled. Therefore, the aim of this paper is to provide a Machine Learning (ML) model that helps us to prevent when a patient is about to be critical. Although we are in the era of data, regarding the SARS-COV-2 patients, there are currently few tools and solutions that help medical professionals to predict the evolution of patients in order to improve their treatment and the needs of critical resources at hospitals. Moreover, most of these tools have been created from small populations and/or Chinese populations, which carries a high risk of bias. In this paper, we present a model, based on ML techniques, based on 5378 Spanish patients' data from which a quality cohort of 1201 was extracted to train the model. Our model is capable of predicting the probability of death of patients with SARS-COV-2 based on age, sex and comorbidities of the patient. It also allows what-if analysis, with the inclusion of comorbidities that the patient may develop during the SARS-COV-2 infection. For the training of the model, we have followed an agnostic approach. We explored all the active comorbidities during the SARS-COV-2 infection of the patients with the objective that the model weights the effect of each comorbidity on the patient's evolution according to the data available. The model has been validated by using stratified cross-validation with k = 5 to prevent class imbalance. We obtained robust results, presenting a high hit rate, with 84.16% accuracy, 83.33% sensitivity, and an Area Under the Curve (AUC) of 0.871. The main advantage of our model, in addition to its high success rate, is that it can be used with medical records in order to predict their diagnosis, allowing the critical population to be identified in advance. Furthermore, it uses the International Classification of Diseases, Ninth Revision, Clinical Modification (ICD 9-CM) standard. In this sense, we should also emphasize that those hospitals using other encodings can add an intermediate layer business to business (B2B) with the aim of making transformations to the same international format.",True,computer vision,Not specified
35325662,Nonlaboratory-based risk assessment model for coronary heart disease screening: Model development and validation,"BACKGROUND: Identifying groups at high risk of coronary heart disease (CHD) is important to reduce mortality due to CHD. Although machine learning methods have been introduced, many require laboratory or imaging parameters, which are not always readily available; thus, their wide applications are limited.
OBJECTIVE: The aim of this study was to develop and validate a simple, efficient, and joint machine learning model for identifying individuals at high risk of CHD using easily obtainable nonlaboratory parameters.
METHODS: This prospective study used data from the Henan Rural Cohort Study, which was conducted in rural areas of Henan Province, China, between July 2015 and September 2017. A joint machine learning model was developed by selecting and combining four base machine learning algorithms, including logistic regression (LR), artificial neural network (ANN), random forest (RF), and gradient boosting machine (GBM). We used readily accessible variables, including demographics, medical and family history, lifestyle and dietary factors, and anthropometric data, to inform the model. The model was also externally validated by a cohort of individuals from the Dongfeng-Tongji cohort study. Model discrimination was assessed by using the area under the receiver operating characteristic curve (AUC), and calibration was measured by using the Brier score (BS).
RESULTS: A total of 38 716 participants (mean [SD] age, 55.64[12.19] years; 23449[60.6%] female) from the Henan Rural Cohort Study and 17 958 subjects (mean [SD] age, 62.74 [7.59] years; 10,076 [56.1%] female) from the Dongfeng-Tongji cohort study were included in the analysis. Age, waist circumference, pulse pressure, heart rate, family history of CHD, education level, family history of type 2 diabetes mellitus (T2DM), and family history of dyslipidaemia were strongly associated with the development of CHD. In regard to internal validation, the model we built demonstrated good discrimination (AUC, 0.844 (95% CI 0.828-0.860)) and had acceptable calibration (BS, 0. 066). In regard to external validation, the model performed well with clearly useful discrimination (AUC, 0.792 (95% CI 0.774-0.810)) and robust calibration (BS, 0.069).
CONCLUSIONS: In this study, the novel and simple, machine learning-based model comprising readily accessible variables accurately identified individuals at high risk of CHD. This model has the potential to be widely applied for large-scale screening of CHD populations, especially in medical resource-constrained settings.
TRIAL REGISTRATION: The Henan Rural Cohort Study has been registered at the Chinese Clinical Trial Register. (Trial registration: ChiCTR-OOC-15006699. Registered 6 July 2015 - Retrospectively registered) http://www.chictr.org.cn/showproj.aspx?proj=11375.",True,other,Not specified
35299717,Interpretable temporal graph neural network for prognostic prediction of Alzheimer's disease using longitudinal neuroimaging data,"Alzheimer's disease (AD) is a progressive neurodegenerative brain disorder characterized by memory loss and cognitive decline. Early detection and accurate prognosis of AD is an important research topic, and numerous machine learning methods have been proposed to solve this problem. However, traditional machine learning models are facing challenges in effectively integrating longitudinal neuroimaging data and biologically meaningful structure and knowledge to build accurate and interpretable prognostic predictors. To bridge this gap, we propose an interpretable graph neural network (GNN) model for AD prognostic prediction based on longitudinal neuroimaging data while embracing the valuable knowledge of structural brain connectivity. In our empirical study, we demonstrate that 1) the proposed model outperforms several competing models (i.e., DNN, SVM) in terms of prognostic prediction accuracy, and 2) our model can capture neuroanatomical contribution to the prognostic predictor and yield biologically meaningful interpretation to facilitate better mechanistic understanding of the Alzheimer's disease. Source code is available at https://github.com/JaesikKim/temporal-GNN.",True,other,recurrent neural network
35224316,Feature importance: Opening a soil-transmitted helminth machine learning model via SHAP,"In the field of landscape epidemiology, the contribution of machine learning (ML) to modeling of epidemiological risk scenarios presents itself as a good alternative. This study aims to break with the ""black box"" paradigm that underlies the application of automatic learning techniques by using SHAP to determine the contribution of each variable in ML models applied to geospatial health, using the prevalence of hookworms, intestinal parasites, in Ethiopia, where they are widely distributed; the country bears the third-highest burden of hookworm in Sub-Saharan Africa. XGBoost software was used, a very popular ML model, to fit and analyze the data. The Python SHAP library was used to understand the importance in the trained model, of the variables for predictions. The description of the contribution of these variables on a particular prediction was obtained, using different types of plot methods. The results show that the ML models are superior to the classical statistical models; not only demonstrating similar results but also explaining, by using the SHAP package, the influence and interactions between the variables in the generated models. This analysis provides information to help understand the epidemiological problem presented and provides a tool for similar studies.",True,other,Not specified
35139846,Diabetes mellitus risk prediction in the presence of class imbalance using flexible machine learning methods,"BACKGROUND: Early detection and prediction of type two diabetes mellitus incidence by baseline measurements could reduce associated complications in the future. The low incidence rate of diabetes in comparison with non-diabetes makes accurate prediction of minority diabetes class more challenging.
METHODS: Deep neural network (DNN), extremely gradient boosting (XGBoost), and random forest (RF) performance is compared in predicting minority diabetes class in Tehran Lipid and Glucose Study (TLGS) cohort data. The impact of changing threshold, cost-sensitive learning, over and under-sampling strategies as solutions to class imbalance have been compared in improving algorithms performance.
RESULTS: DNN with the highest accuracy in predicting diabetes, 54.8%, outperformed XGBoost and RF in terms of AUROC, g-mean, and f1-measure in original imbalanced data. Changing threshold based on the maximum of f1-measure improved performance in g-mean, and f1-measure in three algorithms. Repeated edited nearest neighbors (RENN) under-sampling in DNN and cost-sensitive learning in tree-based algorithms were the best solutions to tackle the imbalance issue. RENN increased ROC and Precision-Recall AUCs, g-mean and f1-measure from 0.857, 0.603, 0.713, 0.575 to 0.862, 0.608, 0.773, 0.583, respectively in DNN. Weighing improved g-mean and f1-measure from 0.667, 0.554 to 0.776, 0.588 in XGBoost, and from 0.659, 0.543 to 0.775, 0.566 in RF, respectively. Also, ROC and Precision-Recall AUCs in RF increased from 0.840, 0.578 to 0.846, 0.591, respectively.
CONCLUSION: G-mean experienced the most increase by all imbalance solutions. Weighing and changing threshold as efficient strategies, in comparison with resampling methods are faster solutions to handle class imbalance. Among sampling strategies, under-sampling methods had better performance than others.",True,other,recurrent neural network
35067382,A comparative analysis of machine learning approaches to predict C. difficile infection in hospitalized patients,"BACKGROUND: Interventions to better prevent or manage Clostridioides difficile infection (CDI) may significantly reduce morbidity, mortality, and healthcare spending.
METHODS: We present a retrospective study using electronic health record data from over 700 United States hospitals. A subset of hospitals was used to develop machine learning algorithms (MLAs); the remaining hospitals served as an external test set. Three MLAs were evaluated: gradient-boosted decision trees (XGBoost), Deep Long Short Term Memory neural network, and one-dimensional convolutional neural network. MLA performance was evaluated with area under the receiver operating characteristic curve (AUROC), sensitivity, specificity, diagnostic odds ratios and likelihood ratios.
RESULTS: The development dataset contained 13,664,840 inpatient encounters with 80,046 CDI encounters; the external dataset contained 1,149,088 inpatient encounters with 7,107 CDI encounters. The highest AUROCs were achieved for XGB, Deep Long Short Term Memory neural network, and one-dimensional convolutional neural network via abstaining from use of specialized training techniques, resampling in isolation, and resampling and output bias in combination, respectively. XGBoost achieved the highest AUROC.
CONCLUSIONS: MLAs can predict future CDI in hospitalized patients using just 6 hours of data. In clinical practice, a machine-learning based tool may support prophylactic measures, earlier diagnosis, and more timely implementation of infection control measures.",True,computer vision,Not specified
35066631,Malignancy risk stratification of cystic renal lesions based on a contrast-enhanced CT-based machine learning model and a clinical decision algorithm,"OBJECTIVE: To distinguish benign from malignant cystic renal lesions (CRL) using a contrast-enhanced CT-based radiomics model and a clinical decision algorithm.
METHODS: This dual-center retrospective study included patients over 18 years old with CRL between 2005 and 2018. The reference standard was histopathology or 4-year imaging follow-up. Training and testing datasets were acquired from two institutions. Quantitative 3D radiomics analyses were performed on nephrographic phase CT images. Ten-fold cross-validated LASSO regression was applied to the training dataset to identify the most discriminative features. A logistic regression model was trained to classify malignancy and tested on the independent dataset. Reported metrics included areas under the receiver operating characteristic curves (AUC) and balanced accuracy. Decision curve analysis for stratifying patients for surgery was performed in the testing dataset. A decision algorithm was built by combining consensus radiological readings of Bosniak categories and radiomics-based risks.
RESULTS: A total of 149 CRL (139 patients; 65 years [56-72]) were included in the training dataset-35 Bosniak(B)-IIF (8.6% malignancy), 23 B-III (43.5%), and 23 B-IV (87.0%)-and 50 CRL (46 patients; 61 years [51-68]) in the testing dataset-12 B-IIF (8.3%), 10 B-III (60.0%), and 9 B-IV (100%). The machine learning model achieved high diagnostic performance in predicting malignancy in the testing dataset (AUC = 0.96; balanced accuracy = 94%). There was a net benefit across threshold probabilities in using the clinical decision algorithm over management guidelines based on Bosniak categories.
CONCLUSION: CT-based radiomics modeling accurately distinguished benign from malignant CRL, outperforming the Bosniak classification. The decision algorithm best stratified lesions for surgery and active surveillance.
KEY POINTS: • The radiomics model achieved excellent diagnostic performance in identifying malignant cystic renal lesions in an independent testing dataset (AUC = 0.96). • The machine learning-enhanced decision algorithm outperformed the management guidelines based on the Bosniak classification for stratifying patients to surgical ablation or active surveillance.",True,both,Not specified
34972690,COVID-19 screening: use of an artificial neural network,"OBJECTIVES: COVID-19 is the biggest pandemic of the 21st century. The disease can be influenced by various sociodemographic factors and can manifest as clinical, pulmonary and gastrointestinal symptoms. This study used an artificial neural network (ANN) model with important sociodemographic factors as well as clinical, pulmonary and gastrointestinal symptoms to screen patients for COVID-19. Patients themselves can screen for these symptoms at home.
METHODS: Data on all registered patients were extracted in autumn. The best ANN model was selected from different combinations of connections, some hidden layers and some neurons in each hidden layer. In this study, 70% of the data were used in the network training process and the remaining 30% were used to evaluate the function of the multilayer, feed-forward, back-propagation algorithm.
RESULTS: The sensitivity and specificity of the ANN model in diagnosing patients with COVID-19 were 94.5% and 17.4%. In order of priority, clinical symptoms, sociodemographic factors, pulmonary symptoms and gastrointestinal symptoms were important predictive factors for COVID-19 using the ANN model. Screening patients for COVID-19 using clinical symptoms and sociodemographic factors (80% importance) remains essential.
CONCLUSIONS: Home monitoring of oxygen saturation and body temperature as well as old age and drug addiction can be helpful in self-screening symptoms of COVID-19 at home, thereby preventing unnecessary visits to medical centres and reducing burden on medical services.",True,both,recurrent neural network
34951484,Neural networks for clustered and longitudinal data using mixed effects models,"Although most statistical methods for the analysis of longitudinal data have focused on retrospective models of association, new advances in mobile health data have presented opportunities for predicting future health status by leveraging an individual's behavioral history alongside data from similar patients. Methods that incorporate both individual-level and sample-level effects are critical to using these data to its full predictive capacity. Neural networks are powerful tools for prediction, but many assume input observations are independent even when they are clustered or correlated in some way, such as in longitudinal data. Generalized linear mixed models (GLMM) provide a flexible framework for modeling longitudinal data but have poor predictive power particularly when the data are highly nonlinear. We propose a generalized neural network mixed model that replaces the linear fixed effect in a GLMM with the output of a feed-forward neural network. The model simultaneously accounts for the correlation structure and complex nonlinear relationship between input variables and outcomes, and it utilizes the predictive power of neural networks. We apply this approach to predict depression and anxiety levels of schizophrenic patients using longitudinal data collected from passive smartphone sensor data.",True,other,recurrent neural network
34916529,Explainable artificial intelligence (XAI) for exploring spatial variability of lung and bronchus cancer (LBC) mortality rates in the contiguous USA,"Machine learning (ML) has demonstrated promise in predicting mortality; however, understanding spatial variation in risk factor contributions to mortality rate requires explainability. We applied explainable artificial intelligence (XAI) on a stack-ensemble machine learning model framework to explore and visualize the spatial distribution of the contributions of known risk factors to lung and bronchus cancer (LBC) mortality rates in the conterminous United States. We used five base-learners-generalized linear model (GLM), random forest (RF), Gradient boosting machine (GBM), extreme Gradient boosting machine (XGBoost), and Deep Neural Network (DNN) for developing stack-ensemble models. Then we applied several model-agnostic approaches to interpret and visualize the stack ensemble model's output in global and local scales (at the county level). The stack ensemble generally performs better than all the base learners and three spatial regression models. A permutation-based feature importance technique ranked smoking prevalence as the most important predictor, followed by poverty and elevation. However, the impact of these risk factors on LBC mortality rates varies spatially. This is the first study to use ensemble machine learning with explainable algorithms to explore and visualize the spatial heterogeneity of the relationships between LBC mortality and risk factors in the contiguous USA.",True,other,Not specified
34891625,Machine Learning Model for Predicting CVD Risk on NHANES Data,"Cardiovascular disease (CVD) is a major health problem throughout the world. It is the leading cause of morbidity and mortality and also causes considerable economic burden to society. The early symptoms related to previous observations and abnormal events, which can be subjectively acquired by self-assessment of individuals, bear significant clinical relevance and are regularly preserved in the patient's health record. The aim of our study is to develop a machine learning model based on selected CVD-related information encompassed in NHANES data in order to assess CVD risk. This model can be used as a screening tool, as well as a retrospective reference in association with current clinical data in order to improve CVD assessment. In this form it is planned to be used for mass screening and evaluation of young adults entering their army service. The experimental results are promising in that the proposed model can effectively complement and support the CVD prediction for the timely alertness and control of cardiovascular problems aiming to prevent the occurrence of serious cardiac events.",True,other,RNN
34886312,Development of Nonlaboratory-Based Risk Prediction Models for Cardiovascular Diseases Using Conventional and Machine Learning Approaches,"Criticism of the implementation of existing risk prediction models (RPMs) for cardiovascular diseases (CVDs) in new populations motivates researchers to develop regional models. The predominant usage of laboratory features in these RPMs is also causing reproducibility issues in low-middle-income countries (LMICs). Further, conventional logistic regression analysis (LRA) does not consider non-linear associations and interaction terms in developing these RPMs, which might oversimplify the phenomenon. This study aims to develop alternative machine learning (ML)-based RPMs that may perform better at predicting CVD status using nonlaboratory features in comparison to conventional RPMs. The data was based on a case-control study conducted at the Punjab Institute of Cardiology, Pakistan. Data from 460 subjects, aged between 30 and 76 years, with (1:1) gender-based matching, was collected. We tested various ML models to identify the best model/models considering LRA as a baseline RPM. An artificial neural network and a linear support vector machine outperformed the conventional RPM in the majority of performance matrices. The predictive accuracies of the best performed ML-based RPMs were between 80.86 and 81.09% and were found to be higher than 79.56% for the baseline RPM. The discriminating capabilities of the ML-based RPMs were also comparable to baseline RPMs. Further, ML-based RPMs identified substantially different orders of features as compared to baseline RPM. This study concludes that nonlaboratory feature-based RPMs can be a good choice for early risk assessment of CVDs in LMICs. ML-based RPMs can identify better order of features as compared to the conventional approach, which subsequently provided models with improved prognostic capabilities.",True,other,Not specified
34858564,Machine Learning-Based Gynecologic Tumor Diagnosis and Its Postoperative Incisional Infection Influence Factor Analysis,"Various factors influencing postoperative incisional infection in gynecologic tumors were analyzed, and the value of quality nursing intervention was studied. In this study, 74 surgically treated gynecologic tumor patients were randomly selected from within the hospital as the study population and were divided into study and control groups. For this purpose, the whole-group random sampling method is utilized to compare the postoperative incisional infection rates of the two groups, analyze their influencing factors, and develop quality nursing interventions. In this paper, a breast cancer diagnosis prediction model was developed by combining the self-attentive mechanism. The preprocessing work such as data quantification and normalization was performed first which is followed by adding the preprocessed data to the self-attentive mechanism. This model has solved the problem that recurrent neural networks (RNNs) could not extract and calculate the features at the same time. Likewise, it has solved the drawback that the RNN could not consider global features at the same time when extracting the features, and then, the feature matrix extracted by the self-attentive mechanism was added to the adaptive neural network. The adaptive neural network model for breast cancer diagnosis prediction was constructed and, finally, relevant parameters of the adaptive neural network model were adjusted according to different tasks to make the model performance optimal. Experimental results showed that the postoperative incision infection rate of patients in the study group was 2.70%, which was significantly lower than that of 21.62% in the control group (P &lt; 0.05). Likewise, operation time, operation method, hospitalization time, preoperative fever, diabetes mellitus, and anemia were the main influencing factors of postoperative incision infection in women with gynecologic tumors. The time of surgery, surgical method, long hospital stay, preoperative fever, diabetes, and anemia are the main factors that lead to postoperative incisional infection in female gynecologic tumor patients.",True,both,Not specified
34849027,Application of Machine Learning Techniques to Predict Bone Metastasis in Patients with Prostate Cancer,"OBJECTIVE: This study aimed to develop and validate a machine learning model for predicting bone metastases (BM) in prostate cancer (PCa) patients.
METHODS: Demographic and clinicopathologic variables of PCa patients in the Surveillance, Epidemiology and End Results (SEER) database from 2010 to 2017 were retrospectively analyzed. We used six different machine learning algorithms, including Decision tree (DT), Random forest (RF), Multilayer Perceptron (MLP), Logistic regression (LR), Naive Bayes classifiers (NBC), and eXtreme gradient boosting (XGB), to build prediction models. External validation using data from 644 PCa patients of the First Affiliated Hospital of Nanchang University from 2010 to 2016. The performance of the models was evaluated using the area under receiver operating characteristic curve (AUC), accuracy score, sensitivity (recall rate) and specificity. A web predictor was developed based on the best performance model.
RESULTS: A total of 207,137 PCa patients from SEER were included in this study. Of whom, 6725 (3.25%) developed BM. Gleason score, Prostate-specific antigen (PSA) value, T, N stage and age were found to be the risk factors of BM. The XGB model offered the best predictive performance among these 6 models (AUC: 0.962, accuracy: 0.884, sensitivity (recall rate): 0.906, and specificity: 0.879). An XGB model-based web predictor was developed to predict BM in PCa patients.
CONCLUSION: This study developed a machine learning model and a web predictor for predicting the risk of BM in PCa patients, which may help physicians make personalized clinical decisions and treatment strategy for patients.",True,other,Not specified
34847294,Machine learning approach to predicting albuminuria in persons with type 2 diabetes: An analysis of the LOOK AHEAD Cohort,"Albuminuria and estimated glomerular filtration rate (e-GFR) are early markers of renal disease and cardiovascular outcomes in persons with diabetes. Although body composition has been shown to predict systolic blood pressure, its application in predicting albuminuria is unknown. In this study, we have used machine learning methods to assess the risk of albuminuria in persons with diabetes using body composition and other determinants of metabolic health. This study is a comparative analysis of the different methods to predict albuminuria in persons with diabetes mellitus who are older than 40 years of age, using the LOOK AHEAD study cohort-baseline characteristics. Age, different metrics of body composition, duration of diabetes, hemoglobin A1c, serum creatinine, serum triglycerides, serum cholesterol, serum HDL, serum LDL, maximum exercise capacity, systolic blood pressure, diastolic blood pressure, and the ankle-brachial index are used as predictors of albuminuria. We used Area under the curve (AUC) as a metric to compare the classification results of different algorithms, and we show that AUC for the different models are as follows: Random forest classifier-0.65, gradient boost classifier-0.61, logistic regression-0.66, support vector classifier -0.61, multilayer perceptron -0.67, and stacking classifier-0.62. We used the Random forest model to show that the duration of diabetes, A1C, serum triglycerides, SBP, Maximum exercise Capacity, serum creatinine, subtotal lean mass, DBP, and subtotal fat mass are important features for the classification of albuminuria. In summary, when applied to metabolic imaging (using DXA), machine learning techniques offer unique insights into the risk factors that determine the development of albuminuria in diabetes.",True,other,Not specified
34798580,Longitudinal validation of an electronic health record delirium prediction model applied at admission in COVID-19 patients,"OBJECTIVE: To validate a previously published machine learning model of delirium risk in hospitalized patients with coronavirus disease 2019 (COVID-19).
METHOD: Using data from six hospitals across two academic medical networks covering care occurring after initial model development, we calculated the predicted risk of delirium using a previously developed risk model applied to diagnostic, medication, laboratory, and other clinical features available in the electronic health record (EHR) at time of hospital admission. We evaluated the accuracy of these predictions against subsequent delirium diagnoses during that admission.
RESULTS: Of the 5102 patients in this cohort, 716 (14%) developed delirium. The model's risk predictions produced a c-index of 0.75 (95% CI, 0.73-0.77) with 27.7% of cases occurring in the top decile of predicted risk scores. Model calibration was diminished compared to the initial COVID-19 wave.
CONCLUSION: This EHR delirium risk prediction model, developed during the initial surge of COVID-19 patients, produced consistent discrimination over subsequent larger waves; however, with changing cohort composition and delirium occurrence rates, model calibration decreased. These results underscore the importance of calibration, and the challenge of developing risk models for clinical contexts where standard of care and clinical populations may shift.",True,other,convolutional neural network
34782634,Machine learning models for screening carotid atherosclerosis in asymptomatic adults,"Carotid atherosclerosis (CAS) is a risk factor for cardiovascular and cerebrovascular events, but duplex ultrasonography isn't recommended in routine screening for asymptomatic populations according to medical guidelines. We aim to develop machine learning models to screen CAS in asymptomatic adults. A total of 2732 asymptomatic subjects for routine physical examination in our hospital were included in the study. We developed machine learning models to classify subjects with or without CAS using decision tree, random forest (RF), extreme gradient boosting (XGBoost), support vector machine (SVM) and multilayer perceptron (MLP) with 17 candidate features. The performance of models was assessed on the testing dataset. The model using MLP achieved the highest accuracy (0.748), positive predictive value (0.743), F1 score (0.742), area under receiver operating characteristic curve (AUC) (0.766) and Kappa score (0.445) among all classifiers. It's followed by models using XGBoost and SVM. In conclusion, the model using MLP is the best one to screen CAS in asymptomatic adults based on the results from routine physical examination, followed by using XGBoost and SVM. Those models may provide an effective and applicable method for physician and primary care doctors to screen asymptomatic CAS without risk factors in general population, and improve risk predictions and preventions of cardiovascular and cerebrovascular events in asymptomatic adults.",True,other,Not specified
34774886,Using machine learning to predict atrial fibrillation diagnosed after ischemic stroke,"BACKGROUND: Selecting best candidates for prolonged poststroke cardiac monitoring in acute ischemic stroke (AIS) patients is still challenging. We aimed to develop a machine learning (ML) model to select AIS patients at high risk of poststroke atrial fibrillation (AF) for prolonged cardiac monitoring and then to compare ML model with traditional risk scores and classic statistical logistic regression (classic-LR) model.
METHODS: AIS patients from July 2012 to September 2020 across Nanjing First Hospital were collected. We performed the LASSO regression for selecting the critical features and built five ML models to assess the risk of poststroke AF. The SHAP and partial dependence plot (PDP) method were introduced to interpret the optimal model. We also compared ML model with CHADS<sub>2</sub> score, CHA<sub>2</sub>DS<sub>2</sub>-VASc score, AS5F score, HAVOC score, and classic-LR model.
RESULTS: A total of 3929 AIS patients were included. Among the five ML models, deep neural network (DNN) was the model with best performance. It also exhibited superior performance compared with CHADS<sub>2</sub> score, CHA<sub>2</sub>DS<sub>2</sub>-VASc score, AS5F score, HAVOC score and classic-LR model. The results of SHAP and PDP method revealed age, cardioembolic stroke, large-artery atherosclerosis stroke, and NIHSS score at admission were the top four important features and revealed the DNN model had good interpretability and reliability.
CONCLUSION: The DNN model achieved best performance and improved prediction performance compared with traditional risk scores and classic-LR model. The DNN model can be applied to identify AIS patients at high risk of poststroke AF as best candidates for prolonged poststroke cardiac monitoring.",True,other,RNN
34724938,Application of machine learning to predict the occurrence of arrhythmia after acute myocardial infarction,"BACKGROUND: Early identification of the occurrence of arrhythmia in patients with acute myocardial infarction plays an essential role in clinical decision-making. The present study attempted to use machine learning (ML) methods to build predictive models of arrhythmia after acute myocardial infarction (AMI).
METHODS: A total of 2084 patients with acute myocardial infarction were enrolled in this study. (All data is available on Github: https://github.com/wangsuhuai/AMI-database1.git) . The primary outcome is whether tachyarrhythmia occurred during admission containing atrial arrhythmia, ventricular arrhythmia, and supraventricular tachycardia. All data is randomly divided into a training set (80%) and an internal testing set (20%). Apply three machine learning algorithms: decision tree, random forest (RF), and artificial neural network (ANN) to learn the training set to build a model, then use the testing set to evaluate the prediction performance, and compare it with the model built by the Global Registry of Acute Coronary Events (GRACE) risk variable set.
RESULTS: Three ML models predict the occurrence of tachyarrhythmias after AMI. After variable selection, the artificial neural network (ANN) model has reached the highest accuracy rate, which is better than the model constructed using the Grace variable set. After applying SHapley Additive exPlanations (SHAP) to make the model interpretable, the most important features are abnormal wall motion, lesion location, bundle branch block, age, and heart rate. Among them, RBBB (odds ratio [OR]: 4.21; 95% confidence interval [CI]: 2.42-7.02), ≥ 2 ventricular walls motion abnormal (OR: 3.26; 95% CI: 2.01-4.36) and right coronary artery occlusion (OR: 3.00; 95% CI: 1.98-4.56) are significant factors related to arrhythmia after AMI.
CONCLUSIONS: We used advanced machine learning methods to build prediction models for tachyarrhythmia after AMI for the first time (especially the ANN model that has the best performance). The current study can supplement the current AMI risk score, provide a reliable evaluation method for the clinic, and broaden the new horizons of ML and clinical research. Trial registration Clinical Trial Registry No.: ChiCTR2100041960.",True,other,Not specified
34697635,Machine learning with D-dimer in the risk stratification for pulmonary embolism: a derivation and internal validation study,"AIM: To develop a machine learning model to predict the diagnosis of pulmonary embolism (PE).
METHODS AND RESULTS: We undertook a derivation and internal validation study to develop a risk prediction model for use in patients being investigated for possible PE. The machine learning technique, generalized logistic regression using elastic net, was chosen following an assessment of seven machine learning techniques and on the basis that it optimized the area under the receiver operator characteristic curve (AUC) and Brier score. Models were developed both with and without the addition of D-dimer. A total of 3347 patients were included in the study of whom, 219 (6.5%) had PE. Four clinical variables (O2 saturation, previous deep venous thrombosis or PE, immobilization or surgery, and alternative diagnosis equal or more likely than PE) plus D-dimer contributed to the machine learning models. The addition of D-dimer improved the AUC by 0.16 (95% confidence interval 0.13-0.19), from 0.73 to 0.89 (0.87-0.91) and decreased the Brier score by 14% (10-18%). More could be ruled out with a higher positive likelihood ratio than by the Wells score combined with D-dimer, revised Geneva score combined with D-dimer, or the Pulmonary Embolism Rule-out Criteria score. Machine learning with D-dimer maintained a low-false-negative rate at a true-negative rate of nearly 53%, which was better performance than any of the other alternatives.
CONCLUSION: A machine learning model outperformed traditional risk scores for the risk stratification of PE in the emergency department. However, external validation is needed.",True,other,Not specified
34553310,Developing a machine learning model to identify delirium risk in geriatric internal medicine inpatients,"PURPOSE: To develop a machine learning model that predicts delirium risk in geriatric internal medicine inpatients.
METHODS: A prospective cohort study of internal medicine wards in a tertiary care hospital in China. Blinded observers assessed delirium using the Confusion Assessment Method (CAM). The data set was randomly divided into a training set (70%) and a test set (30%). The model was trained on the training set using the decision tree and the five-fold cross-validation, and then the model performance was evaluated on the test set. Under-sampling was used to address the class imbalance. The discriminatory power of the model was measured by the area under the receiver operating characteristic curve (AUC) and F1 score. The data set comprised 740 patients from March 2016 to January 2017.
RESULTS: The training set included 518 patients; the median (IQR) age was 84 (79-87) years; 364 (70.3%) were men; 71 (13.7%) with delirium. The test set included 222 patients; the median (IQR) age was 84.5 (79-87) years; 163 (73.4%) were men; 30 (13.5%) with delirium. In total, the data set included 740 hospital admissions with a median (IQR) age of 84 (79-87) years, 527 (71.2%) were men, and 101 (13.6%) with delirium. From 32 potential predictors, we included five variables in the predictive model: depression, cognitive impairment, types of drugs, nutritional status, and activity of daily life (ADL). The mean AUC on the training set was 0.967, the AUC and F1 score on the test set was 0.950 and 0.810, respectively. The model achieved 93.3% sensitivity, 94.3% specificity, 71.8% positive predictive value, 98.9% negative predictive value, and 94.1% accuracy on the test set.
CONCLUSION: This machine learning model may allow more precise targeting of delirium prevention and could support clinical decision making in geriatric internal medicine wards.",True,other,Not specified
34526544,Machine learning risk prediction model for acute coronary syndrome and death from use of non-steroidal anti-inflammatory drugs in administrative data,"Our aim was to investigate the usefulness of machine learning approaches on linked administrative health data at the population level in predicting older patients' one-year risk of acute coronary syndrome and death following the use of non-steroidal anti-inflammatory drugs (NSAIDs). Patients from a Western Australian cardiovascular population who were supplied with NSAIDs between 1 Jan 2003 and 31 Dec 2004 were identified from Pharmaceutical Benefits Scheme data. Comorbidities from linked hospital admissions data and medication history were inputs. Admissions for acute coronary syndrome or death within one year from the first supply date were outputs. Machine learning classification methods were used to build models to predict ACS and death. Model performance was measured by the area under the receiver operating characteristic curve (AUC-ROC), sensitivity and specificity. There were 68,889 patients in the NSAIDs cohort with mean age 76 years and 54% were female. 1882 patients were admitted for acute coronary syndrome and 5405 patients died within one year after their first supply of NSAIDs. The multi-layer neural network, gradient boosting machine and support vector machine were applied to build various classification models. The gradient boosting machine achieved the best performance with an average AUC-ROC of 0.72 predicting ACS and 0.84 predicting death. Machine learning models applied to linked administrative data can potentially improve adverse outcome risk prediction. Further investigation of additional data and approaches are required to improve the performance for adverse outcome risk prediction.",True,other,Not specified
34480134,Identifying the predictive effectiveness of a genetic risk score for incident hypertension using machine learning methods among populations in rural China,"Current studies have shown the controversial effect of genetic risk scores (GRSs) in hypertension prediction. Machine learning methods are used extensively in the medical field but rarely in the mining of genetic information. This study aims to determine whether genetic information can improve the prediction of incident hypertension using machine learning approaches in a prospective study. The study recruited 4592 subjects without hypertension at baseline from a cohort study conducted in rural China. A polygenic risk score (PGGRS) was calculated using 13 SNPs. According to a ratio of 7:3, subjects were randomly allocated to the train and test datasets. Models with and without the PGGRS were established using the train dataset with Cox regression, artificial neural network (ANN), random forest (RF), and gradient boosting machine (GBM) methods. The discrimination and reclassification of models were estimated using the test dataset. The PGGRS showed a significant association with the risk of incident hypertension (HR (95% CI), 1.046 (1.004, 1.090), P = 0.031) irrespective of baseline blood pressure. Models that did not include the PGGRS achieved AUCs (95% CI) of 0.785 (0.763, 0.807), 0.790 (0.768, 0.811), 0.838 (0.817, 0.857), and 0.854 (0.835, 0.873) for the Cox, ANN, RF, and GBM methods, respectively. The addition of the PGGRS led to the improvement of the AUC by 0.001, 0.008, 0.023, and 0.017; IDI by 1.39%, 2.86%, 4.73%, and 4.68%; and NRI by 25.05%, 13.01%, 44.87%, and 22.94%, respectively. Incident hypertension risk was better predicted by the traditional+PGGRS model, especially when machine learning approaches were used, suggesting that genetic information may have the potential to identify new hypertension cases using machine learning methods in resource-limited areas. CLINICAL TRIAL REGISTRATION: The Henan Rural Cohort Study has been registered at the Chinese Clinical Trial Register (Registration number: ChiCTR-OOC-15006699). http://www.chictr.org.cn/showproj.aspx?proj=11375 .",True,other,recurrent neural network
34473796,Can co-authorship networks be used to predict author research impact? A machine-learning based analysis within the field of degenerative cervical myelopathy research,"INTRODUCTION: Degenerative Cervical Myelopathy (DCM) is a common and disabling condition, with a relatively modest research capacity. In order to accelerate knowledge discovery, the AO Spine RECODE-DCM project has recently established the top priorities for DCM research. Uptake of these priorities within the research community will require their effective dissemination, which can be supported by identifying key opinion leaders (KOLs). In this paper, we aim to identify KOLs using artificial intelligence. We produce and explore a DCM co-authorship network, to characterise researchers' impact within the research field.
METHODS: Through a bibliometric analysis of 1674 scientific papers in the DCM field, a co-authorship network was created. For each author, statistics about their connections to the co-authorship network (and so the nature of their collaboration) were generated. Using these connectedness statistics, a neural network was used to predict H-Index for each author (as a proxy for research impact). The neural network was retrospectively validated on an unseen author set.
RESULTS: DCM research is regionally clustered, with strong collaboration across some international borders (e.g., North America) but not others (e.g., Western Europe). In retrospective validation, the neural network achieves a correlation coefficient of 0.86 (p<0.0001) between the true and predicted H-Index of each author. Thus, author impact can be accurately predicted using only the nature of an author's collaborations.
DISCUSSION: Analysis of the neural network shows that the nature of collaboration strongly impacts an author's research visibility, and therefore suitability as a KOL. This also suggests greater collaboration within the DCM field could help to improve both individual research visibility and global synergy.",True,other,LSTM
34457147,Recurrent Neural Networks to Automatically Identify Rare Disease Epidemiologic Studies from PubMed,"Rare diseases affect between 25 and 30 million people in the United States, and understanding their epidemiology is critical to focusing research efforts. However, little is known about the prevalence of many rare diseases. Given a lack of automated tools, current methods to identify and collect epidemiological data are managed through manual curation. To accelerate this process systematically, we developed a novel predictive model to programmatically identify epidemiologic studies on rare diseases from PubMed. A long short-term memory recurrent neural network was developed to predict whether a PubMed abstract represents an epidemiologic study. Our model performed well on our validation set (precision = 0.846, recall = 0.937, AUC = 0.967), and obtained satisfying results on the test set. This model thus shows promise to accelerate the pace of epidemiologic data curation in rare diseases and could be extended for use in other types of studies and in other disease domains.",True,other,Not specified
34454079,A novel hierarchical machine learning model for hospital-acquired venous thromboembolism risk assessment among multiple-departments,"Venous thromboembolism (VTE) is a common vascular disease and potentially fatal complication during hospitalization, and so the early identification of VTE risk is of significant importance. Compared with traditional scale assessments, machine learning methods provide new opportunities for precise early warning of VTE from clinical medical records. This research aimed to propose a two-stage hierarchical machine learning model for VTE risk prediction in patients from multiple departments. First, we built a machine learning prediction model that covered the entire hospital, based on all cohorts and common risk factors. Then, we took the prediction output of the first stage as an initial assessment score and then built specific models for each department. Over the duration of the study, a total of 9213 inpatients, including 1165 VTE-positive samples, were collected from four departments, which were split into developing and test datasets. The proposed model achieved an AUC of 0.879 in the department of oncology, which outperformed the first-stage model (0.730) and the department model (0.787). This was attributed to the fully usage of both the large sample size at the hospital level and variable abundance at the department level. Experimental results show that our model could effectively improve the prediction of hospital-acquired VTE risk before image diagnosis and provide decision support for further nursing and medical intervention.",True,other,convolutional neural network
34433892,Machine learning model to predict hypotension after starting continuous renal replacement therapy,"Hypotension after starting continuous renal replacement therapy (CRRT) is associated with worse outcomes compared with normotension, but it is difficult to predict because several factors have interactive and complex effects on the risk. The present study applied machine learning algorithms to develop models to predict hypotension after initiating CRRT. Among 2349 adult patients who started CRRT due to acute kidney injury, 70% and 30% were randomly assigned into the training and testing sets, respectively. Hypotension was defined as a reduction in mean arterial pressure (MAP) ≥ 20 mmHg from the initial value within 6 h. The area under the receiver operating characteristic curves (AUROCs) in machine learning models, such as support vector machine (SVM), deep neural network (DNN), light gradient boosting machine (LGBM), and extreme gradient boosting machine (XGB) were compared with those in disease-severity scores such as the Sequential Organ Failure Assessment and Acute Physiology and Chronic Health Evaluation II. The XGB model showed the highest AUROC (0.828 [0.796-0.861]), and the DNN and LGBM models followed with AUROCs of 0.822 (0.789-0.856) and 0.813 (0.780-0.847), respectively; all machine learning AUROC values were higher than those obtained from disease-severity scores (AUROCs < 0.6). Although other definitions of hypotension were used such as a reduction of MAP ≥ 30 mmHg or a reduction occurring within 1 h, the AUROCs of machine learning models were higher than those of disease-severity scores. Machine learning models successfully predict hypotension after starting CRRT and can serve as the basis of systems to predict hypotension before starting CRRT.",True,other,Not specified
34424948,DeepDRIM: a deep neural network to reconstruct cell-type-specific gene regulatory network using single-cell RNA-seq data,"Single-cell RNA sequencing has enabled to capture the gene activities at single-cell resolution, thus allowing reconstruction of cell-type-specific gene regulatory networks (GRNs). The available algorithms for reconstructing GRNs are commonly designed for bulk RNA-seq data, and few of them are applicable to analyze scRNA-seq data by dealing with the dropout events and cellular heterogeneity. In this paper, we represent the joint gene expression distribution of a gene pair as an image and propose a novel supervised deep neural network called DeepDRIM which utilizes the image of the target TF-gene pair and the ones of the potential neighbors to reconstruct GRN from scRNA-seq data. Due to the consideration of TF-gene pair's neighborhood context, DeepDRIM can effectively eliminate the false positives caused by transitive gene-gene interactions. We compared DeepDRIM with nine GRN reconstruction algorithms designed for either bulk or single-cell RNA-seq data. It achieves evidently better performance for the scRNA-seq data collected from eight cell lines. The simulated data show that DeepDRIM is robust to the dropout rate, the cell number and the size of the training data. We further applied DeepDRIM to the scRNA-seq gene expression of B cells from the bronchoalveolar lavage fluid of the patients with mild and severe coronavirus disease 2019. We focused on the cell-type-specific GRN alteration and observed targets of TFs that were differentially expressed between the two statuses to be enriched in lysosome, apoptosis, response to decreased oxygen level and microtubule, which had been proved to be associated with coronavirus infection.",True,other,recurrent neural network
34404458,Machine learning identifies ICU outcome predictors in a multicenter COVID-19 cohort,"BACKGROUND: Intensive Care Resources are heavily utilized during the COVID-19 pandemic. However, risk stratification and prediction of SARS-CoV-2 patient clinical outcomes upon ICU admission remain inadequate. This study aimed to develop a machine learning model, based on retrospective & prospective clinical data, to stratify patient risk and predict ICU survival and outcomes.
METHODS: A Germany-wide electronic registry was established to pseudonymously collect admission, therapeutic and discharge information of SARS-CoV-2 ICU patients retrospectively and prospectively. Machine learning approaches were evaluated for the accuracy and interpretability of predictions. The Explainable Boosting Machine approach was selected as the most suitable method. Individual, non-linear shape functions for predictive parameters and parameter interactions are reported.
RESULTS: 1039 patients were included in the Explainable Boosting Machine model, 596 patients retrospectively collected, and 443 patients prospectively collected. The model for prediction of general ICU outcome was shown to be more reliable to predict ""survival"". Age, inflammatory and thrombotic activity, and severity of ARDS at ICU admission were shown to be predictive of ICU survival. Patients' age, pulmonary dysfunction and transfer from an external institution were predictors for ECMO therapy. The interaction of patient age with D-dimer levels on admission and creatinine levels with SOFA score without GCS were predictors for renal replacement therapy.
CONCLUSIONS: Using Explainable Boosting Machine analysis, we confirmed and weighed previously reported and identified novel predictors for outcome in critically ill COVID-19 patients. Using this strategy, predictive modeling of COVID-19 ICU patient outcomes can be performed overcoming the limitations of linear regression models. Trial registration ""ClinicalTrials"" (clinicaltrials.gov) under NCT04455451.",True,other,RNN
34326290,Improvement in the Prediction of Coronary Heart Disease Risk by Using Artificial Neural Networks,"BACKGROUND AND OBJECTIVES: Cardiovascular diseases, such as coronary heart disease (CHD), are the main cause of mortality and morbidity worldwide. Although CHD cannot be entirely predicted by classic risk factors, it is preventable. Therefore, predicting CHD risk is crucial to clinical cardiology research, and the development of innovative methods for predicting CHD risk is of great practical interest. The Framingham risk score (FRS) is one of the most frequently implemented risk models. However, recent advances in the field of analytics may enhance the prediction of CHD risk beyond the FRS. Here, we propose a model based on an artificial neural network (ANN) for predicting CHD risk with respect to the Framingham Heart Study (FHS) dataset. The performance of this model was compared to that of the FRS.
METHODS: A sample of 3066 subjects from the FHS offspring cohort was subjected to an ANN. A multilayer perceptron ANN architecture was used and the lift, gains, receiver operating characteristic (ROC), and precision-recall predicted by the ANN were compared with those of the FRS.
RESULTS: The lift and gain curves of the ANN model outperformed those of the FRS model in terms of top percentiles. The ROC curve showed that, for higher risk scores, the ANN model had higher sensitivity and higher specificity than those of the FRS model, although its area under the curve (AUC) was lower. For the precision-recall measures, the ANN generated significantly better results than the FRS with a higher AUC.
CONCLUSIONS: The findings suggest that the ANN model is a promising approach for predicting CHD risk and a good screening procedure to identify high-risk subjects.",True,other,Not specified
34300086,Development of Machine Learning Models for Prediction of Osteoporosis from Clinical Health Examination Data,"Osteoporosis is treatable but often overlooked in clinical practice. We aimed to construct prediction models with machine learning algorithms to serve as screening tools for osteoporosis in adults over fifty years old. Additionally, we also compared the performance of newly developed models with traditional prediction models. Data were acquired from community-dwelling participants enrolled in health checkup programs at a medical center in Taiwan. A total of 3053 men and 2929 women were included. Models were constructed for men and women separately with artificial neural network (ANN), support vector machine (SVM), random forest (RF), k-nearest neighbor (KNN), and logistic regression (LoR) to predict the presence of osteoporosis. Area under receiver operating characteristic curve (AUROC) was used to compare the performance of the models. We achieved AUROC of 0.837, 0.840, 0.843, 0.821, 0.827 in men, and 0.781, 0.807, 0.811, 0.767, 0.772 in women, for ANN, SVM, RF, KNN, and LoR models, respectively. The ANN, SVM, RF, and LoR models in men, and the ANN, SVM, and RF models in women performed significantly better than the traditional Osteoporosis Self-Assessment Tool for Asians (OSTA) model. We have demonstrated that machine learning algorithms improve the performance of screening for osteoporosis. By incorporating the models in clinical practice, patients could potentially benefit from earlier diagnosis and treatment of osteoporosis.",True,other,Not specified
34285708,Clinical Feature-Based Machine Learning Model for 1-Year Mortality Risk Prediction of ST-Segment Elevation Myocardial Infarction in Patients with Hyperuricemia: A Retrospective Study,"Accurate risk assessment of high-risk patients is essential in clinical practice. However, there is no practical method to predict or monitor the prognosis of patients with ST-segment elevation myocardial infarction (STEMI) complicated by hyperuricemia. We aimed to evaluate the performance of different machine learning models for the prediction of 1-year mortality in STEMI patients with hyperuricemia. We compared five machine learning models (logistic regression, k-nearest neighbor, CatBoost, random forest, and XGBoost) with the traditional global (GRACE) risk score for acute coronary event registrations. We registered patients aged &gt;18 years diagnosed with STEMI and hyperuricemia at the Affiliated Hospital of Zunyi Medical University between January 2016 and January 2020. Overall, 656 patients were enrolled (average age, 62.5 ± 13.6 years; 83.6%, male). All patients underwent emergency percutaneous coronary intervention. We evaluated the performance of five machine learning classifiers and the GRACE risk model in predicting 1-year mortality. The area under the curve (AUC) of the six models, including the GRACE risk model, ranged from 0.75 to 0.88. Among all the models, CatBoost had the highest predictive accuracy (0.89), AUC (0.87), precision (0.84), and F1 value (0.44). After hybrid sampling technique optimization, CatBoost had the highest accuracy (0.96), AUC (0.99), precision (0.95), and F1 value (0.97). Machine learning algorithms, especially the CatBoost model, can accurately predict the mortality associated with STEMI complicated by hyperuricemia after a 1-year follow-up.",True,other,Not specified
34126702,Machine Learning Model for Predicting Postoperative Survival of Patients with Colorectal Cancer,"PURPOSE: Machine learning (ML) is a strong candidate for making accurate predictions, as we can use large amount of data with powerful computational algorithms. We developed a ML based model to predict survival of patients with colorectal cancer (CRC) using data from two independent datasets.
MATERIALS AND METHODS: A total of 364,316 and 1,572 CRC patients were included from the Surveillance, Epidemiology, and End Results (SEER) and a Korean dataset, respectively. As SEER combines data from 18 cancer registries, internal validation was done using 18-Fold-Cross-Validation then external validation was performed by testing the trained model on the Korean dataset. Performance was evaluated using area under the receiver operating characteristic curve (AUROC), sensitivity and positive predictive values.
RESULTS: Clinicopathological characteristics were significantly different between the two datasets and the SEER showed a significant lower 5-year survival rate compared to the Korean dataset (60.1% vs. 75.3%, p < 0.001). The ML-based model using the Light gradient boosting algorithm achieved a better performance in predicting 5-year-survival compared to American Joint Committee on Cancer stage (AUROC, 0.804 vs. 0.736; p < 0.001). The most important features which influenced model performance were age, number of examined lymph nodes, and tumor size. Sensitivity and positive predictive values of predicting 5-year-survival for classes including dead or alive were reported as 68.14%, 77.51% and 49.88%, 88.1% respectively in the validation set. Survival probability can be checked using the web-based survival predictor (http://colorectalcancer.pythonanywhere.com).
CONCLUSION: ML-based model achieved a much better performance compared to staging in individualized estimation of survival of patients with CRC.",True,other,Not specified
34016929,"Development of a field artificial intelligence triage tool: Confidence in the prediction of shock, transfusion, and definitive surgical therapy in patients with truncal gunshot wounds","BACKGROUND: In-field triage tools for trauma patients are limited by availability of information, linear risk classification, and a lack of confidence reporting. We therefore set out to develop and test a machine learning algorithm that can overcome these limitations by accurately and confidently making predictions to support in-field triage in the first hours after traumatic injury.
METHODS: Using an American College of Surgeons Trauma Quality Improvement Program-derived database of truncal and junctional gunshot wound (GSW) patients (aged 16-60 years), we trained an information-aware Dirichlet deep neural network (field artificial intelligence triage). Using supervised training, field artificial intelligence triage was trained to predict shock and the need for major hemorrhage control procedures or early massive transfusion (MT) using GSW anatomical locations, vital signs, and patient information available in the field. In parallel, a confidence model was developed to predict the true-class probability (scale of 0-1), indicating the likelihood that the prediction made was correct, based on the values and interconnectivity of input variables.
RESULTS: A total of 29,816 patients met all the inclusion criteria. Shock, major surgery, and early MT were identified in 13.0%, 22.4%, and 6.3% of the included patients, respectively. Field artificial intelligence triage achieved mean areas under the receiver operating characteristic curve of 0.89, 0.86, and 0.82 for prediction of shock, early MT, and major surgery, respectively, for 80/20 train-test splits over 1,000 epochs. Mean predicted true-class probability for errors/correct predictions was 0.25/0.87 for shock, 0.30/0.81 for MT, and 0.24/0.69 for major surgery.
CONCLUSION: Field artificial intelligence triage accurately identifies potential shock in truncal GSW patients and predicts their need for MT and major surgery, with a high degree of certainty. The presented model is an important proof of concept. Future iterations will use an expansion of databases to refine and validate the model, further adding to its potential to improve triage in the field, both in civilian and military settings.
LEVEL OF EVIDENCE: Prognostic, Level III.",True,other,convolutional neural network
33999838,A Machine Learning Approach for Mortality Prediction in COVID-19 Pneumonia: Development and Evaluation of the Piacenza Score,"BACKGROUND: Several models have been developed to predict mortality in patients with COVID-19 pneumonia, but only a few have demonstrated enough discriminatory capacity. Machine learning algorithms represent a novel approach for the data-driven prediction of clinical outcomes with advantages over statistical modeling.
OBJECTIVE: We aimed to develop a machine learning-based score-the Piacenza score-for 30-day mortality prediction in patients with COVID-19 pneumonia.
METHODS: The study comprised 852 patients with COVID-19 pneumonia, admitted to the Guglielmo da Saliceto Hospital in Italy from February to November 2020. Patients' medical history, demographics, and clinical data were collected using an electronic health record. The overall patient data set was randomly split into derivation and test cohorts. The score was obtained through the naïve Bayes classifier and externally validated on 86 patients admitted to Centro Cardiologico Monzino (Italy) in February 2020. Using a forward-search algorithm, 6 features were identified: age, mean corpuscular hemoglobin concentration, PaO<sub>2</sub>/FiO<sub>2</sub> ratio, temperature, previous stroke, and gender. The Brier index was used to evaluate the ability of the machine learning model to stratify and predict the observed outcomes. A user-friendly website was designed and developed to enable fast and easy use of the tool by physicians. Regarding the customization properties of the Piacenza score, we added a tailored version of the algorithm to the website, which enables an optimized computation of the mortality risk score for a patient when some of the variables used by the Piacenza score are not available. In this case, the naïve Bayes classifier is retrained over the same derivation cohort but using a different set of patient characteristics. We also compared the Piacenza score with the 4C score and with a naïve Bayes algorithm with 14 features chosen a priori.
RESULTS: The Piacenza score exhibited an area under the receiver operating characteristic curve (AUC) of 0.78 (95% CI 0.74-0.84, Brier score=0.19) in the internal validation cohort and 0.79 (95% CI 0.68-0.89, Brier score=0.16) in the external validation cohort, showing a comparable accuracy with respect to the 4C score and to the naïve Bayes model with a priori chosen features; this achieved an AUC of 0.78 (95% CI 0.73-0.83, Brier score=0.26) and 0.80 (95% CI 0.75-0.86, Brier score=0.17), respectively.
CONCLUSIONS: Our findings demonstrated that a customizable machine learning-based score with a purely data-driven selection of features is feasible and effective for the prediction of mortality among patients with COVID-19 pneumonia.",True,other,Not specified
33988129,Prediction of premature all-cause mortality in patients receiving peritoneal dialysis using modified artificial neural networks,"Premature all-cause mortality is high in patients receiving peritoneal dialysis (PD). The accurate and early prediction of mortality is critical and difficult. Three prediction models, the logistic regression (LR) model, artificial neural network (ANN) classic model and a new structured ANN model (ANN mixed model), were constructed and evaluated using a receiver operating characteristic (ROC) curve analysis. The permutation feature importance was used to interpret the important features in the ANN models. Eight hundred fifty-nine patients were enrolled in the study. The LR model performed slightly better than the other two ANN models on the test dataset; however, in the total dataset, the ANN models fit much better. The ANN mixed model showed the best prediction performance, with area under the ROC curves (AUROCs) of 0.8 and 0.79 for the 6-month and 12-month datasets. Our study showed that age, diastolic blood pressure (DBP), and low-density lipoprotein cholesterol (LDL-c) levels were common risk factors for premature mortality in patients receiving PD. Our ANN mixed model had incomparable advantages in fitting the overall data characteristics, and age is a steady risk factor for premature mortality in patients undergoing PD. Otherwise, DBP and LDL-c levels should receive more attention for all-cause mortality during follow-up.",True,text mining,Not specified
33972584,COVID-Classifier: an automated machine learning model to assist in the diagnosis of COVID-19 infection in chest X-ray images,"Chest-X ray (CXR) radiography can be used as a first-line triage process for non-COVID-19 patients with pneumonia. However, the similarity between features of CXR images of COVID-19 and pneumonia caused by other infections makes the differential diagnosis by radiologists challenging. We hypothesized that machine learning-based classifiers can reliably distinguish the CXR images of COVID-19 patients from other forms of pneumonia. We used a dimensionality reduction method to generate a set of optimal features of CXR images to build an efficient machine learning classifier that can distinguish COVID-19 cases from non-COVID-19 cases with high accuracy and sensitivity. By using global features of the whole CXR images, we successfully implemented our classifier using a relatively small dataset of CXR images. We propose that our COVID-Classifier can be used in conjunction with other tests for optimal allocation of hospital resources by rapid triage of non-COVID-19 cases.",True,other,Not specified
33962987,Development and validation of a machine learning model to predict mortality risk in patients with COVID-19,"New York City quickly became an epicentre of the COVID-19 pandemic. An ability to triage patients was needed due to a sudden and massive increase in patients during the COVID-19 pandemic as healthcare providers incurred an exponential increase in workload,which created a strain on the staff and limited resources. Further, methods to better understand and characterise the predictors of morbidity and mortality was needed. METHODS: We developed a prediction model to predict patients at risk for mortality using only laboratory, vital and demographic information readily available in the electronic health record on more than 3395 hospital admissions with COVID-19. Multiple methods were applied, and final model was selected based on performance. A variable importance algorithm was used for interpretability, and understanding of performance and predictors was applied to the best model. We built a model with an area under the receiver operating characteristic curve of 83-97 to identify predictors and patients with high risk of mortality due to COVID-19. Oximetry, respirations, blood urea nitrogen, lymphocyte per cent, calcium, troponin and neutrophil percentage were important features, and key ranges were identified that contributed to a 50% increase in patients' mortality prediction score. With an increasing negative predictive value starting 0.90 after the second day of admission suggests we might be able to more confidently identify likely survivors DISCUSSION: This study serves as a use case of a machine learning methods with visualisations to aide clinicians with a better understanding of the model and predictors of mortality. CONCLUSION: As we continue to understand COVID-19, computer assisted algorithms might be able to improve the care of patients.",True,computer vision,Not specified
33940479,Predicting hospitalization of pediatric asthma patients in emergency departments using machine learning,"MOTIVATION: The timely identification of patients for hospitalization in emergency departments (EDs) can facilitate efficient use of hospital resources. Machine learning can help the early prediction of ED disposition; however, application of machine learning models requires both computer science skills and domain knowledge. This presents a barrier for those who want to apply machine learning to real-world settings.
OBJECTIVES: The objective of this study was to construct a competitive predictive model with a minimal amount of human effort to facilitate decisions regarding hospitalization of patients.
METHODS: This study used the electronic health record data from five EDs in a single healthcare system, including an academic urban children's hospital ED, from January 2009 to December 2013. We constructed two machine learning models by using automated machine learning algorithm (autoML) which allows non-experts to use machine learning model: one with data only available at ED triage, the other adding information available one hour into the ED visit. Random forest and logistic regression were employed as bench-marking models. The ratio of the training dataset to the test dataset was 8:2, and the area under the receiver operating characteristic curve (AUC), accuracy, and F1 were calculated to assess the quality of the models.
RESULTS: Of the 9,069 ED visits analyzed, the study population was made up of males (62.7 %), median (IQR) age was 6 (4, 10) years, and public insurance coverage (66.0 %). The majority had an Emergency Severity Index score of 3 (52.9 %). The prevalence of hospitalization was 22.5 %. The AUCs were 0.914 and 0.942. AUCs were 0.831 and 0.886 for random forests, and 0.795 and 0.823 for logistic regression. Among the predictors, an outcome at a prior visit, ESI level, time to first medication, and time to triage were the most important features for the prediction of the need for hospitalization.
CONCLUSIONS: In comparison with the conventional approaches, the use of autoML improved the predictive ability for the need for hospitalization. The findings can optimize ED management, hospital-level resource utilization and improve quality. Furthermore, this approach can support the design of a more effective patient ED flow for pediatric asthma care.",True,other,RNN
33882060,Development of a severity of disease score and classification model by machine learning for hospitalized COVID-19 patients,"BACKGROUND: Efficient and early triage of hospitalized Covid-19 patients to detect those with higher risk of severe disease is essential for appropriate case management.
METHODS: We trained, validated, and externally tested a machine-learning model to early identify patients who will die or require mechanical ventilation during hospitalization from clinical and laboratory features obtained at admission. A development cohort with 918 Covid-19 patients was used for training and internal validation, and 352 patients from another hospital were used for external testing. Performance of the model was evaluated by calculating the area under the receiver-operating-characteristic curve (AUC), sensitivity and specificity.
RESULTS: A total of 363 of 918 (39.5%) and 128 of 352 (36.4%) Covid-19 patients from the development and external testing cohort, respectively, required mechanical ventilation or died during hospitalization. In the development cohort, the model obtained an AUC of 0.85 (95% confidence interval [CI], 0.82 to 0.87) for predicting severity of disease progression. Variables ranked according to their contribution to the model were the peripheral blood oxygen saturation (SpO2)/fraction of inspired oxygen (FiO2) ratio, age, estimated glomerular filtration rate, procalcitonin, C-reactive protein, updated Charlson comorbidity index and lymphocytes. In the external testing cohort, the model performed an AUC of 0.83 (95% CI, 0.81 to 0.85). This model is deployed in an open source calculator, in which Covid-19 patients at admission are individually stratified as being at high or non-high risk for severe disease progression.
CONCLUSIONS: This machine-learning model, applied at hospital admission, predicts risk of severe disease progression in Covid-19 patients.",True,computer vision,Not specified
33867486,Application of machine-learning techniques in classification of HIV medical care status for people living with HIV in South Carolina,"OBJECTIVES: Ending the HIV epidemic requires innovative use of data for intelligent decision-making from surveillance through treatment. This study sought to examine the usefulness of using linked integrated PLWH health data to predict PLWH's future HIV care status and compare the performance of machine-learning methods for predicting future HIV care status for SC PLWH.
DESIGN: We employed supervised machine learning for its ability to predict PLWH's future care status by synthesizing and learning from PLWH's existing health data. This method is appropriate for the nature of integrated PLWH data because of its high volume and dimensionality.
METHODS: A data set of 8888 distinct PLWH's health records were retrieved from an integrated PLWH data repository. We experimented and scored seven representative machine-learning models including Bayesian Network, Automated Neural Network, Support Vector Machine, Logistic Regression, LASSO, Decision Trees and Random Forest to best predict PLWH's care status. We further identified principal factors that can predict the retention-in-care based on the champion model.
RESULTS: Bayesian Network (F = 0.87, AUC = 0.94, precision = 0.87, recall = 0.86) was the best predictive model, followed by Random Forest (F = 0.78, AUC = 0.81, precision = 0.72, recall = 0.85), Decision Tree (F = 0.76, AUC = 0.75, precision = 0.70, recall = 0.82) and Neural Network (cluster) (F = 0.75, AUC = 0.71, precision = 0.69, recall = 0.81).
CONCLUSION: These algorithmic applications of Bayesian Networks and other machine-learning algorithms hold promise for predicting future HIV care status at the individual level. Prediction of future care patterns for SC PLWH can help optimize health service resources for effective interventions. Predictions can also help improve retention across the HIV continuum.",True,other,Not specified
33817554,Iterative transfer learning with neural network for clustering and cell type classification in single-cell RNA-seq analysis,"Clustering and cell type classification are important steps in single-cell RNA-seq (scRNA-seq) analysis. As more and more scRNA-seq data are becoming available, supervised cell type classification methods that utilize external well-annotated source data start to gain popularity over unsupervised clustering algorithms. However, the performance of existing supervised methods is highly dependent on source data quality, and they often have limited accuracy to classify cell types that are missing in the source data. To overcome these limitations, we developed ItClust, a transfer learning algorithm that borrows idea from supervised cell type classification algorithms, but also leverages information in target data to ensure sensitivity in classifying cells that are only present in the target data. Through extensive evaluations using data from different species and tissues generated with diverse scRNA-seq protocols, we show that ItClust significantly improves clustering and cell type classification accuracy over popular unsupervised clustering and supervised cell type classification algorithms.",True,other,recurrent neural network
33786999,Diagnostic and prognostic capabilities of a biomarker and EMR-based machine learning algorithm for sepsis,"Sepsis is a major cause of mortality among hospitalized patients worldwide. Shorter time to administration of broad-spectrum antibiotics is associated with improved outcomes, but early recognition of sepsis remains a major challenge. In a two-center cohort study with prospective sample collection from 1400 adult patients in emergency departments suspected of sepsis, we sought to determine the diagnostic and prognostic capabilities of a machine-learning algorithm based on clinical data and a set of uncommonly measured biomarkers. Specifically, we demonstrate that a machine-learning model developed using this dataset outputs a score with not only diagnostic capability but also prognostic power with respect to hospital length of stay (LOS), 30-day mortality, and 3-day inpatient re-admission both in our entire testing cohort and various subpopulations. The area under the receiver operating curve (AUROC) for diagnosis of sepsis was 0.83. Predicted risk scores for patients with septic shock were higher compared with patients with sepsis but without shock (p < 0.0001). Scores for patients with infection and organ dysfunction were higher compared with those without either condition (p < 0.0001). Stratification based on predicted scores of the patients into low, medium, and high-risk groups showed significant differences in LOS (p < 0.0001), 30-day mortality (p < 0.0001), and 30-day inpatient readmission (p < 0.0001). In conclusion, a machine-learning algorithm based on electronic medical record (EMR) data and three nonroutinely measured biomarkers demonstrated good diagnostic and prognostic capability at the time of initial blood culture.",True,other,Not specified
33783520,Use of Machine Learning to Develop and Evaluate Models Using Preoperative and Intraoperative Data to Identify Risks of Postoperative Complications,"IMPORTANCE: Postoperative complications can significantly impact perioperative care management and planning.
OBJECTIVES: To assess machine learning (ML) models for predicting postoperative complications using independent and combined preoperative and intraoperative data and their clinically meaningful model-agnostic interpretations.
DESIGN, SETTING, AND PARTICIPANTS: This retrospective cohort study assessed 111 888 operations performed on adults at a single academic medical center from June 1, 2012, to August 31, 2016, with a mean duration of follow-up based on the length of postoperative hospital stay less than 7 days. Data analysis was performed from February 1 to September 31, 2020.
MAIN OUTCOMES AND MEASURES: Outcomes included 5 postoperative complications: acute kidney injury (AKI), delirium, deep vein thrombosis (DVT), pulmonary embolism (PE), and pneumonia. Patient and clinical characteristics available preoperatively, intraoperatively, and a combination of both were used as inputs for 5 candidate ML models: logistic regression, support vector machine, random forest, gradient boosting tree (GBT), and deep neural network (DNN). Model performance was compared using the area under the receiver operating characteristic curve (AUROC). Model interpretations were generated using Shapley Additive Explanations by transforming model features into clinical variables and representing them as patient-specific visualizations.
RESULTS: A total of 111 888 patients (mean [SD] age, 54.4 [16.8] years; 56 915 [50.9%] female; 82 533 [73.8%] White) were included in this study. The best-performing model for each complication combined the preoperative and intraoperative data with the following AUROCs: pneumonia (GBT), 0.905 (95% CI, 0.903-0.907); AKI (GBT), 0.848 (95% CI, 0.846-0.851); DVT (GBT), 0.881 (95% CI, 0.878-0.884); PE (DNN), 0.831 (95% CI, 0.824-0.839); and delirium (GBT), 0.762 (95% CI, 0.759-0.765). Performance of models that used only preoperative data or only intraoperative data was marginally lower than that of models that used combined data. When adding variables with missing data as input, AUROCs increased from 0.588 to 0.905 for pneumonia, 0.579 to 0.848 for AKI, 0.574 to 0.881 for DVT, 0.5 to 0.831 for PE, and 0.6 to 0.762 for delirium. The Shapley Additive Explanations analysis generated model-agnostic interpretation that illustrated significant clinical contributors associated with risks of postoperative complications.
CONCLUSIONS AND RELEVANCE: The ML models for predicting postoperative complications with model-agnostic interpretation offer opportunities for integrating risk predictions for clinical decision support. Such real-time clinical decision support can mitigate patient risks and help in anticipatory management for perioperative contingency planning.",True,computer vision,Not specified
33778804,Machine learning compared with rule-in/rule-out algorithms and logistic regression to predict acute myocardial infarction based on troponin T concentrations,"OBJECTIVE: Computerized decision-support tools may improve diagnosis of acute myocardial infarction (AMI) among patients presenting with chest pain at the emergency department (ED). The primary aim was to assess the predictive accuracy of machine learning algorithms based on paired high-sensitivity cardiac troponin T (hs-cTnT) concentrations with varying sampling times, age, and sex in order to rule in or out AMI.
METHODS: In this register-based, cross-sectional diagnostic study conducted retrospectively based on 5695 chest pain patients at 2 hospitals in Sweden 2013-2014 we used 5-fold cross-validation 200 times in order to compare the performance of an artificial neural network (ANN) with European guideline-recommended 0/1- and 0/3-hour algorithms for hs-cTnT and with logistic regression without interaction terms. Primary outcome was the size of the intermediate risk group where AMI could not be ruled in or out, while holding the sensitivity (rule-out) and specificity (rule-in) constant across models.
RESULTS: ANN and logistic regression had similar (95%) areas under the receiver operating characteristics curve. In patients (n = 4171) where the timing requirements (0/1 or 0/3 hour) for the sampling were met, using ANN led to a relative decrease of 9.2% (95% confidence interval 4.4% to 13.8%; from 24.5% to 22.2% of all tested patients) in the size of the intermediate group compared to the recommended algorithms. By contrast, using logistic regression did not substantially decrease the size of the intermediate group.
CONCLUSION: Machine learning algorithms allow for flexibility in sampling and have the potential to improve risk assessment among chest pain patients at the ED.",True,other,RNN
33708997,An Interpretable Model-Based Prediction of Severity and Crucial Factors in Patients with COVID-19,"This study established an interpretable machine learning model to predict the severity of coronavirus disease 2019 (COVID-19) and output the most crucial deterioration factors. Clinical information, laboratory tests, and chest computed tomography (CT) scans at admission were collected. Two experienced radiologists reviewed the scans for the patterns, distribution, and CT scores of lung abnormalities. Six machine learning models were established to predict the severity of COVID-19. After parameter tuning and performance comparison, the optimal model was explained using Shapley Additive explanations to output the crucial factors. This study enrolled and classified 198 patients into mild (n = 162; 46.93 ± 14.49 years old) and severe (n = 36; 60.97 ± 15.91 years old) groups. The severe group had a higher temperature (37.42 ± 0.99°C vs. 36.75 ± 0.66°C), CT score at admission, neutrophil count, and neutrophil-to-lymphocyte ratio than the mild group. The XGBoost model ranked first among all models, with an AUC, sensitivity, and specificity of 0.924, 90.91%, and 97.96%, respectively. The early stage of chest CT, total CT score of the percentage of lung involvement, and age were the top three contributors to the prediction of the deterioration of XGBoost. A higher total score on chest CT had a more significant impact on the prediction. In conclusion, the XGBoost model to predict the severity of COVID-19 achieved excellent performance and output the essential factors in the deterioration process, which may help with early clinical intervention, improve prognosis, and reduce mortality.",True,other,recurrent neural network
33692779,Machine Learning Identifies Complicated Sepsis Course and Subsequent Mortality Based on 20 Genes in Peripheral Blood Immune Cells at 24 H Post-ICU Admission,"A complicated clinical course for critically ill patients admitted to the intensive care unit (ICU) usually includes multiorgan dysfunction and subsequent death. Owing to the heterogeneity, complexity, and unpredictability of the disease progression, ICU patient care is challenging. Identifying the predictors of complicated courses and subsequent mortality at the early stages of the disease and recognizing the trajectory of the disease from the vast array of longitudinal quantitative clinical data is difficult. Therefore, we attempted to perform a meta-analysis of previously published gene expression datasets to identify novel early biomarkers and train the artificial intelligence systems to recognize the disease trajectories and subsequent clinical outcomes. Using the gene expression profile of peripheral blood cells obtained within 24 h of pediatric ICU (PICU) admission and numerous clinical data from 228 septic patients from pediatric ICU, we identified 20 differentially expressed genes predictive of complicated course outcomes and developed a new machine learning model. After 5-fold cross-validation with 10 iterations, the overall mean area under the curve reached 0.82. Using a subset of the same set of genes, we further achieved an overall area under the curve of 0.72, 0.96, 0.83, and 0.82, respectively, on four independent external validation sets. This model was highly effective in identifying the clinical trajectories of the patients and mortality. Artificial intelligence systems identified eight out of twenty novel genetic markers (SDC4, CLEC5A, TCN1, MS4A3, HCAR3, OLAH, PLCB1, and NLRP1) that help predict sepsis severity or mortality. While these genes have been previously associated with sepsis mortality, in this work, we show that these genes are also implicated in complex disease courses, even among survivors. The discovery of eight novel genetic biomarkers related to the overactive innate immune system, including neutrophil function, and a new predictive machine learning method provides options to effectively recognize sepsis trajectories, modify real-time treatment options, improve prognosis, and patient survival.",True,other,recurrent neural network
33689741,Cardiac Operative Risk in Latin America: A Comparison of Machine Learning Models vs EuroSCORE-II,"BACKGROUND: Machine learning is a useful tool for predicting medical outcomes. This study aimed to develop a machine learning-based preoperative score to predict cardiac surgical operative mortality.
METHODS: We developed various models to predict cardiac operative mortality using machine learning techniques and compared each model to European System for Cardiac Operative Risk Evaluation-II (EuroSCORE-II) using the area under the receiver operating characteristic (ROC) and precision-recall (PR) curves (ROC AUC and PR AUC) as performance metrics. The model calibration in our population was also reported with all models and in high-risk groups for gradient boosting and EuroSCORE-II. This study is a retrospective cohort based on a prospectively collected database from July 2008 to April 2018 from a single cardiac surgical center in Bogotá, Colombia.
RESULTS: Model comparison consisted of hold-out validation: 80% of the data were used for model training, and the remaining 20% of the data were used to test each model and EuroSCORE-II. Operative mortality was 6.45% in the entire database and 6.59% in the test set. The performance metrics for the best machine learning model, gradient boosting (ROC: 0.755; PR: 0.292), were higher than those of EuroSCORE-II (ROC: 0.716, PR: 0.179), with a P value of .318 for the AUC of the ROC and .137 for the AUC of the PR.
CONCLUSIONS: The gradient boosting model was more precise than EuroSCORE-II in predicting mortality in our population based on ROC and PR analyses, although the difference was not statistically significant.",True,other,Not specified
33688915,Use of Machine Learning Models to Predict Death After Acute Myocardial Infarction,"IMPORTANCE: Accurate prediction of adverse outcomes after acute myocardial infarction (AMI) can guide the triage of care services and shared decision-making, and novel methods hold promise for using existing data to generate additional insights.
OBJECTIVE: To evaluate whether contemporary machine learning methods can facilitate risk prediction by including a larger number of variables and identifying complex relationships between predictors and outcomes.
DESIGN, SETTING, AND PARTICIPANTS: This cohort study used the American College of Cardiology Chest Pain-MI Registry to identify all AMI hospitalizations between January 1, 2011, and December 31, 2016. Data analysis was performed from February 1, 2018, to October 22, 2020.
MAIN OUTCOMES AND MEASURES: Three machine learning models were developed and validated to predict in-hospital mortality based on patient comorbidities, medical history, presentation characteristics, and initial laboratory values. Models were developed based on extreme gradient descent boosting (XGBoost, an interpretable model), a neural network, and a meta-classifier model. Their accuracy was compared against the current standard developed using a logistic regression model in a validation sample.
RESULTS: A total of 755 402 patients (mean [SD] age, 65 [13] years; 495 202 [65.5%] male) were identified during the study period. In independent validation, 2 machine learning models, gradient descent boosting and meta-classifier (combination including inputs from gradient descent boosting and a neural network), marginally improved discrimination compared with logistic regression (C statistic, 0.90 for best performing machine learning model vs 0.89 for logistic regression). Nearly perfect calibration in independent validation data was found in the XGBoost (slope of predicted to observed events, 1.01; 95% CI, 0.99-1.04) and the meta-classifier model (slope of predicted-to-observed events, 1.01; 95% CI, 0.99-1.02), with more precise classification across the risk spectrum. The XGBoost model reclassified 32 393 of 121 839 individuals (27%) and the meta-classifier model reclassified 30 836 of 121 839 individuals (25%) deemed at moderate to high risk for death in logistic regression as low risk, which were more consistent with the observed event rates.
CONCLUSIONS AND RELEVANCE: In this cohort study using a large national registry, none of the tested machine learning models were associated with substantive improvement in the discrimination of in-hospital mortality after AMI, limiting their clinical utility. However, compared with logistic regression, XGBoost and meta-classifier models, but not the neural network, offered improved resolution of risk for high-risk individuals.",True,computer vision,Not specified
33686949,Artificial intelligence prediction model for overall survival of clear cell renal cell carcinoma based on a 21-gene molecular prognostic score system,"We developed and validated a new prognostic model for predicting the overall survival in clear cell renal cell carcinoma (ccRCC) patients. In this study, artificial intelligence (AI) algorithms including random forest and neural network were trained to build a molecular prognostic score (mPS) system. Afterwards, we investigated the potential mechanisms underlying mPS by assessing gene set enrichment analysis, mutations, copy number variations (CNVs) and immune cell infiltration. A total of 275 prognosis-related genes were identified, which were also differentially expressed between ccRCC patients and healthy controls. We then constructed a universal mPS system that depends on the expression status of only 21 of these genes by applying AI-based algorithms. Then, the mPS were validated by another independent cohort and demonstrated to be applicable to ccRCC subsets. Furthermore, a nomogram comprising the mPS score and several independent variables was established and proved to effectively predict ccRCC patient prognosis. Finally, significant differences were identified regarding the pathways, mutated genes, CNVs and tumor-infiltrating immune cells among the subgroups of ccRCC stratified by the mPS system. The AI-based mPS system can provide critical prognostic prediction for ccRCC patients and may be useful to inform treatment and surveillance decisions before initial intervention.",True,other,Not specified
33684933,Development of a novel machine learning model to predict presence of nonalcoholic steatohepatitis,"OBJECTIVE: To develop a computer model to predict patients with nonalcoholic steatohepatitis (NASH) using machine learning (ML).
MATERIALS AND METHODS: This retrospective study utilized two databases: a) the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) nonalcoholic fatty liver disease (NAFLD) adult database (2004-2009), and b) the Optum® de-identified Electronic Health Record dataset (2007-2018), a real-world dataset representative of common electronic health records in the United States. We developed an ML model to predict NASH, using confirmed NASH and non-NASH based on liver histology results in the NIDDK dataset to train the model.
RESULTS: Models were trained and tested on NIDDK NAFLD data (704 patients) and the best-performing models evaluated on Optum data (~3,000,000 patients). An eXtreme Gradient Boosting model (XGBoost) consisting of 14 features exhibited high performance as measured by area under the curve (0.82), sensitivity (81%), and precision (81%) in predicting NASH. Slightly reduced performance was observed with an abbreviated feature set of 5 variables (0.79, 80%, 80%, respectively). The full model demonstrated good performance (AUC 0.76) to predict NASH in Optum data.
DISCUSSION: The proposed model, named NASHmap, is the first ML model developed with confirmed NASH and non-NASH cases as determined through liver biopsy and validated on a large, real-world patient dataset. Both the 14 and 5-feature versions exhibit high performance.
CONCLUSION: The NASHmap model is a convenient and high performing tool that could be used to identify patients likely to have NASH in clinical settings, allowing better patient management and optimal allocation of clinical resources.",True,other,Not specified
33684246,Development of machine learning model algorithm for prediction of 5-year soft tissue myxoid liposarcoma survival,"BACKGROUND: Predicting survival in myxoid liposarcoma (MLS) patients is very challenging given its propensity to metastasize and the controversial role of adjuvant therapy. The purpose of this study was to develop a machine-learning algorithm for the prediction of survival at five years for patients with MLS and externally validate it using our institutional cohort.
METHODS: Two databases, the surveillance, epidemiology, and end results program (SEER) database and an institutional database, were used in this study. Five machine learning models were created based on the SEER database and performance was rated using the TRIPOD criteria. The model that performed best on the SEER data was again tested on our institutional database.
RESULTS: The net-elastic penalized logistic regression model was the best according to our performance indicators. This model had an area under the curve (AUC) of 0.85 when compared to the SEER testing data and an AUC of 0.76 when tested against institutional database. An application to use this calculator is available at https://sorg-apps.shinyapps.io/myxoid_liposarcoma/.
CONCLUSION: MLS is a soft-tissue sarcoma with adjunct treatment options that are, in part, decided by prognostic survival. We developed the first machine-learning predictive algorithm specifically for MLS using the SEER registry that retained performance during external validation with institutional data.",True,other,Not specified
33661883,Treatment of individual predictors with neural network algorithms improves Global Registry of Acute Coronary Events score discrimination,"OBJECTIVE: The aim of this study was to develop, train, and test different neural network (NN) algorithm-based models to improve the Global Registry of Acute Coronary Events (GRACE) score performance to predict in-hospital mortality after an acute coronary syndrome.
METHODS: We analyzed a prospective database, including 40 admission variables of 1255 patients admitted with the acute coronary syndrome in a community hospital. Individual predictors included in GRACE score were used to train and test three NN algorithm-based models (guided models), namely: one- and two-hidden layer multilayer perceptron and a radial basis function network. Three extra NNs were built using the 40 admission variables of the entire database (unguided models). Expected mortality according to GRACE score was calculated using the logistic regression equation.
RESULTS: In terms of receiver operating characteristic area and negative predictive value (NPV), almost all NN algorithms outperformed logistic regression. Only radial basis function models obtained a better accuracy level based on NPV improvement, at the expense of positive predictive value (PPV) reduction. The independent normalized importance of variables for the best unguided NN was: creatinine 100%, Killip class 61%, ejection fraction 52%, age 44%, maximum creatine-kinase level 41%, glycemia 40%, left bundle branch block 35%, and weight 33%, among the top 8 predictors.
CONCLUSIONS: Treatment of individual predictors of GRACE score with NN algorithms improved accuracy and discrimination power in all models with respect to the traditional logistic regression approach; nevertheless, PPV was only marginally enhanced. Unguided variable selection would be able to achieve better results in PPV terms.",True,other,RNN
33564090,Machine learning prediction models for prognosis of critically ill patients after open-heart surgery,"We aimed to build up multiple machine learning models to predict 30-days mortality, and 3 complications including septic shock, thrombocytopenia, and liver dysfunction after open-heart surgery. Patients who underwent coronary artery bypass surgery, aortic valve replacement, or other heart-related surgeries between 2001 and 2012 were extracted from MIMIC-III databases. Extreme gradient boosting, random forest, artificial neural network, and logistic regression were employed to build models by utilizing fivefold cross-validation and grid search. Receiver operating characteristic curve, area under curve (AUC), decision curve analysis, test accuracy, F1 score, precision, and recall were applied to access the performance. Among 6844 patients enrolled in this study, 215 patients (3.1%) died within 30 days after surgery, part of patients appeared liver dysfunction (248; 3.6%), septic shock (32; 0.5%), and thrombocytopenia (202; 2.9%). XGBoost, selected to be our final model, achieved the best performance with highest AUC and F1 score. AUC and F1 score of XGBoost for 4 outcomes: 0.88 and 0.58 for 30-days mortality, 0.98 and 0.70 for septic shock, 0.88 and 0.55 for thrombocytopenia, 0.89 and 0.40 for liver dysfunction. We developed a promising model, presented as software, to realize monitoring for patients in ICU and to improve prognosis.",True,other,recurrent neural network
33557253,"Predicting Potential SARS-COV-2 Drugs-In Depth Drug Database Screening Using Deep Neural Network Framework SSnet, Classical Virtual Screening and Docking","Severe Acute Respiratory Syndrome Corona Virus 2 has altered life on a global scale. A concerted effort from research labs around the world resulted in the identification of potential pharmaceutical treatments for CoVID-19 using existing drugs, as well as the discovery of multiple vaccines. During an urgent crisis, rapidly identifying potential new treatments requires global and cross-discipline cooperation, together with an enhanced open-access research model to distribute new ideas and leads. Herein, we introduce an application of a deep neural network based drug screening method, validating it using a docking algorithm on approved drugs for drug repurposing efforts, and extending the screen to a large library of 750,000 compounds for de novo drug discovery effort. The results of large library screens are incorporated into an open-access web interface to allow researchers from diverse fields to target molecules of interest. Our combined approach allows for both the identification of existing drugs that may be able to be repurposed and de novo design of ACE2-regulatory compounds. Through these efforts we demonstrate the utility of a new machine learning algorithm for drug discovery, SSnet, that can function as a tool to triage large molecular libraries to identify classes of molecules with possible efficacy.",True,other,Not specified
33428298,Machine learning in liver transplantation: a tool for some unsolved questions?,"Machine learning has recently been proposed as a useful tool in many fields of Medicine, with the aim of increasing diagnostic and prognostic accuracy. Models based on machine learning have been introduced in the setting of solid organ transplantation too, where prognosis depends on a complex, multidimensional and nonlinear relationship between variables pertaining to the donor, the recipient and the surgical procedure. In the setting of liver transplantation, machine learning models have been developed to predict pretransplant survival in patients with cirrhosis, to assess the best donor-to-recipient match during allocation processes, and to foresee postoperative complications and outcomes. This is a narrative review on the role of machine learning in the field of liver transplantation, highlighting strengths and pitfalls, and future perspectives.",True,other,convolutional neural network
33410720,Clinical and inflammatory features based machine learning model for fatal risk prediction of hospitalized COVID-19 patients: results from a retrospective cohort study,"OBJECTIVES: To appraise effective predictors for COVID-19 mortality in a retrospective cohort study.
METHODS: A total of 1270 COVID-19 patients, including 984 admitted in Sino French New City Branch (training and internal validation sets randomly split at 7:3 ratio) and 286 admitted in Optical Valley Branch (external validation set) of Wuhan Tongji hospital, were included in this study. Forty-eight clinical and laboratory features were screened with LASSO method. Further multi-tree extreme gradient boosting (XGBoost) machine learning-based model was used to rank importance of features selected from LASSO and subsequently constructed death risk prediction model with simple-tree XGBoost model. Performances of models were evaluated by AUC, prediction accuracy, precision, and F1 scores.
RESULTS: Six features, including disease severity, age, levels of high-sensitivity C-reactive protein (hs-CRP), lactate dehydrogenase (LDH), ferritin, and interleukin-10 (IL-10), were selected as predictors for COVID-19 mortality. Simple-tree XGBoost model conducted by these features can predict death risk accurately with >90% precision and >85% sensitivity, as well as F1 scores >0.90 in training and validation sets.
CONCLUSION: We proposed the disease severity, age, serum levels of hs-CRP, LDH, ferritin, and IL-10 as significant predictors for death risk of COVID-19, which may help to identify the high-risk COVID-19 cases. KEY MESSAGES A machine learning method is used to build death risk model for COVID-19 patients. Disease severity, age, hs-CRP, LDH, ferritin, and IL-10 are death risk factors. These findings may help to identify the high-risk COVID-19 cases.",True,other,Not specified
33362244,Assessing the risk of dengue severity using demographic information and laboratory test results with machine learning,"BACKGROUND: Dengue virus causes a wide spectrum of disease, which ranges from subclinical disease to severe dengue shock syndrome. However, estimating the risk of severe outcomes using clinical presentation or laboratory test results for rapid patient triage remains a challenge. Here, we aimed to develop prognostic models for severe dengue using machine learning, according to demographic information and clinical laboratory data of patients with dengue.
METHODOLOGY/PRINCIPAL FINDINGS: Out of 1,581 patients in the National Cheng Kung University Hospital with suspected dengue infections and subjected to NS1 antigen, IgM and IgG, and qRT-PCR tests, 798 patients including 138 severe cases were enrolled in the study. The primary target outcome was severe dengue. Machine learning models were trained and tested using the patient dataset that included demographic information and qualitative laboratory test results collected on day 1 when they sought medical advice. To develop prognostic models, we applied various machine learning methods, including logistic regression, random forest, gradient boosting machine, support vector classifier, and artificial neural network, and compared the performance of the methods. The artificial neural network showed the highest average discrimination area under the receiver operating characteristic curve (0.8324 ± 0.0268) and balance accuracy (0.7523 ± 0.0273). According to the model explainer that analyzed the contributions/co-contributions of the different factors, patient age and dengue NS1 antigenemia were the two most important risk factors associated with severe dengue. Additionally, co-existence of anti-dengue IgM and IgG in patients with dengue increased the probability of severe dengue.
CONCLUSIONS/SIGNIFICANCE: We developed prognostic models for the prediction of dengue severity in patients, using machine learning. The discriminative ability of the artificial neural network exhibited good performance for severe dengue prognosis. This model could help clinicians obtain a rapid prognosis during dengue outbreaks. However, the model requires further validation using external cohorts in future studies.",True,other,Not specified
33301414,An Artificial Intelligence Model to Predict the Mortality of COVID-19 Patients at Hospital Admission Time Using Routine Blood Samples: Development and Validation of an Ensemble Model,"BACKGROUND: COVID-19, which is accompanied by acute respiratory distress, multiple organ failure, and death, has spread worldwide much faster than previously thought. However, at present, it has limited treatments.
OBJECTIVE: To overcome this issue, we developed an artificial intelligence (AI) model of COVID-19, named EDRnet (ensemble learning model based on deep neural network and random forest models), to predict in-hospital mortality using a routine blood sample at the time of hospital admission.
METHODS: We selected 28 blood biomarkers and used the age and gender information of patients as model inputs. To improve the mortality prediction, we adopted an ensemble approach combining deep neural network and random forest models. We trained our model with a database of blood samples from 361 COVID-19 patients in Wuhan, China, and applied it to 106 COVID-19 patients in three Korean medical institutions.
RESULTS: In the testing data sets, EDRnet provided high sensitivity (100%), specificity (91%), and accuracy (92%). To extend the number of patient data points, we developed a web application (BeatCOVID19) where anyone can access the model to predict mortality and can register his or her own blood laboratory results.
CONCLUSIONS: Our new AI model, EDRnet, accurately predicts the mortality rate for COVID-19. It is publicly available and aims to help health care providers fight COVID-19 and improve patients' outcomes.",True,other,recurrent neural network
33262083,Artificial Neural Networks as a Way to Predict Future Kidney Cancer Incidence in the United States,"INTRODUCTION: The incidence of kidney cancer is increasing; it could be counteracted with new ways to predict and detect it. We aimed to implement an artificial neural network in order to predict new cases of renal-cell carcinoma (RCC) in the population using population rate, obesity, smoking incidence, uncontrolled hypertension, and life expectancy data in the United States.
PATIENTS AND METHODS: Statistics were collected on US population numbers, life expectancy, obesity, smoking, and hypertension. We used MATLAB R2018 (MathWorks) software to implement an artificial neural network. Data were repeatedly and randomly divided into training (70%) and validation (30%) subsets.
RESULTS: The number of new RCC cases will grow from 44,400 (2020) to 55,400 (2050), an increase of +24.7%. Our data show that preventing hypertension would have the greatest impact on reduction of the incidence, estimated at -775 and -575 cases per year in 2020 and in 2030, respectively. The prevention of obesity and smoking would have a more limited impact, estimated at -64 and -180 cases per year in 2020 and in 2030, respectively, for obesity, and -173 and -21 cases per year in 2020 and in 2030, respectively, for smoking.
CONCLUSIONS: Our predictions underline the need for accurate studies on RCC-related risk factors to reduce the incidence.",True,other,recurrent neural network
33238219,Development of a machine learning algorithm to predict intubation among hospitalized patients with COVID-19,"PURPOSE: The purpose of this study is to develop a machine learning algorithm to predict future intubation among patients diagnosed or suspected with COVID-19.
MATERIALS AND METHODS: This is a retrospective cohort study of patients diagnosed or under investigation for COVID-19. A machine learning algorithm was trained to predict future presence of intubation based on prior vitals, laboratory, and demographic data. Model performance was compared to ROX index, a validated prognostic tool for prediction of mechanical ventilation.
RESULTS: 4087 patients admitted to five hospitals between February 2020 and April 2020 were included. 11.03% of patients were intubated. The machine learning model outperformed the ROX-index, demonstrating an area under the receiver characteristic curve (AUC) of 0.84 and 0.64, and area under the precision-recall curve (AUPRC) of 0.30 and 0.13, respectively. In the Kaplan-Meier analysis, patients alerted by the model were more likely to require intubation during their admission (p < 0.0001).
CONCLUSION: In patients diagnosed or under investigation for COVID-19, machine learning can be used to predict future risk of intubation based on clinical data which are routinely collected and available in clinical setting. Such an approach may facilitate identification of high-risk patients to assist in clinical care.",True,other,RNN
33225319,A Machine Learning-Aided Global Diagnostic and Comparative Tool to Assess Effect of Quarantine Control in COVID-19 Spread,"We have developed a globally applicable diagnostic COVID-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms used on publicly available COVID-19 data. The model decomposes the contributions to the infection time series to analyze and compare the role of quarantine control policies used in highly affected regions of Europe, North America, South America, and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions' respective governments. In addition, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform.",True,computer vision,recurrent neural network
33181159,Predicting the development of adverse cardiac events in patients with hypertrophic cardiomyopathy using machine learning,"BACKGROUND: Only a subset of patients with hypertrophic cardiomyopathy (HCM) develop adverse cardiac events - e.g., end-stage heart failure, cardiovascular death. Current risk stratification methods are imperfect, limiting identification of high-risk patients with HCM. Our aim was to improve the prediction of adverse cardiac events in patients with HCM using machine learning methods.
METHODS: We applied modern machine learning methods to a prospective cohort of adults with HCM. The outcome was a composite of death due to heart failure, heart transplant, and sudden death. As the reference model, we constructed logistic regression model using known predictors. We determined 20 predictive characteristics based on random forest classification and a priori knowledge, and developed 4 machine learning models. Results Of 183 patients in the cohort, the mean age was 53 (SD = 17) years and 45% were female. During the median follow-up of 2.2 years (interquartile range, 0.6-3.8), 33 subjects (18%) developed an outcome event, the majority of which (85%) was heart transplant. The predictive accuracy of the reference model was 73% (sensitivity 76%, specificity 72%) while that of the machine learning model was 85% (e.g., sensitivity 88%, specificity 84% with elastic net regression). All 4 machine learning models significantly outperformed the reference model - e.g., area under the receiver-operating-characteristic curve 0.79 with the reference model vs. 0.93 with elastic net regression (p < 0.001).
CONCLUSIONS: Compared with conventional risk stratification, the machine learning models demonstrated a superior ability to predict adverse cardiac events. These modern machine learning methods may enhance identification of high-risk HCM subpopulations.",True,other,Not specified
33180900,In pursuit of glioma diagnosis: the challenges and opportunities of deep neural network augmented analyses,,True,other,GAN
33141161,"Development, Validation, and Evaluation of a Simple Machine Learning Model to Predict Cirrhosis Mortality","IMPORTANCE: Machine-learning algorithms offer better predictive accuracy than traditional prognostic models but are too complex and opaque for clinical use.
OBJECTIVE: To compare different machine learning methods in predicting overall mortality in cirrhosis and to use machine learning to select easily scored clinical variables for a novel cirrhosis prognostic model.
DESIGN, SETTING, AND PARTICIPANTS: This prognostic study used a retrospective cohort of adult patients with cirrhosis or its complications seen in 130 hospitals and affiliated ambulatory clinics in the integrated, national Veterans Affairs health care system from October 1, 2011, to September 30, 2015. Patients were followed up through December 31, 2018. Data were analyzed from October 1, 2017, to May 31, 2020.
EXPOSURES: Potential predictors included demographic characteristics; liver disease etiology, severity, and complications; use of health care resources; comorbid conditions; and comprehensive laboratory and medication data. Patients were randomly selected for model development (66.7%) and validation (33.3%). Three different statistical and machine learning methods were evaluated: gradient descent boosting, logistic regression with least absolute shrinkage and selection operator (LASSO) regularization, and logistic regression with LASSO constrained to select no more than 10 predictors (partial pathway model). Predictor inclusion and model performance were evaluated in a 5-fold cross-validation. Last, the predictors identified in the most parsimonious (the partial path) model were refit using maximum-likelihood estimation (Cirrhosis Mortality Model [CiMM]), and its predictive performance was compared with that of the widely used Model for End Stage Liver Disease with sodium (MELD-Na) score.
MAIN OUTCOMES AND MEASURES: All-cause mortality.
RESULTS: Of the 107 939 patients with cirrhosis (mean [SD] age, 62.7 [9.6] years; 96.6% male; 66.3% white, 18.4% African American), the annual mortality rate ranged from 8.8% to 15.3%. In total, 32.7% of patients died within 3 years, and 46.2% died within 5 years after the index date. Models predicting 1-year mortality had good discrimination for the gradient descent boosting (area under the receiver operating characteristics curve [AUC], 0.81; 95% CI, 0.80-0.82), logistic regression with LASSO regularization (AUC, 0.78; 95% CI, 0.77-0.79), and the partial path logistic model (AUC, 0.78; 95% CI, 0.76-0.78). All models showed good calibration. The final CiMM model with machine learning-derived clinical variables offered significantly better discrimination than the MELD-Na score, with AUCs of 0.78 (95% CI, 0.77-0.79) vs 0.67 (95% CI, 0.66-0.68) for 1-year mortality, respectively (DeLong z = 17.00; P < .001).
CONCLUSIONS AND RELEVANCE: In this study, simple machine learning techniques performed as well as the more advanced ensemble gradient boosting. Using the clinical variables identified from simple machine learning in a cirrhosis mortality model produced a new score more transparent than machine learning and more predictive than the MELD-Na score.",True,other,Not specified
33108316,An Easy-to-Use Machine Learning Model to Predict the Prognosis of Patients With COVID-19: Retrospective Cohort Study,"BACKGROUND: Prioritizing patients in need of intensive care is necessary to reduce the mortality rate during the COVID-19 pandemic. Although several scoring methods have been introduced, many require laboratory or radiographic findings that are not always easily available.
OBJECTIVE: The purpose of this study was to develop a machine learning model that predicts the need for intensive care for patients with COVID-19 using easily obtainable characteristics-baseline demographics, comorbidities, and symptoms.
METHODS: A retrospective study was performed using a nationwide cohort in South Korea. Patients admitted to 100 hospitals from January 25, 2020, to June 3, 2020, were included. Patient information was collected retrospectively by the attending physicians in each hospital and uploaded to an online case report form. Variables that could be easily provided were extracted. The variables were age, sex, smoking history, body temperature, comorbidities, activities of daily living, and symptoms. The primary outcome was the need for intensive care, defined as admission to the intensive care unit, use of extracorporeal life support, mechanical ventilation, vasopressors, or death within 30 days of hospitalization. Patients admitted until March 20, 2020, were included in the derivation group to develop prediction models using an automated machine learning technique. The models were externally validated in patients admitted after March 21, 2020. The machine learning model with the best discrimination performance was selected and compared against the CURB-65 (confusion, urea, respiratory rate, blood pressure, and 65 years of age or older) score using the area under the receiver operating characteristic curve (AUC).
RESULTS: A total of 4787 patients were included in the analysis, of which 3294 were assigned to the derivation group and 1493 to the validation group. Among the 4787 patients, 460 (9.6%) patients needed intensive care. Of the 55 machine learning models developed, the XGBoost model revealed the highest discrimination performance. The AUC of the XGBoost model was 0.897 (95% CI 0.877-0.917) for the derivation group and 0.885 (95% CI 0.855-0.915) for the validation group. Both the AUCs were superior to those of CURB-65, which were 0.836 (95% CI 0.825-0.847) and 0.843 (95% CI 0.829-0.857), respectively.
CONCLUSIONS: We developed a machine learning model comprising simple patient-provided characteristics, which can efficiently predict the need for intensive care among patients with COVID-19.",True,computer vision,Not specified
33078300,"Machine Learning to Develop and Internally Validate a Predictive Model for Post-operative Delirium in a Prospective, Observational Clinical Cohort Study of Older Surgical Patients","BACKGROUND: Our objective was to assess the performance of machine learning methods to predict post-operative delirium using a prospective clinical cohort.
METHODS: We analyzed data from an observational cohort study of 560 older adults (≥ 70 years) without dementia undergoing major elective non-cardiac surgery. Post-operative delirium was determined by the Confusion Assessment Method supplemented by a medical chart review (N = 134, 24%). Five machine learning algorithms and a standard stepwise logistic regression model were developed in a training sample (80% of participants) and evaluated in the remaining hold-out testing sample. We evaluated three overlapping feature sets, restricted to variables that are readily available or minimally burdensome to collect in clinical settings, including interview and medical record data. A large feature set included 71 potential predictors. A smaller set of 18 features was selected by an expert panel using a consensus process, and this smaller feature set was considered with and without a measure of pre-operative mental status.
RESULTS: The area under the receiver operating characteristic curve (AUC) was higher in the large feature set conditions (range of AUC, 0.62-0.71 across algorithms) versus the selected feature set conditions (AUC range, 0.53-0.57). The restricted feature set with mental status had intermediate AUC values (range, 0.53-0.68). In the full feature set condition, algorithms such as gradient boosting, cross-validated logistic regression, and neural network (AUC = 0.71, 95% CI 0.58-0.83) were comparable with a model developed using traditional stepwise logistic regression (AUC = 0.69, 95% CI 0.57-0.82). Calibration for all models and feature sets was poor.
CONCLUSIONS: We developed machine learning prediction models for post-operative delirium that performed better than chance and are comparable with traditional stepwise logistic regression. Delirium proved to be a phenotype that was difficult to predict with appreciable accuracy.",True,other,recurrent neural network
33046699,Deep transfer learning for reducing health care disparities arising from biomedical data inequality,"As artificial intelligence (AI) is increasingly applied to biomedical research and clinical decisions, developing unbiased AI models that work equally well for all ethnic groups is of crucial importance to health disparity prevention and reduction. However, the biomedical data inequality between different ethnic groups is set to generate new health care disparities through data-driven, algorithm-based biomedical research and clinical decisions. Using an extensive set of machine learning experiments on cancer omics data, we find that current prevalent schemes of multiethnic machine learning are prone to generating significant model performance disparities between ethnic groups. We show that these performance disparities are caused by data inequality and data distribution discrepancies between ethnic groups. We also find that transfer learning can improve machine learning model performance for data-disadvantaged ethnic groups, and thus provides an effective approach to reduce health care disparities arising from data inequality among ethnic groups.",True,other,Not specified
33024092,Machine learning based early warning system enables accurate mortality risk prediction for COVID-19,"Soaring cases of coronavirus disease (COVID-19) are pummeling the global health system. Overwhelmed health facilities have endeavored to mitigate the pandemic, but mortality of COVID-19 continues to increase. Here, we present a mortality risk prediction model for COVID-19 (MRPMC) that uses patients' clinical data on admission to stratify patients by mortality risk, which enables prediction of physiological deterioration and death up to 20 days in advance. This ensemble model is built using four machine learning methods including Logistic Regression, Support Vector Machine, Gradient Boosted Decision Tree, and Neural Network. We validate MRPMC in an internal validation cohort and two external validation cohorts, where it achieves an AUC of 0.9621 (95% CI: 0.9464-0.9778), 0.9760 (0.9613-0.9906), and 0.9246 (0.8763-0.9729), respectively. This model enables expeditious and accurate mortality risk stratification of patients with COVID-19, and potentially facilitates more responsive health systems that are conducive to high risk COVID-19 patients.",True,computer vision,recurrent neural network
33004133,"Machine Learning Improves Cardiovascular Risk Definition for Young, Asymptomatic Individuals","BACKGROUND: Clinical practice guidelines recommend assessment of subclinical atherosclerosis using imaging techniques in individuals with intermediate atherosclerotic cardiovascular risk according to standard risk prediction tools.
OBJECTIVES: The purpose of this study was to develop a machine-learning model based on routine, quantitative, and easily measured variables to predict the presence and extent of subclinical atherosclerosis (SA) in young, asymptomatic individuals. The risk of having SA estimated by this model could be used to refine risk estimation and optimize the use of imaging for risk assessment.
METHODS: The Elastic Net (EN) model was built to predict SA extent, defined by a combined metric of the coronary artery calcification score and 2-dimensional vascular ultrasound. The performance of the model for the prediction of SA extension and progression was compared with traditional risk scores of cardiovascular disease (CVD). An external independent cohort was used for validation.
RESULTS: EN-PESA (Progression of Early Subclinical Atherosclerosis) yielded a c-statistic of 0.88 for the prediction of generalized subclinical atherosclerosis. Moreover, EN-PESA was found to be a predictor of 3-year progression independent of the baseline extension of SA. EN-PESA assigned an intermediate to high cardiovascular risk to 40.1% (n = 1,411) of the PESA individuals, a significantly larger number than atherosclerotic CVD (n = 267) and SCORE (Systematic Coronary Risk Evaluation) (n = 507) risk scores. In total, 86.8% of the individuals with an increased risk based on EN-PESA presented signs of SA at baseline or a significant progression of SA over 3 years.
CONCLUSIONS: The EN-PESA model uses age, systolic blood pressure, and 10 commonly used blood/urine tests and dietary intake values to identify young, asymptomatic individuals with an increased risk of CVD based on their extension and progression of SA. These individuals are likely to benefit from imaging tests or pharmacological treatment. (Progression of Early Subclinical Atherosclerosis [PESA]; NCT01410318).",True,other,Not specified
32844582,Machine-learning-based early prediction of end-stage renal disease in patients with diabetic kidney disease using clinical trials data,"AIM: To predict end-stage renal disease (ESRD) in patients with type 2 diabetes by using machine-learning models with multiple baseline demographic and clinical characteristics.
MATERIALS AND METHODS: In total, 11 789 patients with type 2 diabetes and nephropathy from three clinical trials, RENAAL (n = 1513), IDNT (n = 1715) and ALTITUDE (n = 8561), were used in this study. Eighteen baseline demographic and clinical characteristics were used as predictors to train machine-learning models to predict ESRD (doubling of serum creatinine and/or ESRD). We used the area under the receiver operator curve (AUC) to assess the prediction performance of models and compared this with traditional Cox proportional hazard regression and kidney failure risk equation models.
RESULTS: The feed forward neural network model predicted ESRD with an AUC of 0.82 (0.76-0.87), 0.81 (0.75-0.86) and 0.84 (0.79-0.90) in the RENAAL, IDNT and ALTITUDE trials, respectively. The feed forward neural network model selected urinary albumin to creatinine ratio, serum albumin, uric acid and serum creatinine as important predictors and obtained a state-of-the-art performance for predicting long-term ESRD.
CONCLUSIONS: Despite large inter-patient variability, non-linear machine-learning models can be used to predict long-term ESRD in patients with type 2 diabetes and nephropathy using baseline demographic and clinical characteristics. The proposed method has the potential to create accurate and multiple outcome prediction automated models to identify high-risk patients who could benefit from therapy in clinical practice.",True,other,Not specified
32821921,Development of a Machine Learning Model for Survival Risk Stratification of Patients With Advanced Oral Cancer,"IMPORTANCE: A tool for precisely stratifying postoperative patients with advanced oral cancer is crucial for the treatment plan, such as intensifying or deintensifying the regimen to improve their quality of life and prognosis.
OBJECTIVE: To develop and validate a machine learning-based algorithm that can provide survival risk stratification for patients with advanced oral cancer who have comprehensive clinicopathologic and genetic data.
DESIGN, SETTING, AND PARTICIPANTS: In this prognostic cohort study, the elastic net penalized Cox proportional hazards regression-based risk stratification model was developed and validated using single-center data collected between January 1, 1996, and December 31, 2011. In total, comprehensive clinicopathologic and genetic data (including clinical, pathologic, and 44 cancer-related gene variant profiles) of 334 patients with stage III or IV oral squamous cell carcinoma were used to develop and validate the algorithm in this 15-year cohort study. Data analysis was conducted between February 1, 2018, and May 6, 2020.
MAIN OUTCOMES AND MEASURES: The main outcomes were cancer-specific survival, distant metastasis-free survival, and locoregional recurrence-free survival. Model performance was compared in terms of the Akaike information criterion and the Harrell concordance index (C index).
RESULTS: Complete data were available for 334 patients (315 men; median age at onset, 48 years [interquartile range, 42-56 years]). The predictive models using comprehensive clinicopathologic and genetic data outperformed those using clinicopathologic data alone. In the groups of postoperative patients receiving adjuvant concurrent chemoradiotherapy, the models demonstrated higher classification performance than those using clinicopathologic data alone in cancer-specific survival (mean [SD] C index, 0.689 [0.050] vs 0.673 [0.051]; P = .02) and locoregional recurrence-free survival (mean [SD] C index, 0.693 [0.039] vs 0.678 [0.035]; P = .004). The classification performance in distant metastasis-free survival was not different (mean [SD] C index, 0.702 [0.056] vs 0.688 [0.048]; P = .09).
CONCLUSIONS AND RELEVANCE: A risk stratification model using comprehensive clinicopathologic and genetic data accurately differentiated the high-risk group from the low-risk group in cancer-specific survival and locoregional recurrence-free survival for postoperative patients with advanced oral cancer. This algorithm could be used through an online calculator to provide additional personalized information for postoperative management of patients with advanced oral squamous cell carcinoma.",True,other,Not specified
32810233,Can machine learning improve mortality prediction following cardiac surgery?,"OBJECTIVES: Interest in the clinical usefulness of machine learning for risk prediction has bloomed recently. Cardiac surgery patients are at high risk of complications and therefore presurgical risk assessment is of crucial relevance. We aimed to compare the performance of machine learning algorithms over traditional logistic regression (LR) model to predict in-hospital mortality following cardiac surgery.
METHODS: A single-centre data set of prospectively collected information from patients undergoing adult cardiac surgery from 1996 to 2017 was split into 70% training set and 30% testing set. Prediction models were developed using neural network, random forest, naive Bayes and retrained LR based on features included in the EuroSCORE. Discrimination was assessed using area under the receiver operating characteristic curve, and calibration analysis was undertaken using the calibration belt method. Model calibration drift was assessed by comparing Goodness of fit χ2 statistics observed in 2 equal bins from the testing sample ordered by procedure date.
RESULTS: A total of 28 761 cardiac procedures were performed during the study period. The in-hospital mortality rate was 2.7%. Retrained LR [area under the receiver operating characteristic curve 0.80; 95% confidence interval (CI) 0.77-0.83] and random forest model (0.80; 95% CI 0.76-0.83) showed the best discrimination. All models showed significant miscalibration. Retrained LR proved to have the weakest calibration drift.
CONCLUSIONS: Our findings do not support the hypothesis that machine learning methods provide advantage over LR model in predicting operative mortality after cardiac surgery.",True,other,Not specified
32773672,A statistically rigorous deep neural network approach to predict mortality in trauma patients admitted to the intensive care unit,"BACKGROUND: Trauma patients admitted to critical care are at high risk of mortality because of their injuries. Our aim was to develop a machine learning-based model to predict mortality using Fahad-Liaqat-Ahmad Intensive Machine (FLAIM) framework. We hypothesized machine learning could be applied to critically ill patients and would outperform currently used mortality scores.
METHODS: The current Deep-FLAIM model evaluates the statistically significant risk factors and then supply these risk factors to deep neural network to predict mortality in trauma patients admitted to the intensive care unit (ICU). We analyzed adult patients (≥18 years) admitted to the trauma ICU in the publicly available database Medical Information Mart for Intensive Care III version 1.4. The first phase selection of risk factor was done using Cox-regression univariate and multivariate analyses. In the second phase, we applied deep neural network and other traditional machine learning models like Linear Discriminant Analysis, Gaussian Naïve Bayes, Decision Tree Model, and k-nearest neighbor models.
RESULTS: We identified a total of 3,041 trauma patients admitted to the trauma surgery ICU. We observed that several clinical and laboratory-based variables were statistically significant for both univariate and multivariate analyses while others were not. With most significant being serum anion gap (hazard ratio [HR], 2.46; 95% confidence interval [CI], 1.94-3.11), sodium (HR, 2.11; 95% CI, 1.61-2.77), and chloride (HR, 2.11; 95% CI, 1.69-2.64) abnormalities on laboratories, while clinical variables included the diagnosis of sepsis (HR, 2.03; 95% CI, 1.23-3.37), Quick Sequential Organ Failure Assessment score (HR, 1.52; 95% CI, 1.32-3.76). And Systemic Inflammatory Response Syndrome criteria (HR. 1.41; 95% CI, 1.24-1.26). After we used these clinically significant variables and applied various machine learning models to the data, we found out that our proposed DNN outperformed all the other methods with test set accuracy of 92.25%, sensitivity of 79.13%, and specificity of 94.16%; positive predictive value, 66.42%; negative predictive value, 96.87%; and area under the curve of the receiver-operator curve of 0.91 (1.45-1.29).
CONCLUSION: Our novel Deep-FLAIM model outperformed all other machine learning models. The model is easy to implement, user friendly and with high accuracy.
LEVEL OF EVIDENCE: Prognostic study, level II.",True,other,convolutional neural network
32773372,Personal Health Information Inference Using Machine Learning on RNA Expression Data from Patients With Cancer: Algorithm Validation Study,"BACKGROUND: As the need for sharing genomic data grows, privacy issues and concerns, such as the ethics surrounding data sharing and disclosure of personal information, are raised.
OBJECTIVE: The main purpose of this study was to verify whether genomic data is sufficient to predict a patient's personal information.
METHODS: RNA expression data and matched patient personal information were collected from 9538 patients in The Cancer Genome Atlas program. Five personal information variables (age, gender, race, cancer type, and cancer stage) were recorded for each patient. Four different machine learning algorithms (support vector machine, decision tree, random forest, and artificial neural network) were used to determine whether a patient's personal information could be accurately predicted from RNA expression data. Performance measurement of the prediction models was based on the accuracy and area under the receiver operating characteristic curve. We selected five cancer types (breast carcinoma, kidney renal clear cell carcinoma, head and neck squamous cell carcinoma, low-grade glioma, and lung adenocarcinoma) with large samples sizes to verify whether predictive accuracy would differ between them. We also validated the efficacy of our four machine learning models in analyzing normal samples from 593 cancer patients.
RESULTS: In most samples, personal information with high genetic relevance, such as gender and cancer type, could be predicted from RNA expression data alone. The prediction accuracies for gender and cancer type, which were the best models, were 0.93-0.99 and 0.78-0.94, respectively. Other aspects of personal information, such as age, race, and cancer stage, were difficult to predict from RNA expression data, with accuracies ranging from 0.0026-0.29, 0.76-0.96, and 0.45-0.79, respectively. Among the tested machine learning methods, the highest predictive accuracy was obtained using the support vector machine algorithm (mean accuracy 0.77), while the lowest accuracy was obtained using the random forest method (mean accuracy 0.65). Gender and race were predicted more accurately than other variables in the samples. On average, the accuracy of cancer stage prediction ranged between 0.71-0.67, while the age prediction accuracy ranged between 0.18-0.23 for the five cancer types.
CONCLUSIONS: We attempted to predict patient information using RNA expression data. We found that some identifiers could be predicted, but most others could not. This study showed that personal information available from RNA expression data is limited and this information cannot be used to identify specific patients.",True,other,Not specified
32652499,Use of Machine Learning and Artificial Intelligence to predict SARS-CoV-2 infection from Full Blood Counts in a population,"Since December 2019 the novel coronavirus SARS-CoV-2 has been identified as the cause of the pandemic COVID-19. Early symptoms overlap with other common conditions such as common cold and Influenza, making early screening and diagnosis are crucial goals for health practitioners. The aim of the study was to use machine learning (ML), an artificial neural network (ANN) and a simple statistical test to identify SARS-CoV-2 positive patients from full blood counts without knowledge of symptoms or history of the individuals. The dataset included in the analysis and training contains anonymized full blood counts results from patients seen at the Hospital Israelita Albert Einstein, at São Paulo, Brazil, and who had samples collected to perform the SARS-CoV-2 rt-PCR test during a visit to the hospital. Patient data was anonymised by the hospital, clinical data was standardized to have a mean of zero and a unit standard deviation. This data was made public with the aim to allow researchers to develop ways to enable the hospital to rapidly predict and potentially identify SARS-CoV-2 positive patients. We find that with full blood counts random forest, shallow learning and a flexible ANN model predict SARS-CoV-2 patients with high accuracy between populations on regular wards (AUC = 94-95%) and those not admitted to hospital or in the community (AUC = 80-86%). Here, AUC is the Area Under the receiver operating characteristics Curve and a measure for model performance. Moreover, a simple linear combination of 4 blood counts can be used to have an AUC of 85% for patients within the community. The normalised data of different blood parameters from SARS-CoV-2 positive patients exhibit a decrease in platelets, leukocytes, eosinophils, basophils and lymphocytes, and an increase in monocytes. SARS-CoV-2 positive patients exhibit a characteristic immune response profile pattern and changes in different parameters measured in the full blood count that are detected from simple and rapid blood tests. While symptoms at an early stage of infection are known to overlap with other common conditions, parameters of the full blood counts can be analysed to distinguish the viral type at an earlier stage than current rt-PCR tests for SARS-CoV-2 allow at present. This new methodology has potential to greatly improve initial screening for patients where PCR based diagnostic tools are limited.",True,other,Not specified
32591310,Machine-Learning-Based In-Hospital Mortality Prediction for Transcatheter Mitral Valve Repair in the United States,"BACKGROUND: Transcatheter mitral valve repair (TMVR) utilization has increased significantly in the United States over the last years. Yet, a risk-prediction tool for adverse events has not been developed. We aimed to generate a machine-learning-based algorithm to predict in-hospital mortality after TMVR.
METHODS: Patients who underwent TMVR from 2012 through 2015 were identified using the National Inpatient Sample database. The study population was randomly divided into a training set (n = 636) and a testing set (n = 213). Prediction models for in-hospital mortality were obtained using five supervised machine-learning classifiers.
RESULTS: A total of 849 TMVRs were analyzed in our study. The overall in-hospital mortality was 3.1%. A naïve Bayes (NB) model had the best discrimination for fifteen variables, with an area under the receiver-operating curve (AUC) of 0.83 (95% CI, 0.80-0.87), compared to 0.77 for logistic regression (95% CI, 0.58-0.95), 0.73 for an artificial neural network (95% CI, 0.55-0.91), and 0.67 for both a random forest and a support-vector machine (95% CI, 0.47-0.87). History of coronary artery disease, of chronic kidney disease, and smoking were the three most significant predictors of in-hospital mortality.
CONCLUSIONS: We developed a robust machine-learning-derived model to predict in-hospital mortality in patients undergoing TMVR. This model is promising for decision-making and deserves further clinical validation.",True,both,Not specified
32549653,Measuring the Quality of Explanations: The System Causability Scale (SCS): Comparing Human and Machine Explanations,"Recent success in Artificial Intelligence (AI) and Machine Learning (ML) allow problem solving automatically without any human intervention. Autonomous approaches can be very convenient. However, in certain domains, e.g., in the medical domain, it is necessary to enable a domain expert to understand, why an algorithm came up with a certain result. Consequently, the field of Explainable AI (xAI) rapidly gained interest worldwide in various domains, particularly in medicine. Explainable AI studies transparency and traceability of opaque AI/ML and there are already a huge variety of methods. For example with layer-wise relevance propagation relevant parts of inputs to, and representations in, a neural network which caused a result, can be highlighted. This is a first important step to ensure that end users, e.g., medical professionals, assume responsibility for decision making with AI/ML and of interest to professionals and regulators. Interactive ML adds the component of human expertise to AI/ML processes by enabling them to re-enact and retrace AI/ML results, e.g. let them check it for plausibility. This requires new human-AI interfaces for explainable AI. In order to build effective and efficient interactive human-AI interfaces we have to deal with the question of how to evaluate the quality of explanations given by an explainable AI system. In this paper we introduce our System Causability Scale to measure the quality of explanations. It is based on our notion of Causability (Holzinger et al. in Wiley Interdiscip Rev Data Min Knowl Discov 9(4), 2019) combined with concepts adapted from a widely-accepted usability scale.",True,other,CNN
32488331,Borrowing external information to improve Bayesian confidence propagation neural network,"PURPOSE: A Bayesian confidence propagation neural network (BCPNN) is a signal detection method used by the World Health Organization Uppsala Monitoring Centre to analyze spontaneous reporting system databases. We modify the BCPNN to increase its sensitivity for detecting potential adverse drug reactions (ADRs).
METHOD: In a BCPNN, the information component (IC) is defined as an index of disproportionality between the observed and expected number of reported drugs and events. Our proposed method adjusts the IC value by borrowing information about events that have occurred in drugs defined as similar to the target drug. We compare the performance of our method with that of a traditional BCPNN through a simulation study.
RESULTS: The false positive rate of the proposed method was lower than that of the traditional BCPNN method and close to the nominal value, 0.025, around the true difference in ICs between the target drug and similar drugs equal to 0. The sensitivity of the proposed method was much higher than that of the traditional BCPNN method in case in which the difference in ICs between the target drug and similar drugs ranges from 0 to 2. When applied to a database managed by Japanese regulatory authority, the proposed method could detect known ADRs earlier than the traditional method.
CONCLUSIONS: The proposed method is a novel criterion for early detection of signals if similar drugs have the same tendencies. The proposed BCPNN tends to have higher sensitivity when the true difference is greater than 0.",True,other,CNN
32401790,Differentiation of Cytopathic Effects (CPE) induced by influenza virus infection using deep Convolutional Neural Networks (CNN),"Cell culture remains as the golden standard for primary isolation of viruses in clinical specimens. In the current practice, researchers have to recognize the cytopathic effects (CPE) induced by virus infection and subsequently use virus-specific monoclonal antibody to confirm the presence of virus. Considering the broad applications of neural network in various fields, we aimed to utilize convolutional neural networks (CNN) to shorten the timing required for CPE identification and to improve the assay sensitivity. Based on the characteristics of influenza-induced CPE, a CNN model with larger sizes of filters and max-pooling kernels was constructed in the absence of transfer learning. A total of 601 images from mock-infected and influenza-infected MDCK cells were used to train the model. The performance of the model was tested by using extra 400 images and the percentage of correct recognition was 99.75%. To further examine the limit of our model in evaluating the changes of CPE overtime, additional 1190 images from a new experiment were used and the recognition rates at 16 hour (hr), 28 hr, and 40 hr post virus infection were 71.80%, 98.25%, and 87.46%, respectively. The specificity of our model, examined by images of MDCK cells infected by six other non-influenza viruses, was 100%. Hence, a simple CNN model was established to enhance the identification of influenza virus in clinical practice.",True,other,CNN
32401216,Using Machine Learning to Predict Early Onset Acute Organ Failure in Critically Ill Intensive Care Unit Patients With Sickle Cell Disease: Retrospective Study,"BACKGROUND: Sickle cell disease (SCD) is a genetic disorder of the red blood cells, resulting in multiple acute and chronic complications, including pain episodes, stroke, and kidney disease. Patients with SCD develop chronic organ dysfunction, which may progress to organ failure during disease exacerbations. Early detection of acute physiological deterioration leading to organ failure is not always attainable. Machine learning techniques that allow for prediction of organ failure may enable early identification and treatment and potentially reduce mortality.
OBJECTIVE: The aim of this study was to test the hypothesis that machine learning physiomarkers can predict the development of organ dysfunction in a sample of adult patients with SCD admitted to intensive care units (ICUs).
METHODS: We applied diverse machine learning methods, statistical methods, and data visualization techniques to develop classification models to distinguish SCD from controls.
RESULTS: We studied 63 sequential SCD patients admitted to ICUs with 163 patient encounters (mean age 30.7 years, SD 9.8 years). A subset of these patient encounters, 22.7% (37/163), met the sequential organ failure assessment criteria. The other 126 SCD patient encounters served as controls. A set of signal processing features (such as fast Fourier transform, energy, and continuous wavelet transform) derived from heart rate, blood pressure, and respiratory rate was identified to distinguish patients with SCD who developed acute physiological deterioration leading to organ failure from patients with SCD who did not meet the criteria. A multilayer perceptron model accurately predicted organ failure up to 6 hours before onset, with an average sensitivity and specificity of 96% and 98%, respectively.
CONCLUSIONS: This retrospective study demonstrated the viability of using machine learning to predict acute organ failure among hospitalized adults with SCD. The discovery of salient physiomarkers through machine learning techniques has the potential to further accelerate the development and implementation of innovative care delivery protocols and strategies for medically vulnerable patients.",True,other,Not specified
32350658,Development and validation of machine learning prediction model based on computed tomography angiography-derived hemodynamics for rupture status of intracranial aneurysms: a Chinese multicenter study,"OBJECTIVES: To build models based on conventional logistic regression (LR) and machine learning (ML) algorithms combining clinical, morphological, and hemodynamic information to predict individual rupture status of unruptured intracranial aneurysms (UIAs), afterwards tested in internal and external validation datasets.
METHODS: Patients with intracranial aneurysms diagnosed by computed tomography angiography and confirmed by invasive cerebral angiograph or clipping surgery were included. The prediction models were developed based on clinical, aneurysm morphological, and hemodynamic parameters by conventional LR and ML methods.
RESULTS: The training, internal validation, and external validation cohorts were composed of 807 patients, 200 patients, and 108 patients, respectively. The area under curves (AUCs) of conventional LR models 1 (clinical), 2 (clinical and aneurysm morphological), and 3 (clinical, aneurysm morphological and hemodynamic characteristics) were 0.608, 0.765, and 0.886, respectively (all p < 0.05). The AUCs of ML models using random forest (RF), multilayer perceptron (MLP), and support vector machine (SVM) were 0.871, 0.851, and 0.863, respectively. There were no difference among AUCs of conventional LR, RF, and SVM (all p > 0.05/6), while the AUC of MLP was lower than that of conventional LR (p = 0.0055).
CONCLUSION: Hemodynamic parameters play an important role in the prediction performance of the models. ML methods cannot outperform conventional LR in prediction models for rupture status of UIAs integrating clinical, aneurysm morphological, and hemodynamic parameters.
KEY POINTS: • The addition of hemodynamic parameters can improve prediction performance for rupture status of unruptured intracranial aneurysms. • Machine learning algorithms cannot outperform conventional logistic regression in prediction models for rupture status integrating clinical, aneurysm morphological, and hemodynamic parameters. • Models integrating clinical, aneurysm morphological, and hemodynamic parameters may help choose the optimal management.",True,text mining,Not specified
32350021,Predicting the Risk of Inpatient Hypoglycemia With Machine Learning Using Electronic Health Records,"OBJECTIVE: We analyzed data from inpatients with diabetes admitted to a large university hospital to predict the risk of hypoglycemia through the use of machine learning algorithms.
RESEARCH DESIGN AND METHODS: Four years of data were extracted from a hospital electronic health record system. This included laboratory and point-of-care blood glucose (BG) values to identify biochemical and clinically significant hypoglycemic episodes (BG ≤3.9 and ≤2.9 mmol/L, respectively). We used patient demographics, administered medications, vital signs, laboratory results, and procedures performed during the hospital stays to inform the model. Two iterations of the data set included the doses of insulin administered and the past history of inpatient hypoglycemia. Eighteen different prediction models were compared using the area under the receiver operating characteristic curve (AUROC) through a 10-fold cross validation.
RESULTS: We analyzed data obtained from 17,658 inpatients with diabetes who underwent 32,758 admissions between July 2014 and August 2018. The predictive factors from the logistic regression model included people undergoing procedures, weight, type of diabetes, oxygen saturation level, use of medications (insulin, sulfonylurea, and metformin), and albumin levels. The machine learning model with the best performance was the XGBoost model (AUROC 0.96). This outperformed the logistic regression model, which had an AUROC of 0.75 for the estimation of the risk of clinically significant hypoglycemia.
CONCLUSIONS: Advanced machine learning models are superior to logistic regression models in predicting the risk of hypoglycemia in inpatients with diabetes. Trials of such models should be conducted in real time to evaluate their utility to reduce inpatient hypoglycemia.",True,other,Not specified
32325370,Predicting in-hospital mortality of patients with febrile neutropenia using machine learning models,"BACKGROUND: Febrile neutropenia (FN) has been associated with high mortality among adults with cancer. Current systems for early detection of inpatient FN mortality are based on scoring indexes that require intensive physicians' subjective evaluation.
OBJECTIVE: In this study, we leveraged machine learning techniques to build a FN mortality risk evaluation tool focused on FN admissions without physicians' subjective evaluation.
METHODS: We used the National Inpatient Sample and Nationwide Inpatient Sample (NIS) that included mortality data among adult inpatients who were diagnosed with FN during a hospital admission. Machine learning techniques that we compared included linear models (ridge logistic regression and linear support vector machine) and non-linear models (gradient boosting tree and neural network). The primary outcome for this study was death among individuals with a recorded FN admission. Model comparison was evaluated based on areas under the receiver operating characteristic curve (AUROC) and model performance was estimated using 30 % test set created via stratified split.
RESULTS: Our analysis detected 126,013 adult admissions within the NIS data that were diagnosed with FN, among which 5,856 were declared as deceased (4.6 %). Our machine learning results demonstrate linear models and non-linear models achieved areas under the receiver operating characteristic (AUROC) around 92 % in survival prediction.
CONCLUSIONS: We developed machine learning models that do not require physicians' subjective evaluation for FN mortality risk prediction.",True,other,RNN
32324754,Feature engineering with clinical expert knowledge: A case study assessment of machine learning model complexity and performance,"Incorporating expert knowledge at the time machine learning models are trained holds promise for producing models that are easier to interpret. The main objectives of this study were to use a feature engineering approach to incorporate clinical expert knowledge prior to applying machine learning techniques, and to assess the impact of the approach on model complexity and performance. Four machine learning models were trained to predict mortality with a severe asthma case study. Experiments to select fewer input features based on a discriminative score showed low to moderate precision for discovering clinically meaningful triplets, indicating that discriminative score alone cannot replace clinical input. When compared to baseline machine learning models, we found a decrease in model complexity with use of fewer features informed by discriminative score and filtering of laboratory features with clinical input. We also found a small difference in performance for the mortality prediction task when comparing baseline ML models to models that used filtered features. Encoding demographic and triplet information in ML models with filtered features appeared to show performance improvements from the baseline. These findings indicated that the use of filtered features may reduce model complexity, and with little impact on performance.",True,other,recurrent neural network
32304429,Machine-learning approaches to substance-abuse research: emerging trends and their implications,"PURPOSE OF REVIEW: To provide an accessible overview of some of the most recent trends in the application of machine learning to the field of substance use disorders and their implications for future research and practice.
RECENT FINDINGS: Machine-learning (ML) techniques have recently been applied to substance use disorder (SUD) data for multiple predictive applications including detecting current abuse, assessing future risk and predicting treatment success. These models cover a wide range of machine-learning techniques and data types including physiological measures, longitudinal surveys, treatment outcomes, national surveys, medical records and social media.
SUMMARY: The application of machine-learning models to substance use disorder data shows significant promise, with some use cases and data types showing high predictive accuracy, particularly for models of physiological and behavioral measures for predicting current substance use, portending potential clinical diagnostic applications; however, these results are uneven, with some models performing poorly or at chance, a limitation likely reflecting insufficient data and/or weak validation methods. The field will likely benefit from larger and more multimodal datasets, greater standardization of data recording and rigorous testing protocols as well as greater use of modern deep neural network models applied to multimodal unstructured datasets.",True,other,Not specified
32271458,A classifier prediction model to predict the status of Coronavirus COVID-19 patients in South Korea,"OBJECTIVE: Coronavirus COVID-19 further transmitted to several countries globally. The status of the infected cases can be determined basing on the treatment process along with several other factors. This research aims to build a classifier prediction model to predict the status of recovered and death coronavirus CovID-19 patients in South Korea.
MATERIALS AND METHODS: Artificial neural network principle is used to classify the collected data between February 20, 2020 and March 9, 2020. The proposed classifier used different seven variables, namely, country, infection reason, sex, group, confirmation date, birth year, and region. The most effective variables on recovered and fatal cases are analyzed based on the neural network model.
RESULTS: The results found that the proposed predictive classifier efficiently predicted recovered and death cases. Besides, it is found that discovering the infection reason would increase the probability to recover the patient. This indicates that the virus might be controllable based on infection reasons. In addition, the earlier discovery of the disease affords better control and a higher probability of being recovered.
CONCLUSIONS: Our recommendation is to use this model to predict the status of the patients globally.",True,computer vision,recurrent neural network
32271281,"Machine Learning and Deep Neural Network Applications in the Thorax: Pulmonary Embolism, Chronic Thromboembolic Pulmonary Hypertension, Aorta, and Chronic Obstructive Pulmonary Disease","The radiologic community is rapidly integrating a revolution that has not fully entered daily practice. It necessitates a close collaboration between computer scientists and radiologists to move from concepts to practical applications. This article reviews the current littérature on machine learning and deep neural network applications in the field of pulmonary embolism, chronic thromboembolic pulmonary hypertension, aorta, and chronic obstructive pulmonary disease.",True,other,RNN
32258430,Siamese neural networks for continuous disease severity evaluation and change detection in medical imaging,"Using medical images to evaluate disease severity and change over time is a routine and important task in clinical decision making. Grading systems are often used, but are unreliable as domain experts disagree on disease severity category thresholds. These discrete categories also do not reflect the underlying continuous spectrum of disease severity. To address these issues, we developed a convolutional Siamese neural network approach to evaluate disease severity at single time points and change between longitudinal patient visits on a continuous spectrum. We demonstrate this in two medical imaging domains: retinopathy of prematurity (ROP) in retinal photographs and osteoarthritis in knee radiographs. Our patient cohorts consist of 4861 images from 870 patients in the Imaging and Informatics in Retinopathy of Prematurity (i-ROP) cohort study and 10,012 images from 3021 patients in the Multicenter Osteoarthritis Study (MOST), both of which feature longitudinal imaging data. Multiple expert clinician raters ranked 100 retinal images and 100 knee radiographs from excluded test sets for severity of ROP and osteoarthritis, respectively. The Siamese neural network output for each image in comparison to a pool of normal reference images correlates with disease severity rank (ρ = 0.87 for ROP and ρ = 0.89 for osteoarthritis), both within and between the clinical grading categories. Thus, this output can represent the continuous spectrum of disease severity at any single time point. The difference in these outputs can be used to show change over time. Alternatively, paired images from the same patient at two time points can be directly compared using the Siamese neural network, resulting in an additional continuous measure of change between images. Importantly, our approach does not require manual localization of the pathology of interest and requires only a binary label for training (same versus different). The location of disease and site of change detected by the algorithm can be visualized using an occlusion sensitivity map-based approach. For a longitudinal binary change detection task, our Siamese neural networks achieve test set receiving operator characteristic area under the curves (AUCs) of up to 0.90 in evaluating ROP or knee osteoarthritis change, depending on the change detection strategy. The overall performance on this binary task is similar compared to a conventional convolutional deep-neural network trained for multi-class classification. Our results demonstrate that convolutional Siamese neural networks can be a powerful tool for evaluating the continuous spectrum of disease severity and change in medical imaging.",True,both,recurrent neural network
32132525,A generalizable 29-mRNA neural-network classifier for acute bacterial and viral infections,"Improved identification of bacterial and viral infections would reduce morbidity from sepsis, reduce antibiotic overuse, and lower healthcare costs. Here, we develop a generalizable host-gene-expression-based classifier for acute bacterial and viral infections. We use training data (N = 1069) from 18 retrospective transcriptomic studies. Using only 29 preselected host mRNAs, we train a neural-network classifier with a bacterial-vs-other area under the receiver-operating characteristic curve (AUROC) 0.92 (95% CI 0.90-0.93) and a viral-vs-other AUROC 0.92 (95% CI 0.90-0.93). We then apply this classifier, inflammatix-bacterial-viral-noninfected-version 1 (IMX-BVN-1), without retraining, to an independent cohort (N = 163). In this cohort, IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.86 (95% CI 0.77-0.93), and viral-vs.-other 0.85 (95% CI 0.76-0.93). In patients enrolled within 36 h of hospital admission (N = 70), IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.92 (95% CI 0.83-0.99), and viral-vs.-other 0.91 (95% CI 0.82-0.98). With further study, IMX-BVN-1 could provide a tool for assessing patients with suspected infection and sepsis at hospital admission.",True,other,recurrent neural network
31965266,Machine learning for the prediction of sepsis: a systematic review and meta-analysis of diagnostic test accuracy,"PURPOSE: Early clinical recognition of sepsis can be challenging. With the advancement of machine learning, promising real-time models to predict sepsis have emerged. We assessed their performance by carrying out a systematic review and meta-analysis.
METHODS: A systematic search was performed in PubMed, Embase.com and Scopus. Studies targeting sepsis, severe sepsis or septic shock in any hospital setting were eligible for inclusion. The index test was any supervised machine learning model for real-time prediction of these conditions. Quality of evidence was assessed using the Grading of Recommendations Assessment, Development and Evaluation (GRADE) methodology, with a tailored Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) checklist to evaluate risk of bias. Models with a reported area under the curve of the receiver operating characteristic (AUROC) metric were meta-analyzed to identify strongest contributors to model performance.
RESULTS: After screening, a total of 28 papers were eligible for synthesis, from which 130 models were extracted. The majority of papers were developed in the intensive care unit (ICU, n = 15; 54%), followed by hospital wards (n = 7; 25%), the emergency department (ED, n = 4; 14%) and all of these settings (n = 2; 7%). For the prediction of sepsis, diagnostic test accuracy assessed by the AUROC ranged from 0.68-0.99 in the ICU, to 0.96-0.98 in-hospital and 0.87 to 0.97 in the ED. Varying sepsis definitions limit pooling of the performance across studies. Only three papers clinically implemented models with mixed results. In the multivariate analysis, temperature, lab values, and model type contributed most to model performance.
CONCLUSION: This systematic review and meta-analysis show that on retrospective data, individual machine learning models can accurately predict sepsis onset ahead of time. Although they present alternatives to traditional scoring systems, between-study heterogeneity limits the assessment of pooled results. Systematic reporting and clinical implementation studies are needed to bridge the gap between bytes and bedside.",True,other,recurrent neural network
31798281,Application of preoperative artificial neural network based on blood biomarkers and clinicopathological parameters for predicting long-term survival of patients with gastric cancer,"BACKGROUND: Because of the powerful abilities of self-learning and handling complex biological information, artificial neural network (ANN) models have been widely applied to disease diagnosis, imaging analysis, and prognosis prediction. However, there has been no trained preoperative ANN (preope-ANN) model to preoperatively predict the prognosis of patients with gastric cancer (GC).
AIM: To establish a neural network model that can predict long-term survival of GC patients before surgery to evaluate the tumor condition before the operation.
METHODS: The clinicopathological data of 1608 GC patients treated from January 2011 to April 2015 at the Department of Gastric Surgery, Fujian Medical University Union Hospital were analyzed retrospectively. The patients were randomly divided into a training set (70%) for establishing a preope-ANN model and a testing set (30%). The prognostic evaluation ability of the preope-ANN model was compared with that of the American Joint Commission on Cancer (8th edition) clinical TNM (cTNM) and pathological TNM (pTNM) staging through the receiver operating characteristic curve, Akaike information criterion index, Harrell's C index, and likelihood ratio chi-square.
RESULTS: We used the variables that were statistically significant factors for the 3-year overall survival as input-layer variables to develop a preope-ANN in the training set. The survival curves within each score of the preope-ANN had good discrimination (P &lt; 0.05). Comparing the preope-ANN model, cTNM, and pTNM in both the training and testing sets, the preope-ANN model was superior to cTNM in predictive discrimination (C index), predictive homogeneity (likelihood ratio chi-square), and prediction accuracy (area under the curve). The prediction efficiency of the preope-ANN model is similar to that of pTNM.
CONCLUSION: The preope-ANN model can accurately predict the long-term survival of GC patients, and its predictive efficiency is not inferior to that of pTNM stage.",True,other,recurrent neural network
31760945,Attention-based recurrent neural network for influenza epidemic prediction,"BACKGROUND: Influenza is an infectious respiratory disease that can cause serious public health hazard. Due to its huge threat to the society, precise real-time forecasting of influenza outbreaks is of great value to our public.
RESULTS: In this paper, we propose a new deep neural network structure that forecasts a real-time influenza-like illness rate (ILI%) in Guangzhou, China. Long short-term memory (LSTM) neural networks is applied to precisely forecast accurateness due to the long-term attribute and diversity of influenza epidemic data. We devise a multi-channel LSTM neural network that can draw multiple information from different types of inputs. We also add attention mechanism to improve forecasting accuracy. By using this structure, we are able to deal with relationships between multiple inputs more appropriately. Our model fully consider the information in the data set, targetedly solving practical problems of the Guangzhou influenza epidemic forecasting.
CONCLUSION: We assess the performance of our model by comparing it with different neural network structures and other state-of-the-art methods. The experimental results indicate that our model has strong competitiveness and can provide effective real-time influenza epidemic forecasting.",True,other,recurrent neural network
31715534,Machine learning to predict 30-day quality-adjusted survival in critically ill patients with cancer,"PURPOSE: To develop and compare the predictive performance of machine-learning algorithms to estimate the risk of quality-adjusted life year (QALY) lower than or equal to 30 days (30-day QALY).
MATERIAL AND METHODS: Six machine-learning algorithms were applied to predict 30-day QALY for 777 patients admitted in a prospective cohort study conducted in Intensive Care Units (ICUs) of two public Brazilian hospitals specialized in cancer care. The predictors were 37 characteristics collected at ICU admission. Discrimination was evaluated using the area under the receiver operating characteristic (AUROC) curve. Sensitivity, 1-specificity, true/false positive and negative cases were measured for different estimated probability cutoff points (30%, 20% and 10%). Calibration was evaluated with GiViTI calibration belt and test.
RESULTS: Except for basic decision trees, the adjusted predictive models were nearly equivalent, presenting good results for discrimination (AUROC curves over 0.80). Artificial neural networks and gradient boosted trees achieved the overall best calibration, implying an accurately predicted probability for 30-day QALY.
CONCLUSIONS: Except for basic decision trees, predictive models derived from different machine-learning algorithms discriminated the QALY risk at 30 days well. Regarding calibration, artificial neural network model presented the best ability to estimate 30-day QALY in critically ill oncologic patients admitted to ICUs.",True,other,recurrent neural network
31651589,Development and Internal Validation of Machine Learning Algorithms for Preoperative Survival Prediction of Extremity Metastatic Disease,"BACKGROUND: A preoperative estimation of survival is critical for deciding on the operative management of metastatic bone disease of the extremities. Several tools have been developed for this purpose, but there is room for improvement. Machine learning is an increasingly popular and flexible method of prediction model building based on a data set. It raises some skepticism, however, because of the complex structure of these models.
QUESTIONS/PURPOSES: The purposes of this study were (1) to develop machine learning algorithms for 90-day and 1-year survival in patients who received surgical treatment for a bone metastasis of the extremity, and (2) to use these algorithms to identify those clinical factors (demographic, treatment related, or surgical) that are most closely associated with survival after surgery in these patients.
METHODS: All 1090 patients who underwent surgical treatment for a long-bone metastasis at two institutions between 1999 and 2017 were included in this retrospective study. The median age of the patients in the cohort was 63 years (interquartile range [IQR] 54 to 72 years), 56% of patients (610 of 1090) were female, and the median BMI was 27 kg/m (IQR 23 to 30 kg/m). The most affected location was the femur (70%), followed by the humerus (22%). The most common primary tumors were breast (24%) and lung (23%). Intramedullary nailing was the most commonly performed type of surgery (58%), followed by endoprosthetic reconstruction (22%), and plate screw fixation (14%). Missing data were imputed using the missForest methods. Features were selected by random forest algorithms, and five different models were developed on the training set (80% of the data): stochastic gradient boosting, random forest, support vector machine, neural network, and penalized logistic regression. These models were chosen as a result of their classification capability in binary datasets. Model performance was assessed on both the training set and the validation set (20% of the data) by discrimination, calibration, and overall performance.
RESULTS: We found no differences among the five models for discrimination, with an area under the curve ranging from 0.86 to 0.87. All models were well calibrated, with intercepts ranging from -0.03 to 0.08 and slopes ranging from 1.03 to 1.12. Brier scores ranged from 0.13 to 0.14. The stochastic gradient boosting model was chosen to be deployed as freely available web-based application and explanations on both a global and an individual level were provided. For 90-day survival, the three most important factors associated with poorer survivorship were lower albumin level, higher neutrophil-to-lymphocyte ratio, and rapid growth primary tumor. For 1-year survival, the three most important factors associated with poorer survivorship were lower albumin level, rapid growth primary tumor, and lower hemoglobin level.
CONCLUSIONS: Although the final models must be externally validated, the algorithms showed good performance on internal validation. The final models have been incorporated into a freely accessible web application that can be found at https://sorg-apps.shinyapps.io/extremitymetssurvival/. Pending external validation, clinicians may use this tool to predict survival for their individual patients to help in shared treatment decision making.
LEVEL OF EVIDENCE: Level III, therapeutic study.",True,other,Not specified
31608599,FluChip-8G Insight: HA and NA subtyping of potentially pandemic influenza A viruses in a single assay,"BACKGROUND: Global influenza surveillance in humans and animals is a critical component of pandemic preparedness. The FluChip-8G Insight assay was developed to subtype both seasonal and potentially pandemic influenza viruses in a single assay with a same day result. FluChip-8G Insight uses whole gene segment RT-PCR-based amplification to provide robustness against genetic drift and subsequent microarray detection with artificial neural network-based data interpretation.
OBJECTIVES: The objective of this study was to verify and validate the performance of the FluChip-8G Insight assay for the detection and positive identification of human and animal origin non-seasonal influenza A specimens.
METHODS: We evaluated the ability of the FluChip-8G Insight technology to type and HA and NA subtype a sample set consisting of 297 results from 180 unique non-seasonal influenza A strains (49 unique subtypes).
RESULTS: FluChip-8G Insight demonstrated a positive percent agreement ≥93% for 5 targeted HA and 5 targeted NA subtypes except for H9 (88%), and negative percent agreement exceeding 95% for all targeted subtypes.
CONCLUSIONS: The FluChip-8G Insight neural network-based algorithm used for virus identification performed well over a data set of 297 naïve sample results, and can be easily updated to improve performance on emerging strains without changing the underlying assay chemistry.",True,other,autoencoder
31320027,Machine Learning Prediction Models for In-Hospital Mortality After Transcatheter Aortic Valve Replacement,"OBJECTIVES: This study sought to develop and compare an array of machine learning methods to predict in-hospital mortality after transcatheter aortic valve replacement (TAVR) in the United States.
BACKGROUND: Existing risk prediction tools for in-hospital complications in patients undergoing TAVR have been designed using statistical modeling approaches and have certain limitations.
METHODS: Patient data were obtained from the National Inpatient Sample database from 2012 to 2015. The data were randomly divided into a development cohort (n = 7,615) and a validation cohort (n = 3,268). Logistic regression, artificial neural network, naive Bayes, and random forest machine learning algorithms were applied to obtain in-hospital mortality prediction models.
RESULTS: A total of 10,883 TAVRs were analyzed in our study. The overall in-hospital mortality was 3.6%. Overall, prediction models' performance measured by area under the curve were good (>0.80). The best model was obtained by logistic regression (area under the curve: 0.92; 95% confidence interval: 0.89 to 0.95). Most obtained models plateaued after introducing 10 variables. Acute kidney injury was the main predictor of in-hospital mortality ranked with the highest mean importance in all the models. The National Inpatient Sample TAVR score showed the best discrimination among available TAVR prediction scores.
CONCLUSIONS: Machine learning methods can generate robust models to predict in-hospital mortality for TAVR. The National Inpatient Sample TAVR score should be considered for prognosis and shared decision making in TAVR patients.",True,both,recurrent neural network
31112896,Efficient learning from big data for cancer risk modeling: A case study with melanoma,"BACKGROUND: Building cancer risk models from real-world data requires overcoming challenges in data preprocessing, efficient representation, and computational performance. We present a case study of a cloud-based approach to learning from de-identified electronic health record data and demonstrate its effectiveness for melanoma risk prediction.
METHODS: We used a hybrid distributed and non-distributed approach to computing in the cloud: distributed processing with Apache Spark for data preprocessing and labeling, and non-distributed processing for machine learning model training with scikit-learn. Moreover, we explored the effects of sampling the training dataset to improve computational performance. Risk factors were evaluated using regression weights as well as tree SHAP values.
RESULTS: Among 4,061,172 patients who did not have melanoma through the 2016 calendar year, 10,129 were diagnosed with melanoma within one year. A gradient-boosted classifier achieved the best predictive performance with cross-validation (AUC = 0.799, Sensitivity = 0.753, Specificity = 0.688). Compared to a model built on the original data, a dataset two orders of magnitude smaller could achieve statistically similar or better performance with less than 1% of the training time and cost.
CONCLUSIONS: We produced a model that can effectively predict melanoma risk for a diverse dermatology population in the U.S. by using hybrid computing infrastructure and data sampling. For this de-identified clinical dataset, sampling approaches significantly shortened the time for model building while retaining predictive accuracy, allowing for more rapid machine learning model experimentation on familiar computing machinery. A large number of risk factors (>300) were required to produce the best model.",True,other,recurrent neural network
30785874,Machine learning analysis of gene expression data reveals novel diagnostic and prognostic biomarkers and identifies therapeutic targets for soft tissue sarcomas,"Based on morphology it is often challenging to distinguish between the many different soft tissue sarcoma subtypes. Moreover, outcome of disease is highly variable even between patients with the same disease. Machine learning on transcriptome sequencing data could be a valuable new tool to understand differences between and within entities. Here we used machine learning analysis to identify novel diagnostic and prognostic markers and therapeutic targets for soft tissue sarcomas. Gene expression data was used from the Cancer Genome Atlas, the Genotype-Tissue Expression project and the French Sarcoma Group. We identified three groups of tumors that overlap in their molecular profiles as seen with unsupervised t-Distributed Stochastic Neighbor Embedding clustering and a deep neural network. The three groups corresponded to subtypes that are morphologically overlapping. Using a random forest algorithm, we identified novel diagnostic markers for soft tissue sarcoma that distinguished between synovial sarcoma and MPNST, and that we validated using qRT-PCR in an independent series. Next, we identified prognostic genes that are strong predictors of disease outcome when used in a k-nearest neighbor algorithm. The prognostic genes were further validated in expression data from the French Sarcoma Group. One of these, HMMR, was validated in an independent series of leiomyosarcomas using immunohistochemistry on tissue micro array as a prognostic gene for disease-free interval. Furthermore, reconstruction of regulatory networks combined with data from the Connectivity Map showed, amongst others, that HDAC inhibitors could be a potential effective therapy for multiple soft tissue sarcoma subtypes. A viability assay with two HDAC inhibitors confirmed that both leiomyosarcoma and synovial sarcoma are sensitive to HDAC inhibition. In this study we identified novel diagnostic markers, prognostic markers and therapeutic leads from multiple soft tissue sarcoma gene expression datasets. Thus, machine learning algorithms are powerful new tools to improve our understanding of rare tumor entities.",True,other,Not specified
30738152,Predictive Abilities of Machine Learning Techniques May Be Limited by Dataset Characteristics: Insights From the UNOS Database,"BACKGROUND: Traditional statistical approaches to prediction of outcomes have drawbacks when applied to large clinical databases. It is hypothesized that machine learning methodologies might overcome these limitations by considering higher-dimensional and nonlinear relationships among patient variables.
METHODS AND RESULTS: The Unified Network for Organ Sharing (UNOS) database was queried from 1987 to 2014 for adult patients undergoing cardiac transplantation. The dataset was divided into 3 time periods corresponding to major allocation adjustments and based on geographic regions. For our outcome of 1-year survival, we used the standard statistical methods logistic regression, ridge regression, and regressions with LASSO (least absolute shrinkage and selection operator) and compared them with the machine learning methodologies neural networks, naïve-Bayes, tree-augmented naïve-Bayes, support vector machines, random forest, and stochastic gradient boosting. Receiver operating characteristic curves and C-statistics were calculated for each model. C-Statistics were used for comparison of discriminatory capacity across models in the validation sample. After identifying 56,477 patients, the major univariate predictors of 1-year survival after heart transplantation were consistent with earlier reports and included age, renal function, body mass index, liver function tests, and hemodynamics. Advanced analytic models demonstrated similarly modest discrimination capabilities compared with traditional models (C-statistic ≤0.66, all). The neural network model demonstrated the highest C-statistic (0.66) but this was only slightly superior to the simple logistic regression, ridge regression, and regression with LASSO models (C-statistic = 0.65, all). Discrimination did not vary significantly across the 3 historically important time periods.
CONCLUSIONS: The use of advanced analytic algorithms did not improve prediction of 1-year survival from heart transplant compared with more traditional prediction models. The prognostic abilities of machine learning techniques may be limited by quality of the clinical dataset.",True,other,RNN
30356283,A multi-parameterized artificial neural network for lung cancer risk prediction,"The objective of this study is to train and validate a multi-parameterized artificial neural network (ANN) based on personal health information to predict lung cancer risk with high sensitivity and specificity. The 1997-2015 National Health Interview Survey adult data was used to train and validate our ANN, with inputs: gender, age, BMI, diabetes, smoking status, emphysema, asthma, race, Hispanic ethnicity, hypertension, heart diseases, vigorous exercise habits, and history of stroke. We identified 648 cancer and 488,418 non-cancer cases. For the training set the sensitivity was 79.8% (95% CI, 75.9%-83.6%), specificity was 79.9% (79.8%-80.1%), and AUC was 0.86 (0.85-0.88). For the validation set sensitivity was 75.3% (68.9%-81.6%), specificity was 80.6% (80.3%-80.8%), and AUC was 0.86 (0.84-0.89). Our results indicate that the use of an ANN based on personal health information gives high specificity and modest sensitivity for lung cancer detection, offering a cost-effective and non-invasive clinical tool for risk stratification.",True,other,Not specified
30319525,Predicting Outcome of Endovascular Treatment for Acute Ischemic Stroke: Potential Value of Machine Learning Algorithms,"Background: Endovascular treatment (EVT) is effective for stroke patients with a large vessel occlusion (LVO) of the anterior circulation. To further improve personalized stroke care, it is essential to accurately predict outcome after EVT. Machine learning might outperform classical prediction methods as it is capable of addressing complex interactions and non-linear relations between variables. Methods: We included patients from the Multicenter Randomized Clinical Trial of Endovascular Treatment for Acute Ischemic Stroke in the Netherlands (MR CLEAN) Registry, an observational cohort of LVO patients treated with EVT. We applied the following machine learning algorithms: Random Forests, Support Vector Machine, Neural Network, and Super Learner and compared their predictive value with classic logistic regression models using various variable selection methodologies. Outcome variables were good reperfusion (post-mTICI ≥ 2b) and functional independence (modified Rankin Scale ≤2) at 3 months using (1) only baseline variables and (2) baseline and treatment variables. Area under the ROC-curves (AUC) and difference of mean AUC between the models were assessed. Results: We included 1,383 EVT patients, with good reperfusion in 531 (38%) and functional independence in 525 (38%) patients. Machine learning and logistic regression models all performed poorly in predicting good reperfusion (range mean AUC: 0.53-0.57), and moderately in predicting 3-months functional independence (range mean AUC: 0.77-0.79) using only baseline variables. All models performed well in predicting 3-months functional independence using both baseline and treatment variables (range mean AUC: 0.88-0.91) with a negligible difference of mean AUC (0.01; 95%CI: 0.00-0.01) between best performing machine learning algorithm (Random Forests) and best performing logistic regression model (based on prior knowledge). Conclusion: In patients with LVO machine learning algorithms did not outperform logistic regression models in predicting reperfusion and 3-months functional independence after endovascular treatment. For all models at time of admission radiological outcome was more difficult to predict than clinical outcome.",True,other,Not specified
30179954,Can Machine-learning Techniques Be Used for 5-year Survival Prediction of Patients With Chondrosarcoma?,"BACKGROUND: Several studies have identified prognostic factors for patients with chondrosarcoma, but there are few studies investigating the accuracy of computationally intensive methods such as machine learning. Machine learning is a type of artificial intelligence that enables computers to learn from data. Studies using machine learning are potentially appealing, because of its possibility to explore complex patterns in data and to improve its models over time.
QUESTIONS/PURPOSES: The purposes of this study were (1) to develop machine-learning algorithms for the prediction of 5-year survival in patients with chondrosarcoma; and (2) to deploy the best algorithm as an accessible web-based app for clinical use.
METHODS: All patients with a microscopically confirmed diagnosis of conventional or dedifferentiated chondrosarcoma were extracted from the Surveillance, Epidemiology, and End Results (SEER) Registry from 2000 to 2010. SEER covers approximately 30% of the US population and consists of demographic, tumor characteristic, treatment, and outcome data. In total, 1554 patients met the inclusion criteria. Mean age at diagnosis was 52 years (SD 17), ranging from 7 to 102 years; 813 of the 1554 patients were men (55%); and mean tumor size was 8 cm (SD 6), ranging from 0.1 cm to 50 cm. Exact size was missing in 340 of 1544 patients (22%), grade in 88 of 1544 (6%), tumor extension in 41 of 1544 (3%), and race in 16 of 1544 (1%). Data for 1-, 3-, 5-, and 10-year overall survival were available for 1533 (99%), 1512 (98%), 1487 (96%), and 977 (63%) patients, respectively. One-year survival was 92%, 3-year survival was 82%, 5-year survival was 76%, and 10-year survival was 54%. Missing data were imputed using the nonparametric missForest method. Boosted decision tree, support vector machine, Bayes point machine, and neural network models were developed for 5-year survival. These models were chosen as a result of their capability of predicting two outcomes based on prior work on machine-learning models for binary classification. The models were assessed by discrimination, calibration, and overall performance. The c-statistic is a measure of discrimination. It ranges from 0.5 to 1.0 with 1.0 being perfect discrimination and 0.5 that the model is no better than chance at making a prediction. The Brier score measures the squared difference between the predicted probability and the actual outcome. A Brier score of 0 indicates perfect prediction, whereas a Brier score of 1 indicates the poorest prediction. The Brier scores of the models are compared with the null model, which is calculated by assigning each patient a probability equal to the prevalence of the outcome.
RESULTS: Four models for 5-year survival were developed with c-statistics ranging from 0.846 to 0.868 and Brier scores ranging from 0.117 to 0.135 with a null model Brier score of 0.182. The Bayes point machine was incorporated into a freely available web-based application. This application can be accessed through https://sorg-apps.shinyapps.io/chondrosarcoma/.
CONCLUSIONS: Although caution is warranted, because the prediction model has not been validated yet, healthcare providers could use the online prediction tool in daily practice when survival prediction of patients with chondrosarcoma is desired. Future studies should seek to validate the developed prediction model.
LEVEL OF EVIDENCE: Level III, prognostic study.",True,other,Not specified
30023379,Opening the black box of neural networks: methods for interpreting neural network models in clinical applications,"Artificial neural networks (ANNs) are powerful tools for data analysis and are particularly suitable for modeling relationships between variables for best prediction of an outcome. While these models can be used to answer many important research questions, their utility has been critically limited because the interpretation of the ""black box"" model is difficult. Clinical investigators usually employ ANN models to predict the clinical outcomes or to make a diagnosis; the model however is difficult to interpret for clinicians. To address this important shortcoming of neural network modeling methods, we describe several methods to help subject-matter audiences (e.g., clinicians, medical policy makers) understand neural network models. Garson's algorithm describes the relative magnitude of the importance of a descriptor (predictor) in its connection with outcome variables by dissecting the model weights. The Lek's profile method explores the relationship of the outcome variable and a predictor of interest, while holding other predictors at constant values (e.g., minimum, 20th quartile, maximum). While Lek's profile was developed specifically for neural networks, partial dependence plot is a more generic version that visualize the relationship between an outcome and one or two predictors. Finally, the local interpretable model-agnostic explanations (LIME) method can show the predictions of any classification or regression, by approximating it locally with an interpretable model. R code for the implementations of these methods is shown by using example data fitted with a standard, feed-forward neural network model. We offer codes and step-by-step description on how to use these tools to facilitate better understanding of ANN.",True,other,recurrent neural network
29854369,Research on Improved Depth Belief Network-Based Prediction of Cardiovascular Diseases,"Quantitative analysis and prediction can help to reduce the risk of cardiovascular disease. Quantitative prediction based on traditional model has low accuracy. The variance of model prediction based on shallow neural network is larger. In this paper, cardiovascular disease prediction model based on improved deep belief network (DBN) is proposed. Using the reconstruction error, the network depth is determined independently, and unsupervised training and supervised optimization are combined. It ensures the accuracy of model prediction while guaranteeing stability. Thirty experiments were performed independently on the Statlog (Heart) and Heart Disease Database data sets in the UCI database. Experimental results showed that the mean of prediction accuracy was 91.26% and 89.78%, respectively. The variance of prediction accuracy was 5.78 and 4.46, respectively.",True,other,recurrent neural network
29763967,Machine learning algorithms for outcome prediction in (chemo)radiotherapy: An empirical comparison of classifiers,"PURPOSE: Machine learning classification algorithms (classifiers) for prediction of treatment response are becoming more popular in radiotherapy literature. General Machine learning literature provides evidence in favor of some classifier families (random forest, support vector machine, gradient boosting) in terms of classification performance. The purpose of this study is to compare such classifiers specifically for (chemo)radiotherapy datasets and to estimate their average discriminative performance for radiation treatment outcome prediction.
METHODS: We collected 12 datasets (3496 patients) from prior studies on post-(chemo)radiotherapy toxicity, survival, or tumor control with clinical, dosimetric, or blood biomarker features from multiple institutions and for different tumor sites, that is, (non-)small-cell lung cancer, head and neck cancer, and meningioma. Six common classification algorithms with built-in feature selection (decision tree, random forest, neural network, support vector machine, elastic net logistic regression, LogitBoost) were applied on each dataset using the popular open-source R package caret. The R code and documentation for the analysis are available online (https://github.com/timodeist/classifier_selection_code). All classifiers were run on each dataset in a 100-repeated nested fivefold cross-validation with hyperparameter tuning. Performance metrics (AUC, calibration slope and intercept, accuracy, Cohen's kappa, and Brier score) were computed. We ranked classifiers by AUC to determine which classifier is likely to also perform well in future studies. We simulated the benefit for potential investigators to select a certain classifier for a new dataset based on our study (pre-selection based on other datasets) or estimating the best classifier for a dataset (set-specific selection based on information from the new dataset) compared with uninformed classifier selection (random selection).
RESULTS: Random forest (best in 6/12 datasets) and elastic net logistic regression (best in 4/12 datasets) showed the overall best discrimination, but there was no single best classifier across datasets. Both classifiers had a median AUC rank of 2. Preselection and set-specific selection yielded a significant average AUC improvement of 0.02 and 0.02 over random selection with an average AUC rank improvement of 0.42 and 0.66, respectively.
CONCLUSION: Random forest and elastic net logistic regression yield higher discriminative performance in (chemo)radiotherapy outcome and toxicity prediction than other studied classifiers. Thus, one of these two classifiers should be the first choice for investigators when building classification models or to benchmark one's own modeling results against. Our results also show that an informed preselection of classifiers based on existing datasets can improve discrimination over random selection.",True,other,Not specified
29637403,Accurate Diabetes Risk Stratification Using Machine Learning: Role of Missing Value and Outliers,"Diabetes mellitus is a group of metabolic diseases in which blood sugar levels are too high. About 8.8% of the world was diabetic in 2017. It is projected that this will reach nearly 10% by 2045. The major challenge is that when machine learning-based classifiers are applied to such data sets for risk stratification, leads to lower performance. Thus, our objective is to develop an optimized and robust machine learning (ML) system under the assumption that missing values or outliers if replaced by a median configuration will yield higher risk stratification accuracy. This ML-based risk stratification is designed, optimized and evaluated, where: (i) the features are extracted and optimized from the six feature selection techniques (random forest, logistic regression, mutual information, principal component analysis, analysis of variance, and Fisher discriminant ratio) and combined with ten different types of classifiers (linear discriminant analysis, quadratic discriminant analysis, naïve Bayes, Gaussian process classification, support vector machine, artificial neural network, Adaboost, logistic regression, decision tree, and random forest) under the hypothesis that both missing values and outliers when replaced by computed medians will improve the risk stratification accuracy. Pima Indian diabetic dataset (768 patients: 268 diabetic and 500 controls) was used. Our results demonstrate that on replacing the missing values and outliers by group median and median values, respectively and further using the combination of random forest feature selection and random forest classification technique yields an accuracy, sensitivity, specificity, positive predictive value, negative predictive value and area under the curve as: 92.26%, 95.96%, 79.72%, 91.14%, 91.20%, and 0.93, respectively. This is an improvement of 10% over previously developed techniques published in literature. The system was validated for its stability and reliability. RF-based model showed the best performance when outliers are replaced by median values.",True,other,Not specified
29634719,Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data,"Artificial neural networks (ANN) are computing architectures with many interconnections of simple neural-inspired computing elements, and have been applied to biomedical fields such as imaging analysis and diagnosis. We have developed a new ANN framework called Cox-nnet to predict patient prognosis from high throughput transcriptomics data. In 10 TCGA RNA-Seq data sets, Cox-nnet achieves the same or better predictive accuracy compared to other methods, including Cox-proportional hazards regression (with LASSO, ridge, and mimimax concave penalty), Random Forests Survival and CoxBoost. Cox-nnet also reveals richer biological information, at both the pathway and gene levels. The outputs from the hidden layer node provide an alternative approach for survival-sensitive dimension reduction. In summary, we have developed a new method for accurate and efficient prognosis prediction on high throughput data, with functional biological insights. The source code is freely available at https://github.com/lanagarmire/cox-nnet.",True,other,RNN
29572601,Multi-Modality Cascaded Convolutional Neural Networks for Alzheimer's Disease Diagnosis,"Accurate and early diagnosis of Alzheimer's disease (AD) plays important role for patient care and development of future treatment. Structural and functional neuroimages, such as magnetic resonance images (MRI) and positron emission tomography (PET), are providing powerful imaging modalities to help understand the anatomical and functional neural changes related to AD. In recent years, machine learning methods have been widely studied on analysis of multi-modality neuroimages for quantitative evaluation and computer-aided-diagnosis (CAD) of AD. Most existing methods extract the hand-craft imaging features after image preprocessing such as registration and segmentation, and then train a classifier to distinguish AD subjects from other groups. This paper proposes to construct cascaded convolutional neural networks (CNNs) to learn the multi-level and multimodal features of MRI and PET brain images for AD classification. First, multiple deep 3D-CNNs are constructed on different local image patches to transform the local brain image into more compact high-level features. Then, an upper high-level 2D-CNN followed by softmax layer is cascaded to ensemble the high-level features learned from the multi-modality and generate the latent multimodal correlation features of the corresponding image patches for classification task. Finally, these learned features are combined by a fully connected layer followed by softmax layer for AD classification. The proposed method can automatically learn the generic multi-level and multimodal features from multiple imaging modalities for classification, which are robust to the scale and rotation variations to some extent. No image segmentation and rigid registration are required in pre-processing the brain images. Our method is evaluated on the baseline MRI and PET images of 397 subjects including 93 AD patients, 204 mild cognitive impairment (MCI, 76 pMCI +128 sMCI) and 100 normal controls (NC) from Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves an accuracy of 93.26% for classification of AD vs. NC and 82.95% for classification pMCI vs. NC, demonstrating the promising classification performance.",True,other,Not specified
29552000,Can Machines Learn Respiratory Virus Epidemiology?: A Comparative Study of Likelihood-Free Methods for the Estimation of Epidemiological Dynamics,"To estimate and predict the transmission dynamics of respiratory viruses, the estimation of the basic reproduction number, R<sub>0</sub>, is essential. Recently, approximate Bayesian computation methods have been used as likelihood free methods to estimate epidemiological model parameters, particularly R<sub>0</sub>. In this paper, we explore various machine learning approaches, the multi-layer perceptron, convolutional neural network, and long-short term memory, to learn and estimate the parameters. Further, we compare the accuracy of the estimates and time requirements for machine learning and the approximate Bayesian computation methods on both simulated and real-world epidemiological data from outbreaks of influenza A(H1N1)pdm09, mumps, and measles. We find that the machine learning approaches can be verified and tested faster than the approximate Bayesian computation method, but that the approximate Bayesian computation method is more robust across different datasets.",True,other,convolutional neural network
29480983,Predicting the Survival of Gastric Cancer Patients Using Artificial and Bayesian Neural Networks,"Introduction and purpose: In recent years the use of neural networks without any premises for investigation of prognosis in analyzing survival data has increased. Artificial neural networks (ANN) use small processors with a continuous network to solve problems inspired by the human brain. Bayesian neural networks (BNN) constitute a neural-based approach to modeling and non-linearization of complex issues using special algorithms and statistical methods. Gastric cancer incidence is the first and third ranking for men and women in Iran, respectively. The aim of the present study was to assess the value of an artificial neural network and a Bayesian neural network for modeling and predicting of probability of gastric cancer patient death. Materials and Methods: In this study, we used information on 339 patients aged from 20 to 90 years old with positive gastric cancer, referred to Afzalipoor and Shahid Bahonar Hospitals in Kerman City from 2001 to 2015. The three layers perceptron neural network (ANN) and the Bayesian neural network (BNN) were used for predicting the probability of mortality using the available data. To investigate differences between the models, sensitivity, specificity, accuracy and the area under receiver operating characteristic curves (AUROCs) were generated. Results: In this study, the sensitivity and specificity of the artificial neural network and Bayesian neural network models were 0.882, 0.903 and 0.954, 0.909, respectively. Prediction accuracy and the area under curve ROC for the two models were 0.891, 0.944 and 0.935, 0.961. The age at diagnosis of gastric cancer was most important for predicting survival, followed by tumor grade, morphology, gender, smoking history, opium consumption, receiving chemotherapy, presence of metastasis, tumor stage, receiving radiotherapy, and being resident in a village. Conclusion: The findings of the present study indicated that the Bayesian neural network is preferable to an artificial neural network for predicting survival of gastric cancer patients in Iran.",True,other,RNN
29477418,Tuberculosis diagnosis support analysis for precarious health information systems,"BACKGROUND AND OBJECTIVE: Pulmonary tuberculosis is a world emergency for the World Health Organization. Techniques and new diagnosis tools are important to battle this bacterial infection. There have been many advances in all those fields, but in developing countries such as Colombia, where the resources and infrastructure are limited, new fast and less expensive strategies are increasingly needed. Artificial neural networks are computational intelligence techniques that can be used in this kind of problems and offer additional support in the tuberculosis diagnosis process, providing a tool to medical staff to make decisions about management of subjects under suspicious of tuberculosis.
MATERIALS AND METHODS: A database extracted from 105 subjects with precarious information of people under suspect of pulmonary tuberculosis was used in this study. Data extracted from sex, age, diabetes, homeless, AIDS status and a variable with clinical knowledge from the medical personnel were used. Models based on artificial neural networks were used, exploring supervised learning to detect the disease. Unsupervised learning was used to create three risk groups based on available information.
RESULTS: Obtained results are comparable with traditional techniques for detection of tuberculosis, showing advantages such as fast and low implementation costs. Sensitivity of 97% and specificity of 71% where achieved.
CONCLUSIONS: Used techniques allowed to obtain valuable information that can be useful for physicians who treat the disease in decision making processes, especially under limited infrastructure and data.",True,other,Not specified
29244814,Forecasting influenza-like illness dynamics for military populations using neural networks and social media,"This work is the first to take advantage of recurrent neural networks to predict influenza-like illness (ILI) dynamics from various linguistic signals extracted from social media data. Unlike other approaches that rely on timeseries analysis of historical ILI data and the state-of-the-art machine learning models, we build and evaluate the predictive power of neural network architectures based on Long Short Term Memory (LSTMs) units capable of nowcasting (predicting in ""real-time"") and forecasting (predicting the future) ILI dynamics in the 2011 - 2014 influenza seasons. To build our models we integrate information people post in social media e.g., topics, embeddings, word ngrams, stylistic patterns, and communication behavior using hashtags and mentions. We then quantitatively evaluate the predictive power of different social media signals and contrast the performance of the-state-of-the-art regression models with neural networks using a diverse set of evaluation metrics. Finally, we combine ILI and social media signals to build a joint neural network model for ILI dynamics prediction. Unlike the majority of the existing work, we specifically focus on developing models for local rather than national ILI surveillance, specifically for military rather than general populations in 26 U.S. and six international locations., and analyze how model performance depends on the amount of social media data available per location. Our approach demonstrates several advantages: (a) Neural network architectures that rely on LSTM units trained on social media data yield the best performance compared to previously used regression models. (b) Previously under-explored language and communication behavior features are more predictive of ILI dynamics than stylistic and topic signals expressed in social media. (c) Neural network models learned exclusively from social media signals yield comparable or better performance to the models learned from ILI historical data, thus, signals from social media can be potentially used to accurately forecast ILI dynamics for the regions where ILI historical data is not available. (d) Neural network models learned from combined ILI and social media signals significantly outperform models that rely solely on ILI historical data, which adds to a great potential of alternative public sources for ILI dynamics prediction. (e) Location-specific models outperform previously used location-independent models e.g., U.S. only. (f) Prediction results significantly vary across geolocations depending on the amount of social media data available and ILI activity patterns. (g) Model performance improves with more tweets available per geo-location e.g., the error gets lower and the Pearson score gets higher for locations with more tweets.",True,other,recurrent neural network
29065583,Neural Network-Based Coronary Heart Disease Risk Prediction Using Feature Correlation Analysis,"BACKGROUND: Of the machine learning techniques used in predicting coronary heart disease (CHD), neural network (NN) is popularly used to improve performance accuracy.
OBJECTIVE: Even though NN-based systems provide meaningful results based on clinical experiments, medical experts are not satisfied with their predictive performances because NN is trained in a ""black-box"" style.
METHOD: We sought to devise an NN-based prediction of CHD risk using feature correlation analysis (NN-FCA) using two stages. First, the feature selection stage, which makes features acceding to the importance in predicting CHD risk, is ranked, and second, the feature correlation analysis stage, during which one learns about the existence of correlations between feature relations and the data of each NN predictor output, is determined.
RESULT: Of the 4146 individuals in the Korean dataset evaluated, 3031 had low CHD risk and 1115 had CHD high risk. The area under the receiver operating characteristic (ROC) curve of the proposed model (0.749 ± 0.010) was larger than the Framingham risk score (FRS) (0.393 ± 0.010).
CONCLUSIONS: The proposed NN-FCA, which utilizes feature correlation analysis, was found to be better than FRS in terms of CHD risk prediction. Furthermore, the proposed model resulted in a larger ROC curve and more accurate predictions of CHD risk in the Korean population than the FRS.",True,other,convolutional neural network
28964254,Fangorn Forest (F2): a machine learning approach to classify genes and genera in the family Geminiviridae,"BACKGROUND: Geminiviruses infect a broad range of cultivated and non-cultivated plants, causing significant economic losses worldwide. The studies of the diversity of species, taxonomy, mechanisms of evolution, geographic distribution, and mechanisms of interaction of these pathogens with the host have greatly increased in recent years. Furthermore, the use of rolling circle amplification (RCA) and advanced metagenomics approaches have enabled the elucidation of viromes and the identification of many viral agents in a large number of plant species. As a result, determining the nomenclature and taxonomically classifying geminiviruses turned into complex tasks. In addition, the gene responsible for viral replication (particularly, the viruses belonging to the genus Mastrevirus) may be spliced due to the use of the transcriptional/splicing machinery in the host cells. However, the current tools have limitations concerning the identification of introns.
RESULTS: This study proposes a new method, designated Fangorn Forest (F2), based on machine learning approaches to classify genera using an ab initio approach, i.e., using only the genomic sequence, as well as to predict and classify genes in the family Geminiviridae. In this investigation, nine genera of the family Geminiviridae and their related satellite DNAs were selected. We obtained two training sets, one for genus classification, containing attributes extracted from the complete genome of geminiviruses, while the other was made up to classify geminivirus genes, containing attributes extracted from ORFs taken from the complete genomes cited above. Three ML algorithms were applied on those datasets to build the predictive models: support vector machines, using the sequential minimal optimization training approach, random forest (RF), and multilayer perceptron. RF demonstrated a very high predictive power, achieving 0.966, 0.964, and 0.995 of precision, recall, and area under the curve (AUC), respectively, for genus classification. For gene classification, RF could reach 0.983, 0.983, and 0.998 of precision, recall, and AUC, respectively.
CONCLUSIONS: Therefore, Fangorn Forest is proven to be an efficient method for classifying genera of the family Geminiviridae with high precision and effective gene prediction and classification. The method is freely accessible at www.geminivirus.org:8080/geminivirusdw/discoveryGeminivirus.jsp .",True,other,Not specified
28683828,VirFinder: a novel k-mer based tool for identifying viral sequences from assembled metagenomic data,"BACKGROUND: Identifying viral sequences in mixed metagenomes containing both viral and host contigs is a critical first step in analyzing the viral component of samples. Current tools for distinguishing prokaryotic virus and host contigs primarily use gene-based similarity approaches. Such approaches can significantly limit results especially for short contigs that have few predicted proteins or lack proteins with similarity to previously known viruses.
METHODS: We have developed VirFinder, the first k-mer frequency based, machine learning method for virus contig identification that entirely avoids gene-based similarity searches. VirFinder instead identifies viral sequences based on our empirical observation that viruses and hosts have discernibly different k-mer signatures. VirFinder's performance in correctly identifying viral sequences was tested by training its machine learning model on sequences from host and viral genomes sequenced before 1 January 2014 and evaluating on sequences obtained after 1 January 2014.
RESULTS: VirFinder had significantly better rates of identifying true viral contigs (true positive rates (TPRs)) than VirSorter, the current state-of-the-art gene-based virus classification tool, when evaluated with either contigs subsampled from complete genomes or assembled from a simulated human gut metagenome. For example, for contigs subsampled from complete genomes, VirFinder had 78-, 2.4-, and 1.8-fold higher TPRs than VirSorter for 1, 3, and 5 kb contigs, respectively, at the same false positive rates as VirSorter (0, 0.003, and 0.006, respectively), thus VirFinder works considerably better for small contigs than VirSorter. VirFinder furthermore identified several recently sequenced virus genomes (after 1 January 2014) that VirSorter did not and that have no nucleotide similarity to previously sequenced viruses, demonstrating VirFinder's potential advantage in identifying novel viral sequences. Application of VirFinder to a set of human gut metagenomes from healthy and liver cirrhosis patients reveals higher viral diversity in healthy individuals than cirrhosis patients. We also identified contig bins containing crAssphage-like contigs with higher abundance in healthy patients and a putative Veillonella genus prophage associated with cirrhosis patients.
CONCLUSIONS: This innovative k-mer based tool complements gene-based approaches and will significantly improve prokaryotic viral sequence identification, especially for metagenomic-based studies of viral ecology.",True,other,convolutional neural network
28066809,Deep Feature Transfer Learning in Combination with Traditional Features Predicts Survival Among Patients with Lung Adenocarcinoma,"Lung cancer is the most common cause of cancer-related deaths in the USA. It can be detected and diagnosed using computed tomography images. For an automated classifier, identifying predictive features from medical images is a key concern. Deep feature extraction using pretrained convolutional neural networks (CNNs) has recently been successfully applied in some image domains. Here, we applied a pretrained CNN to extract deep features from 40 computed tomography images, with contrast, of non-small cell adenocarcinoma lung cancer, and combined deep features with traditional image features and trained classifiers to predict short- and long-term survivors. We experimented with several pretrained CNNs and several feature selection strategies. The best previously reported accuracy when using traditional quantitative features was 77.5% (area under the curve [AUC], 0.712), which was achieved by a decision tree classifier. The best reported accuracy from transfer learning and deep features was 77.5% (AUC, 0.713) using a decision tree classifier. When extracted deep neural network features were combined with traditional quantitative features, we obtained an accuracy of 90% (AUC, 0.935) with the 5 best post-rectified linear unit features extracted from a vgg-f pretrained CNN and the 5 best traditional features. The best results were achieved with the symmetric uncertainty feature ranking algorithm followed by a random forests classifier.",True,other,Not specified
27727189,Learning the Relationship between the Primary Structure of HIV Envelope Glycoproteins and Neutralization Activity of Particular Antibodies by Using Artificial Neural Networks,"The dependency between the primary structure of HIV envelope glycoproteins (ENV) and the neutralization data for given antibodies is very complicated and depends on a large number of factors, such as the binding affinity of a given antibody for a given ENV protein, and the intrinsic infection kinetics of the viral strain. This paper presents a first approach to learning these dependencies using an artificial feedforward neural network which is trained to learn from experimental data. The results presented here demonstrate that the trained neural network is able to generalize on new viral strains and to predict reliable values of neutralizing activities of given antibodies against HIV-1.",True,other,convolutional neural network
27532883,Advanced Online Survival Analysis Tool for Predictive Modelling in Clinical Data Science,"One of the prevailing applications of machine learning is the use of predictive modelling in clinical survival analysis. In this work, we present our view of the current situation of computer tools for survival analysis, stressing the need of transferring the latest results in the field of machine learning to biomedical researchers. We propose a web based software for survival analysis called OSA (Online Survival Analysis), which has been developed as an open access and user friendly option to obtain discrete time, predictive survival models at individual level using machine learning techniques, and to perform standard survival analysis. OSA employs an Artificial Neural Network (ANN) based method to produce the predictive survival models. Additionally, the software can easily generate survival and hazard curves with multiple options to personalise the plots, obtain contingency tables from the uploaded data to perform different tests, and fit a Cox regression model from a number of predictor variables. In the Materials and Methods section, we depict the general architecture of the application and introduce the mathematical background of each of the implemented methods. The study concludes with examples of use showing the results obtained with public datasets.",True,other,Not specified
26854419,Automatically quantifying the scientific quality and sensationalism of news records mentioning pandemics: validating a maximum entropy machine-learning model,"OBJECTIVE: To develop and validate a method for automatically quantifying the scientific quality and sensationalism of individual news records.
STUDY DESIGN: After retrieving 163,433 news records mentioning the Severe Acute Respiratory Syndrome (SARS) and H1N1 pandemics, a maximum entropy model for inductive machine learning was used to identify relationships among 500 randomly sampled news records that correlated with systematic human assessments of their scientific quality and sensationalism. These relationships were then computationally applied to automatically classify 10,000 additional randomly sampled news records. The model was validated by randomly sampling 200 records and comparing human assessments of them to the computer assessments.
RESULTS: The computer model correctly assessed the relevance of 86% of news records, the quality of 65% of records, and the sensationalism of 73% of records, as compared to human assessments. Overall, the scientific quality of SARS and H1N1 news media coverage had potentially important shortcomings, but coverage was not too sensationalizing. Coverage slightly improved between the two pandemics.
CONCLUSION: Automated methods can evaluate news records faster, cheaper, and possibly better than humans. The specific procedure implemented in this study can at the very least identify subsets of news records that are far more likely to have particular scientific and discursive qualities.",True,other,convolutional neural network
26733278,Lopinavir Resistance Classification with Imbalanced Data Using Probabilistic Neural Networks,"Resistance to antiretroviral drugs has been a major obstacle for long-lasting treatment of HIV-infected patients. The development of models to predict drug resistance is recognized as useful for helping the decision of the best therapy for each HIV+ individual. The aim of this study was to develop classifiers for predicting resistance to the HIV protease inhibitor lopinavir using a probabilistic neural network (PNN). The data were provided by the Molecular Virology Laboratory of the Health Sciences Center, Federal University of Rio de Janeiro (CCS-UFRJ/Brazil). Using bootstrap and stepwise techniques, ten features were selected by logistic regression (LR) to be used as inputs to the network. Bootstrap and cross-validation were used to define the smoothing parameter of the PNN networks. Four balanced models were designed and evaluated using a separate test set. The accuracies of the classifiers with the test set ranged from 0.89 to 0.94, and the area under the receiver operating characteristic (ROC) curve (AUC) ranged from 0.96 to 0.97. The sensitivity ranged from 0.94 to 1.00, and the specificity was between 0.88 and 0.92. Four classifiers showed performances very close to three existing expert-based interpretation systems, the HIVdb, the Rega and the ANRS algorithms, and to a k-Nearest Neighbor.",True,other,Not specified
26163648,Use of an Artificial Neural Network to Construct a Model of Predicting Deep Fungal Infection in Lung Cancer Patients,"BACKGROUND: The statistical methods to analyze and predict the related dangerous factors of deep fungal infection in lung cancer patients were several, such as logic regression analysis, meta-analysis, multivariate Cox proportional hazards model analysis, retrospective analysis, and so on, but the results are inconsistent.
MATERIALS AND METHODS: A total of 696 patients with lung cancer were enrolled. The factors were compared employing Student's t-test or the Mann-Whitney test or the Chi-square test and variables that were significantly related to the presence of deep fungal infection selected as candidates for input into the final artificial neural network analysis (ANN) model. The receiver operating characteristic (ROC) and area under curve (AUC) were used to evaluate the performance of the artificial neural network (ANN) model and logistic regression (LR) model.
RESULTS: The prevalence of deep fungal infection from lung cancer in this entire study population was 32.04%(223/696), deep fungal infections occur in sputum specimens 44.05% (200/454). The ratio of candida albicans was 86.99% (194/223) in the total fungi. It was demonstrated that older (≥65 years), use of antibiotics, low serum albumin concentrations (≤37.18 g /L), radiotherapy, surgery, low hemoglobin hyperlipidemia (≤93.67 g /L), long time of hospitalization (≥14 days) were apt to deep fungal infection and the ANN model consisted of the seven factors. The AUC of ANN model (0.829±0.019) was higher than that of LR model (0.756±0.021).
CONCLUSIONS: The artificial neural network model with variables consisting of age, use of antibiotics, serum albumin concentrations, received radiotherapy, received surgery, hemoglobin, time of hospitalization should be useful for predicting the deep fungal infection in lung cancer.",True,other,Not specified
25953014,Prediction of in-hospital mortality after ruptured abdominal aortic aneurysm repair using an artificial neural network,"OBJECTIVE: Ruptured abdominal aortic aneurysm (rAAA) carries a high mortality rate, even with prompt transfer to a medical center. An artificial neural network (ANN) is a computational model that improves predictive ability through pattern recognition while continually adapting to new input data. The goal of this study was to effectively use ANN modeling to provide vascular surgeons a discriminant adjunct to assess the likelihood of in-hospital mortality on a pending rAAA admission using easily obtainable patient information from the field.
METHODS: Of 332 total patients from a single institution from 1998 to 2013 who had attempted rAAA repair, 125 were reviewed for preoperative factors associated with in-hospital mortality; 108 patients received an open operation, and 17 patients received endovascular repair. Five variables were found significant on multivariate analysis (P < .05), and four of these five (preoperative shock, loss of consciousness, cardiac arrest, and age) were modeled by multiple logistic regression and an ANN. These predictive models were compared against the Glasgow Aneurysm Score. All models were assessed by generation of receiver operating characteristic curves and actual vs predicted outcomes plots, with area under the curve and Pearson r(2) value as the primary measures of discriminant ability.
RESULTS: Of the 125 patients, 53 (42%) did not survive to discharge. Five preoperative factors were significant (P < .05) independent predictors of in-hospital mortality in multivariate analysis: advanced age, renal disease, loss of consciousness, cardiac arrest, and shock, although renal disease was excluded from the models. The sequential accumulation of zero to four of these risk factors progressively increased overall mortality rate, from 11% to 16% to 44% to 76% to 89% (age ≥ 70 years considered a risk factor). Algorithms derived from multiple logistic regression, ANN, and Glasgow Aneurysm Score models generated area under the curve values of 0.85 ± 0.04, 0.88 ± 0.04 (training set), and 0.77 ± 0.06 and Pearson r(2) values of .36, .52 and .17, respectively. The ANN model represented the most discriminant of the three.
CONCLUSIONS: An ANN-based predictive model may represent a simple, useful, and highly discriminant adjunct to the vascular surgeon in accurately identifying those patients who may carry a high mortality risk from attempted repair of rAAA, using only easily definable preoperative variables. Although still requiring external validation, our model is available for demonstration at https://redcap.vanderbilt.edu/surveys/?s=NN97NM7DTK.",True,other,RNN
25750696,Machine learning applications in cancer prognosis and prediction,"Cancer has been characterized as a heterogeneous disease consisting of many different subtypes. The early diagnosis and prognosis of a cancer type have become a necessity in cancer research, as it can facilitate the subsequent clinical management of patients. The importance of classifying cancer patients into high or low risk groups has led many research teams, from the biomedical and the bioinformatics field, to study the application of machine learning (ML) methods. Therefore, these techniques have been utilized as an aim to model the progression and treatment of cancerous conditions. In addition, the ability of ML tools to detect key features from complex datasets reveals their importance. A variety of these techniques, including Artificial Neural Networks (ANNs), Bayesian Networks (BNs), Support Vector Machines (SVMs) and Decision Trees (DTs) have been widely applied in cancer research for the development of predictive models, resulting in effective and accurate decision making. Even though it is evident that the use of ML methods can improve our understanding of cancer progression, an appropriate level of validation is needed in order for these methods to be considered in the everyday clinical practice. In this work, we present a review of recent ML approaches employed in the modeling of cancer progression. The predictive models discussed here are based on various supervised ML techniques as well as on different input features and data samples. Given the growing trend on the application of ML methods in cancer research, we present here the most recent publications that employ these techniques as an aim to model cancer risk or patient outcomes.",True,other,Not specified
25449060,The Impact of Oversampling with SMOTE on the Performance of 3 Classifiers in Prediction of Type 2 Diabetes,"OBJECTIVE: To evaluate the impact of the synthetic minority oversampling technique (SMOTE) on the performance of probabilistic neural network (PNN), naïve Bayes (NB), and decision tree (DT) classifiers for predicting diabetes in a prospective cohort of the Tehran Lipid and Glucose Study (TLGS).
METHODS: . Data of the 6647 nondiabetic participants, aged 20 years or older with more than 10 years of follow-up, were used to develop prediction models based on 21 common risk factors. The minority class in the training dataset was oversampled using the SMOTE technique, at 100%, 200%, 300%, 400%, 500%, 600%, and 700% of its original size. The original and the oversampled training datasets were used to establish the classification models. Accuracy, sensitivity, specificity, precision, F-measure, and Youden's index were used to evaluated the performance of classifiers in the test dataset. To compare the performance of the 3 classification models, we used the ROC convex hull (ROCCH).
RESULTS: Oversampling the minority class at 700% (completely balanced) increased the sensitivity of the PNN, DT, and NB by 64%, 51%, and 5%, respectively, but decreased the accuracy and specificity of the 3 classification methods. NB had the best Youden's index before and after oversampling. The ROCCH showed that PNN is suboptimal for any class and cost conditions.
CONCLUSIONS: To determine a classifier with a machine learning algorithm like the PNN and DT, class skew in data should be considered. The NB and DT were optimal classifiers in a prediction task in an imbalanced medical database.",True,other,recurrent neural network
24521170,ANN multiscale model of anti-HIV drugs activity vs AIDS prevalence in the US at county level based on information indices of molecular graphs and social networks,"This work is aimed at describing the workflow for a methodology that combines chemoinformatics and pharmacoepidemiology methods and at reporting the first predictive model developed with this methodology. The new model is able to predict complex networks of AIDS prevalence in the US counties, taking into consideration the social determinants and activity/structure of anti-HIV drugs in preclinical assays. We trained different Artificial Neural Networks (ANNs) using as input information indices of social networks and molecular graphs. We used a Shannon information index based on the Gini coefficient to quantify the effect of income inequality in the social network. We obtained the data on AIDS prevalence and the Gini coefficient from the AIDSVu database of Emory University. We also used the Balaban information indices to quantify changes in the chemical structure of anti-HIV drugs. We obtained the data on anti-HIV drug activity and structure (SMILE codes) from the ChEMBL database. Last, we used Box-Jenkins moving average operators to quantify information about the deviations of drugs with respect to data subsets of reference (targets, organisms, experimental parameters, protocols). The best model found was a Linear Neural Network (LNN) with values of Accuracy, Specificity, and Sensitivity above 0.76 and AUROC > 0.80 in training and external validation series. This model generates a complex network of AIDS prevalence in the US at county level with respect to the preclinical activity of anti-HIV drugs in preclinical assays. To train/validate the model and predict the complex network we needed to analyze 43,249 data points including values of AIDS prevalence in 2,310 counties in the US vs ChEMBL results for 21,582 unique drugs, 9 viral or human protein targets, 4,856 protocols, and 10 possible experimental measures.",True,other,convolutional neural network
24011972,A comparison of the performances of an artificial neural network and a regression model for GFR estimation,"BACKGROUND: Accurate estimation of glomerular filtration rate (GFR) is important in clinical practice. Current models derived from regression are limited by the imprecision of GFR estimates. We hypothesized that an artificial neural network (ANN) might improve the precision of GFR estimates.
STUDY DESIGN: A study of diagnostic test accuracy.
SETTING & PARTICIPANTS: 1,230 patients with chronic kidney disease were enrolled, including the development cohort (n=581), internal validation cohort (n=278), and external validation cohort (n=371).
INDEX TESTS: Estimated GFR (eGFR) using a new ANN model and a new regression model using age, sex, and standardized serum creatinine level derived in the development and internal validation cohort, and the CKD-EPI (Chronic Kidney Disease Epidemiology Collaboration) 2009 creatinine equation.
REFERENCE TEST: Measured GFR (mGFR).
OTHER MEASUREMENTS: GFR was measured using a diethylenetriaminepentaacetic acid renal dynamic imaging method. Serum creatinine was measured with an enzymatic method traceable to isotope-dilution mass spectrometry.
RESULTS: In the external validation cohort, mean mGFR was 49±27 (SD) mL/min/1.73 m2 and biases (median difference between mGFR and eGFR) for the CKD-EPI, new regression, and new ANN models were 0.4, 1.5, and -0.5 mL/min/1.73 m2, respectively (P<0.001 and P=0.02 compared to CKD-EPI and P<0.001 comparing the new regression and ANN models). Precisions (IQRs for the difference) were 22.6, 14.9, and 15.6 mL/min/1.73 m2, respectively (P<0.001 for both compared to CKD-EPI and P<0.001 comparing the new ANN and new regression models). Accuracies (proportions of eGFRs not deviating >30% from mGFR) were 50.9%, 77.4%, and 78.7%, respectively (P<0.001 for both compared to CKD-EPI and P=0.5 comparing the new ANN and new regression models).
LIMITATIONS: Different methods for measuring GFR were a source of systematic bias in comparisons of new models to CKD-EPI, and both the derivation and validation cohorts consisted of a group of patients who were referred to the same institution.
CONCLUSIONS: An ANN model using 3 variables did not perform better than a new regression model. Whether ANN can improve GFR estimation using more variables requires further investigation.",True,other,Not specified
22609534,A fast and adaptive automated disease diagnosis method with an innovative neural network model,"Automatic disease diagnosis systems have been used for many years. While these systems are constructed, the data used needs to be classified appropriately. For this purpose, a variety of methods have been proposed in the literature so far. As distinct from the ones in the literature, in this study, a general-purpose, fast and adaptive disease diagnosis system is developed. This newly proposed method is based on Learning Vector Quantization (LVQ) artificial neural networks which are powerful classification algorithms. In this study, the classification ability of LVQ networks is developed by embedding a reinforcement mechanism into the LVQ network in order to increase the success rate of the disease diagnosis method and reduce the decision time. The parameters of the reinforcement learning mechanism are updated in an adaptive way in the network. Thus, the loss of time due to incorrect selection of the parameters and decrement in the success rate are avoided. After the development process mentioned, the newly proposed classification technique is named ""Adaptive LVQ with Reinforcement Mechanism (ALVQ-RM)"". The method proposed handles data with missing values. To prove that this method did not offer a special solution for a particular disease, because of its adaptive structure, it is used both for diagnosis of breast cancer, and for diagnosis of thyroid disorders, and a correct diagnosis rate after replacing missing values using median method over 99.5% is acquired in average for both diseases. In addition, the success rate of determination of the parameters of the proposed ""LVQ with Reinforcement Mechanism (LVQ-RM)"" classifier, and how this determination affected the required number of iterations for acquiring that success rate are discussed with comparison to the other studies.",True,text mining,recurrent neural network
21272346,Statistical learning techniques applied to epidemiology: a simulated case-control comparison study with logistic regression,"BACKGROUND: When investigating covariate interactions and group associations with standard regression analyses, the relationship between the response variable and exposure may be difficult to characterize. When the relationship is nonlinear, linear modeling techniques do not capture the nonlinear information content. Statistical learning (SL) techniques with kernels are capable of addressing nonlinear problems without making parametric assumptions. However, these techniques do not produce findings relevant for epidemiologic interpretations. A simulated case-control study was used to contrast the information embedding characteristics and separation boundaries produced by a specific SL technique with logistic regression (LR) modeling representing a parametric approach. The SL technique was comprised of a kernel mapping in combination with a perceptron neural network. Because the LR model has an important epidemiologic interpretation, the SL method was modified to produce the analogous interpretation and generate odds ratios for comparison.
RESULTS: The SL approach is capable of generating odds ratios for main effects and risk factor interactions that better capture nonlinear relationships between exposure variables and outcome in comparison with LR.
CONCLUSIONS: The integration of SL methods in epidemiology may improve both the understanding and interpretation of complex exposure/disease relationships.",True,other,Not specified
21073895,An artificial neural network improves the non-invasive diagnosis of significant fibrosis in HIV/HCV coinfected patients,"OBJECTIVE: To develop an artificial neural network to predict significant fibrosis (F≥2) (ANN-SF) in HIV/Hepatitis C (HCV) coinfected patients using clinical data derived from peripheral blood.
METHODS: Patients were randomly divided into an estimation group (217 cases) used to generate the ANN and a test group (145 cases) used to confirm its power to predict F≥2. Liver fibrosis was estimated according to the METAVIR score.
RESULTS: The values of the area under the receiver operating characteristic curve (AUC-ROC) of the ANN-SF were 0.868 in the estimation set and 0.846 in the test set. In the estimation set, with a cut-off value of <0.35 to predict the absence of F≥2, the sensitivity (Se), specificity (Sp), and positive (PPV) and negative predictive values (NPV) were 94.1%, 41.8%, 66.3% and 85.4% respectively. Furthermore, with a cut-off value of >0.75 to predict the presence of F≥2, the ANN-SF provided Se, Sp, PPV and NPV of 53.8%, 94.9%, 92.8% and 62.8% respectively. In the test set, with a cut-off value of <0.35 to predict the absence of F≥2, the Se, Sp, PPV and NPV were 91.8%, 51.7%, 72.9% and 81.6% respectively. Furthermore, with a cut-off value of >0.75 to predict the presence of F≥2, the ANN-SF provided Se, Sp, PPV and NPV of 43.5%, 96.7%, 94.9% and 54.7% respectively.
CONCLUSION: The ANN-SF accurately predicted significant fibrosis and outperformed other simple non-invasive indices for HIV/HCV coinfected patients. Our data suggest that ANN may be a helpful tool for guiding therapeutic decisions in clinical practice concerning HIV/HCV coinfection.",True,both,Not specified
20958936,"MChip, a low density microarray, differentiates among seasonal human H1N1, North American swine H1N1, and the 2009 pandemic H1N1","BACKGROUND: The MChip uses data from the hybridization of amplified viral RNA to 15 distinct oligonucleotides that target the influenza A matrix (M) gene segment. An artificial neural network (ANN) automates the interpretation of subtle differences in fluorescence intensity patterns from the microarray. The complete process from clinical specimen to identification including amplification of viral RNA can be completed in <8 hours for under US$10.
OBJECTIVES: The work presented here represents an effort to expand and test the capabilities of the MChip to differentiate influenza A/H1N1 of various species origin.
METHODS: The MChip ANN was trained to recognize fluorescence image patterns of a variety of known influenza A viruses, including examples of human H1N1, human H3N2, swine H1N1, 2009 pandemic influenza A H1N1, and a wide variety of avian, equine, canine, and swine influenza viruses. Robustness of the MChip ANN was evaluated using 296 blinded isolates.
RESULTS: Training of the ANN was expanded by the addition of 71 well-characterized influenza A isolates and yielded relatively high accuracy (little misclassification) in distinguishing unique H1N1 strains: nine human A/H1N1 (88·9% correct), 35 human A/H3N2 (97·1% correct), 31 North American swine A/H1N1 (80·6% correct), 14 2009 pandemic A/H1N1 (87·7% correct), and 23 negative samples (91·3% correct). Genetic diversity among the swine H1N1 isolates may have contributed to the lower success rate for these viruses.
CONCLUSIONS: The current study demonstrates the MChip has the capability to differentiate the genetic variations among influenza viruses with appropriate ANN training. Further selective enrichment of the ANN will improve its ability to rapidly and reliably characterize influenza viruses of unknown origin.",True,other,RNN
20703665,Neural network diagnostic system for dengue patients risk classification,"With the dramatic increase of the worldwide threat of dengue disease, it has been very crucial to correctly diagnose the dengue patients in order to decrease the disease severity. However, it has been a great challenge for the physicians to identify the level of risk in dengue patients due to overlapping of the medical classification criteria. Therefore, this study aims to construct a noninvasive diagnostic system to assist the physicians for classifying the risk in dengue patients. Systematic producers have been followed to develop the system. Firstly, the assessment of the significant predictors associated with the level of risk in dengue patients was carried out utilizing the statistical analyses technique. Secondly, Multilayer perceptron neural network models trained via Levenberg-Marquardt and Scaled Conjugate Gradient algorithms was employed for constructing the diagnostic system. Finally, precise tuning for the models' parameters was conducted in order to achieve the optimal performance. As a result, 9 noninvasive predictors were found to be significantly associated with the level of risk in dengue patients. By employing those predictors, 75% prediction accuracy has been achieved for classifying the risk in dengue patients using Scaled Conjugate Gradient algorithm while 70.7% prediction accuracy were achieved by using Levenberg-Marquardt algorithm.",True,computer vision,Not specified
20206661,Comparison between an artificial neural network and logistic regression in predicting acute graft-vs-host disease after unrelated donor hematopoietic stem cell transplantation in thalassemia patients,"OBJECTIVE: There is growing interest in the development of prognostic models for predicting the occurrence of acute graft-vs-host disease (aGVHD) after unrelated donor hematopoietic stem cell transplantation. A high number of variables have been shown to play a role in aGVHD, but the search for a predictive algorithm is still ongoing. Artificial neural networks (ANNs) represent an attractive alternative to multivariate analysis for clinical prognosis. So far, no reports have investigated the ability of ANNs in predicting HSCT outcome.
MATERIALS AND METHODS: We compared the prognostic performance of ANNs with that of logistic regression (LR) in 78 beta-thalassemia major patients given unrelated donor hematopoietic stem cell transplantation. Twenty-four independent variables were analyzed for their potential impact on outcomes.
RESULTS: Twenty-six patients (33.3%) developed grade II to IV aGVHD. In multivariate analysis, homozygosity for donor KIR haplotype A (p = 0.03), donor age (p = 0.05), and donor homozygosity for the deletion of the human leukocyte antigen-G 14-bp polymorphism (p = 0.05) were independently significantly correlated to aGVHD. The mean sensitivity of LR and ANNs (capability of predicting aGVHD in patients who developed aGVHD) in test datasets was 21.7% and 83.3%, respectively (p < 0.001); the mean specificity (capability of predicting absence of aGVHD in patients who did not develop aGVHD) was 80.5% and 90.1%, respectively (p = NS).
CONCLUSION: Although ANNs are unable to calculate the weight of single variables on outcomes, they were found to have a better performance than LR. A combination of these two methods could be more efficient in predicting outcomes and help tailor GVHD prophylaxis regimens according to the predicted risk of each patient. Whether ANN technology will provide better predictive performance when applied to other datasets remains to be confirmed.",True,other,Not specified
19602982,Artificial neural network versus multiple logistic function to predict 25-year coronary heart disease mortality in the Seven Countries Study,"AIMS AND METHODS: We investigated 12 763 men enrolled in the Seven Countries Study and 25-year coronary heart disease (CHD) mortality to compare the predictive discrimination of the multilayer perceptron (MLP) neural network versus multiple logistic function based on four standard, continuous risk factors, selected a priori. The patients were grouped according to geographical distribution, which also parallels CHD mortality risk. Logistic model solutions were estimated for each geographic area. Training neural network models were estimated in one high risk (US) and one low risk (Italy) population and each was rerun in each nonindex population.
RESULTS: CHD mortality prediction by training MLP neural network or multiple logistic function had similar (0.669-0.699) receiver operating characteristic area under the curve (AUC). The rerun of MLP neural network models derived from the US and Italy yielded comparable AUC similar to the logistic solutions in Northern and Eastern Europe, but higher AUC in two areas [0.633 (logistic) vs. 0.665 or 0.666 (neural network: P<0.05) in Southern Europe and 0.676 (logistic) vs. 0.725 or 0.737 (neural network: P<0.01) in Japan].
CONCLUSION: This is the first investigation performed on epidemiological data to suggest a good performance in predicting long-term CHD mortality, on the basis of few continuous risk factors, of a training neural network model that could be rerun on different populations with satisfactory findings.",True,other,recurrent neural network
19524413,A comparison of three computational modelling methods for the prediction of virological response to combination HIV therapy,"OBJECTIVE: HIV treatment failure is commonly associated with drug resistance and the selection of a new regimen is often guided by genotypic resistance testing. The interpretation of complex genotypic data poses a major challenge. We have developed artificial neural network (ANN) models that predict virological response to therapy from HIV genotype and other clinical information. Here we compare the accuracy of ANN with alternative modelling methodologies, random forests (RF) and support vector machines (SVM).
METHODS: Data from 1204 treatment change episodes (TCEs) were identified from the HIV Resistance Response Database Initiative (RDI) database and partitioned at random into a training set of 1154 and a test set of 50. The training set was then partitioned using an L-cross (L=10 in this study) validation scheme for training individual computational models. Seventy six input variables were used for training the models: 55 baseline genotype mutations; the 14 potential drugs in the new treatment regimen; four treatment history variables; baseline viral load; CD4 count and time to follow-up viral load. The output variable was follow-up viral load. Performance was evaluated in terms of the correlations and absolute differences between the individual models' predictions and the actual DeltaVL values.
RESULTS: The correlations (r(2)) between predicted and actual DeltaVL varied from 0.318 to 0.546 for ANN, 0.590 to 0.751 for RF and 0.300 to 0.720 for SVM. The mean absolute differences varied from 0.677 to 0.903 for ANN, 0.494 to 0.644 for RF and 0.500 to 0.790 for SVM. ANN models were significantly inferior to RF and SVM models. The predictions of the ANN, RF and SVM committees all correlated highly significantly with the actual DeltaVL of the independent test TCEs, producing r(2) values of 0.689, 0.707 and 0.620, respectively. The mean absolute differences were 0.543, 0.600 and 0.607log(10)copies/ml for ANN, RF and SVM, respectively. There were no statistically significant differences between the three committees. Combining the committees' outputs improved correlations between predicted and actual virological responses. The combination of all three committees gave a correlation of r(2)=0.728. The mean absolute differences followed a similar pattern.
CONCLUSIONS: RF and SVM models can produce predictions of virological response to HIV treatment that are comparable in accuracy to a committee of ANN models. Combining the predictions of different models improves their accuracy somewhat. This approach has potential as a future clinical tool and a combination of ANN and RF models is being taken forward for clinical evaluation.",True,other,RNN
19237446,A neural network model for constructing endophenotypes of common complex diseases: an application to male young-onset hypertension microarray data,"MOTIVATION: Identification of disease-related genes using high-throughput microarray data is more difficult for complex diseases as compared with monogenic ones. We hypothesized that an endophenotype derived from transcriptional data is associated with a set of genes corresponding to a pathway cluster. We assumed that a complex disease is associated with multiple endophenotypes and can be induced by their up/downregulated gene expression patterns. Thus, a neural network model was adopted to simulate the gene-endophenotype-disease relationship in which endophenotypes were represented by hidden nodes.
RESULTS: We successfully constructed a three-endophenotype model for Taiwanese hypertensive males with high identification accuracy. Of the three endophenotypes, one is strongly protective, another is weakly protective and the third is highly correlated with developing young-onset male hypertension. Sixteen of the involved 101 genes were highly and consistently influential to the endophenotypes. Identification of SLC4A5, SLC5A10 and LDOC1 indicated that sodium/bicarbonate transport, sodium/glucose transport and cell-proliferation regulation may play important upstream roles and identification of BNIP1, APOBEC3F and LDOC1 suggested that apoptosis, innate immune response and cell-proliferation regulation may play important downstream roles in hypertension. The involved genes not only provide insights into the mechanism of hypertension but should also be considered in future gene mapping endeavors.",True,other,recurrent neural network
18309244,Artificial neural network model is superior to logistic regression model in predicting treatment outcomes of interferon-based combination therapy in patients with chronic hepatitis C,"BACKGROUND/AIMS: Patients with chronic hepatitis C (CHC) can achieve a sustained virologic response if they received pegylated interferon plus ribavirin therapy; however, some of them do not respond or relapse after treatment. The aim of this study was to compare the ability of two statistical models to predict treatment outcomes.
METHODS: Clinical data, biochemical values, and liver histological features of 107 patients with CHC were collected and assessed using a logistic regression (LR) model and an artificial neural network (ANN) model. Both the LR and ANN models were compared by receiver-operating characteristics curves.
RESULTS: Aspartate aminotransferase (p = 0.017), prothrombin time (p = 0.002), body mass index (BMI; p = 0.003), and fibrosis score of liver histology (p = 0.002) were found to be significant predictive factors by univariate analysis. The independent significant predicting factor was BMI by multivariate LR analysis (p = 0.0095). The area under receiver-operating characteristics of the ANN model was larger than that of the LR model (85 vs. 58.4%).
CONCLUSIONS: It was found that BMI is an independent factor for identifying patients with favorable treatment response. A useful ANN model in predicting outcomes of standard treatment for CHC infection was developed and showed greater accuracy than the LR model.",True,other,Not specified
17503743,The development of artificial neural networks to predict virological response to combination HIV therapy,"INTRODUCTION: When used in combination, antiretroviral drugs are highly effective for suppressing HIV replication. Nevertheless, treatment failure commonly occurs and is generally associated with viral drug resistance. The choice of an alternative regimen may be guided by a drug-resistance test. However, interpretation of resistance from genotypic data poses a major challenge.
METHODS: As an alternative to current interpretation systems, we have developed artificial neural network (ANN) models to predict virological response to combination therapy from HIV genotype and other clinical information.
RESULTS: ANN models trained with genotype, baseline viral load and time to follow-up viral load (1154 treatment change episodes from multiple clinics), produced predictions of virological response that were highly significantly correlated with actual responses (r2 = 0.53; P < 0.00001) using independent test data from clinics that contributed training data. Augmented models, trained with the additional variables of baseline CD4+ T-cell count and four treatment history variables, were more accurate, explaining 69% of the variance in virological response. Models trained with the full input dataset, but only those data involving highly active antiretroviral therapy (three or more full-dose antiretroviral drugs in combination), performed at an intermediate level, explaining 61% of the variance. The augmented models performed less well when tested with data from unfamiliar clinics that had not contributed data to the training dataset, explaining 46% of the variance in response.
CONCLUSION: These data indicate that ANN models can be quite accurate predictors of virological response to HIV therapy even for patients from unfamiliar clinics. ANN models therefore warrant further development as a potential tool to aid treatment selection.",True,other,Not specified
17188168,Identification of severe acute pancreatitis using an artificial neural network,"BACKGROUND: The aim of this study was to construct and validate an artificial neural network (ANN) model to identify severe acute pancreatitis (AP) and predict fatal outcome.
METHODS: All patients who presented with AP from January 2000 to September 2004 were reviewed. Presentation data on admission and at 48 hours were collected. Acute Physiology and Chronic Health Evaluation (APACHE) II and Glasgow severity (GS) score were calculated. A feed-forward ANN was created and trained to predict development of severe AP and mortality from AP; 25% of the data set was withheld from training and was used to evaluate the accuracy of the ANN. Accuracy of the ANN in predicting severity of AP was compared with APACHE II and GS scores.
RESULTS: A total of 664 patients with AP were identified of whom 181 (27.3%) fulfilled the clinical and radiologic criteria for severe pancreatitis and 42 patients died (6.3%). Median APACHE II score at 48 hours was 4 (range, 0 to 23). ANN was more accurate than APACHE II or GS scoring systems at predicting progression to a severe course (P < .05 and P < .01, respectively), predicting development of multiorgan dysfunction syndrome (P < .05 and P < .01) and at predicting death from AP (P < .05).
CONCLUSIONS: An ANN was able to predict progression to severe disease, development of organ failure and mortality from acute pancreatitis with considerable accuracy and outperformed other clinical risk scoring systems. Further studies are required to assess its utility in aiding management decisions in patients with AP.",True,computer vision,RNN
20634919,Understanding the Evolutionary Process of Grammatical Evolution Neural Networks for Feature Selection in Genetic Epidemiology,"The identification of genetic factors/features that predict complex diseases is an important goal of human genetics. The commonality of gene-gene interactions in the underlying genetic architecture of common diseases presents a daunting analytical challenge. Previously, we introduced a grammatical evolution neural network (GENN) approach that has high power to detect such interactions in the absence of any marginal main effects. While the success of this method is encouraging, it elicits questions regarding the evolutionary process of the algorithm itself and the feasibility of scaling the method to account for the immense dimensionality of datasets with enormous numbers of features. When the features of interest show no main effects, how is GENN able to build correct models? How and when should evolutionary parameters be adjusted according to the scale of a particular dataset? In the current study, we monitor the performance of GENN during its evolutionary process using different population sizes and numbers of generations. We also compare the evolutionary characteristics of GENN to that of a random search neural network strategy to better understand the benefits provided by the evolutionary learning process-including advantages with respect to chromosome size and the representation of functional versus non-functional features within the models generated by the two approaches. Finally, we apply lessons from the characterization of GENN to analyses of datasets containing increasing numbers of features to demonstrate the scalability of the method.",True,other,convolutional neural network
16779050,Neural network-longitudinal assessment of the Electronic Anti-Retroviral THerapy (EARTH) cohort to follow response to HIV-treatment,"HIV infection is for the most part a chronic and asymptomatic disease. To properly monitor the health status of infected individuals it is important to use host and viral surrogate markers as well as pharmacokinetic parameters. Disease progression, assessment of the antiviral potency of the drugs and response to therapy can only be monitored by repetitive measures of viral and host parameters. To prevent the emergence of antiviral drug-resistance, long term side effects and to decide on the appropriate treatment choices, a comprehensive assessment of all contributing factors, medical and non-medical, is necessary. However, the relationship between treatment outcomes with disease markers and other contributing factors is not simple. To date, a model that accurately predicts the likelihood of disease progression or treatment failure in HIV infected patients does not exist. Extending our previous work in this area, we developed temporal Artificial Intelligence models based on Jordan-Elman networks to longitudinally follow viral surrogate markers together with demographics, biochemical and laboratory data to describe the drug-virus-host interactions in over 4000 HIV adult patients. In an international (multi-continent) study of HIV clinical and laboratory data, the profiles of drug-naïve as well as treated patients were evaluated during a 20 year follow-up. Validation of models on a subset of this cohort (n=595) estimated the sensitivity and specificity of treatment success/failure, under different management modalities for individual patients. ROC-curves predicted: virologic success from baseline (ROC=0.871) in drug-naïve previously non-treated patients, switch from virologic success/ failure to failure/success if ever and when (ROC=0.625), switch to virologic success/failure from failure/success within 6 months (ROC=0.722) following a previous switch. This tool may be helpful in the design of longitudinal clinical trials.",True,computer vision,Not specified
16151110,Artificial neural network prediction of viruses in shellfish,"A database was probed with artificial neural network (ANN) and multivariate logistic regression (MLR) models to investigate the efficacy of predicting PCR-identified human adenovirus (ADV), Norwalk-like virus (NLV), and enterovirus (EV) presence or absence in shellfish harvested from diverse countries in Europe (Spain, Sweden, Greece, and the United Kingdom). The relative importance of numerical and heuristic input variables to the ANN model for each country and for the combined data was analyzed with a newly defined relative strength effect, which illuminated the importance of bacteriophages as potential viral indicators. The results of this analysis showed that ANN models predicted all types of viral presence and absence in shellfish with better precision than MLR models for a multicountry database. For overall presence/absence classification accuracy, ANN modeling had a performance rate of 95.9%, 98.9%, and 95.7% versus 60.5%, 75.0%, and 64.6% for the MLR for ADV, NLV, and EV, respectively. The selectivity (prediction of viral negatives) was greater than the sensitivity (prediction of viral positives) for both models and with all virus types, with the ANN model performing with greater sensitivity than the MLR. ANN models were able to illuminate site-specific relationships between microbial indicators chosen as model inputs and human virus presence. A validation study on ADV demonstrated that the MLR and ANN models differed in sensitivity and selectivity, with the ANN model correctly identifying ADV presence with greater precision.",True,text mining,Not specified
16013091,A bayesian recurrent neural network for unsupervised pattern recognition in large incomplete data sets,"A recurrent neural network, modified to handle highly incomplete training data is described. Unsupervised pattern recognition is demonstrated in the WHO database of adverse drug reactions. Comparison is made to a well established method, AutoClass, and the performances of both methods is investigated on simulated data. The neural network method performs comparably to AutoClass in simulated data, and better than AutoClass in real world data. With its better scaling properties, the neural network is a promising tool for unsupervised pattern recognition in huge databases of incomplete observations.",True,other,recurrent neural network
15706526,Neural-network-based parameter estimation in S-system models of biological networks,"The genomic and post-genomic eras have been blessing us with overwhelming amounts of data that are of increasing quality. The challenge is that most of these data alone are mere snapshots of the functioning organism and do not reveal the organizational structure of which the particular genes and metabolites are contributors. To gain an appreciation of their roles and functions within cells and organisms, genomic and metabolic data need to be integrated in systems models that allow the testing of hypotheses, generate experimentally testable predictions, and ultimately lead to true explanations. One type of data that is particularly well suited for such integration consists of time profiles, which show gene activities, metabolite concentrations, or protein prevalences at dense series of time points. We show with a specific example how such time series can be analyzed and evaluated, if some structural information about the data is available, even if this information is incomplete. The method consists of three components. The first is a particularly suitable mathematical modeling framework, namely Biochemical Systems Theory, in which parameters are direct indicators of the organization of the underlying phenomenon, the second is the training of an artificial neural network for data smoothing and complementation, and the third is a technique for reinterpreting differential equations in a fashion that facilitates parameter estimation. A prototype webtool for these analyses is available at https://bioinformatics.musc.edu/webmetabol/.",True,text mining,Not specified
15360910,Comparison of machine learning techniques with classical statistical models in predicting health outcomes,"Several machine learning techniques (multilayer and single layer perceptron, logistic regression, least square linear separation and support vector machines) are applied to calculate the risk of death from two biomedical data sets, one from patient care records, and another from a population survey. Each dataset contained multiple sources of information: history of related symptoms and other illnesses, physical examination findings, laboratory tests, medications (patient records dataset), health attitudes, and disabilities in activities of daily living (survey dataset). Each technique showed very good mortality prediction in the acute patients data sample (AUC up to 0.89) and fair prediction accuracy for six year mortality (AUC from 0.70 to 0.76) in individuals from epidemiological database surveys. The results suggest that the nature of data is of primary importance rather than the learning technique. However, the consistently superior performance of the artificial neural network (multi-layer perceptron) indicates that nonlinear relationships (which cannot be discerned by linear separation techniques) can provide additional improvement in correctly predicting health outcomes.",True,other,Not specified
15126220,Dental data mining: potential pitfalls and practical issues,"Knowledge Discovery and Data Mining (KDD) have become popular buzzwords. But what exactly is data mining? What are its strengths and limitations? Classic regression, artificial neural network (ANN), and classification and regression tree (CART) models are common KDD tools. Some recent reports (e.g., Kattan et al., 1998) show that ANN and CART models can perform better than classic regression models: CART models excel at covariate interactions, while ANN models excel at nonlinear covariates. Model prediction performance is examined with the use of validation procedures and evaluating concordance, sensitivity, specificity, and likelihood ratio. To aid interpretation, various plots of predicted probabilities are utilized, such as lift charts, receiver operating characteristic curves, and cumulative captured-response plots. A dental caries study is used as an illustrative example. This paper compares the performance of logistic regression with KDD methods of CART and ANN in analyzing data from the Rochester caries study. With careful analysis, such as validation with sufficient sample size and the use of proper competitors, problems of naïve KDD analyses (Schwarzer et al., 2000) can be carefully avoided.",True,text mining,recurrent neural network
14975135,Risk factors for coronary artery disease and the use of neural networks to predict the presence or absence of high blood pressure,"BACKGROUND: The Framingham Heart Study was initiated in 1948 as a long-term longitudinal study to identify risk factors associated with cardiovascular disease (CVD). Over the years the scope of the study has expanded to include offspring and other family members of the original cohort, marker data useful for gene mapping and information on other diseases. As a result, it is a rich resource for many areas of research going beyond the original goals. As part of the Genetic Analysis Workshop 13, we used data from the study to evaluate the ability of neural networks to use CVD risk factors as training data for predictions of normal and high blood pressure.
RESULTS: Applying two different strategies to the coding of CVD risk data as risk factors (one longitudinal and one independent of time), we found that neural networks could not be trained to clearly separate individuals into normal and high blood pressure groups. When training was successful, validation was not, suggesting over-fitting of the model. When the number of parameters was reduced, training was not as good. An analysis of the input data showed that the neural networks were, in fact, finding consistent patterns, but that these patterns were not correlated with the presence or absence of high blood pressure.
CONCLUSION: Neural network analysis, applied to risk factors for CVD in the Framingham data, did not lead to a clear classification of individuals into groups with normal and high blood pressure. Thus, although high blood pressure may itself be a risk factor for CVD, it does not appear to be clearly predictable using observations from a set of other CVD risk factors.",True,other,RNN
14687512,[Study on the application of artificial neural network on diabetes mellitus/insulin-glucose tolerance classification],"OBJECTIVE: To discuss the potential application of artificial neural network (ANN) on the epidemiological classification of disease.
METHODS: Learning vector quantification neural network (LVQNN) and discriminate analysis were applied to data from epidemiological survey in a mine in 1996.
RESULTS: The structure of LVQNN was 25-->13-->3. The total veracity rates was 96.98%, and 92.45% among the abnormal blood glucose individuals. Through stepwise discriminate analysis, the discriminate equations were established including 11 variables with a total veracity rate of 87.34%, but was 85.53% in the abnormal blood glucose individuals. Further analysis on 30 cases with missing values showed that the disagreement ratio of LVQ was 1/30, lower than that of discriminate analysis of 7/30.
CONCLUSIONS: Compared to the conventional statistics method, LVQ not only showed better prediction precision, but could treat data with missing values satisfactorily plus it had no limit to the type or distribution of relevant data, thus provided a new powerful method to epidemiologic prediction.",True,other,recurrent neural network
12934180,Enhanced prediction of lopinavir resistance from genotype by use of artificial neural networks,"Our objective was to accurately predict, from complex mutation patterns, human immunodeficiency virus type 1 resistance to the protease inhibitor lopinavir, by use of artificial intelligence. Two neural network models were constructed: 1 based on changes at 11 positions in the protease that were previously recognized as being significant for lopinavir resistance and another based on a newly derived set of 28 mutations that were identified by performing category prevalence analysis. Both models were trained, validated, and tested with 1322 clinical samples. A procedure of determining the optimal neural network parameters was proposed to speed up the training processes. The results suggested that the 28-mutation set was a more accurate predictor of lopinavir susceptibility (correlation coefficient, R2=0.88). We identified potentially significant new mutations associated with lopinavir resistance and demonstrated the utility of neural network models in predicting phenotypic susceptibility from complex genotypes.",True,other,recurrent neural network
12911662,Predicting mortality in patients with cirrhosis of liver with application of neural network technology,"BACKGROUND: Prediction of mortality from cirrhosis is important in planning optimal timing of liver transplantation and other interventions. We evaluated the role of the Artificial Neural Network (ANN), which uses non-linear statistics for pattern recognition in predicting one-year liver disease-related mortality using information available during initial clinical evaluation.
METHODS: The ANN was constructed using software with data from a training set (n = 46) selected at random from a cohort of adult cirrhotics (n = 92). After training, validation was performed in the remaining patients (n = 46) whose outcome in terms of one-year mortality was unknown to the network. The performance of ANN was compared to those of a logistic regression model (LRM) and Child-Pugh's score (CPS). Death (related to cirrhosis/its complications) within one year of inclusion was the outcome variable. The ANN was also tested in an external validation sample (EVS, n = 62) from another hospital.
RESULTS: Patients in the EVS were younger (mean age, 41 vs 45 years), infrequently of alcoholic etiology (5% vs 49%), had less severe disease (mean CPS 6.6 vs 10.8), and had lower one-year mortality (13 vs 46%). In the internal validation sample, ANN's accuracy was 91%, sensitivity 90% and specificity 92% in prediction of one-year mortality; area under the receiver-operating characteristic (ROC) curve was 0.94. The performance of the LRM (accuracy 74%) and the CPS (accuracy 55%) was significantly worse than ANN (P < 0.05, McNemar's test). Despite differences in the characteristics of the two groups, the ANN performed fairly well in the EVS (accuracy of 90%, area under curve 0.85).
CONCLUSIONS: ANN can accurately predict one-year mortality in cirrhosis and is superior to CPS and LRM.",True,computer vision,Not specified
12131528,Microalbuminuria identifies overall cardiovascular risk in essential hypertension: an artificial neural network-based approach,"BACKGROUND: Ultrasound (US) examination of heart and carotid arteries provides an accurate assessment of target organ damage (TOD) and may influence the stratification of the absolute cardiovascular risk profile. Microalbuminuria has recently proved to be a useful cost-effective marker of increased cardiovascular risk but is still too often neglected in clinical practice.
OBJECTIVE: To evaluate how well artificial neural networks (ANNs) predict cardiovascular risk stratification by means of routine data and urinary albumin excretion, as compared to prediction by the clinical work-up suggested by the International Society of Hypertension (ISH), with and without ultrasound-determined TOD.
METHODS: A group of 346 never previously treated essential hypertensives (212 men, 134 women, mean age 47 +/- 9 years) was studied. Risk was stratified according to the criteria suggested by the 1999 WHO/ISH guidelines; first, by routine procedures alone, and subsequently by reassessment, using data on cardiac and vascular structures obtained by US evaluation. The ANN was trained and tested to predict the overall cardiovascular risk on the basis of routine clinical data and urinary albumin excretion (UAE). The impact of these three approaches on the determination of cardiovascular risk profile was evaluated.
RESULTS: According to the first classification, 5.5% (n = 19) of patients were considered at low risk, 47.3% (n = 164) at medium, 26.7% (n = 92) at high and 20.6% (n = 71) at very high risk. A marked change in risk stratification, namely an increase in the prevalence of high- and very-high-risk patients (2.3% low, 29.8% medium, 42.8% high and 25.2% very high risk; chi(2) 15.201, P < 0.0001), was obtained when US examination of TOD was taken into consideration. On the basis of routine clinical data and UAE, the artificial neural network successfully predicted overall cardiovascular risk and allocated patients in different classes as accurately as the US-based evaluation.
CONCLUSIONS: The use of US techniques allows a more precise stratification of absolute cardiovascular risk in hypertensive patients as compared to routine clinical data. An ANN can accurately identify the patients' risk status by using low-cost routine data and UAE. These results further emphasize the value of UAE in the stratification of cardiovascular risk.",True,other,RNN
11942655,Outcome analysis of patients with acute pancreatitis by using an artificial neural network,"RATIONALE AND OBJECTIVES: The authors performed this study to evaluate the ability of an artificial neural network (ANN) that uses radiologic and laboratory data to predict the outcome in patients with acute pancreatitis.
MATERIALS AND METHODS: An ANN was constructed with data from 92 patients with acute pancreatitis who underwent computed tomography (CT). Input nodes included clinical, laboratory, and CT data. The ANN was trained and tested by using a round-robin technique, and the performance of the ANN was compared with that of linear discriminant analysis and Ranson and Balthazar grading systems by using receiver operating characteristic analysis. The length of hospital stay was used as an outcome measure.
RESULTS: Hospital stay ranged from 0 to 45 days, with a mean of 8.4 days. The hospital stay was shorter than the mean for 62 patients and longer than the mean for 30. The 23 input features were reduced by using stepwise linear discriminant analysis, and an ANN was developed with the six most statistically significant parameters (blood pressure, extent of inflammation, fluid aspiration, serum creatinine level, serum calcium level, and the presence of concurrent severe illness). With these features, the ANN successfully predicted whether the patient would exceed the mean length of stay (Az = 0.83 +/- 0.05). Although the Az performance of the ANN was statistically significantly better than that of the Ranson (Az = 0.68 +/- 0.06, P < .02) and Balthazar (Az = 0.62 +/- 0.06, P < .003) grades, it was not significantly better than that of linear discriminant analysis (Az = 0.82 +/- 0.05, P = .53).
CONCLUSION: An ANN may be useful for predicting outcome in patients with acute pancreatitis.",True,computer vision,LSTM
11849962,Predictive non-linear modeling of complex data by artificial neural networks,An artificial neural network (ANN) is an artificial intelligence tool that identifies arbitrary nonlinear multiparametric discriminant functions directly from experimental data. The use of ANNs has gained increasing popularity for applications where a mechanistic description of the dependency between dependent and independent variables is either unknown or very complex. This machine learning technique can be roughly described as a universal algebraic function that will distinguish signal from noise directly from experimental data. The application of ANNs to complex relationships makes them highly attractive for the study of biological systems. Recent applications include the analysis of expression profiles and genomic and proteomic sequences.,True,other,recurrent neural network
11833478,Neural networks in the assessment of HIV immunopathology,"Surrogate markers are by definition quantifiable laboratory variables that have clinical and biological relevance to disease outcomes. Virologic and immunologic surrogate markers have proven useful in following HIV-associated viral burden, immune dysregulation, dysfunction and deficiency. Monitoring of sequential changes in these markers and their interrelationships may provide significant information about viral-host-drug dynamics. The complexity and fluidity of these changes necessitates that an efficient means be developed for their monitoring. We therefore generated a neural network-based model for assessing host dynamics over time and compared its performance with that of a multiple regression model. Both modeling approaches were applied to the actual, non-filtered, clinical observations on 58 HIV-infected individuals treated consistently with Highly Active Anti-Retroviral Therapy (HAART), for a period of over-52 weeks resulting in an average of 16 observations per patient throughout this time span. Results demonstrated that the neural network was at least as accurate as a multi-regression model. Since our dataset was modest in size we also believe that neural networks warrant further consideration for modeling the complexity of HIV-host dynamics on larger datasets.",True,both,recurrent neural network
11261552,Minimal number of chicken daily growth velocities for artificial neural network detection of pulmonary hypertension syndrome (PHS),"Previously, evaluation of the first 2 wk of daily growth velocity with an artificial neural network (ANN) provided an effective noninvasive approach for predicting the susceptibility of broilers to pulmonary hypertension syndrome (PHS). This study was conducted to define the minimum number of days of growth data and the type of ANN required for the best prediction of PHS susceptibility. Four experiments were conducted in which broilers were weighed daily at 0800 h. In Experiment 1, Hubbard male broilers were reared to 50 d of age, with 13 developing PHS and 33 remaining normal (N), for a PHS:N ratio of 13:33. In Experiment 2, ANAK broilers were exposed to cool temperatures (16 to 17 C) from 17 to 42 d of age, resulting in a PHS:N ratio of 16:46 for males. In Experiments 3 and 4, Hubbard male and female chicks from a base population and a PHS-resistant line were exposed to cool temperatures from 17 to 42 d (Experiment 3) or 49 d of age (Experiment 4). The PHS:N ratios were 40:68 for males and 6:96 for females in Experiment 3 and 26:91 for males and 10:58 for females in Experiment 4. Four ANN, back propagation (BP3), Ward back propagation (WardBP), probabilistic (PNN), and general regression (GRNN), were evaluated for their ability to predict PHS in the shortest number of days based on daily growth velocities (BWd+1-BWd). A 100% prediction of PHS and N birds was considered the criterion of success. Starting with 14 d of data, each ANN was trained on daily growth velocity, and the number of predictive days was reduced with each run of the ANN. The best ANN was a GRNN, which correctly diagnosed PHS and N male broilers on 4 and 6 d of growth velocity data for Experiments 1 and 2, respectively. The results were poorer with the BP3, WardBP, and PNN. The diagnostic ability of the neural network was not consistent over all four experiments. In Experiment 2, a minimum of 6 d was required for 100% PHS detection for males. In Experiment 3, the best diagnostic value for males was 93% PHS detection and 100% N detection at 15 d. For females, the 100% PHS detection occurred at a minimum of 8 d. In Experiment 4, males had 100% PHS and N detection at a minimum of 11 d. Females had a 100% PHS and N detection at a minimum of 10 d. An attempt to build a single neural network that would detect PHS susceptibility in Hubbard (Experiment 1) and ANAK (Experiment 2) broilers was unsuccessful. The application (validation) of neural networks between experiments also was not successful (data not presented). However, these studies demonstrate that within a breed or line reared under similar selection pressures for ascites, a GRNN based on the first 14 d of growth velocity can detect, with at least 93% accuracy, broilers susceptible to PHS.",True,text mining,Not specified
11242311,Application of an artificial neural network,,True,other,GAN
10752362,Applying artificial neural network models to clinical decision making,"Because psychological assessment typically lacks biological gold standards, it traditionally has relied on clinicians' expert knowledge. A more empirically based approach frequently has applied linear models to data to derive meaningful constructs and appropriate measures. Statistical inferences are then used to assess the generality of the findings. This article introduces artificial neural networks (ANNs), flexible nonlinear modeling techniques that test a model's generality by applying its estimates against ""future"" data. ANNs have potential for overcoming some shortcomings of linear models. The basics of ANNs and their applications to psychological assessment are reviewed. Two examples of clinical decision making are described in which an ANN is compared with linear models, and the complexity of the network performance is examined. Issues salient to psychological assessment are addressed.",True,other,Not specified
10531161,Predicting active pulmonary tuberculosis using an artificial neural network,"BACKGROUND: Nosocomial outbreaks of tuberculosis (TB) have been attributed to unrecognized pulmonary TB. Accurate assessment in identifying index cases of active TB is essential in preventing transmission of the disease.
OBJECTIVES: To develop an artificial neural network using clinical and radiographic information to predict active pulmonary TB at the time of presentation at a health-care facility that is superior to physicians' opinion.
DESIGN: Nonconcurrent prospective study.
SETTING: University-affiliated hospital.
PARTICIPANTS: A derivation group of 563 isolation episodes and a validation group of 119 isolation episodes.
INTERVENTIONS: A general regression neural network (GRNN) was used to develop the predictive model.
MEASUREMENTS: Predictive accuracy of the neural network compared with clinicians' assessment.
RESULTS: Predictive accuracy was assessed by the c-index, which is equivalent to the area under the receiver operating characteristic curve. The GRNN significantly outperformed the physicians' prediction, with calculated c-indices (+/- SEM) of 0.947 +/- 0.028 and 0.61 +/- 0.045, respectively (p < 0.001). When the GRNN was applied to the validation group, the corresponding c-indices were 0. 923 +/- 0.056 and 0.716 +/- 0.095, respectively.
CONCLUSION: An artificial neural network can identify patients with active pulmonary TB more accurately than physicians' clinical assessment.",True,other,RNN
10430425,Artificial neural networks improve the prediction of mortality in intracerebral hemorrhage,"BACKGROUND: Artificial neural network (ANN) analysis methods have led to more sensitive diagnosis of myocardial infarction and improved prediction of mortality in breast cancer, prostate cancer, and trauma patients. Prognostic studies have identified early clinical and radiographic predictors of mortality after intracerebral hemorrhage (ICH). To date, published models have not achieved the accuracy necessary for use in making decisions to limit medical interventions. We recently reported a logistic regression model that correctly classified 79% of patients who died and 90% of patients who survived. In an attempt to improve prediction of mortality we computed an ANN model with the same data.
OBJECTIVE: To determine whether an ANN analysis would provide a more accurate prediction of mortality after ICH when compared with multiple logistic regression models computed using the same data.
METHODS: Analyses were conducted on data collected prospectively on 81 patients with supratentorial ICH. Multiple logistic regression was used to predict hospital mortality, then an ANN analysis was applied to the same data set. Input variables were age, gender, race, hydrocephalus, mean arterial pressure, pulse pressure, Glasgow Coma Scale score, intraventricular hemorrhage, hydrocephalus, hematoma size, hematoma location (ganglionic, thalamic, or lobar), cisternal effacement, pineal shift, history of hypertension, history of diabetes, and age.
RESULTS: The ANN model correctly classified all patients (100%) as alive or dead compared with 85% correct classification for the logistic regression model. A second ANN verification model was equally accurate. The ANN was superior to the logistic regression model on all objective measures of fit.
CONCLUSIONS: ANN analysis more effectively uses information for prediction of mortality in this sample of patients with ICH. A well-validated ANN may have a role in the clinical management of ICH.",True,both,Not specified
9751012,Prediction of cirrhosis in patients with chronic hepatitis C infection by artificial neural network analysis of virus and clinical factors,"The diagnosis of cirrhosis in patients with hepatitis C virus (HCV) infection is currently made using a liver biopsy. In this study we have trained and validated artificial neural networks (ANN) with routine clinical host and viral parameters to predict the presence or absence of cirrhosis in patients with chronic HCV infection and assessed and interpreted the role of the different inputs on the ANN classification. Fifteen routine clinical and virological factors were collated from 112 patients who were HCV RNA positive by reverse transcriptase-polymerase chain reaction (RT-PCR). Standard and Ward-type feed-forward fully-connected ANN analyses were carried out both by training the networks with data from 82 patients and subsequently testing with data from 30 patients plus performing leave-one-out tests for the whole patient data set. The ANN results were also compared with those from multiple logistic regression. The performance of both ANN methods was superior compared with the logistic regression. The best performance was obtained with the Ward-type ANNs resulting in a sensitivity of 92% and a specificity of 98.9% together with a predictive value of a positive test of 95% and a predictive value of a negative test of 97% in the leave-one-out test. Hence, further validation of the ANN analysis is likely to provide a non-invasive test for diagnosing cirrhosis in HCV-infected patients.",True,other,Not specified
9566456,Predicting mortality after coronary artery bypass surgery: what do artificial neural networks learn? The Steering Committee of the Cardiac Care Network of Ontario,"OBJECTIVE: To compare the abilities of artificial neural network and logistic regression models to predict the risk of in-hospital mortality after coronary artery bypass graft (CABG) surgery.
METHODS: Neural network and logistic regression models were developed using a training set of 4,782 patients undergoing CABG surgery in Ontario, Canada, in 1991, and they were validated in two test sets of 5,309 and 5,517 patients having CABG surgery in 1992 and 1993, respectively.
RESULTS: The probabilities predicted from a fully trained neural network were similar to those of a ""saturated"" regression model, with both models detecting all possible interactions in the training set and validating poorly in the two test sets. A second neural network was developed by cross-validating a network against a new set of data and terminating network training early to create a more generalizable model. A simple ""main effects"" regression model without any interaction terms was also developed. Both of these models validated well, with areas under the receiver operating characteristic curves of 0.78 and 0.77 (p > 0.10) in the 1993 test set. The predictions from the two models were very highly correlated (r=0.95).
CONCLUSIONS: Artificial neural networks and logistic regression models learn similar relationships between patient characteristics and mortality after CABG surgery.",True,other,recurrent neural network
9355144,Probabilistic neural network prediction of ascites in broilers based on minimally invasive physiological factors,"A Probabilistic Neural Network (PNN) was trained to predict ascites in broilers based on minimally invasive inputs (i.e., physiological factors that do not require the death of the bird). A PNN is a supervised, three-layer, artificial neural network that classifies input patterns (e.g., physiological data) into specific output categories (e.g., ascites or no ascites). The PNN inputs were O2 level in the blood, body weight, electrocardiogram (ECG), hematocrit, S wave, and heart rate of individual birds. These data were from three experiments that have been described previously (Roush et al., 1996a,b). The three data sets were pooled into a combined data set for a total of 170 observations. From the pooled data, a training set (117 birds), a calibration set (17 birds), and a verification set (36 birds) were extracted. The PNN was trained on the training data set. To prevent the PNN from overfitting the training data, the neural network was evaluated on its ability to make correct predictions of the calibration data set. At the point at which the neural network made the highest number of correct classifications for the calibration data set, the trained neural network was saved on the computer. When the PNN was applied to the complete data set, the sensitivity or proportion of the birds with ascites that the PNN correctly diagnosed was 0.97 (75/77 birds). The specificity or proportion of birds that the PNN made a correct diagnosis of not having ascites was 0.98 (91/93 birds). When the PNN was applied to the verification data set, which was not subjected to neural network training, the sensitivity was 0.95 (19/20) and the specificity was 0.88 (14/16 birds). Use of models developed with artificial neural networks may enhance the diagnosis of ascites in broilers. The results may be useful in choosing and developing broiler strains that do not have a propensity for ascites.",True,other,recurrent neural network
9274582,Artificial neural networks applied to outcome prediction for colorectal cancer patients in separate institutions,"BACKGROUND: Artificial neural networks are computer programs that can be used to discover complex relations within data sets. They permit the recognition of patterns in complex biological data sets that cannot be detected with conventional linear statistical analysis. One such complex problem is the prediction of outcome for individual patients treated for colorectal cancer. Predictions of outcome in such patients have traditionally been based on population statistics. However, these predictions have little meaning for the individual patient. We report the training of neural networks to predict outcome for individual patients from one institution and their predictive performance on data from a different institution in another region.
METHODS: 5-year follow-up data from 334 patients treated for colorectal cancer were used to train and validate six neural networks designed for the prediction of death within 9, 12, 15, 18, 21, and 24 months. The previously trained 12-month neural network was then applied to 2-year follow-up data from patients from a second institution; outcome was concealed. No further training of the neural network was undertaken. The network's predictions were compared with those of two consultant colorectal surgeons supplied with the same data.
FINDINGS: All six neural networks were able to achieve overall accuracy greater than 80% for the prediction of death for individual patients at institution 1 within 9, 12, 15, 18, 21, and 24 months. The mean sensitivity and specificity were 60% and 88%. When the neural network trained to predict death within 12 months was applied to data from the second institution, overall accuracy of 90% (95% CI 84-96) was achieved, compared with the overall accuracy of the colorectal surgeons of 79% (71-87) and 75% (66-84).
INTERPRETATION: The neural networks were able to predict outcome for individual patients with colorectal cancer much more accurately than the currently available clinicopathological methods. Once trained on data from one institution, the neural networks were able to predict outcome for patients from an unrelated institution.",True,other,recurrent neural network
9205161,Coronary artery bypass risk prediction using neural networks,"BACKGROUND: Neural networks are nonparametric, robust, pattern recognition techniques that can be used to model complex relationships.
METHODS: The applicability of multilayer perceptron neural networks (MLP) to coronary artery bypass grafting risk prediction was assessed using The Society of Thoracic Surgeons database of 80,606 patients who underwent coronary artery bypass grafting in 1993. The results of traditional logistic regression and Bayesian analysis were compared with single-layer (no hidden layer), two-layer (one hidden layer), and three-layer (two hidden layer) MLP neural networks. These networks were trained using stochastic gradient descent with early stopping. All prediction models used the same variables and were evaluated by training on 40,480 patients and cross-validation testing on a separate group of 40,126 patients. Techniques were also developed to calculate effective odds ratios for MLP networks and to generate confidence intervals for MLP risk predictions using an auxiliary ""confidence MLP.""
RESULTS: Receiver operating characteristic curve areas for predicting mortality were approximately 76% for all classifiers, including neural networks. Calibration (accuracy of posterior probability prediction) was slightly better with a two-member committee classifier that averaged the outputs of a MLP network and a logistic regression model. Unlike the individual methods, the committee classifier did not overestimate or underestimate risk for high-risk patients.
CONCLUSIONS: A committee classifier combining the best neural network and logistic regression provided the best model calibration, but the receiver operating characteristic curve area was only 76% irrespective of which predictive model was used.",True,other,recurrent neural network
9000270,Artificial neural network prediction of ascites in broilers,"An artificial neural network was trained to predict the presence or absence of ascites in broiler chickens. The neural network was a three-layer back-propagation neural network with an input layer of 15 neurons (defining 15 physiological variables), a hidden layer of 16 neurons, and an output layer of 2 neurons (the presence or absence of ascites). Male by-products of a breeder pullet line were brooded at 32 and 30 C during Weeks 1 and 2, respectively. The training set for the neural network consisted of data from birds subjected to cool temperatures (18 C) to induce ascites. After training, the predictive ability of the neural network was verified with two new data sets. The second data set was from birds subjected to cool temperatures (18 C). The third data set was from birds subjected to clamping of the pulmonary artery to simulate the physiological processes involved in ascites (the temperature was 24 C). A comparison was made between laboratory diagnostic results and the neural network predicted ascites incidence. The neural network accurately identified the presence or absence of ascites in the first (training) set. Two false positives and one false positive were identified in the second and third verification sets, respectively. The birds identified as false positives were determined to be in the developmental stages of ascites before the occurrence of fluid accumulation. Artificial neural networks were found to effectively identify broilers with and without ascites.",True,other,recurrent neural network
8609749,Prediction of outcome in critically ill patients using artificial neural network synthesised by genetic algorithm,"BACKGROUND: Decisions about which patients to admit to intensive care and how long to keep them there are difficult. A flexible computer-based mathematical model which is sensitive to the complexity of intensive care medicine, and which accurately models prognosis, seems highly desirable.
METHODS: We have created, optimised by genetic algorithms, trained, and evaluated the performance of an artificial neural network (ANN) in the clinical setting of systemic inflammatory response syndrome and haemodynamic shock. 258 patients were selected from an intensive care database of 4484 patients at a London teaching hospital and randomised to a network training set (168) and a test set (90). The outcome evaluated was death during that hospital admission and the performance of the neural net was compared (by receiver operating characteristic [ROC] curves and by Brier scores) with that of a logistic regression model.
FINDINGS: Artificial neural network performance increased with successive generations; the best-performing ANN was created after 7 generations and predicted outcome more accurately than the logistic regression model (ROC curve area 0.863 vs 0.753).
INTERPRETATION: In this study, ANNs have lent themselves particularly well to modelling a complex clinical situation; we suggest that this relates to their inherently flexible nature which accommodates interactions between the clinical input fields. In addition, we have demonstrated the value of a second computational technique (genetic algorithms) in ""tuning"" ANN performance. These techniques can potentially be implemented in individual intensive care units; the outcome models which they will generate will be sensitive to local practice. Analysis of such accurate clinical outcome models may empower clinicians with a hitherto unappreciated degree of insight into those elements of their clinical practice which are most relevant to their patients' outcome.",True,computer vision,RNN
7862997,Artificial neural network for diagnosis of acute pulmonary embolism: effect of case and observer selection,"PURPOSE: To compare the diagnostic performance of an artificial neural network (ANN) with that of physicians in patients with suspected pulmonary embolism (PE).
MATERIALS AND METHODS: An ANN was developed to predict PE by using findings from ventilation-perfusion lung scans and chest radiographs. First, the network was evaluated on 1,064 cases from the Prospective Investigation of Pulmonary Embolism Diagnosis (PIOPED) study that had a definitive angiographic outcome. An upper and lower bound of its diagnostic performance was provided depending on case difficulty. Then, the network was tested on 104 patients with suspected PE in whom pulmonary angiography was essential for diagnosis. The diagnostic performance of the ANN was compared with that of (a) two nuclear medicine physicians who read the scans for the needs of this study and (b) the nuclear medicine physicians who originally read the scans. The effects of case and observer selection on performance were addressed.
RESULTS: The ANN outperformed the physicians when they used the PIOPED criteria for categoric assessment, and it performed as well as the two study physicians on the basis of their probability assessments.
CONCLUSION: The ANN can detect or exclude PE in a highly selected group of difficult cases with a consistency equivalent to that of very experienced physicians.",True,other,RNN
7937158,Back-propagation and counter-propagation neural networks for phylogenetic classification of ribosomal RNA sequences,"A neural network system has been developed for rapid and accurate classification of ribosomal RNA sequences according to phylogenetic relationship. The molecular sequences are encoded into neural input vectors using an n-gram hashing method. A SVD (singular value decomposition) method is used to compress and reduce the size of long and sparse n-gram input vectors. The neural networks used are three-layered, feed-forward networks that employ supervised learning paradigms, including the back-propagation algorithm and a modified counter-propagation algorithm. A pedagogical pattern selection strategy is used to reduce the training time. After trained with ribosomal RNA sequences of the RDP (Ribosomal Database Project) database, the system can classify query sequences into more than one hundred phylogenetic classes with a 100% accuracy at a rate of less than 0.3 CPU second per sequence on a workstation. When compared to other sequence similarity search methods, including Similarity Rank, Blast and Fasta, the neural network method has a higher classification accuracy at a speed of about an order of magnitude faster. The software tool will be made available to the biology community, and the system may be extended into a gene identification system for classifying indiscriminately sequenced DNA fragments.",True,other,convolutional neural network
8269158,Prediction of valve-related complications for artificial heart valves using adaptive neural networks: a preliminary study,"A novel approach to the prediction of valve-related complications in patients with implanted artificial heart valves is discussed. Adaptive artificial neural networks were used to identify patients at high risk of valve-related events based on preoperative data. Data from a clinical trial on 789 subjects with Carpentier-Edwards pericardial bioprostheses were used. Patients' records were divided into two groups, one of which was used for training the neural network and the other for testing the trained network and determining error rates. Patient information such as age, sex, NYHA class and anticoagulation therapy, as well as valve information such as size and the date of implant, were used as the network inputs. The neural net had a single output variable indicating the risk that an individual patient would develop a valve-related complication resulting in death. The results show that a trained neural network was able to predict valve-related deaths in the specified time interval of 1981-1991 with a high degree of accuracy. The neural network was also successful in classifying patients into high and low risk categories.",True,other,recurrent neural network
39008489,Modeling epidemic dynamics using Graph Attention based Spatial Temporal networks,"The COVID-19 pandemic and influenza outbreaks have underscored the critical need for predictive models that can effectively integrate spatial and temporal dynamics to enable accurate epidemic forecasting. Traditional time-series analysis approaches have fallen short in capturing the intricate interplay between these factors. Recent advancements have witnessed the incorporation of graph neural networks and machine learning techniques to bridge this gap, enhancing predictive accuracy and providing novel insights into disease spread mechanisms. Notable endeavors include leveraging human mobility data, employing transfer learning, and integrating advanced models such as Transformers and Graph Convolutional Networks (GCNs) to improve forecasting performance across diverse geographies for both influenza and COVID-19. However, these models often face challenges related to data quality, model transferability, and potential overfitting, highlighting the necessity for more adaptable and robust approaches. This paper introduces the Graph Attention-based Spatial Temporal (GAST) model, which employs graph attention networks (GATs) to overcome these limitations by providing a nuanced understanding of epidemic dynamics through a sophisticated spatio-temporal analysis framework. Our contributions include the development and validation of the GAST model, demonstrating its superior forecasting capabilities for influenza and COVID-19 spread, with a particular focus on short-term, daily predictions. The model's application to both influenza and COVID-19 datasets showcases its versatility and potential to inform public health interventions across a range of infectious diseases.",True,other,recurrent neural network
38263181,Efficacy of MRI data harmonization in the age of machine learning: a multicenter study across 36 datasets,"Pooling publicly-available MRI data from multiple sites allows to assemble extensive groups of subjects, increase statistical power, and promote data reuse with machine learning techniques. The harmonization of multicenter data is necessary to reduce the confounding effect associated with non-biological sources of variability in the data. However, when applied to the entire dataset before machine learning, the harmonization leads to data leakage, because information outside the training set may affect model building, and potentially falsely overestimate performance. We propose a 1) measurement of the efficacy of data harmonization; 2) harmonizer transformer, i.e., an implementation of the ComBat harmonization allowing its encapsulation among the preprocessing steps of a machine learning pipeline, avoiding data leakage by design. We tested these tools using brain T<sub>1</sub>-weighted MRI data from 1740 healthy subjects acquired at 36 sites. After harmonization, the site effect was removed or reduced, and we showed the data leakage effect in predicting individual age from MRI data, highlighting that introducing the harmonizer transformer into a machine learning pipeline allows for avoiding data leakage by design.",True,other,convolutional neural network
36426767,LitCovid ensemble learning for COVID-19 multi-label classification,"The Coronavirus Disease 2019 (COVID-19) pandemic has shifted the focus of research worldwide, and more than 10 000 new articles per month have concentrated on COVID-19-related topics. Considering this rapidly growing literature, the efficient and precise extraction of the main topics of COVID-19-relevant articles is of great importance. The manual curation of this information for biomedical literature is labor-intensive and time-consuming, and as such the procedure is insufficient and difficult to maintain. In response to these complications, the BioCreative VII community has proposed a challenging task, LitCovid Track, calling for a global effort to automatically extract semantic topics for COVID-19 literature. This article describes our work on the BioCreative VII LitCovid Track. We proposed the LitCovid Ensemble Learning (LCEL) method for the tasks and integrated multiple biomedical pretrained models to address the COVID-19 multi-label classification problem. Specifically, seven different transformer-based pretrained models were ensembled for the initialization and fine-tuning processes independently. To enhance the representation abilities of the deep neural models, diverse additional biomedical knowledge was utilized to facilitate the fruitfulness of the semantic expressions. Simple yet effective data augmentation was also leveraged to address the learning deficiency during the training phase. In addition, given the imbalanced label distribution of the challenging task, a novel asymmetric loss function was applied to the LCEL model, which explicitly adjusted the negative-positive importance by assigning different exponential decay factors and helped the model focus on the positive samples. After the training phase, an ensemble bagging strategy was adopted to merge the outputs from each model for final predictions. The experimental results show the effectiveness of our proposed approach, as LCEL obtains the state-of-the-art performance on the LitCovid dataset. Database URL: https://github.com/JHnlp/LCEL.",True,other,Not specified
